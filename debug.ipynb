{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpaint_pixel_image = torch.load(\"/home/longc/data/code/Fooocus/inpaint_pixel_image.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpaint_pixel_mask = torch.load(\"/home/longc/data/code/Fooocus/inpaint_pixel_mask.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inpaint = torch.load(\"/home/longc/data/code/Fooocus/latent_inpaint.pth\")\n",
    "latent_mask = torch.load(\"/home/longc/data/code/Fooocus/latent_mask.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 21.9999,  19.1250,  17.7500,  ...,  19.5000,  17.7500,  20.3750],\n",
       "         [ 19.5000,  16.5000,  16.0000,  ...,  17.6250,  16.6250,  16.7500],\n",
       "         [ 18.2500,  17.3750,  17.8750,  ...,  17.0000,  15.6250,  19.0000],\n",
       "         ...,\n",
       "         [ 17.7500,  19.3750,  16.6250,  ...,  19.1250,  16.5000,  19.1250],\n",
       "         [ 15.5000,  16.6250,  17.2500,  ...,  17.5000,  18.0000,  19.5000],\n",
       "         [ 19.7501,  19.6250,  19.3750,  ...,  19.7499,  19.6249,  18.6250]],\n",
       "\n",
       "        [[ -0.2325,  -2.7656,  -2.7031,  ...,  -1.4922,  -1.7266,   3.4532],\n",
       "         [  0.5859,   0.8359,   0.0630,  ...,   1.8125,   1.6484,   2.9687],\n",
       "         [  0.5039,   1.3203,   0.2168,  ...,  -0.3535,   1.2109,   5.3126],\n",
       "         ...,\n",
       "         [ -0.0337,   4.2500,   0.0649,  ...,   3.3906,   1.5703,   5.4063],\n",
       "         [ -3.0000,  -0.4980,   2.4219,  ...,   1.3828,   4.5938,   3.8438],\n",
       "         [  4.2812,   4.3125,   4.0625,  ...,   4.9687,   3.3907,   4.1250]],\n",
       "\n",
       "        [[  7.2813,  -0.7188,   2.2812,  ...,  -1.0781,   2.8438,   7.5315],\n",
       "         [  5.2500,   4.0000,   3.9844,  ...,   8.0000,   7.8750,   0.5312],\n",
       "         [  9.5000,   8.4375,   8.2500,  ...,   8.4375,   3.7500,   7.6875],\n",
       "         ...,\n",
       "         [  9.0625,   6.5000,   7.7500,  ...,   6.0000,   0.1465,   7.6561],\n",
       "         [  2.0781,   3.5156,   7.9375,  ...,   0.0859,   2.5625,   7.9372],\n",
       "         [  5.7186,   5.2813,   5.5312,  ...,   5.3750,   5.2187,   6.0624]],\n",
       "\n",
       "        [[ -1.7344,  -4.4688,  -8.8125,  ...,  -4.5625,  -8.5625,  -3.9060],\n",
       "         [ -0.2871, -11.6250, -10.3125,  ...,  -8.2500,  -7.9063, -10.9375],\n",
       "         [ -4.5312,  -7.2812,  -7.3750,  ...,  -7.2813, -10.2500,  -6.0000],\n",
       "         ...,\n",
       "         [ -4.6251,  -7.8438,  -7.0938,  ...,  -8.1250,  -6.6875,  -6.5627],\n",
       "         [ -9.4375, -10.3750,  -8.0000,  ...,  -6.8125, -12.1250,  -5.5935],\n",
       "         [ -2.9844,  -5.4062,  -5.2500,  ...,  -5.7498,  -4.7189,  -3.2969]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_inpaint[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 960, 1088])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpaint_pixel_image.permute(0, 3, 1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webui = torch.load(\"/home/longc/data/code/stable-diffusion-webui/webui.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = torch.load(\"/data/SD-models/Lora/inpaint_v26.fooocus.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file, load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorafile = \"/home/longc/data/code/Fooocus/models/inpaint/inpaint_v26.fooocus.patch\"\n",
    "state_dict = torch.load(lorafile, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['diffusion_model.time_embed.0.weight', 'diffusion_model.time_embed.0.bias', 'diffusion_model.time_embed.2.weight', 'diffusion_model.time_embed.2.bias', 'diffusion_model.label_emb.0.0.weight', 'diffusion_model.label_emb.0.0.bias', 'diffusion_model.label_emb.0.2.weight', 'diffusion_model.label_emb.0.2.bias', 'diffusion_model.input_blocks.0.0.weight', 'diffusion_model.input_blocks.0.0.bias', 'diffusion_model.input_blocks.1.0.in_layers.0.weight', 'diffusion_model.input_blocks.1.0.in_layers.0.bias', 'diffusion_model.input_blocks.1.0.in_layers.2.weight', 'diffusion_model.input_blocks.1.0.in_layers.2.bias', 'diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'diffusion_model.input_blocks.1.0.out_layers.0.weight', 'diffusion_model.input_blocks.1.0.out_layers.0.bias', 'diffusion_model.input_blocks.1.0.out_layers.3.weight', 'diffusion_model.input_blocks.1.0.out_layers.3.bias', 'diffusion_model.input_blocks.2.0.in_layers.0.weight', 'diffusion_model.input_blocks.2.0.in_layers.0.bias', 'diffusion_model.input_blocks.2.0.in_layers.2.weight', 'diffusion_model.input_blocks.2.0.in_layers.2.bias', 'diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'diffusion_model.input_blocks.2.0.out_layers.0.weight', 'diffusion_model.input_blocks.2.0.out_layers.0.bias', 'diffusion_model.input_blocks.2.0.out_layers.3.weight', 'diffusion_model.input_blocks.2.0.out_layers.3.bias', 'diffusion_model.input_blocks.3.0.op.weight', 'diffusion_model.input_blocks.3.0.op.bias', 'diffusion_model.input_blocks.4.0.in_layers.0.weight', 'diffusion_model.input_blocks.4.0.in_layers.0.bias', 'diffusion_model.input_blocks.4.0.in_layers.2.weight', 'diffusion_model.input_blocks.4.0.in_layers.2.bias', 'diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'diffusion_model.input_blocks.4.0.out_layers.0.weight', 'diffusion_model.input_blocks.4.0.out_layers.0.bias', 'diffusion_model.input_blocks.4.0.out_layers.3.weight', 'diffusion_model.input_blocks.4.0.out_layers.3.bias', 'diffusion_model.input_blocks.4.0.skip_connection.weight', 'diffusion_model.input_blocks.4.0.skip_connection.bias', 'diffusion_model.input_blocks.4.1.norm.weight', 'diffusion_model.input_blocks.4.1.norm.bias', 'diffusion_model.input_blocks.4.1.proj_in.weight', 'diffusion_model.input_blocks.4.1.proj_in.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.4.1.proj_out.weight', 'diffusion_model.input_blocks.4.1.proj_out.bias', 'diffusion_model.input_blocks.5.0.in_layers.0.weight', 'diffusion_model.input_blocks.5.0.in_layers.0.bias', 'diffusion_model.input_blocks.5.0.in_layers.2.weight', 'diffusion_model.input_blocks.5.0.in_layers.2.bias', 'diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'diffusion_model.input_blocks.5.0.out_layers.0.weight', 'diffusion_model.input_blocks.5.0.out_layers.0.bias', 'diffusion_model.input_blocks.5.0.out_layers.3.weight', 'diffusion_model.input_blocks.5.0.out_layers.3.bias', 'diffusion_model.input_blocks.5.1.norm.weight', 'diffusion_model.input_blocks.5.1.norm.bias', 'diffusion_model.input_blocks.5.1.proj_in.weight', 'diffusion_model.input_blocks.5.1.proj_in.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.5.1.proj_out.weight', 'diffusion_model.input_blocks.5.1.proj_out.bias', 'diffusion_model.input_blocks.6.0.op.weight', 'diffusion_model.input_blocks.6.0.op.bias', 'diffusion_model.input_blocks.7.0.in_layers.0.weight', 'diffusion_model.input_blocks.7.0.in_layers.0.bias', 'diffusion_model.input_blocks.7.0.in_layers.2.weight', 'diffusion_model.input_blocks.7.0.in_layers.2.bias', 'diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'diffusion_model.input_blocks.7.0.out_layers.0.weight', 'diffusion_model.input_blocks.7.0.out_layers.0.bias', 'diffusion_model.input_blocks.7.0.out_layers.3.weight', 'diffusion_model.input_blocks.7.0.out_layers.3.bias', 'diffusion_model.input_blocks.7.0.skip_connection.weight', 'diffusion_model.input_blocks.7.0.skip_connection.bias', 'diffusion_model.input_blocks.7.1.norm.weight', 'diffusion_model.input_blocks.7.1.norm.bias', 'diffusion_model.input_blocks.7.1.proj_in.weight', 'diffusion_model.input_blocks.7.1.proj_in.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm3.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm3.bias', 'diffusion_model.input_blocks.7.1.proj_out.weight', 'diffusion_model.input_blocks.7.1.proj_out.bias', 'diffusion_model.input_blocks.8.0.in_layers.0.weight', 'diffusion_model.input_blocks.8.0.in_layers.0.bias', 'diffusion_model.input_blocks.8.0.in_layers.2.weight', 'diffusion_model.input_blocks.8.0.in_layers.2.bias', 'diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'diffusion_model.input_blocks.8.0.out_layers.0.weight', 'diffusion_model.input_blocks.8.0.out_layers.0.bias', 'diffusion_model.input_blocks.8.0.out_layers.3.weight', 'diffusion_model.input_blocks.8.0.out_layers.3.bias', 'diffusion_model.input_blocks.8.1.norm.weight', 'diffusion_model.input_blocks.8.1.norm.bias', 'diffusion_model.input_blocks.8.1.proj_in.weight', 'diffusion_model.input_blocks.8.1.proj_in.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm3.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm3.bias', 'diffusion_model.input_blocks.8.1.proj_out.weight', 'diffusion_model.input_blocks.8.1.proj_out.bias', 'diffusion_model.middle_block.0.in_layers.0.weight', 'diffusion_model.middle_block.0.in_layers.0.bias', 'diffusion_model.middle_block.0.in_layers.2.weight', 'diffusion_model.middle_block.0.in_layers.2.bias', 'diffusion_model.middle_block.0.emb_layers.1.weight', 'diffusion_model.middle_block.0.emb_layers.1.bias', 'diffusion_model.middle_block.0.out_layers.0.weight', 'diffusion_model.middle_block.0.out_layers.0.bias', 'diffusion_model.middle_block.0.out_layers.3.weight', 'diffusion_model.middle_block.0.out_layers.3.bias', 'diffusion_model.middle_block.1.norm.weight', 'diffusion_model.middle_block.1.norm.bias', 'diffusion_model.middle_block.1.proj_in.weight', 'diffusion_model.middle_block.1.proj_in.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.norm3.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.norm3.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.norm3.bias', 'diffusion_model.middle_block.1.proj_out.weight', 'diffusion_model.middle_block.1.proj_out.bias', 'diffusion_model.middle_block.2.in_layers.0.weight', 'diffusion_model.middle_block.2.in_layers.0.bias', 'diffusion_model.middle_block.2.in_layers.2.weight', 'diffusion_model.middle_block.2.in_layers.2.bias', 'diffusion_model.middle_block.2.emb_layers.1.weight', 'diffusion_model.middle_block.2.emb_layers.1.bias', 'diffusion_model.middle_block.2.out_layers.0.weight', 'diffusion_model.middle_block.2.out_layers.0.bias', 'diffusion_model.middle_block.2.out_layers.3.weight', 'diffusion_model.middle_block.2.out_layers.3.bias', 'diffusion_model.output_blocks.0.0.in_layers.0.weight', 'diffusion_model.output_blocks.0.0.in_layers.0.bias', 'diffusion_model.output_blocks.0.0.in_layers.2.weight', 'diffusion_model.output_blocks.0.0.in_layers.2.bias', 'diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'diffusion_model.output_blocks.0.0.out_layers.0.weight', 'diffusion_model.output_blocks.0.0.out_layers.0.bias', 'diffusion_model.output_blocks.0.0.out_layers.3.weight', 'diffusion_model.output_blocks.0.0.out_layers.3.bias', 'diffusion_model.output_blocks.0.0.skip_connection.weight', 'diffusion_model.output_blocks.0.0.skip_connection.bias', 'diffusion_model.output_blocks.0.1.norm.weight', 'diffusion_model.output_blocks.0.1.norm.bias', 'diffusion_model.output_blocks.0.1.proj_in.weight', 'diffusion_model.output_blocks.0.1.proj_in.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm3.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm3.bias', 'diffusion_model.output_blocks.0.1.proj_out.weight', 'diffusion_model.output_blocks.0.1.proj_out.bias', 'diffusion_model.output_blocks.1.0.in_layers.0.weight', 'diffusion_model.output_blocks.1.0.in_layers.0.bias', 'diffusion_model.output_blocks.1.0.in_layers.2.weight', 'diffusion_model.output_blocks.1.0.in_layers.2.bias', 'diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'diffusion_model.output_blocks.1.0.out_layers.0.weight', 'diffusion_model.output_blocks.1.0.out_layers.0.bias', 'diffusion_model.output_blocks.1.0.out_layers.3.weight', 'diffusion_model.output_blocks.1.0.out_layers.3.bias', 'diffusion_model.output_blocks.1.0.skip_connection.weight', 'diffusion_model.output_blocks.1.0.skip_connection.bias', 'diffusion_model.output_blocks.1.1.norm.weight', 'diffusion_model.output_blocks.1.1.norm.bias', 'diffusion_model.output_blocks.1.1.proj_in.weight', 'diffusion_model.output_blocks.1.1.proj_in.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm3.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm3.bias', 'diffusion_model.output_blocks.1.1.proj_out.weight', 'diffusion_model.output_blocks.1.1.proj_out.bias', 'diffusion_model.output_blocks.2.0.in_layers.0.weight', 'diffusion_model.output_blocks.2.0.in_layers.0.bias', 'diffusion_model.output_blocks.2.0.in_layers.2.weight', 'diffusion_model.output_blocks.2.0.in_layers.2.bias', 'diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'diffusion_model.output_blocks.2.0.out_layers.0.weight', 'diffusion_model.output_blocks.2.0.out_layers.0.bias', 'diffusion_model.output_blocks.2.0.out_layers.3.weight', 'diffusion_model.output_blocks.2.0.out_layers.3.bias', 'diffusion_model.output_blocks.2.0.skip_connection.weight', 'diffusion_model.output_blocks.2.0.skip_connection.bias', 'diffusion_model.output_blocks.2.1.norm.weight', 'diffusion_model.output_blocks.2.1.norm.bias', 'diffusion_model.output_blocks.2.1.proj_in.weight', 'diffusion_model.output_blocks.2.1.proj_in.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm3.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm3.bias', 'diffusion_model.output_blocks.2.1.proj_out.weight', 'diffusion_model.output_blocks.2.1.proj_out.bias', 'diffusion_model.output_blocks.2.2.conv.weight', 'diffusion_model.output_blocks.2.2.conv.bias', 'diffusion_model.output_blocks.3.0.in_layers.0.weight', 'diffusion_model.output_blocks.3.0.in_layers.0.bias', 'diffusion_model.output_blocks.3.0.in_layers.2.weight', 'diffusion_model.output_blocks.3.0.in_layers.2.bias', 'diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'diffusion_model.output_blocks.3.0.out_layers.0.weight', 'diffusion_model.output_blocks.3.0.out_layers.0.bias', 'diffusion_model.output_blocks.3.0.out_layers.3.weight', 'diffusion_model.output_blocks.3.0.out_layers.3.bias', 'diffusion_model.output_blocks.3.0.skip_connection.weight', 'diffusion_model.output_blocks.3.0.skip_connection.bias', 'diffusion_model.output_blocks.3.1.norm.weight', 'diffusion_model.output_blocks.3.1.norm.bias', 'diffusion_model.output_blocks.3.1.proj_in.weight', 'diffusion_model.output_blocks.3.1.proj_in.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.3.1.proj_out.weight', 'diffusion_model.output_blocks.3.1.proj_out.bias', 'diffusion_model.output_blocks.4.0.in_layers.0.weight', 'diffusion_model.output_blocks.4.0.in_layers.0.bias', 'diffusion_model.output_blocks.4.0.in_layers.2.weight', 'diffusion_model.output_blocks.4.0.in_layers.2.bias', 'diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'diffusion_model.output_blocks.4.0.out_layers.0.weight', 'diffusion_model.output_blocks.4.0.out_layers.0.bias', 'diffusion_model.output_blocks.4.0.out_layers.3.weight', 'diffusion_model.output_blocks.4.0.out_layers.3.bias', 'diffusion_model.output_blocks.4.0.skip_connection.weight', 'diffusion_model.output_blocks.4.0.skip_connection.bias', 'diffusion_model.output_blocks.4.1.norm.weight', 'diffusion_model.output_blocks.4.1.norm.bias', 'diffusion_model.output_blocks.4.1.proj_in.weight', 'diffusion_model.output_blocks.4.1.proj_in.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.4.1.proj_out.weight', 'diffusion_model.output_blocks.4.1.proj_out.bias', 'diffusion_model.output_blocks.5.0.in_layers.0.weight', 'diffusion_model.output_blocks.5.0.in_layers.0.bias', 'diffusion_model.output_blocks.5.0.in_layers.2.weight', 'diffusion_model.output_blocks.5.0.in_layers.2.bias', 'diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'diffusion_model.output_blocks.5.0.out_layers.0.weight', 'diffusion_model.output_blocks.5.0.out_layers.0.bias', 'diffusion_model.output_blocks.5.0.out_layers.3.weight', 'diffusion_model.output_blocks.5.0.out_layers.3.bias', 'diffusion_model.output_blocks.5.0.skip_connection.weight', 'diffusion_model.output_blocks.5.0.skip_connection.bias', 'diffusion_model.output_blocks.5.1.norm.weight', 'diffusion_model.output_blocks.5.1.norm.bias', 'diffusion_model.output_blocks.5.1.proj_in.weight', 'diffusion_model.output_blocks.5.1.proj_in.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.5.1.proj_out.weight', 'diffusion_model.output_blocks.5.1.proj_out.bias', 'diffusion_model.output_blocks.5.2.conv.weight', 'diffusion_model.output_blocks.5.2.conv.bias', 'diffusion_model.output_blocks.6.0.in_layers.0.weight', 'diffusion_model.output_blocks.6.0.in_layers.0.bias', 'diffusion_model.output_blocks.6.0.in_layers.2.weight', 'diffusion_model.output_blocks.6.0.in_layers.2.bias', 'diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'diffusion_model.output_blocks.6.0.out_layers.0.weight', 'diffusion_model.output_blocks.6.0.out_layers.0.bias', 'diffusion_model.output_blocks.6.0.out_layers.3.weight', 'diffusion_model.output_blocks.6.0.out_layers.3.bias', 'diffusion_model.output_blocks.6.0.skip_connection.weight', 'diffusion_model.output_blocks.6.0.skip_connection.bias', 'diffusion_model.output_blocks.7.0.in_layers.0.weight', 'diffusion_model.output_blocks.7.0.in_layers.0.bias', 'diffusion_model.output_blocks.7.0.in_layers.2.weight', 'diffusion_model.output_blocks.7.0.in_layers.2.bias', 'diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'diffusion_model.output_blocks.7.0.out_layers.0.weight', 'diffusion_model.output_blocks.7.0.out_layers.0.bias', 'diffusion_model.output_blocks.7.0.out_layers.3.weight', 'diffusion_model.output_blocks.7.0.out_layers.3.bias', 'diffusion_model.output_blocks.7.0.skip_connection.weight', 'diffusion_model.output_blocks.7.0.skip_connection.bias', 'diffusion_model.output_blocks.8.0.in_layers.0.weight', 'diffusion_model.output_blocks.8.0.in_layers.0.bias', 'diffusion_model.output_blocks.8.0.in_layers.2.weight', 'diffusion_model.output_blocks.8.0.in_layers.2.bias', 'diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'diffusion_model.output_blocks.8.0.out_layers.0.weight', 'diffusion_model.output_blocks.8.0.out_layers.0.bias', 'diffusion_model.output_blocks.8.0.out_layers.3.weight', 'diffusion_model.output_blocks.8.0.out_layers.3.bias', 'diffusion_model.output_blocks.8.0.skip_connection.weight', 'diffusion_model.output_blocks.8.0.skip_connection.bias', 'diffusion_model.out.0.weight', 'diffusion_model.out.0.bias', 'diffusion_model.out.2.weight', 'diffusion_model.out.2.bias'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    w1, w_min, w_max = v\n",
    "    ks = k.split(\".\")\n",
    "    module_name = \"_\".join(ks[:-1])\n",
    "    param_name = ks[-1]\n",
    "    for subname, value in zip([\"w\", \"w_min\", \"w_max\"], v):\n",
    "        new_state_dict[f\"{module_name}.{subname}.{param_name}\"] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(new_state_dict, \"/data/SD-models/Lora/inpaint_v26.fooocus.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['diffusion_model.time_embed.0.weight', 'diffusion_model.time_embed.0.bias', 'diffusion_model.time_embed.2.weight', 'diffusion_model.time_embed.2.bias', 'diffusion_model.label_emb.0.0.weight', 'diffusion_model.label_emb.0.0.bias', 'diffusion_model.label_emb.0.2.weight', 'diffusion_model.label_emb.0.2.bias', 'diffusion_model.input_blocks.0.0.weight', 'diffusion_model.input_blocks.0.0.bias', 'diffusion_model.input_blocks.1.0.in_layers.0.weight', 'diffusion_model.input_blocks.1.0.in_layers.0.bias', 'diffusion_model.input_blocks.1.0.in_layers.2.weight', 'diffusion_model.input_blocks.1.0.in_layers.2.bias', 'diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'diffusion_model.input_blocks.1.0.out_layers.0.weight', 'diffusion_model.input_blocks.1.0.out_layers.0.bias', 'diffusion_model.input_blocks.1.0.out_layers.3.weight', 'diffusion_model.input_blocks.1.0.out_layers.3.bias', 'diffusion_model.input_blocks.2.0.in_layers.0.weight', 'diffusion_model.input_blocks.2.0.in_layers.0.bias', 'diffusion_model.input_blocks.2.0.in_layers.2.weight', 'diffusion_model.input_blocks.2.0.in_layers.2.bias', 'diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'diffusion_model.input_blocks.2.0.out_layers.0.weight', 'diffusion_model.input_blocks.2.0.out_layers.0.bias', 'diffusion_model.input_blocks.2.0.out_layers.3.weight', 'diffusion_model.input_blocks.2.0.out_layers.3.bias', 'diffusion_model.input_blocks.3.0.op.weight', 'diffusion_model.input_blocks.3.0.op.bias', 'diffusion_model.input_blocks.4.0.in_layers.0.weight', 'diffusion_model.input_blocks.4.0.in_layers.0.bias', 'diffusion_model.input_blocks.4.0.in_layers.2.weight', 'diffusion_model.input_blocks.4.0.in_layers.2.bias', 'diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'diffusion_model.input_blocks.4.0.out_layers.0.weight', 'diffusion_model.input_blocks.4.0.out_layers.0.bias', 'diffusion_model.input_blocks.4.0.out_layers.3.weight', 'diffusion_model.input_blocks.4.0.out_layers.3.bias', 'diffusion_model.input_blocks.4.0.skip_connection.weight', 'diffusion_model.input_blocks.4.0.skip_connection.bias', 'diffusion_model.input_blocks.4.1.norm.weight', 'diffusion_model.input_blocks.4.1.norm.bias', 'diffusion_model.input_blocks.4.1.proj_in.weight', 'diffusion_model.input_blocks.4.1.proj_in.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.4.1.proj_out.weight', 'diffusion_model.input_blocks.4.1.proj_out.bias', 'diffusion_model.input_blocks.5.0.in_layers.0.weight', 'diffusion_model.input_blocks.5.0.in_layers.0.bias', 'diffusion_model.input_blocks.5.0.in_layers.2.weight', 'diffusion_model.input_blocks.5.0.in_layers.2.bias', 'diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'diffusion_model.input_blocks.5.0.out_layers.0.weight', 'diffusion_model.input_blocks.5.0.out_layers.0.bias', 'diffusion_model.input_blocks.5.0.out_layers.3.weight', 'diffusion_model.input_blocks.5.0.out_layers.3.bias', 'diffusion_model.input_blocks.5.1.norm.weight', 'diffusion_model.input_blocks.5.1.norm.bias', 'diffusion_model.input_blocks.5.1.proj_in.weight', 'diffusion_model.input_blocks.5.1.proj_in.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.5.1.proj_out.weight', 'diffusion_model.input_blocks.5.1.proj_out.bias', 'diffusion_model.input_blocks.6.0.op.weight', 'diffusion_model.input_blocks.6.0.op.bias', 'diffusion_model.input_blocks.7.0.in_layers.0.weight', 'diffusion_model.input_blocks.7.0.in_layers.0.bias', 'diffusion_model.input_blocks.7.0.in_layers.2.weight', 'diffusion_model.input_blocks.7.0.in_layers.2.bias', 'diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'diffusion_model.input_blocks.7.0.out_layers.0.weight', 'diffusion_model.input_blocks.7.0.out_layers.0.bias', 'diffusion_model.input_blocks.7.0.out_layers.3.weight', 'diffusion_model.input_blocks.7.0.out_layers.3.bias', 'diffusion_model.input_blocks.7.0.skip_connection.weight', 'diffusion_model.input_blocks.7.0.skip_connection.bias', 'diffusion_model.input_blocks.7.1.norm.weight', 'diffusion_model.input_blocks.7.1.norm.bias', 'diffusion_model.input_blocks.7.1.proj_in.weight', 'diffusion_model.input_blocks.7.1.proj_in.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm3.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm3.bias', 'diffusion_model.input_blocks.7.1.proj_out.weight', 'diffusion_model.input_blocks.7.1.proj_out.bias', 'diffusion_model.input_blocks.8.0.in_layers.0.weight', 'diffusion_model.input_blocks.8.0.in_layers.0.bias', 'diffusion_model.input_blocks.8.0.in_layers.2.weight', 'diffusion_model.input_blocks.8.0.in_layers.2.bias', 'diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'diffusion_model.input_blocks.8.0.out_layers.0.weight', 'diffusion_model.input_blocks.8.0.out_layers.0.bias', 'diffusion_model.input_blocks.8.0.out_layers.3.weight', 'diffusion_model.input_blocks.8.0.out_layers.3.bias', 'diffusion_model.input_blocks.8.1.norm.weight', 'diffusion_model.input_blocks.8.1.norm.bias', 'diffusion_model.input_blocks.8.1.proj_in.weight', 'diffusion_model.input_blocks.8.1.proj_in.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm3.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm3.bias', 'diffusion_model.input_blocks.8.1.proj_out.weight', 'diffusion_model.input_blocks.8.1.proj_out.bias', 'diffusion_model.middle_block.0.in_layers.0.weight', 'diffusion_model.middle_block.0.in_layers.0.bias', 'diffusion_model.middle_block.0.in_layers.2.weight', 'diffusion_model.middle_block.0.in_layers.2.bias', 'diffusion_model.middle_block.0.emb_layers.1.weight', 'diffusion_model.middle_block.0.emb_layers.1.bias', 'diffusion_model.middle_block.0.out_layers.0.weight', 'diffusion_model.middle_block.0.out_layers.0.bias', 'diffusion_model.middle_block.0.out_layers.3.weight', 'diffusion_model.middle_block.0.out_layers.3.bias', 'diffusion_model.middle_block.1.norm.weight', 'diffusion_model.middle_block.1.norm.bias', 'diffusion_model.middle_block.1.proj_in.weight', 'diffusion_model.middle_block.1.proj_in.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.norm3.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.norm3.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.norm3.bias', 'diffusion_model.middle_block.1.proj_out.weight', 'diffusion_model.middle_block.1.proj_out.bias', 'diffusion_model.middle_block.2.in_layers.0.weight', 'diffusion_model.middle_block.2.in_layers.0.bias', 'diffusion_model.middle_block.2.in_layers.2.weight', 'diffusion_model.middle_block.2.in_layers.2.bias', 'diffusion_model.middle_block.2.emb_layers.1.weight', 'diffusion_model.middle_block.2.emb_layers.1.bias', 'diffusion_model.middle_block.2.out_layers.0.weight', 'diffusion_model.middle_block.2.out_layers.0.bias', 'diffusion_model.middle_block.2.out_layers.3.weight', 'diffusion_model.middle_block.2.out_layers.3.bias', 'diffusion_model.output_blocks.0.0.in_layers.0.weight', 'diffusion_model.output_blocks.0.0.in_layers.0.bias', 'diffusion_model.output_blocks.0.0.in_layers.2.weight', 'diffusion_model.output_blocks.0.0.in_layers.2.bias', 'diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'diffusion_model.output_blocks.0.0.out_layers.0.weight', 'diffusion_model.output_blocks.0.0.out_layers.0.bias', 'diffusion_model.output_blocks.0.0.out_layers.3.weight', 'diffusion_model.output_blocks.0.0.out_layers.3.bias', 'diffusion_model.output_blocks.0.0.skip_connection.weight', 'diffusion_model.output_blocks.0.0.skip_connection.bias', 'diffusion_model.output_blocks.0.1.norm.weight', 'diffusion_model.output_blocks.0.1.norm.bias', 'diffusion_model.output_blocks.0.1.proj_in.weight', 'diffusion_model.output_blocks.0.1.proj_in.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm3.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm3.bias', 'diffusion_model.output_blocks.0.1.proj_out.weight', 'diffusion_model.output_blocks.0.1.proj_out.bias', 'diffusion_model.output_blocks.1.0.in_layers.0.weight', 'diffusion_model.output_blocks.1.0.in_layers.0.bias', 'diffusion_model.output_blocks.1.0.in_layers.2.weight', 'diffusion_model.output_blocks.1.0.in_layers.2.bias', 'diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'diffusion_model.output_blocks.1.0.out_layers.0.weight', 'diffusion_model.output_blocks.1.0.out_layers.0.bias', 'diffusion_model.output_blocks.1.0.out_layers.3.weight', 'diffusion_model.output_blocks.1.0.out_layers.3.bias', 'diffusion_model.output_blocks.1.0.skip_connection.weight', 'diffusion_model.output_blocks.1.0.skip_connection.bias', 'diffusion_model.output_blocks.1.1.norm.weight', 'diffusion_model.output_blocks.1.1.norm.bias', 'diffusion_model.output_blocks.1.1.proj_in.weight', 'diffusion_model.output_blocks.1.1.proj_in.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm3.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm3.bias', 'diffusion_model.output_blocks.1.1.proj_out.weight', 'diffusion_model.output_blocks.1.1.proj_out.bias', 'diffusion_model.output_blocks.2.0.in_layers.0.weight', 'diffusion_model.output_blocks.2.0.in_layers.0.bias', 'diffusion_model.output_blocks.2.0.in_layers.2.weight', 'diffusion_model.output_blocks.2.0.in_layers.2.bias', 'diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'diffusion_model.output_blocks.2.0.out_layers.0.weight', 'diffusion_model.output_blocks.2.0.out_layers.0.bias', 'diffusion_model.output_blocks.2.0.out_layers.3.weight', 'diffusion_model.output_blocks.2.0.out_layers.3.bias', 'diffusion_model.output_blocks.2.0.skip_connection.weight', 'diffusion_model.output_blocks.2.0.skip_connection.bias', 'diffusion_model.output_blocks.2.1.norm.weight', 'diffusion_model.output_blocks.2.1.norm.bias', 'diffusion_model.output_blocks.2.1.proj_in.weight', 'diffusion_model.output_blocks.2.1.proj_in.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm3.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm3.bias', 'diffusion_model.output_blocks.2.1.proj_out.weight', 'diffusion_model.output_blocks.2.1.proj_out.bias', 'diffusion_model.output_blocks.2.2.conv.weight', 'diffusion_model.output_blocks.2.2.conv.bias', 'diffusion_model.output_blocks.3.0.in_layers.0.weight', 'diffusion_model.output_blocks.3.0.in_layers.0.bias', 'diffusion_model.output_blocks.3.0.in_layers.2.weight', 'diffusion_model.output_blocks.3.0.in_layers.2.bias', 'diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'diffusion_model.output_blocks.3.0.out_layers.0.weight', 'diffusion_model.output_blocks.3.0.out_layers.0.bias', 'diffusion_model.output_blocks.3.0.out_layers.3.weight', 'diffusion_model.output_blocks.3.0.out_layers.3.bias', 'diffusion_model.output_blocks.3.0.skip_connection.weight', 'diffusion_model.output_blocks.3.0.skip_connection.bias', 'diffusion_model.output_blocks.3.1.norm.weight', 'diffusion_model.output_blocks.3.1.norm.bias', 'diffusion_model.output_blocks.3.1.proj_in.weight', 'diffusion_model.output_blocks.3.1.proj_in.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.3.1.proj_out.weight', 'diffusion_model.output_blocks.3.1.proj_out.bias', 'diffusion_model.output_blocks.4.0.in_layers.0.weight', 'diffusion_model.output_blocks.4.0.in_layers.0.bias', 'diffusion_model.output_blocks.4.0.in_layers.2.weight', 'diffusion_model.output_blocks.4.0.in_layers.2.bias', 'diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'diffusion_model.output_blocks.4.0.out_layers.0.weight', 'diffusion_model.output_blocks.4.0.out_layers.0.bias', 'diffusion_model.output_blocks.4.0.out_layers.3.weight', 'diffusion_model.output_blocks.4.0.out_layers.3.bias', 'diffusion_model.output_blocks.4.0.skip_connection.weight', 'diffusion_model.output_blocks.4.0.skip_connection.bias', 'diffusion_model.output_blocks.4.1.norm.weight', 'diffusion_model.output_blocks.4.1.norm.bias', 'diffusion_model.output_blocks.4.1.proj_in.weight', 'diffusion_model.output_blocks.4.1.proj_in.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.4.1.proj_out.weight', 'diffusion_model.output_blocks.4.1.proj_out.bias', 'diffusion_model.output_blocks.5.0.in_layers.0.weight', 'diffusion_model.output_blocks.5.0.in_layers.0.bias', 'diffusion_model.output_blocks.5.0.in_layers.2.weight', 'diffusion_model.output_blocks.5.0.in_layers.2.bias', 'diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'diffusion_model.output_blocks.5.0.out_layers.0.weight', 'diffusion_model.output_blocks.5.0.out_layers.0.bias', 'diffusion_model.output_blocks.5.0.out_layers.3.weight', 'diffusion_model.output_blocks.5.0.out_layers.3.bias', 'diffusion_model.output_blocks.5.0.skip_connection.weight', 'diffusion_model.output_blocks.5.0.skip_connection.bias', 'diffusion_model.output_blocks.5.1.norm.weight', 'diffusion_model.output_blocks.5.1.norm.bias', 'diffusion_model.output_blocks.5.1.proj_in.weight', 'diffusion_model.output_blocks.5.1.proj_in.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.5.1.proj_out.weight', 'diffusion_model.output_blocks.5.1.proj_out.bias', 'diffusion_model.output_blocks.5.2.conv.weight', 'diffusion_model.output_blocks.5.2.conv.bias', 'diffusion_model.output_blocks.6.0.in_layers.0.weight', 'diffusion_model.output_blocks.6.0.in_layers.0.bias', 'diffusion_model.output_blocks.6.0.in_layers.2.weight', 'diffusion_model.output_blocks.6.0.in_layers.2.bias', 'diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'diffusion_model.output_blocks.6.0.out_layers.0.weight', 'diffusion_model.output_blocks.6.0.out_layers.0.bias', 'diffusion_model.output_blocks.6.0.out_layers.3.weight', 'diffusion_model.output_blocks.6.0.out_layers.3.bias', 'diffusion_model.output_blocks.6.0.skip_connection.weight', 'diffusion_model.output_blocks.6.0.skip_connection.bias', 'diffusion_model.output_blocks.7.0.in_layers.0.weight', 'diffusion_model.output_blocks.7.0.in_layers.0.bias', 'diffusion_model.output_blocks.7.0.in_layers.2.weight', 'diffusion_model.output_blocks.7.0.in_layers.2.bias', 'diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'diffusion_model.output_blocks.7.0.out_layers.0.weight', 'diffusion_model.output_blocks.7.0.out_layers.0.bias', 'diffusion_model.output_blocks.7.0.out_layers.3.weight', 'diffusion_model.output_blocks.7.0.out_layers.3.bias', 'diffusion_model.output_blocks.7.0.skip_connection.weight', 'diffusion_model.output_blocks.7.0.skip_connection.bias', 'diffusion_model.output_blocks.8.0.in_layers.0.weight', 'diffusion_model.output_blocks.8.0.in_layers.0.bias', 'diffusion_model.output_blocks.8.0.in_layers.2.weight', 'diffusion_model.output_blocks.8.0.in_layers.2.bias', 'diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'diffusion_model.output_blocks.8.0.out_layers.0.weight', 'diffusion_model.output_blocks.8.0.out_layers.0.bias', 'diffusion_model.output_blocks.8.0.out_layers.3.weight', 'diffusion_model.output_blocks.8.0.out_layers.3.bias', 'diffusion_model.output_blocks.8.0.skip_connection.weight', 'diffusion_model.output_blocks.8.0.skip_connection.bias', 'diffusion_model.out.0.weight', 'diffusion_model.out.0.bias', 'diffusion_model.out.2.weight', 'diffusion_model.out.2.bias'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_keys = {key.split(\".\")[0] for key in new_state_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2880"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = load_file(\"/data/SD-models/Lora/sd_xl_offset_example-lora_1.0.safetensors\")\n",
    "# l2 = load_file(\"/data/train-output/pattern/SDXL_20k_LoRA_dim16/fashion-pattern_20kdata_b16_lora.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"diffusion_model_input_blocks_1_0_in_layers_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newkeys = {key.replace(\".\", \"_\") for key in state_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['diffusion_model.time_embed.0.weight', 'diffusion_model.time_embed.0.bias', 'diffusion_model.time_embed.2.weight', 'diffusion_model.time_embed.2.bias', 'diffusion_model.label_emb.0.0.weight', 'diffusion_model.label_emb.0.0.bias', 'diffusion_model.label_emb.0.2.weight', 'diffusion_model.label_emb.0.2.bias', 'diffusion_model.input_blocks.0.0.weight', 'diffusion_model.input_blocks.0.0.bias', 'diffusion_model.input_blocks.1.0.in_layers.0.weight', 'diffusion_model.input_blocks.1.0.in_layers.0.bias', 'diffusion_model.input_blocks.1.0.in_layers.2.weight', 'diffusion_model.input_blocks.1.0.in_layers.2.bias', 'diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'diffusion_model.input_blocks.1.0.out_layers.0.weight', 'diffusion_model.input_blocks.1.0.out_layers.0.bias', 'diffusion_model.input_blocks.1.0.out_layers.3.weight', 'diffusion_model.input_blocks.1.0.out_layers.3.bias', 'diffusion_model.input_blocks.2.0.in_layers.0.weight', 'diffusion_model.input_blocks.2.0.in_layers.0.bias', 'diffusion_model.input_blocks.2.0.in_layers.2.weight', 'diffusion_model.input_blocks.2.0.in_layers.2.bias', 'diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'diffusion_model.input_blocks.2.0.out_layers.0.weight', 'diffusion_model.input_blocks.2.0.out_layers.0.bias', 'diffusion_model.input_blocks.2.0.out_layers.3.weight', 'diffusion_model.input_blocks.2.0.out_layers.3.bias', 'diffusion_model.input_blocks.3.0.op.weight', 'diffusion_model.input_blocks.3.0.op.bias', 'diffusion_model.input_blocks.4.0.in_layers.0.weight', 'diffusion_model.input_blocks.4.0.in_layers.0.bias', 'diffusion_model.input_blocks.4.0.in_layers.2.weight', 'diffusion_model.input_blocks.4.0.in_layers.2.bias', 'diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'diffusion_model.input_blocks.4.0.out_layers.0.weight', 'diffusion_model.input_blocks.4.0.out_layers.0.bias', 'diffusion_model.input_blocks.4.0.out_layers.3.weight', 'diffusion_model.input_blocks.4.0.out_layers.3.bias', 'diffusion_model.input_blocks.4.0.skip_connection.weight', 'diffusion_model.input_blocks.4.0.skip_connection.bias', 'diffusion_model.input_blocks.4.1.norm.weight', 'diffusion_model.input_blocks.4.1.norm.bias', 'diffusion_model.input_blocks.4.1.proj_in.weight', 'diffusion_model.input_blocks.4.1.proj_in.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.4.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.4.1.proj_out.weight', 'diffusion_model.input_blocks.4.1.proj_out.bias', 'diffusion_model.input_blocks.5.0.in_layers.0.weight', 'diffusion_model.input_blocks.5.0.in_layers.0.bias', 'diffusion_model.input_blocks.5.0.in_layers.2.weight', 'diffusion_model.input_blocks.5.0.in_layers.2.bias', 'diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'diffusion_model.input_blocks.5.0.out_layers.0.weight', 'diffusion_model.input_blocks.5.0.out_layers.0.bias', 'diffusion_model.input_blocks.5.0.out_layers.3.weight', 'diffusion_model.input_blocks.5.0.out_layers.3.bias', 'diffusion_model.input_blocks.5.1.norm.weight', 'diffusion_model.input_blocks.5.1.norm.bias', 'diffusion_model.input_blocks.5.1.proj_in.weight', 'diffusion_model.input_blocks.5.1.proj_in.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.5.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.5.1.proj_out.weight', 'diffusion_model.input_blocks.5.1.proj_out.bias', 'diffusion_model.input_blocks.6.0.op.weight', 'diffusion_model.input_blocks.6.0.op.bias', 'diffusion_model.input_blocks.7.0.in_layers.0.weight', 'diffusion_model.input_blocks.7.0.in_layers.0.bias', 'diffusion_model.input_blocks.7.0.in_layers.2.weight', 'diffusion_model.input_blocks.7.0.in_layers.2.bias', 'diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'diffusion_model.input_blocks.7.0.out_layers.0.weight', 'diffusion_model.input_blocks.7.0.out_layers.0.bias', 'diffusion_model.input_blocks.7.0.out_layers.3.weight', 'diffusion_model.input_blocks.7.0.out_layers.3.bias', 'diffusion_model.input_blocks.7.0.skip_connection.weight', 'diffusion_model.input_blocks.7.0.skip_connection.bias', 'diffusion_model.input_blocks.7.1.norm.weight', 'diffusion_model.input_blocks.7.1.norm.bias', 'diffusion_model.input_blocks.7.1.proj_in.weight', 'diffusion_model.input_blocks.7.1.proj_in.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.2.norm3.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm1.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm1.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm2.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm2.bias', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm3.weight', 'diffusion_model.input_blocks.7.1.transformer_blocks.3.norm3.bias', 'diffusion_model.input_blocks.7.1.proj_out.weight', 'diffusion_model.input_blocks.7.1.proj_out.bias', 'diffusion_model.input_blocks.8.0.in_layers.0.weight', 'diffusion_model.input_blocks.8.0.in_layers.0.bias', 'diffusion_model.input_blocks.8.0.in_layers.2.weight', 'diffusion_model.input_blocks.8.0.in_layers.2.bias', 'diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'diffusion_model.input_blocks.8.0.out_layers.0.weight', 'diffusion_model.input_blocks.8.0.out_layers.0.bias', 'diffusion_model.input_blocks.8.0.out_layers.3.weight', 'diffusion_model.input_blocks.8.0.out_layers.3.bias', 'diffusion_model.input_blocks.8.1.norm.weight', 'diffusion_model.input_blocks.8.1.norm.bias', 'diffusion_model.input_blocks.8.1.proj_in.weight', 'diffusion_model.input_blocks.8.1.proj_in.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.1.norm3.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.2.norm3.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm1.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm1.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm2.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm2.bias', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm3.weight', 'diffusion_model.input_blocks.8.1.transformer_blocks.3.norm3.bias', 'diffusion_model.input_blocks.8.1.proj_out.weight', 'diffusion_model.input_blocks.8.1.proj_out.bias', 'diffusion_model.middle_block.0.in_layers.0.weight', 'diffusion_model.middle_block.0.in_layers.0.bias', 'diffusion_model.middle_block.0.in_layers.2.weight', 'diffusion_model.middle_block.0.in_layers.2.bias', 'diffusion_model.middle_block.0.emb_layers.1.weight', 'diffusion_model.middle_block.0.emb_layers.1.bias', 'diffusion_model.middle_block.0.out_layers.0.weight', 'diffusion_model.middle_block.0.out_layers.0.bias', 'diffusion_model.middle_block.0.out_layers.3.weight', 'diffusion_model.middle_block.0.out_layers.3.bias', 'diffusion_model.middle_block.1.norm.weight', 'diffusion_model.middle_block.1.norm.bias', 'diffusion_model.middle_block.1.proj_in.weight', 'diffusion_model.middle_block.1.proj_in.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.1.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.1.norm3.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.2.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.2.norm3.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.norm1.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.norm1.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.norm2.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.norm2.bias', 'diffusion_model.middle_block.1.transformer_blocks.3.norm3.weight', 'diffusion_model.middle_block.1.transformer_blocks.3.norm3.bias', 'diffusion_model.middle_block.1.proj_out.weight', 'diffusion_model.middle_block.1.proj_out.bias', 'diffusion_model.middle_block.2.in_layers.0.weight', 'diffusion_model.middle_block.2.in_layers.0.bias', 'diffusion_model.middle_block.2.in_layers.2.weight', 'diffusion_model.middle_block.2.in_layers.2.bias', 'diffusion_model.middle_block.2.emb_layers.1.weight', 'diffusion_model.middle_block.2.emb_layers.1.bias', 'diffusion_model.middle_block.2.out_layers.0.weight', 'diffusion_model.middle_block.2.out_layers.0.bias', 'diffusion_model.middle_block.2.out_layers.3.weight', 'diffusion_model.middle_block.2.out_layers.3.bias', 'diffusion_model.output_blocks.0.0.in_layers.0.weight', 'diffusion_model.output_blocks.0.0.in_layers.0.bias', 'diffusion_model.output_blocks.0.0.in_layers.2.weight', 'diffusion_model.output_blocks.0.0.in_layers.2.bias', 'diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'diffusion_model.output_blocks.0.0.out_layers.0.weight', 'diffusion_model.output_blocks.0.0.out_layers.0.bias', 'diffusion_model.output_blocks.0.0.out_layers.3.weight', 'diffusion_model.output_blocks.0.0.out_layers.3.bias', 'diffusion_model.output_blocks.0.0.skip_connection.weight', 'diffusion_model.output_blocks.0.0.skip_connection.bias', 'diffusion_model.output_blocks.0.1.norm.weight', 'diffusion_model.output_blocks.0.1.norm.bias', 'diffusion_model.output_blocks.0.1.proj_in.weight', 'diffusion_model.output_blocks.0.1.proj_in.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.2.norm3.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm1.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm1.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm2.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm2.bias', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm3.weight', 'diffusion_model.output_blocks.0.1.transformer_blocks.3.norm3.bias', 'diffusion_model.output_blocks.0.1.proj_out.weight', 'diffusion_model.output_blocks.0.1.proj_out.bias', 'diffusion_model.output_blocks.1.0.in_layers.0.weight', 'diffusion_model.output_blocks.1.0.in_layers.0.bias', 'diffusion_model.output_blocks.1.0.in_layers.2.weight', 'diffusion_model.output_blocks.1.0.in_layers.2.bias', 'diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'diffusion_model.output_blocks.1.0.out_layers.0.weight', 'diffusion_model.output_blocks.1.0.out_layers.0.bias', 'diffusion_model.output_blocks.1.0.out_layers.3.weight', 'diffusion_model.output_blocks.1.0.out_layers.3.bias', 'diffusion_model.output_blocks.1.0.skip_connection.weight', 'diffusion_model.output_blocks.1.0.skip_connection.bias', 'diffusion_model.output_blocks.1.1.norm.weight', 'diffusion_model.output_blocks.1.1.norm.bias', 'diffusion_model.output_blocks.1.1.proj_in.weight', 'diffusion_model.output_blocks.1.1.proj_in.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.2.norm3.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm1.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm1.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm2.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm2.bias', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm3.weight', 'diffusion_model.output_blocks.1.1.transformer_blocks.3.norm3.bias', 'diffusion_model.output_blocks.1.1.proj_out.weight', 'diffusion_model.output_blocks.1.1.proj_out.bias', 'diffusion_model.output_blocks.2.0.in_layers.0.weight', 'diffusion_model.output_blocks.2.0.in_layers.0.bias', 'diffusion_model.output_blocks.2.0.in_layers.2.weight', 'diffusion_model.output_blocks.2.0.in_layers.2.bias', 'diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'diffusion_model.output_blocks.2.0.out_layers.0.weight', 'diffusion_model.output_blocks.2.0.out_layers.0.bias', 'diffusion_model.output_blocks.2.0.out_layers.3.weight', 'diffusion_model.output_blocks.2.0.out_layers.3.bias', 'diffusion_model.output_blocks.2.0.skip_connection.weight', 'diffusion_model.output_blocks.2.0.skip_connection.bias', 'diffusion_model.output_blocks.2.1.norm.weight', 'diffusion_model.output_blocks.2.1.norm.bias', 'diffusion_model.output_blocks.2.1.proj_in.weight', 'diffusion_model.output_blocks.2.1.proj_in.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.2.norm3.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn1.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.0.proj.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.0.proj.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.ff.net.2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_q.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_k.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_v.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_out.0.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.attn2.to_out.0.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm1.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm1.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm2.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm2.bias', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm3.weight', 'diffusion_model.output_blocks.2.1.transformer_blocks.3.norm3.bias', 'diffusion_model.output_blocks.2.1.proj_out.weight', 'diffusion_model.output_blocks.2.1.proj_out.bias', 'diffusion_model.output_blocks.2.2.conv.weight', 'diffusion_model.output_blocks.2.2.conv.bias', 'diffusion_model.output_blocks.3.0.in_layers.0.weight', 'diffusion_model.output_blocks.3.0.in_layers.0.bias', 'diffusion_model.output_blocks.3.0.in_layers.2.weight', 'diffusion_model.output_blocks.3.0.in_layers.2.bias', 'diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'diffusion_model.output_blocks.3.0.out_layers.0.weight', 'diffusion_model.output_blocks.3.0.out_layers.0.bias', 'diffusion_model.output_blocks.3.0.out_layers.3.weight', 'diffusion_model.output_blocks.3.0.out_layers.3.bias', 'diffusion_model.output_blocks.3.0.skip_connection.weight', 'diffusion_model.output_blocks.3.0.skip_connection.bias', 'diffusion_model.output_blocks.3.1.norm.weight', 'diffusion_model.output_blocks.3.1.norm.bias', 'diffusion_model.output_blocks.3.1.proj_in.weight', 'diffusion_model.output_blocks.3.1.proj_in.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.3.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.3.1.proj_out.weight', 'diffusion_model.output_blocks.3.1.proj_out.bias', 'diffusion_model.output_blocks.4.0.in_layers.0.weight', 'diffusion_model.output_blocks.4.0.in_layers.0.bias', 'diffusion_model.output_blocks.4.0.in_layers.2.weight', 'diffusion_model.output_blocks.4.0.in_layers.2.bias', 'diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'diffusion_model.output_blocks.4.0.out_layers.0.weight', 'diffusion_model.output_blocks.4.0.out_layers.0.bias', 'diffusion_model.output_blocks.4.0.out_layers.3.weight', 'diffusion_model.output_blocks.4.0.out_layers.3.bias', 'diffusion_model.output_blocks.4.0.skip_connection.weight', 'diffusion_model.output_blocks.4.0.skip_connection.bias', 'diffusion_model.output_blocks.4.1.norm.weight', 'diffusion_model.output_blocks.4.1.norm.bias', 'diffusion_model.output_blocks.4.1.proj_in.weight', 'diffusion_model.output_blocks.4.1.proj_in.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.4.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.4.1.proj_out.weight', 'diffusion_model.output_blocks.4.1.proj_out.bias', 'diffusion_model.output_blocks.5.0.in_layers.0.weight', 'diffusion_model.output_blocks.5.0.in_layers.0.bias', 'diffusion_model.output_blocks.5.0.in_layers.2.weight', 'diffusion_model.output_blocks.5.0.in_layers.2.bias', 'diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'diffusion_model.output_blocks.5.0.out_layers.0.weight', 'diffusion_model.output_blocks.5.0.out_layers.0.bias', 'diffusion_model.output_blocks.5.0.out_layers.3.weight', 'diffusion_model.output_blocks.5.0.out_layers.3.bias', 'diffusion_model.output_blocks.5.0.skip_connection.weight', 'diffusion_model.output_blocks.5.0.skip_connection.bias', 'diffusion_model.output_blocks.5.1.norm.weight', 'diffusion_model.output_blocks.5.1.norm.bias', 'diffusion_model.output_blocks.5.1.proj_in.weight', 'diffusion_model.output_blocks.5.1.proj_in.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn1.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.0.proj.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.0.proj.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.ff.net.2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_q.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_k.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_v.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_out.0.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.attn2.to_out.0.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm1.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm1.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm2.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm2.bias', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm3.weight', 'diffusion_model.output_blocks.5.1.transformer_blocks.1.norm3.bias', 'diffusion_model.output_blocks.5.1.proj_out.weight', 'diffusion_model.output_blocks.5.1.proj_out.bias', 'diffusion_model.output_blocks.5.2.conv.weight', 'diffusion_model.output_blocks.5.2.conv.bias', 'diffusion_model.output_blocks.6.0.in_layers.0.weight', 'diffusion_model.output_blocks.6.0.in_layers.0.bias', 'diffusion_model.output_blocks.6.0.in_layers.2.weight', 'diffusion_model.output_blocks.6.0.in_layers.2.bias', 'diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'diffusion_model.output_blocks.6.0.out_layers.0.weight', 'diffusion_model.output_blocks.6.0.out_layers.0.bias', 'diffusion_model.output_blocks.6.0.out_layers.3.weight', 'diffusion_model.output_blocks.6.0.out_layers.3.bias', 'diffusion_model.output_blocks.6.0.skip_connection.weight', 'diffusion_model.output_blocks.6.0.skip_connection.bias', 'diffusion_model.output_blocks.7.0.in_layers.0.weight', 'diffusion_model.output_blocks.7.0.in_layers.0.bias', 'diffusion_model.output_blocks.7.0.in_layers.2.weight', 'diffusion_model.output_blocks.7.0.in_layers.2.bias', 'diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'diffusion_model.output_blocks.7.0.out_layers.0.weight', 'diffusion_model.output_blocks.7.0.out_layers.0.bias', 'diffusion_model.output_blocks.7.0.out_layers.3.weight', 'diffusion_model.output_blocks.7.0.out_layers.3.bias', 'diffusion_model.output_blocks.7.0.skip_connection.weight', 'diffusion_model.output_blocks.7.0.skip_connection.bias', 'diffusion_model.output_blocks.8.0.in_layers.0.weight', 'diffusion_model.output_blocks.8.0.in_layers.0.bias', 'diffusion_model.output_blocks.8.0.in_layers.2.weight', 'diffusion_model.output_blocks.8.0.in_layers.2.bias', 'diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'diffusion_model.output_blocks.8.0.out_layers.0.weight', 'diffusion_model.output_blocks.8.0.out_layers.0.bias', 'diffusion_model.output_blocks.8.0.out_layers.3.weight', 'diffusion_model.output_blocks.8.0.out_layers.3.bias', 'diffusion_model.output_blocks.8.0.skip_connection.weight', 'diffusion_model.output_blocks.8.0.skip_connection.bias', 'diffusion_model.out.0.weight', 'diffusion_model.out.0.bias', 'diffusion_model.out.2.weight', 'diffusion_model.out.2.bias'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diffusion_model_input_blocks_0_0_bias',\n",
       " 'diffusion_model_input_blocks_0_0_weight',\n",
       " 'diffusion_model_input_blocks_1_0_emb_layers_1_bias',\n",
       " 'diffusion_model_input_blocks_1_0_emb_layers_1_weight',\n",
       " 'diffusion_model_input_blocks_1_0_in_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_1_0_in_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_1_0_in_layers_2_bias',\n",
       " 'diffusion_model_input_blocks_1_0_in_layers_2_weight',\n",
       " 'diffusion_model_input_blocks_1_0_out_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_1_0_out_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_1_0_out_layers_3_bias',\n",
       " 'diffusion_model_input_blocks_1_0_out_layers_3_weight',\n",
       " 'diffusion_model_input_blocks_2_0_emb_layers_1_bias',\n",
       " 'diffusion_model_input_blocks_2_0_emb_layers_1_weight',\n",
       " 'diffusion_model_input_blocks_2_0_in_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_2_0_in_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_2_0_in_layers_2_bias',\n",
       " 'diffusion_model_input_blocks_2_0_in_layers_2_weight',\n",
       " 'diffusion_model_input_blocks_2_0_out_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_2_0_out_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_2_0_out_layers_3_bias',\n",
       " 'diffusion_model_input_blocks_2_0_out_layers_3_weight',\n",
       " 'diffusion_model_input_blocks_3_0_op_bias',\n",
       " 'diffusion_model_input_blocks_3_0_op_weight',\n",
       " 'diffusion_model_input_blocks_4_0_emb_layers_1_bias',\n",
       " 'diffusion_model_input_blocks_4_0_emb_layers_1_weight',\n",
       " 'diffusion_model_input_blocks_4_0_in_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_4_0_in_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_4_0_in_layers_2_bias',\n",
       " 'diffusion_model_input_blocks_4_0_in_layers_2_weight',\n",
       " 'diffusion_model_input_blocks_4_0_out_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_4_0_out_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_4_0_out_layers_3_bias',\n",
       " 'diffusion_model_input_blocks_4_0_out_layers_3_weight',\n",
       " 'diffusion_model_input_blocks_4_0_skip_connection_bias',\n",
       " 'diffusion_model_input_blocks_4_0_skip_connection_weight',\n",
       " 'diffusion_model_input_blocks_4_1_norm_bias',\n",
       " 'diffusion_model_input_blocks_4_1_norm_weight',\n",
       " 'diffusion_model_input_blocks_4_1_proj_in_bias',\n",
       " 'diffusion_model_input_blocks_4_1_proj_in_weight',\n",
       " 'diffusion_model_input_blocks_4_1_proj_out_bias',\n",
       " 'diffusion_model_input_blocks_4_1_proj_out_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_norm1_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_norm1_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_norm2_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_norm2_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_norm3_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_0_norm3_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_norm1_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_norm1_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_norm2_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_norm2_weight',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_norm3_bias',\n",
       " 'diffusion_model_input_blocks_4_1_transformer_blocks_1_norm3_weight',\n",
       " 'diffusion_model_input_blocks_5_0_emb_layers_1_bias',\n",
       " 'diffusion_model_input_blocks_5_0_emb_layers_1_weight',\n",
       " 'diffusion_model_input_blocks_5_0_in_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_5_0_in_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_5_0_in_layers_2_bias',\n",
       " 'diffusion_model_input_blocks_5_0_in_layers_2_weight',\n",
       " 'diffusion_model_input_blocks_5_0_out_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_5_0_out_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_5_0_out_layers_3_bias',\n",
       " 'diffusion_model_input_blocks_5_0_out_layers_3_weight',\n",
       " 'diffusion_model_input_blocks_5_1_norm_bias',\n",
       " 'diffusion_model_input_blocks_5_1_norm_weight',\n",
       " 'diffusion_model_input_blocks_5_1_proj_in_bias',\n",
       " 'diffusion_model_input_blocks_5_1_proj_in_weight',\n",
       " 'diffusion_model_input_blocks_5_1_proj_out_bias',\n",
       " 'diffusion_model_input_blocks_5_1_proj_out_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_norm1_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_norm1_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_norm2_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_norm2_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_norm3_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_0_norm3_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_norm1_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_norm1_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_norm2_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_norm2_weight',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_norm3_bias',\n",
       " 'diffusion_model_input_blocks_5_1_transformer_blocks_1_norm3_weight',\n",
       " 'diffusion_model_input_blocks_6_0_op_bias',\n",
       " 'diffusion_model_input_blocks_6_0_op_weight',\n",
       " 'diffusion_model_input_blocks_7_0_emb_layers_1_bias',\n",
       " 'diffusion_model_input_blocks_7_0_emb_layers_1_weight',\n",
       " 'diffusion_model_input_blocks_7_0_in_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_7_0_in_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_7_0_in_layers_2_bias',\n",
       " 'diffusion_model_input_blocks_7_0_in_layers_2_weight',\n",
       " 'diffusion_model_input_blocks_7_0_out_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_7_0_out_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_7_0_out_layers_3_bias',\n",
       " 'diffusion_model_input_blocks_7_0_out_layers_3_weight',\n",
       " 'diffusion_model_input_blocks_7_0_skip_connection_bias',\n",
       " 'diffusion_model_input_blocks_7_0_skip_connection_weight',\n",
       " 'diffusion_model_input_blocks_7_1_norm_bias',\n",
       " 'diffusion_model_input_blocks_7_1_norm_weight',\n",
       " 'diffusion_model_input_blocks_7_1_proj_in_bias',\n",
       " 'diffusion_model_input_blocks_7_1_proj_in_weight',\n",
       " 'diffusion_model_input_blocks_7_1_proj_out_bias',\n",
       " 'diffusion_model_input_blocks_7_1_proj_out_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_norm1_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_norm1_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_norm2_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_norm2_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_norm3_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_0_norm3_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_norm1_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_norm1_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_norm2_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_norm2_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_norm3_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_1_norm3_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_norm1_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_norm1_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_norm2_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_norm2_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_norm3_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_2_norm3_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_norm1_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_norm1_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_norm2_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_norm2_weight',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_norm3_bias',\n",
       " 'diffusion_model_input_blocks_7_1_transformer_blocks_3_norm3_weight',\n",
       " 'diffusion_model_input_blocks_8_0_emb_layers_1_bias',\n",
       " 'diffusion_model_input_blocks_8_0_emb_layers_1_weight',\n",
       " 'diffusion_model_input_blocks_8_0_in_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_8_0_in_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_8_0_in_layers_2_bias',\n",
       " 'diffusion_model_input_blocks_8_0_in_layers_2_weight',\n",
       " 'diffusion_model_input_blocks_8_0_out_layers_0_bias',\n",
       " 'diffusion_model_input_blocks_8_0_out_layers_0_weight',\n",
       " 'diffusion_model_input_blocks_8_0_out_layers_3_bias',\n",
       " 'diffusion_model_input_blocks_8_0_out_layers_3_weight',\n",
       " 'diffusion_model_input_blocks_8_1_norm_bias',\n",
       " 'diffusion_model_input_blocks_8_1_norm_weight',\n",
       " 'diffusion_model_input_blocks_8_1_proj_in_bias',\n",
       " 'diffusion_model_input_blocks_8_1_proj_in_weight',\n",
       " 'diffusion_model_input_blocks_8_1_proj_out_bias',\n",
       " 'diffusion_model_input_blocks_8_1_proj_out_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_norm1_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_norm1_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_norm2_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_norm2_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_norm3_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_0_norm3_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_norm1_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_norm1_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_norm2_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_norm2_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_norm3_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_1_norm3_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_norm1_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_norm1_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_norm2_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_norm2_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_norm3_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_2_norm3_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_attn1_to_k_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_attn1_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_attn1_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_attn1_to_q_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_attn1_to_v_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_attn2_to_k_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_attn2_to_out_0_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_attn2_to_out_0_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_attn2_to_q_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_attn2_to_v_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_ff_net_0_proj_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_ff_net_0_proj_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_ff_net_2_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_ff_net_2_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_norm1_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_norm1_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_norm2_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_norm2_weight',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_norm3_bias',\n",
       " 'diffusion_model_input_blocks_8_1_transformer_blocks_3_norm3_weight',\n",
       " 'diffusion_model_label_emb_0_0_bias',\n",
       " 'diffusion_model_label_emb_0_0_weight',\n",
       " 'diffusion_model_label_emb_0_2_bias',\n",
       " 'diffusion_model_label_emb_0_2_weight',\n",
       " 'diffusion_model_middle_block_0_emb_layers_1_bias',\n",
       " 'diffusion_model_middle_block_0_emb_layers_1_weight',\n",
       " 'diffusion_model_middle_block_0_in_layers_0_bias',\n",
       " 'diffusion_model_middle_block_0_in_layers_0_weight',\n",
       " 'diffusion_model_middle_block_0_in_layers_2_bias',\n",
       " 'diffusion_model_middle_block_0_in_layers_2_weight',\n",
       " 'diffusion_model_middle_block_0_out_layers_0_bias',\n",
       " 'diffusion_model_middle_block_0_out_layers_0_weight',\n",
       " 'diffusion_model_middle_block_0_out_layers_3_bias',\n",
       " 'diffusion_model_middle_block_0_out_layers_3_weight',\n",
       " 'diffusion_model_middle_block_1_norm_bias',\n",
       " 'diffusion_model_middle_block_1_norm_weight',\n",
       " 'diffusion_model_middle_block_1_proj_in_bias',\n",
       " 'diffusion_model_middle_block_1_proj_in_weight',\n",
       " 'diffusion_model_middle_block_1_proj_out_bias',\n",
       " 'diffusion_model_middle_block_1_proj_out_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_attn1_to_k_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_attn1_to_out_0_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_attn1_to_out_0_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_attn1_to_q_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_attn1_to_v_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_attn2_to_k_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_attn2_to_out_0_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_attn2_to_out_0_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_attn2_to_q_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_attn2_to_v_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_ff_net_0_proj_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_ff_net_0_proj_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_ff_net_2_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_ff_net_2_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_norm1_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_norm1_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_norm2_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_norm2_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_norm3_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_0_norm3_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_attn1_to_k_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_attn1_to_out_0_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_attn1_to_out_0_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_attn1_to_q_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_attn1_to_v_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_attn2_to_k_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_attn2_to_out_0_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_attn2_to_out_0_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_attn2_to_q_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_attn2_to_v_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_ff_net_0_proj_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_ff_net_0_proj_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_ff_net_2_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_ff_net_2_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_norm1_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_norm1_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_norm2_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_norm2_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_norm3_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_1_norm3_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_attn1_to_k_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_attn1_to_out_0_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_attn1_to_out_0_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_attn1_to_q_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_attn1_to_v_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_attn2_to_k_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_attn2_to_out_0_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_attn2_to_out_0_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_attn2_to_q_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_attn2_to_v_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_ff_net_0_proj_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_ff_net_0_proj_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_ff_net_2_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_ff_net_2_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_norm1_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_norm1_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_norm2_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_norm2_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_norm3_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_2_norm3_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_attn1_to_k_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_attn1_to_out_0_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_attn1_to_out_0_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_attn1_to_q_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_attn1_to_v_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_attn2_to_k_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_attn2_to_out_0_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_attn2_to_out_0_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_attn2_to_q_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_attn2_to_v_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_ff_net_0_proj_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_ff_net_0_proj_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_ff_net_2_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_ff_net_2_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_norm1_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_norm1_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_norm2_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_norm2_weight',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_norm3_bias',\n",
       " 'diffusion_model_middle_block_1_transformer_blocks_3_norm3_weight',\n",
       " 'diffusion_model_middle_block_2_emb_layers_1_bias',\n",
       " 'diffusion_model_middle_block_2_emb_layers_1_weight',\n",
       " 'diffusion_model_middle_block_2_in_layers_0_bias',\n",
       " 'diffusion_model_middle_block_2_in_layers_0_weight',\n",
       " 'diffusion_model_middle_block_2_in_layers_2_bias',\n",
       " 'diffusion_model_middle_block_2_in_layers_2_weight',\n",
       " 'diffusion_model_middle_block_2_out_layers_0_bias',\n",
       " 'diffusion_model_middle_block_2_out_layers_0_weight',\n",
       " 'diffusion_model_middle_block_2_out_layers_3_bias',\n",
       " 'diffusion_model_middle_block_2_out_layers_3_weight',\n",
       " 'diffusion_model_out_0_bias',\n",
       " 'diffusion_model_out_0_weight',\n",
       " 'diffusion_model_out_2_bias',\n",
       " 'diffusion_model_out_2_weight',\n",
       " 'diffusion_model_output_blocks_0_0_emb_layers_1_bias',\n",
       " 'diffusion_model_output_blocks_0_0_emb_layers_1_weight',\n",
       " 'diffusion_model_output_blocks_0_0_in_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_0_0_in_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_0_0_in_layers_2_bias',\n",
       " 'diffusion_model_output_blocks_0_0_in_layers_2_weight',\n",
       " 'diffusion_model_output_blocks_0_0_out_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_0_0_out_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_0_0_out_layers_3_bias',\n",
       " 'diffusion_model_output_blocks_0_0_out_layers_3_weight',\n",
       " 'diffusion_model_output_blocks_0_0_skip_connection_bias',\n",
       " 'diffusion_model_output_blocks_0_0_skip_connection_weight',\n",
       " 'diffusion_model_output_blocks_0_1_norm_bias',\n",
       " 'diffusion_model_output_blocks_0_1_norm_weight',\n",
       " 'diffusion_model_output_blocks_0_1_proj_in_bias',\n",
       " 'diffusion_model_output_blocks_0_1_proj_in_weight',\n",
       " 'diffusion_model_output_blocks_0_1_proj_out_bias',\n",
       " 'diffusion_model_output_blocks_0_1_proj_out_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_norm1_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_norm1_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_norm2_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_norm2_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_norm3_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_0_norm3_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_norm1_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_norm1_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_norm2_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_norm2_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_norm3_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_1_norm3_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_norm1_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_norm1_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_norm2_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_norm2_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_norm3_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_2_norm3_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_norm1_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_norm1_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_norm2_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_norm2_weight',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_norm3_bias',\n",
       " 'diffusion_model_output_blocks_0_1_transformer_blocks_3_norm3_weight',\n",
       " 'diffusion_model_output_blocks_1_0_emb_layers_1_bias',\n",
       " 'diffusion_model_output_blocks_1_0_emb_layers_1_weight',\n",
       " 'diffusion_model_output_blocks_1_0_in_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_1_0_in_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_1_0_in_layers_2_bias',\n",
       " 'diffusion_model_output_blocks_1_0_in_layers_2_weight',\n",
       " 'diffusion_model_output_blocks_1_0_out_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_1_0_out_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_1_0_out_layers_3_bias',\n",
       " 'diffusion_model_output_blocks_1_0_out_layers_3_weight',\n",
       " 'diffusion_model_output_blocks_1_0_skip_connection_bias',\n",
       " 'diffusion_model_output_blocks_1_0_skip_connection_weight',\n",
       " 'diffusion_model_output_blocks_1_1_norm_bias',\n",
       " 'diffusion_model_output_blocks_1_1_norm_weight',\n",
       " 'diffusion_model_output_blocks_1_1_proj_in_bias',\n",
       " 'diffusion_model_output_blocks_1_1_proj_in_weight',\n",
       " 'diffusion_model_output_blocks_1_1_proj_out_bias',\n",
       " 'diffusion_model_output_blocks_1_1_proj_out_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_norm1_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_norm1_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_norm2_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_norm2_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_norm3_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_0_norm3_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_norm1_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_norm1_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_norm2_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_norm2_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_norm3_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_1_norm3_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_norm1_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_norm1_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_norm2_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_norm2_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_norm3_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_2_norm3_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_norm1_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_norm1_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_norm2_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_norm2_weight',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_norm3_bias',\n",
       " 'diffusion_model_output_blocks_1_1_transformer_blocks_3_norm3_weight',\n",
       " 'diffusion_model_output_blocks_2_0_emb_layers_1_bias',\n",
       " 'diffusion_model_output_blocks_2_0_emb_layers_1_weight',\n",
       " 'diffusion_model_output_blocks_2_0_in_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_2_0_in_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_2_0_in_layers_2_bias',\n",
       " 'diffusion_model_output_blocks_2_0_in_layers_2_weight',\n",
       " 'diffusion_model_output_blocks_2_0_out_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_2_0_out_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_2_0_out_layers_3_bias',\n",
       " 'diffusion_model_output_blocks_2_0_out_layers_3_weight',\n",
       " 'diffusion_model_output_blocks_2_0_skip_connection_bias',\n",
       " 'diffusion_model_output_blocks_2_0_skip_connection_weight',\n",
       " 'diffusion_model_output_blocks_2_1_norm_bias',\n",
       " 'diffusion_model_output_blocks_2_1_norm_weight',\n",
       " 'diffusion_model_output_blocks_2_1_proj_in_bias',\n",
       " 'diffusion_model_output_blocks_2_1_proj_in_weight',\n",
       " 'diffusion_model_output_blocks_2_1_proj_out_bias',\n",
       " 'diffusion_model_output_blocks_2_1_proj_out_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_norm1_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_norm1_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_norm2_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_norm2_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_norm3_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_0_norm3_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_norm1_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_norm1_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_norm2_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_norm2_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_norm3_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_1_norm3_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_norm1_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_norm1_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_norm2_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_norm2_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_norm3_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_2_norm3_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_norm1_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_norm1_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_norm2_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_norm2_weight',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_norm3_bias',\n",
       " 'diffusion_model_output_blocks_2_1_transformer_blocks_3_norm3_weight',\n",
       " 'diffusion_model_output_blocks_2_2_conv_bias',\n",
       " 'diffusion_model_output_blocks_2_2_conv_weight',\n",
       " 'diffusion_model_output_blocks_3_0_emb_layers_1_bias',\n",
       " 'diffusion_model_output_blocks_3_0_emb_layers_1_weight',\n",
       " 'diffusion_model_output_blocks_3_0_in_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_3_0_in_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_3_0_in_layers_2_bias',\n",
       " 'diffusion_model_output_blocks_3_0_in_layers_2_weight',\n",
       " 'diffusion_model_output_blocks_3_0_out_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_3_0_out_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_3_0_out_layers_3_bias',\n",
       " 'diffusion_model_output_blocks_3_0_out_layers_3_weight',\n",
       " 'diffusion_model_output_blocks_3_0_skip_connection_bias',\n",
       " 'diffusion_model_output_blocks_3_0_skip_connection_weight',\n",
       " 'diffusion_model_output_blocks_3_1_norm_bias',\n",
       " 'diffusion_model_output_blocks_3_1_norm_weight',\n",
       " 'diffusion_model_output_blocks_3_1_proj_in_bias',\n",
       " 'diffusion_model_output_blocks_3_1_proj_in_weight',\n",
       " 'diffusion_model_output_blocks_3_1_proj_out_bias',\n",
       " 'diffusion_model_output_blocks_3_1_proj_out_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_norm1_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_norm1_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_norm2_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_norm2_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_norm3_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_0_norm3_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_norm1_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_norm1_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_norm2_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_norm2_weight',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_norm3_bias',\n",
       " 'diffusion_model_output_blocks_3_1_transformer_blocks_1_norm3_weight',\n",
       " 'diffusion_model_output_blocks_4_0_emb_layers_1_bias',\n",
       " 'diffusion_model_output_blocks_4_0_emb_layers_1_weight',\n",
       " 'diffusion_model_output_blocks_4_0_in_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_4_0_in_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_4_0_in_layers_2_bias',\n",
       " 'diffusion_model_output_blocks_4_0_in_layers_2_weight',\n",
       " 'diffusion_model_output_blocks_4_0_out_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_4_0_out_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_4_0_out_layers_3_bias',\n",
       " 'diffusion_model_output_blocks_4_0_out_layers_3_weight',\n",
       " 'diffusion_model_output_blocks_4_0_skip_connection_bias',\n",
       " 'diffusion_model_output_blocks_4_0_skip_connection_weight',\n",
       " 'diffusion_model_output_blocks_4_1_norm_bias',\n",
       " 'diffusion_model_output_blocks_4_1_norm_weight',\n",
       " 'diffusion_model_output_blocks_4_1_proj_in_bias',\n",
       " 'diffusion_model_output_blocks_4_1_proj_in_weight',\n",
       " 'diffusion_model_output_blocks_4_1_proj_out_bias',\n",
       " 'diffusion_model_output_blocks_4_1_proj_out_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_norm1_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_norm1_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_norm2_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_norm2_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_norm3_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_0_norm3_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_norm1_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_norm1_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_norm2_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_norm2_weight',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_norm3_bias',\n",
       " 'diffusion_model_output_blocks_4_1_transformer_blocks_1_norm3_weight',\n",
       " 'diffusion_model_output_blocks_5_0_emb_layers_1_bias',\n",
       " 'diffusion_model_output_blocks_5_0_emb_layers_1_weight',\n",
       " 'diffusion_model_output_blocks_5_0_in_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_5_0_in_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_5_0_in_layers_2_bias',\n",
       " 'diffusion_model_output_blocks_5_0_in_layers_2_weight',\n",
       " 'diffusion_model_output_blocks_5_0_out_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_5_0_out_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_5_0_out_layers_3_bias',\n",
       " 'diffusion_model_output_blocks_5_0_out_layers_3_weight',\n",
       " 'diffusion_model_output_blocks_5_0_skip_connection_bias',\n",
       " 'diffusion_model_output_blocks_5_0_skip_connection_weight',\n",
       " 'diffusion_model_output_blocks_5_1_norm_bias',\n",
       " 'diffusion_model_output_blocks_5_1_norm_weight',\n",
       " 'diffusion_model_output_blocks_5_1_proj_in_bias',\n",
       " 'diffusion_model_output_blocks_5_1_proj_in_weight',\n",
       " 'diffusion_model_output_blocks_5_1_proj_out_bias',\n",
       " 'diffusion_model_output_blocks_5_1_proj_out_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_norm1_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_norm1_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_norm2_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_norm2_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_norm3_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_0_norm3_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_attn1_to_k_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_attn1_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_attn1_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_attn1_to_q_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_attn1_to_v_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_attn2_to_k_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_attn2_to_out_0_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_attn2_to_out_0_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_attn2_to_q_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_attn2_to_v_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_ff_net_0_proj_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_ff_net_0_proj_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_ff_net_2_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_ff_net_2_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_norm1_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_norm1_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_norm2_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_norm2_weight',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_norm3_bias',\n",
       " 'diffusion_model_output_blocks_5_1_transformer_blocks_1_norm3_weight',\n",
       " 'diffusion_model_output_blocks_5_2_conv_bias',\n",
       " 'diffusion_model_output_blocks_5_2_conv_weight',\n",
       " 'diffusion_model_output_blocks_6_0_emb_layers_1_bias',\n",
       " 'diffusion_model_output_blocks_6_0_emb_layers_1_weight',\n",
       " 'diffusion_model_output_blocks_6_0_in_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_6_0_in_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_6_0_in_layers_2_bias',\n",
       " 'diffusion_model_output_blocks_6_0_in_layers_2_weight',\n",
       " 'diffusion_model_output_blocks_6_0_out_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_6_0_out_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_6_0_out_layers_3_bias',\n",
       " 'diffusion_model_output_blocks_6_0_out_layers_3_weight',\n",
       " 'diffusion_model_output_blocks_6_0_skip_connection_bias',\n",
       " 'diffusion_model_output_blocks_6_0_skip_connection_weight',\n",
       " 'diffusion_model_output_blocks_7_0_emb_layers_1_bias',\n",
       " 'diffusion_model_output_blocks_7_0_emb_layers_1_weight',\n",
       " 'diffusion_model_output_blocks_7_0_in_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_7_0_in_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_7_0_in_layers_2_bias',\n",
       " 'diffusion_model_output_blocks_7_0_in_layers_2_weight',\n",
       " 'diffusion_model_output_blocks_7_0_out_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_7_0_out_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_7_0_out_layers_3_bias',\n",
       " 'diffusion_model_output_blocks_7_0_out_layers_3_weight',\n",
       " 'diffusion_model_output_blocks_7_0_skip_connection_bias',\n",
       " 'diffusion_model_output_blocks_7_0_skip_connection_weight',\n",
       " 'diffusion_model_output_blocks_8_0_emb_layers_1_bias',\n",
       " 'diffusion_model_output_blocks_8_0_emb_layers_1_weight',\n",
       " 'diffusion_model_output_blocks_8_0_in_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_8_0_in_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_8_0_in_layers_2_bias',\n",
       " 'diffusion_model_output_blocks_8_0_in_layers_2_weight',\n",
       " 'diffusion_model_output_blocks_8_0_out_layers_0_bias',\n",
       " 'diffusion_model_output_blocks_8_0_out_layers_0_weight',\n",
       " 'diffusion_model_output_blocks_8_0_out_layers_3_bias',\n",
       " 'diffusion_model_output_blocks_8_0_out_layers_3_weight',\n",
       " 'diffusion_model_output_blocks_8_0_skip_connection_bias',\n",
       " 'diffusion_model_output_blocks_8_0_skip_connection_weight',\n",
       " 'diffusion_model_time_embed_0_bias',\n",
       " 'diffusion_model_time_embed_0_weight',\n",
       " 'diffusion_model_time_embed_2_bias',\n",
       " 'diffusion_model_time_embed_2_weight'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 4, 3, 3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state_dict[\"diffusion_model.input_blocks.0.0.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lora_unet_input_blocks_1_0_emb_layers_1.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_1_0_emb_layers_1.lora_down.weight': tensor([[ 0.0126,  0.0154, -0.0018,  ..., -0.0051,  0.0364, -0.0209],\n",
       "         [-0.0188, -0.0334, -0.0114,  ...,  0.0009, -0.0036,  0.0334],\n",
       "         [ 0.0097, -0.0302, -0.0023,  ..., -0.0151, -0.0350,  0.0154],\n",
       "         ...,\n",
       "         [-0.0154, -0.0109,  0.0015,  ...,  0.0337,  0.0278, -0.0133],\n",
       "         [ 0.0088, -0.0239, -0.0241,  ..., -0.0103, -0.0079,  0.0141],\n",
       "         [-0.0131, -0.0193,  0.0052,  ..., -0.0031, -0.0242,  0.0026]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_1_0_emb_layers_1.lora_up.weight': tensor([[-2.0618e-03,  2.0676e-03,  5.4073e-04,  ..., -4.6120e-03,\n",
       "           1.0138e-03, -1.3409e-03],\n",
       "         [-8.7814e-03,  5.3444e-03,  3.1137e-04,  ..., -7.3128e-03,\n",
       "           6.8245e-03,  4.7913e-03],\n",
       "         [ 2.5272e-03, -3.0994e-03, -9.1782e-03,  ...,  2.9087e-03,\n",
       "          -2.5024e-03, -6.4969e-06],\n",
       "         ...,\n",
       "         [-1.6769e-02,  2.1912e-02,  2.6672e-02,  ..., -1.8768e-02,\n",
       "           1.7670e-02,  2.9016e-04],\n",
       "         [-2.8137e-02,  2.9251e-02,  2.0996e-02,  ..., -2.9160e-02,\n",
       "           2.8412e-02,  2.0401e-02],\n",
       "         [ 1.5205e-02, -1.4854e-02, -1.1154e-02,  ...,  1.4572e-02,\n",
       "          -1.5182e-02, -1.4740e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_1_0_in_layers_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_1_0_in_layers_2.lora_down.weight': tensor([[[[ 1.6357e-02,  2.7504e-03, -8.0032e-03],\n",
       "           [-3.9139e-03, -2.9430e-03, -6.0692e-03],\n",
       "           [ 2.1759e-02, -1.4893e-02, -8.4839e-03]],\n",
       " \n",
       "          [[-1.3245e-02, -1.4923e-02,  1.3618e-03],\n",
       "           [-1.7807e-02, -2.7084e-02, -5.9700e-03],\n",
       "           [-3.0899e-04,  1.1063e-02, -2.2293e-02]],\n",
       " \n",
       "          [[ 8.8730e-03,  3.4885e-03,  1.0414e-02],\n",
       "           [ 1.3527e-02,  3.0651e-03,  1.3763e-02],\n",
       "           [-7.1259e-03,  2.2369e-02,  1.5961e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.6144e-03,  7.5722e-03, -1.8158e-02],\n",
       "           [-1.2428e-02, -1.1475e-02, -1.7059e-02],\n",
       "           [ 1.3752e-03,  4.5319e-03, -2.0309e-02]],\n",
       " \n",
       "          [[ 1.7426e-02,  1.3214e-02, -1.0500e-03],\n",
       "           [-6.0749e-04,  3.0701e-02,  1.6907e-02],\n",
       "           [ 5.6725e-03,  2.3621e-02,  1.5213e-02]],\n",
       " \n",
       "          [[-2.4918e-02, -1.1879e-02, -1.8448e-02],\n",
       "           [-8.1329e-03, -2.9556e-02, -2.2964e-02],\n",
       "           [-1.4740e-02, -1.8082e-02, -1.4862e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 8.6823e-03, -1.1299e-02,  2.2888e-02],\n",
       "           [ 7.7591e-03,  1.5495e-02,  1.7990e-02],\n",
       "           [-1.3914e-03,  1.2970e-02, -1.6365e-03]],\n",
       " \n",
       "          [[ 6.8474e-03,  1.7319e-03,  1.1765e-02],\n",
       "           [ 4.9973e-03, -6.8092e-03, -4.0016e-03],\n",
       "           [ 1.0986e-02,  1.0071e-02,  6.6299e-03]],\n",
       " \n",
       "          [[ 1.9547e-02,  2.0905e-02,  1.3008e-02],\n",
       "           [ 1.6357e-02, -1.6003e-03,  1.4412e-02],\n",
       "           [-1.3115e-02,  4.4937e-03,  1.8631e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0796e-02,  4.9829e-04, -4.5853e-03],\n",
       "           [-2.9335e-03,  2.6741e-03, -3.3593e-04],\n",
       "           [ 4.0245e-03, -1.1223e-02, -4.5204e-03]],\n",
       " \n",
       "          [[-8.1635e-03,  1.2505e-02,  2.1271e-02],\n",
       "           [ 1.4053e-02, -3.1662e-03, -2.0885e-03],\n",
       "           [ 1.6312e-02,  4.4370e-04, -1.0567e-03]],\n",
       " \n",
       "          [[-2.1698e-02, -2.0599e-02, -4.8409e-03],\n",
       "           [-1.8433e-02, -2.1164e-02, -5.6496e-03],\n",
       "           [-2.1210e-02, -2.1469e-02, -6.1493e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.6956e-03,  3.2539e-03,  2.6608e-03],\n",
       "           [ 6.6376e-03, -9.1457e-04, -1.9257e-02],\n",
       "           [ 1.2016e-02, -1.7052e-03, -1.5045e-02]],\n",
       " \n",
       "          [[ 1.1719e-02, -1.3952e-03,  6.5689e-03],\n",
       "           [ 1.1345e-02, -1.1108e-02,  1.7090e-02],\n",
       "           [ 4.6883e-03,  2.2644e-02,  1.3685e-03]],\n",
       " \n",
       "          [[-1.1497e-02, -4.5128e-03,  1.1009e-02],\n",
       "           [ 1.1894e-02, -3.6507e-03, -1.2455e-03],\n",
       "           [-5.1575e-03, -9.0485e-03,  6.7291e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.5264e-03,  1.6693e-02, -1.2993e-02],\n",
       "           [ 1.8524e-02,  1.7822e-02,  6.9351e-03],\n",
       "           [ 1.2405e-02,  1.6108e-03, -3.0174e-03]],\n",
       " \n",
       "          [[-1.6006e-02,  7.6065e-03,  3.4370e-03],\n",
       "           [ 2.2709e-04, -8.0566e-03, -9.7427e-03],\n",
       "           [ 5.3291e-03, -1.0902e-02,  5.2795e-03]],\n",
       " \n",
       "          [[ 1.4687e-02, -2.1095e-03,  9.3231e-03],\n",
       "           [-8.2550e-03,  2.7069e-02,  2.0187e-02],\n",
       "           [-6.4354e-03,  2.0126e-02, -6.6528e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 2.1713e-02,  6.7711e-03,  1.2146e-02],\n",
       "           [ 2.6077e-02,  4.9362e-03,  2.8046e-02],\n",
       "           [-6.8207e-03,  8.6365e-03,  8.3389e-03]],\n",
       " \n",
       "          [[-1.4351e-02,  2.3594e-03, -1.1940e-02],\n",
       "           [ 1.1721e-03, -6.3667e-03, -1.6922e-02],\n",
       "           [-1.0689e-02, -2.0493e-02, -1.5392e-03]],\n",
       " \n",
       "          [[ 2.4231e-02,  2.0630e-02, -1.3229e-02],\n",
       "           [ 1.2184e-02,  5.7220e-03, -6.8016e-03],\n",
       "           [ 1.0700e-03, -1.2445e-03, -5.2404e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.1162e-02, -4.7569e-03, -3.5725e-03],\n",
       "           [-7.8087e-03, -2.1725e-03,  1.0307e-02],\n",
       "           [-1.1435e-03, -1.4648e-02,  4.3526e-03]],\n",
       " \n",
       "          [[ 2.4017e-02,  2.1652e-02, -2.4071e-03],\n",
       "           [ 2.4658e-02,  1.5762e-02,  1.0262e-03],\n",
       "           [ 1.3069e-02, -3.5954e-03,  1.3115e-02]],\n",
       " \n",
       "          [[-6.2370e-03, -3.9902e-03, -1.0597e-02],\n",
       "           [ 7.9498e-03,  3.8261e-03, -1.9653e-02],\n",
       "           [-1.1940e-02, -1.1429e-02,  5.6744e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 5.2223e-03, -3.0327e-03, -7.9346e-03],\n",
       "           [-1.7883e-02, -1.3100e-02, -1.0700e-03],\n",
       "           [-9.9182e-04, -2.9678e-03, -2.2034e-02]],\n",
       " \n",
       "          [[-1.2517e-05,  1.4275e-02,  1.2497e-02],\n",
       "           [-5.2214e-04, -1.1053e-03, -9.4223e-03],\n",
       "           [ 1.0681e-02,  2.7985e-02,  6.1274e-05]],\n",
       " \n",
       "          [[ 1.5345e-03,  8.8882e-03, -2.4139e-02],\n",
       "           [-2.0325e-02, -1.4473e-02, -1.6953e-02],\n",
       "           [-2.0096e-02,  1.3809e-03, -2.3102e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6068e-02, -1.1120e-03,  7.8506e-03],\n",
       "           [ 1.5182e-02,  1.8387e-02, -9.1782e-03],\n",
       "           [ 1.5076e-02, -1.6144e-02, -8.9569e-03]],\n",
       " \n",
       "          [[-2.6073e-03,  9.5520e-03, -3.3836e-03],\n",
       "           [ 6.2752e-03,  1.2566e-02, -7.5073e-03],\n",
       "           [-1.5884e-02, -2.1820e-02, -5.8937e-03]],\n",
       " \n",
       "          [[ 2.0325e-02, -1.0231e-02,  4.8103e-03],\n",
       "           [ 1.9867e-02, -1.0765e-02,  1.3565e-02],\n",
       "           [ 1.3145e-02, -3.0975e-03,  1.6800e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.6959e-03, -7.0152e-03, -2.1500e-02],\n",
       "           [ 4.2496e-03, -1.2466e-02,  6.4125e-03],\n",
       "           [ 3.7956e-03, -7.5188e-03, -8.4972e-04]],\n",
       " \n",
       "          [[-4.0131e-03, -5.5046e-03, -5.0087e-03],\n",
       "           [-7.4615e-03, -1.2199e-02,  5.0125e-03],\n",
       "           [-6.9504e-03,  3.7346e-03, -2.4582e-02]],\n",
       " \n",
       "          [[-9.3231e-03, -1.2222e-02, -3.0727e-03],\n",
       "           [-1.6953e-02,  4.4746e-03, -1.7929e-02],\n",
       "           [-3.7708e-03, -1.4931e-02,  3.8776e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.8321e-03,  1.5747e-02, -1.2184e-02],\n",
       "           [ 9.1705e-03,  2.2049e-02, -1.1177e-02],\n",
       "           [-3.1033e-03, -3.7050e-04,  1.8890e-02]],\n",
       " \n",
       "          [[-3.5309e-02, -3.3630e-02, -3.3722e-02],\n",
       "           [-2.5864e-02, -5.0240e-03, -1.5099e-02],\n",
       "           [-2.0508e-02, -1.9058e-02, -3.3386e-02]],\n",
       " \n",
       "          [[ 3.5954e-04,  2.1271e-02,  5.3177e-03],\n",
       "           [ 6.2981e-03,  2.3163e-02,  7.2575e-04],\n",
       "           [ 1.0750e-02,  1.0834e-02,  1.4847e-02]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_1_0_in_layers_2.lora_up.weight': tensor([[[[ 0.0193]],\n",
       " \n",
       "          [[-0.0089]],\n",
       " \n",
       "          [[ 0.0056]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0048]],\n",
       " \n",
       "          [[ 0.0033]],\n",
       " \n",
       "          [[ 0.0069]]],\n",
       " \n",
       " \n",
       "         [[[-0.0254]],\n",
       " \n",
       "          [[-0.0235]],\n",
       " \n",
       "          [[ 0.0231]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0256]],\n",
       " \n",
       "          [[ 0.0195]],\n",
       " \n",
       "          [[-0.0021]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0046]],\n",
       " \n",
       "          [[-0.0136]],\n",
       " \n",
       "          [[ 0.0163]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0152]],\n",
       " \n",
       "          [[ 0.0284]],\n",
       " \n",
       "          [[ 0.0037]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0214]],\n",
       " \n",
       "          [[ 0.0084]],\n",
       " \n",
       "          [[-0.0084]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0085]],\n",
       " \n",
       "          [[-0.0069]],\n",
       " \n",
       "          [[-0.0023]]],\n",
       " \n",
       " \n",
       "         [[[-0.0031]],\n",
       " \n",
       "          [[-0.0098]],\n",
       " \n",
       "          [[ 0.0148]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0170]],\n",
       " \n",
       "          [[ 0.0229]],\n",
       " \n",
       "          [[ 0.0138]]],\n",
       " \n",
       " \n",
       "         [[[-0.0278]],\n",
       " \n",
       "          [[ 0.0077]],\n",
       " \n",
       "          [[-0.0094]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0123]],\n",
       " \n",
       "          [[-0.0175]],\n",
       " \n",
       "          [[-0.0095]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_1_0_out_layers_3.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_1_0_out_layers_3.lora_down.weight': tensor([[[[ 2.0508e-02,  1.1978e-02,  1.8967e-02],\n",
       "           [-7.8487e-04, -4.4594e-03,  1.7670e-02],\n",
       "           [ 6.9313e-03,  8.1406e-03,  1.0735e-02]],\n",
       " \n",
       "          [[ 6.9962e-03, -1.4849e-03,  1.8982e-02],\n",
       "           [-3.1261e-03,  2.7275e-03,  9.8419e-03],\n",
       "           [-8.9264e-03,  1.1101e-02,  9.7809e-03]],\n",
       " \n",
       "          [[-6.7177e-03, -1.5747e-02,  6.0959e-03],\n",
       "           [-3.9005e-03, -4.6463e-03, -1.4832e-02],\n",
       "           [-1.2184e-02, -5.8060e-03, -1.6251e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.0507e-04, -2.1317e-02,  1.2112e-04],\n",
       "           [ 1.2550e-02, -9.4223e-03,  1.3819e-03],\n",
       "           [ 7.7705e-03,  2.0050e-02, -9.9487e-03]],\n",
       " \n",
       "          [[ 1.3590e-03,  5.4665e-03,  1.6190e-02],\n",
       "           [ 3.9787e-03,  1.5707e-03,  1.1086e-02],\n",
       "           [ 2.4780e-02, -6.9904e-04, -9.9869e-03]],\n",
       " \n",
       "          [[ 1.0361e-02, -1.0124e-02, -1.3054e-02],\n",
       "           [ 3.6201e-03, -1.5274e-02, -1.0712e-02],\n",
       "           [ 8.2779e-03, -2.4155e-02,  1.0643e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.3711e-03, -7.9346e-03,  1.2062e-02],\n",
       "           [ 1.1124e-02, -2.1164e-02, -1.8356e-02],\n",
       "           [-1.5472e-02, -1.8173e-02, -2.0782e-02]],\n",
       " \n",
       "          [[ 7.1640e-03, -1.3351e-02, -9.5139e-03],\n",
       "           [ 8.1024e-03, -2.4780e-02,  3.9139e-03],\n",
       "           [ 2.1713e-02,  3.8338e-03,  1.5335e-03]],\n",
       " \n",
       "          [[-6.0120e-03,  1.2894e-03,  3.0231e-03],\n",
       "           [-8.3084e-03,  1.9104e-02,  1.9058e-02],\n",
       "           [ 1.3741e-02,  3.0869e-02,  1.3466e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.6951e-03,  1.6922e-02,  1.1894e-02],\n",
       "           [ 6.0730e-03, -1.3664e-02,  1.2184e-02],\n",
       "           [-1.3275e-02, -1.7181e-02, -7.0076e-03]],\n",
       " \n",
       "          [[-1.5175e-02,  1.8784e-02, -9.4223e-03],\n",
       "           [ 1.3878e-02,  1.9318e-02,  4.7150e-03],\n",
       "           [-8.2779e-03, -1.3008e-02,  1.0345e-02]],\n",
       " \n",
       "          [[ 2.0767e-02, -1.0567e-02, -9.5844e-04],\n",
       "           [-8.7204e-03,  3.3131e-03,  1.4984e-02],\n",
       "           [ 1.1383e-02,  1.8539e-02,  2.1301e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.0185e-02, -1.1082e-03,  7.1030e-03],\n",
       "           [-4.2534e-03, -1.3252e-02, -3.0956e-03],\n",
       "           [-3.8376e-03, -1.9821e-02,  3.5553e-03]],\n",
       " \n",
       "          [[ 1.1353e-02, -1.4076e-02,  1.5701e-02],\n",
       "           [ 2.2755e-03,  5.6114e-03, -1.5039e-03],\n",
       "           [-1.4900e-02, -2.0996e-02,  1.4572e-02]],\n",
       " \n",
       "          [[ 7.7171e-03,  2.8095e-03,  1.1200e-02],\n",
       "           [ 1.8173e-02,  1.7456e-02,  9.6436e-03],\n",
       "           [ 3.0640e-02,  2.2858e-02,  2.5269e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.0580e-03, -1.5671e-02, -3.6240e-03],\n",
       "           [-4.9438e-03, -2.4204e-03, -2.2430e-03],\n",
       "           [ 3.7789e-04,  1.0262e-02, -7.1678e-03]],\n",
       " \n",
       "          [[-6.0844e-03, -2.7351e-03, -1.6449e-02],\n",
       "           [-3.6469e-03, -9.4528e-03, -2.1423e-02],\n",
       "           [-2.1332e-02,  1.2390e-02, -1.5434e-02]],\n",
       " \n",
       "          [[ 8.0948e-03,  2.3087e-02,  2.3438e-02],\n",
       "           [ 9.3307e-03,  9.5520e-03,  1.9882e-02],\n",
       "           [ 1.7385e-03,  1.5564e-02,  1.5778e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 3.5477e-03,  2.6321e-03, -3.7823e-03],\n",
       "           [-4.4417e-04, -5.6076e-03,  1.0429e-02],\n",
       "           [-1.4496e-02,  5.3368e-03,  1.1902e-02]],\n",
       " \n",
       "          [[-1.1742e-02, -1.9699e-02, -1.9745e-02],\n",
       "           [ 6.7482e-03,  2.5272e-03,  6.0692e-03],\n",
       "           [ 2.6631e-04,  1.1200e-02, -1.8341e-02]],\n",
       " \n",
       "          [[ 9.8724e-03,  4.9591e-03,  9.6440e-05],\n",
       "           [ 1.4591e-03,  3.1281e-03, -1.9714e-02],\n",
       "           [ 3.4752e-03, -9.1171e-03,  3.4451e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.6159e-02, -6.8092e-03,  1.0857e-02],\n",
       "           [ 9.0714e-03,  2.6665e-03, -1.2665e-02],\n",
       "           [-6.0196e-03, -1.5762e-02, -4.3182e-03]],\n",
       " \n",
       "          [[-2.9144e-02, -2.7878e-02, -3.7750e-02],\n",
       "           [-1.7807e-02, -2.8057e-03, -4.2389e-02],\n",
       "           [-1.4854e-02, -2.3560e-02, -3.7811e-02]],\n",
       " \n",
       "          [[ 4.0474e-03,  1.0750e-02, -8.8654e-03],\n",
       "           [ 1.2611e-02, -1.1734e-02, -7.4921e-03],\n",
       "           [-1.4053e-02, -9.1782e-03,  7.4744e-05]]],\n",
       " \n",
       " \n",
       "         [[[-6.1646e-03,  9.6512e-03, -4.3831e-03],\n",
       "           [ 1.8387e-02,  1.1566e-02,  1.7731e-02],\n",
       "           [-7.3204e-03,  9.7351e-03,  4.8141e-03]],\n",
       " \n",
       "          [[-9.6664e-03,  8.7128e-03,  1.2123e-02],\n",
       "           [-1.4206e-02,  2.6855e-03, -4.9973e-03],\n",
       "           [ 1.3514e-03, -7.4348e-03,  1.0307e-02]],\n",
       " \n",
       "          [[ 1.7891e-03, -2.8397e-02,  6.7329e-03],\n",
       "           [-1.9974e-02, -1.6937e-02, -1.1986e-02],\n",
       "           [-2.4399e-02, -1.9730e-02, -8.0566e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.3367e-02, -1.3268e-04,  1.4824e-02],\n",
       "           [ 5.2910e-03, -1.3458e-02, -7.7629e-03],\n",
       "           [-7.8583e-03, -1.3527e-02, -8.2626e-03]],\n",
       " \n",
       "          [[ 5.9929e-03,  8.0795e-03,  6.3896e-03],\n",
       "           [-7.7629e-04, -2.1744e-03, -1.2131e-02],\n",
       "           [ 6.9008e-03,  1.6647e-02, -7.8058e-04]],\n",
       " \n",
       "          [[-1.9730e-02, -6.9656e-03,  7.9193e-03],\n",
       "           [-6.9427e-03, -2.3315e-02, -6.3858e-03],\n",
       "           [ 2.5158e-03, -1.5869e-02, -2.2995e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.8721e-03, -1.9062e-04, -9.0408e-03],\n",
       "           [ 2.2003e-02,  1.4977e-02,  1.1368e-02],\n",
       "           [ 1.4763e-02,  2.6520e-02,  1.5945e-03]],\n",
       " \n",
       "          [[-2.9160e-02, -3.1281e-02, -2.0523e-02],\n",
       "           [-1.4847e-02, -2.2736e-02,  2.8725e-03],\n",
       "           [ 1.7035e-04, -3.1342e-02, -9.9258e-03]],\n",
       " \n",
       "          [[-1.7761e-02, -1.6489e-03, -8.0185e-03],\n",
       "           [-9.7198e-03, -4.9133e-03,  7.1297e-03],\n",
       "           [-4.8103e-03, -1.5747e-02,  1.4069e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0071e-02, -2.8896e-03, -7.5531e-03],\n",
       "           [-1.4786e-02,  2.7981e-03, -1.1696e-02],\n",
       "           [ 1.4137e-02, -2.3758e-02, -5.4207e-03]],\n",
       " \n",
       "          [[ 9.1629e-03, -7.5607e-03, -1.6678e-02],\n",
       "           [-5.7602e-03, -3.6755e-03,  1.7023e-03],\n",
       "           [ 4.5280e-03, -5.1546e-04, -9.2087e-03]],\n",
       " \n",
       "          [[ 4.4847e-04,  2.2018e-02, -1.1292e-02],\n",
       "           [ 2.3087e-02,  1.2138e-02, -1.8959e-03],\n",
       "           [-8.7738e-03,  2.2614e-02, -1.9178e-03]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_1_0_out_layers_3.lora_up.weight': tensor([[[[-1.5427e-02]],\n",
       " \n",
       "          [[ 1.5549e-02]],\n",
       " \n",
       "          [[ 1.4931e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.6136e-03]],\n",
       " \n",
       "          [[-1.1559e-02]],\n",
       " \n",
       "          [[ 5.6419e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.5004e-02]],\n",
       " \n",
       "          [[-3.2074e-02]],\n",
       " \n",
       "          [[-3.0762e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5320e-02]],\n",
       " \n",
       "          [[ 3.1494e-02]],\n",
       " \n",
       "          [[-2.0935e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.4398e-03]],\n",
       " \n",
       "          [[-1.1325e-05]],\n",
       " \n",
       "          [[-5.6076e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-9.1553e-03]],\n",
       " \n",
       "          [[ 2.3842e-05]],\n",
       " \n",
       "          [[-3.6831e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 2.0161e-03]],\n",
       " \n",
       "          [[-5.7945e-03]],\n",
       " \n",
       "          [[-5.5885e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.3504e-02]],\n",
       " \n",
       "          [[ 1.0353e-02]],\n",
       " \n",
       "          [[ 6.5079e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.2115e-02]],\n",
       " \n",
       "          [[ 1.0284e-02]],\n",
       " \n",
       "          [[ 5.3558e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.8735e-03]],\n",
       " \n",
       "          [[-8.6670e-03]],\n",
       " \n",
       "          [[ 4.3488e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0521e-02]],\n",
       " \n",
       "          [[-4.4556e-03]],\n",
       " \n",
       "          [[-1.2802e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.1986e-03]],\n",
       " \n",
       "          [[ 9.5749e-03]],\n",
       " \n",
       "          [[ 2.0401e-02]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_2_0_emb_layers_1.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_2_0_emb_layers_1.lora_down.weight': tensor([[-0.0071, -0.0052, -0.0131,  ...,  0.0042,  0.0138,  0.0014],\n",
       "         [-0.0024,  0.0017,  0.0215,  ...,  0.0028, -0.0141,  0.0185],\n",
       "         [ 0.0214, -0.0117, -0.0152,  ..., -0.0095,  0.0244, -0.0060],\n",
       "         ...,\n",
       "         [ 0.0197, -0.0020,  0.0280,  ..., -0.0052,  0.0044, -0.0074],\n",
       "         [-0.0026,  0.0054, -0.0159,  ..., -0.0004,  0.0160, -0.0202],\n",
       "         [-0.0116,  0.0320,  0.0082,  ..., -0.0231,  0.0118, -0.0087]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_2_0_emb_layers_1.lora_up.weight': tensor([[ 0.0031, -0.0122,  0.0122,  ..., -0.0080, -0.0106, -0.0113],\n",
       "         [ 0.0253,  0.0139, -0.0140,  ...,  0.0132,  0.0177,  0.0171],\n",
       "         [ 0.0270,  0.0011, -0.0081,  ...,  0.0051,  0.0104,  0.0095],\n",
       "         ...,\n",
       "         [ 0.0130,  0.0052, -0.0101,  ...,  0.0120,  0.0122,  0.0109],\n",
       "         [-0.0197, -0.0050,  0.0014,  ..., -0.0019, -0.0074, -0.0075],\n",
       "         [ 0.0055,  0.0110, -0.0002,  ..., -0.0001,  0.0022,  0.0030]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_2_0_in_layers_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_2_0_in_layers_2.lora_down.weight': tensor([[[[-0.0013, -0.0240, -0.0104],\n",
       "           [-0.0130, -0.0210, -0.0039],\n",
       "           [ 0.0023, -0.0326,  0.0001]],\n",
       " \n",
       "          [[ 0.0377,  0.0370,  0.0213],\n",
       "           [ 0.0463,  0.0128,  0.0561],\n",
       "           [ 0.0460,  0.0432,  0.0354]],\n",
       " \n",
       "          [[ 0.0056,  0.0251, -0.0275],\n",
       "           [-0.0217, -0.0106, -0.0001],\n",
       "           [-0.0148, -0.0204, -0.0180]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0117,  0.0274,  0.0309],\n",
       "           [ 0.0116,  0.0345,  0.0275],\n",
       "           [ 0.0331,  0.0164,  0.0148]],\n",
       " \n",
       "          [[-0.0213,  0.0099, -0.0170],\n",
       "           [ 0.0057, -0.0116, -0.0054],\n",
       "           [ 0.0001, -0.0134,  0.0073]],\n",
       " \n",
       "          [[-0.0008, -0.0146, -0.0143],\n",
       "           [-0.0296, -0.0295, -0.0186],\n",
       "           [-0.0199, -0.0265, -0.0155]]],\n",
       " \n",
       " \n",
       "         [[[-0.0068,  0.0151,  0.0117],\n",
       "           [ 0.0045, -0.0115,  0.0128],\n",
       "           [-0.0178,  0.0031, -0.0086]],\n",
       " \n",
       "          [[-0.0133, -0.0181,  0.0154],\n",
       "           [ 0.0233,  0.0079,  0.0286],\n",
       "           [ 0.0070, -0.0101,  0.0032]],\n",
       " \n",
       "          [[ 0.0071, -0.0087, -0.0076],\n",
       "           [ 0.0027,  0.0010, -0.0135],\n",
       "           [-0.0109, -0.0014,  0.0040]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0048,  0.0084,  0.0042],\n",
       "           [-0.0162, -0.0146, -0.0154],\n",
       "           [-0.0113,  0.0057,  0.0101]],\n",
       " \n",
       "          [[-0.0011,  0.0149,  0.0121],\n",
       "           [-0.0038, -0.0016,  0.0170],\n",
       "           [ 0.0127,  0.0094,  0.0049]],\n",
       " \n",
       "          [[ 0.0105,  0.0034,  0.0218],\n",
       "           [ 0.0219,  0.0010, -0.0022],\n",
       "           [-0.0073, -0.0139, -0.0061]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0064, -0.0146, -0.0091],\n",
       "           [ 0.0109,  0.0182, -0.0131],\n",
       "           [ 0.0216, -0.0018, -0.0031]],\n",
       " \n",
       "          [[ 0.0011, -0.0107,  0.0073],\n",
       "           [ 0.0031, -0.0117, -0.0232],\n",
       "           [-0.0061,  0.0092,  0.0049]],\n",
       " \n",
       "          [[-0.0021,  0.0205,  0.0190],\n",
       "           [ 0.0078, -0.0271,  0.0062],\n",
       "           [ 0.0013, -0.0182,  0.0156]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0120, -0.0133,  0.0069],\n",
       "           [ 0.0203,  0.0228,  0.0133],\n",
       "           [ 0.0216,  0.0179,  0.0136]],\n",
       " \n",
       "          [[-0.0114, -0.0063,  0.0149],\n",
       "           [-0.0040, -0.0117, -0.0022],\n",
       "           [-0.0059,  0.0071,  0.0021]],\n",
       " \n",
       "          [[-0.0016, -0.0197, -0.0047],\n",
       "           [-0.0084, -0.0055, -0.0078],\n",
       "           [-0.0243,  0.0059,  0.0094]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0033, -0.0088, -0.0022],\n",
       "           [ 0.0148,  0.0168,  0.0178],\n",
       "           [ 0.0139, -0.0160,  0.0130]],\n",
       " \n",
       "          [[-0.0269,  0.0094, -0.0009],\n",
       "           [-0.0087,  0.0205,  0.0080],\n",
       "           [ 0.0017,  0.0026,  0.0032]],\n",
       " \n",
       "          [[-0.0024,  0.0156, -0.0147],\n",
       "           [ 0.0086,  0.0316,  0.0234],\n",
       "           [-0.0007,  0.0001,  0.0118]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0144, -0.0137,  0.0084],\n",
       "           [ 0.0075, -0.0078,  0.0055],\n",
       "           [-0.0188,  0.0033,  0.0016]],\n",
       " \n",
       "          [[ 0.0057,  0.0095, -0.0179],\n",
       "           [ 0.0055,  0.0030,  0.0233],\n",
       "           [ 0.0005,  0.0120, -0.0067]],\n",
       " \n",
       "          [[-0.0053,  0.0185,  0.0094],\n",
       "           [-0.0083,  0.0170,  0.0093],\n",
       "           [ 0.0097,  0.0137, -0.0050]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0168, -0.0120,  0.0101],\n",
       "           [-0.0165,  0.0023,  0.0156],\n",
       "           [ 0.0150,  0.0119, -0.0139]],\n",
       " \n",
       "          [[-0.0018,  0.0044, -0.0028],\n",
       "           [-0.0004, -0.0116,  0.0017],\n",
       "           [ 0.0006, -0.0142,  0.0016]],\n",
       " \n",
       "          [[ 0.0090,  0.0073, -0.0023],\n",
       "           [ 0.0111, -0.0076,  0.0064],\n",
       "           [ 0.0183, -0.0133, -0.0010]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0144,  0.0022, -0.0017],\n",
       "           [-0.0112, -0.0010,  0.0158],\n",
       "           [-0.0150, -0.0127,  0.0091]],\n",
       " \n",
       "          [[ 0.0048, -0.0074, -0.0016],\n",
       "           [-0.0212, -0.0104, -0.0161],\n",
       "           [-0.0162,  0.0056, -0.0093]],\n",
       " \n",
       "          [[-0.0155,  0.0029, -0.0163],\n",
       "           [-0.0062,  0.0065,  0.0069],\n",
       "           [-0.0145, -0.0152, -0.0177]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0213,  0.0227,  0.0035],\n",
       "           [-0.0162,  0.0030,  0.0187],\n",
       "           [ 0.0065,  0.0150,  0.0069]],\n",
       " \n",
       "          [[ 0.0150,  0.0030, -0.0026],\n",
       "           [-0.0263, -0.0152, -0.0057],\n",
       "           [-0.0044, -0.0085,  0.0083]],\n",
       " \n",
       "          [[-0.0014, -0.0167,  0.0185],\n",
       "           [-0.0161,  0.0142,  0.0058],\n",
       "           [ 0.0119,  0.0307,  0.0138]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0040, -0.0023, -0.0121],\n",
       "           [-0.0011, -0.0027, -0.0113],\n",
       "           [-0.0294, -0.0072,  0.0044]],\n",
       " \n",
       "          [[ 0.0045, -0.0091, -0.0080],\n",
       "           [-0.0124,  0.0091,  0.0081],\n",
       "           [ 0.0096,  0.0028,  0.0052]],\n",
       " \n",
       "          [[ 0.0241,  0.0273,  0.0023],\n",
       "           [ 0.0095,  0.0076,  0.0210],\n",
       "           [ 0.0165,  0.0213,  0.0098]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_2_0_in_layers_2.lora_up.weight': tensor([[[[-0.0056]],\n",
       " \n",
       "          [[ 0.0034]],\n",
       " \n",
       "          [[-0.0049]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0002]],\n",
       " \n",
       "          [[-0.0077]],\n",
       " \n",
       "          [[-0.0023]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0229]],\n",
       " \n",
       "          [[ 0.0137]],\n",
       " \n",
       "          [[-0.0100]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0062]],\n",
       " \n",
       "          [[-0.0129]],\n",
       " \n",
       "          [[-0.0050]]],\n",
       " \n",
       " \n",
       "         [[[-0.0161]],\n",
       " \n",
       "          [[ 0.0030]],\n",
       " \n",
       "          [[-0.0029]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0031]],\n",
       " \n",
       "          [[-0.0061]],\n",
       " \n",
       "          [[ 0.0083]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0086]],\n",
       " \n",
       "          [[-0.0007]],\n",
       " \n",
       "          [[ 0.0065]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0095]],\n",
       " \n",
       "          [[ 0.0090]],\n",
       " \n",
       "          [[-0.0015]]],\n",
       " \n",
       " \n",
       "         [[[-0.0200]],\n",
       " \n",
       "          [[-0.0165]],\n",
       " \n",
       "          [[ 0.0086]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0067]],\n",
       " \n",
       "          [[ 0.0143]],\n",
       " \n",
       "          [[-0.0010]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0300]],\n",
       " \n",
       "          [[-0.0018]],\n",
       " \n",
       "          [[ 0.0042]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0032]],\n",
       " \n",
       "          [[ 0.0042]],\n",
       " \n",
       "          [[-0.0161]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_2_0_out_layers_3.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_2_0_out_layers_3.lora_down.weight': tensor([[[[ 2.2812e-02,  1.5915e-02,  6.2218e-03],\n",
       "           [ 1.1818e-02,  3.5801e-03, -3.8166e-03],\n",
       "           [ 4.2633e-02,  2.8702e-02,  2.4780e-02]],\n",
       " \n",
       "          [[-7.1335e-03,  1.7670e-02,  1.9821e-02],\n",
       "           [-9.0332e-03,  6.0272e-03,  7.7095e-03],\n",
       "           [-1.3000e-02,  1.8372e-02,  7.5579e-04]],\n",
       " \n",
       "          [[-7.2174e-03,  1.1513e-02, -9.0866e-03],\n",
       "           [ 2.1027e-02, -1.1425e-03,  2.2293e-02],\n",
       "           [ 1.7624e-02,  2.8782e-03,  1.5167e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5022e-02,  1.2276e-02,  2.9907e-02],\n",
       "           [ 8.4000e-03,  2.2903e-02,  3.2654e-03],\n",
       "           [ 1.3321e-02,  3.2864e-03,  1.2711e-02]],\n",
       " \n",
       "          [[-5.0659e-03,  4.9438e-03,  1.7288e-02],\n",
       "           [-3.4027e-03,  2.5070e-02,  1.3885e-02],\n",
       "           [ 2.5131e-02,  2.4765e-02,  2.1317e-02]],\n",
       " \n",
       "          [[ 3.9756e-05,  8.7967e-03,  1.3168e-02],\n",
       "           [-1.6876e-02, -1.3542e-02,  1.6083e-02],\n",
       "           [-2.5535e-04,  5.2223e-03,  1.1425e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 5.0774e-03,  1.8250e-02,  4.0359e-03],\n",
       "           [ 2.2621e-03,  3.6469e-03,  2.7740e-02],\n",
       "           [ 2.2018e-02,  3.5858e-03,  2.5299e-02]],\n",
       " \n",
       "          [[-3.8509e-03,  1.7838e-02, -3.1090e-03],\n",
       "           [-1.2863e-02,  2.2339e-02,  4.0894e-03],\n",
       "           [ 9.4452e-03,  1.3420e-02, -3.6621e-03]],\n",
       " \n",
       "          [[ 4.0936e-04, -5.3291e-03, -1.5287e-03],\n",
       "           [ 2.4776e-03,  2.5726e-02,  5.6267e-03],\n",
       "           [-1.0651e-02,  1.0056e-02, -7.2250e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6159e-02,  2.7100e-02,  5.5542e-03],\n",
       "           [ 9.3689e-03,  2.8885e-02,  3.1372e-02],\n",
       "           [ 1.3405e-02,  1.2413e-02,  2.4994e-02]],\n",
       " \n",
       "          [[-7.5874e-03,  1.0445e-02,  1.8250e-02],\n",
       "           [-1.1454e-03, -1.0765e-02,  1.4984e-02],\n",
       "           [ 2.5970e-02,  6.4926e-03,  1.0422e-02]],\n",
       " \n",
       "          [[ 7.9346e-03, -1.6766e-03, -5.5504e-03],\n",
       "           [-2.1423e-02, -2.2064e-02,  1.3367e-02],\n",
       "           [-2.2717e-03, -4.8065e-04, -1.7166e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 3.4485e-02,  9.3079e-03,  6.8665e-03],\n",
       "           [ 1.4244e-02,  2.5391e-02,  2.6459e-02],\n",
       "           [ 2.4780e-02,  2.3376e-02,  6.2675e-03]],\n",
       " \n",
       "          [[-1.3199e-02,  1.2993e-02,  1.4816e-02],\n",
       "           [ 1.9608e-02,  2.3331e-02,  6.2904e-03],\n",
       "           [ 1.1482e-03, -6.9008e-03, -1.6785e-03]],\n",
       " \n",
       "          [[-6.1531e-03, -6.9084e-03,  5.3825e-03],\n",
       "           [-1.4198e-02,  1.8341e-02, -7.5874e-03],\n",
       "           [-1.2741e-03, -5.7106e-03, -2.2430e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.1606e-02,  5.2109e-03,  9.2621e-03],\n",
       "           [ 1.8570e-02,  1.3084e-02,  2.0657e-03],\n",
       "           [ 1.1734e-02,  9.7656e-03,  1.0208e-02]],\n",
       " \n",
       "          [[ 1.3382e-02,  1.1574e-02,  2.7313e-02],\n",
       "           [-5.8289e-03,  3.6488e-03, -1.9943e-02],\n",
       "           [-1.5282e-02, -1.3981e-03,  7.8011e-03]],\n",
       " \n",
       "          [[ 2.9030e-03, -3.7422e-03,  1.9928e-02],\n",
       "           [ 1.6724e-02, -1.4267e-02,  1.2444e-02],\n",
       "           [-1.0300e-02,  6.3667e-03,  8.5449e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.2314e-02,  1.8005e-02,  2.9480e-02],\n",
       "           [ 8.8043e-03,  1.5421e-03,  2.8992e-02],\n",
       "           [ 4.0283e-02,  2.9984e-02,  3.1113e-02]],\n",
       " \n",
       "          [[-1.2360e-02, -6.0511e-04,  1.2138e-02],\n",
       "           [ 2.5921e-03,  8.5602e-03, -1.7578e-02],\n",
       "           [-1.9730e-02,  1.7822e-02,  1.5808e-02]],\n",
       " \n",
       "          [[ 2.6855e-02,  1.7609e-02,  6.0959e-03],\n",
       "           [ 1.6708e-02,  1.4221e-02,  1.1154e-02],\n",
       "           [ 1.8250e-02,  3.3054e-03,  1.4753e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.2255e-03,  1.4755e-02, -1.6460e-03],\n",
       "           [ 2.0046e-03,  2.9633e-02,  5.4283e-03],\n",
       "           [ 7.1907e-03,  1.6357e-02,  2.9678e-02]],\n",
       " \n",
       "          [[ 1.8631e-02, -9.6664e-03, -9.0485e-03],\n",
       "           [ 1.4105e-03, -1.3647e-03,  6.4516e-04],\n",
       "           [-1.0307e-02,  1.2398e-02, -2.6932e-03]],\n",
       " \n",
       "          [[-8.4991e-03,  1.1116e-02, -1.3771e-02],\n",
       "           [ 9.8419e-03,  1.0582e-02, -1.3725e-02],\n",
       "           [ 5.3368e-03, -6.4774e-03, -2.3209e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.7390e-03,  2.7676e-03, -8.3771e-03],\n",
       "           [ 6.0692e-03, -2.2903e-02, -9.4223e-03],\n",
       "           [-3.3356e-02, -1.6357e-02, -1.8646e-02]],\n",
       " \n",
       "          [[-1.8417e-02, -1.8143e-02,  6.2828e-03],\n",
       "           [-1.1497e-02, -1.0826e-02, -6.4201e-03],\n",
       "           [-6.0463e-03,  5.9929e-03,  4.4708e-03]],\n",
       " \n",
       "          [[-6.5193e-03,  4.3583e-04, -4.3716e-03],\n",
       "           [-5.7373e-03, -1.2947e-02, -2.0462e-02],\n",
       "           [-2.2400e-02, -3.0472e-02, -8.1863e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 8.9493e-03, -2.1393e-02, -3.9558e-03],\n",
       "           [ 1.2695e-02,  1.2741e-02,  1.5366e-02],\n",
       "           [ 1.6312e-02,  4.6086e-04,  8.1406e-03]],\n",
       " \n",
       "          [[-3.3264e-03, -2.0782e-02, -1.7061e-03],\n",
       "           [-5.9223e-04, -8.1253e-03, -4.5395e-03],\n",
       "           [-7.0839e-03, -2.2095e-02,  1.6113e-02]],\n",
       " \n",
       "          [[ 9.7885e-03, -1.6571e-02, -5.1575e-03],\n",
       "           [-2.1866e-02, -1.4153e-02, -4.0650e-04],\n",
       "           [-1.8936e-02,  1.9341e-03,  5.6725e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 4.2038e-03,  9.2316e-03,  4.0245e-03],\n",
       "           [-4.1962e-03,  8.2932e-03, -1.0063e-02],\n",
       "           [ 2.4124e-02,  2.4582e-02,  2.4002e-02]],\n",
       " \n",
       "          [[ 2.2736e-02,  2.5272e-04,  5.9738e-03],\n",
       "           [-4.5738e-03, -8.4457e-03,  1.7487e-02],\n",
       "           [-9.1476e-03,  2.0294e-02,  1.3504e-02]],\n",
       " \n",
       "          [[ 2.2095e-02,  6.8207e-03,  2.2324e-02],\n",
       "           [ 1.5381e-02,  5.1346e-03, -1.4641e-02],\n",
       "           [-2.7943e-03,  3.3142e-02,  2.0874e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.0960e-04,  9.1553e-03,  4.8566e-04],\n",
       "           [ 2.1610e-03,  8.5831e-03, -1.0483e-02],\n",
       "           [-1.7151e-02,  1.0216e-02,  2.3010e-02]],\n",
       " \n",
       "          [[ 1.5503e-02, -3.9597e-03, -1.6266e-02],\n",
       "           [ 1.3947e-02, -5.9052e-03,  1.7960e-02],\n",
       "           [ 3.5057e-03, -4.2963e-04, -6.5536e-03]],\n",
       " \n",
       "          [[ 4.7569e-03, -2.1076e-03, -7.2212e-03],\n",
       "           [ 2.4628e-02,  1.1993e-02,  1.1330e-02],\n",
       "           [-1.2093e-02, -4.2629e-04,  3.1719e-03]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_2_0_out_layers_3.lora_up.weight': tensor([[[[ 0.0105]],\n",
       " \n",
       "          [[ 0.0153]],\n",
       " \n",
       "          [[ 0.0024]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0073]],\n",
       " \n",
       "          [[-0.0178]],\n",
       " \n",
       "          [[ 0.0207]]],\n",
       " \n",
       " \n",
       "         [[[-0.0081]],\n",
       " \n",
       "          [[-0.0023]],\n",
       " \n",
       "          [[-0.0076]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0004]],\n",
       " \n",
       "          [[-0.0040]],\n",
       " \n",
       "          [[ 0.0059]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0068]],\n",
       " \n",
       "          [[ 0.0049]],\n",
       " \n",
       "          [[-0.0088]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0020]],\n",
       " \n",
       "          [[ 0.0107]],\n",
       " \n",
       "          [[-0.0012]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0272]],\n",
       " \n",
       "          [[-0.0242]],\n",
       " \n",
       "          [[-0.0021]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0215]],\n",
       " \n",
       "          [[ 0.0268]],\n",
       " \n",
       "          [[-0.0227]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0091]],\n",
       " \n",
       "          [[ 0.0056]],\n",
       " \n",
       "          [[-0.0168]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0081]],\n",
       " \n",
       "          [[-0.0131]],\n",
       " \n",
       "          [[ 0.0090]]],\n",
       " \n",
       " \n",
       "         [[[-0.0090]],\n",
       " \n",
       "          [[-0.0129]],\n",
       " \n",
       "          [[-0.0277]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0111]],\n",
       " \n",
       "          [[-0.0054]],\n",
       " \n",
       "          [[ 0.0051]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_3_0_op.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_3_0_op.lora_down.weight': tensor([[[[ 2.2644e-02, -2.8858e-03, -1.3062e-02],\n",
       "           [ 3.1967e-03, -3.0499e-03,  2.0767e-02],\n",
       "           [ 2.2919e-02,  1.0002e-02,  2.2232e-02]],\n",
       " \n",
       "          [[ 1.0872e-02, -1.9178e-03, -8.6288e-03],\n",
       "           [-4.1466e-03, -2.2842e-02, -1.5465e-02],\n",
       "           [-2.1100e-05, -8.5068e-03,  1.4870e-02]],\n",
       " \n",
       "          [[ 8.3847e-03,  1.2093e-02, -8.0109e-03],\n",
       "           [-6.9275e-03, -1.5358e-02,  4.8714e-03],\n",
       "           [ 8.6899e-03,  2.6245e-03, -2.2797e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.7564e-03, -2.0309e-02, -8.3466e-03],\n",
       "           [-2.4017e-02, -3.0792e-02, -7.9498e-03],\n",
       "           [-1.8814e-02, -1.0506e-02, -2.2011e-03]],\n",
       " \n",
       "          [[ 6.8817e-03,  8.9417e-03, -1.5442e-02],\n",
       "           [ 1.4282e-02,  1.4252e-02,  2.2675e-02],\n",
       "           [-1.0025e-02,  1.5289e-02,  1.6754e-02]],\n",
       " \n",
       "          [[-1.9730e-02,  1.4389e-02, -1.6296e-02],\n",
       "           [-5.7745e-04, -1.0345e-02, -3.8242e-03],\n",
       "           [ 1.2558e-02,  1.2321e-02, -1.0328e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.3199e-02, -1.8707e-02,  7.0229e-03],\n",
       "           [-1.1177e-02,  9.2621e-03, -4.3640e-03],\n",
       "           [-1.9007e-03, -2.2690e-02, -1.5068e-02]],\n",
       " \n",
       "          [[-1.4008e-02,  1.0109e-02,  2.8515e-03],\n",
       "           [ 1.1101e-02, -6.1455e-03,  1.6708e-02],\n",
       "           [-2.0477e-02, -6.3782e-03, -1.2100e-02]],\n",
       " \n",
       "          [[-1.6876e-02,  1.7197e-02,  2.1896e-02],\n",
       "           [-6.6519e-04, -3.8395e-03,  1.3382e-02],\n",
       "           [-1.8753e-02, -7.8583e-03, -2.0279e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.2995e-02,  3.3661e-02,  1.0048e-02],\n",
       "           [ 2.7481e-02,  2.7191e-02,  2.1835e-02],\n",
       "           [ 1.2794e-02,  2.3331e-02,  2.4475e-02]],\n",
       " \n",
       "          [[ 3.1586e-03, -5.8060e-03,  4.1161e-03],\n",
       "           [-1.3962e-03, -1.0803e-02,  5.3825e-03],\n",
       "           [-1.9089e-02, -2.7710e-02, -2.1545e-02]],\n",
       " \n",
       "          [[ 2.0275e-03, -1.7151e-02, -1.0956e-02],\n",
       "           [-3.2940e-03,  1.4870e-02,  9.7427e-03],\n",
       "           [-2.7733e-03, -1.9012e-02, -1.4923e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.3092e-03,  7.3776e-03,  2.1637e-02],\n",
       "           [ 6.6910e-03, -2.3056e-02,  7.2556e-03],\n",
       "           [ 7.2517e-03, -4.3755e-03,  2.5650e-02]],\n",
       " \n",
       "          [[ 1.0994e-02, -2.1683e-02, -1.6678e-02],\n",
       "           [-1.4183e-02, -1.0254e-02, -8.1482e-03],\n",
       "           [ 2.8286e-03, -1.4709e-02, -3.0441e-03]],\n",
       " \n",
       "          [[-9.7198e-03, -2.9968e-02, -1.3603e-02],\n",
       "           [-4.2343e-03, -8.1482e-03, -1.2619e-02],\n",
       "           [-8.2855e-03,  1.0742e-02,  2.0714e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.2100e-02, -3.1643e-03, -3.0289e-02],\n",
       "           [-2.9984e-02, -3.2898e-02, -2.9205e-02],\n",
       "           [-2.2144e-03, -2.2217e-02, -1.3596e-02]],\n",
       " \n",
       "          [[ 6.1531e-03, -1.2165e-04, -1.6861e-02],\n",
       "           [ 3.1376e-03, -5.5809e-03, -1.5137e-02],\n",
       "           [-1.1879e-02, -1.7147e-03, -7.8430e-03]],\n",
       " \n",
       "          [[-2.1942e-02, -1.2657e-02,  1.3077e-02],\n",
       "           [-3.1796e-03, -9.3994e-03, -8.8196e-03],\n",
       "           [-1.8784e-02, -1.6174e-03, -6.4774e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.0338e-02,  1.6495e-02,  8.3694e-03],\n",
       "           [ 2.9282e-02,  2.7580e-03,  1.0002e-02],\n",
       "           [-1.2131e-03,  1.3840e-02,  1.6739e-02]],\n",
       " \n",
       "          [[ 1.8890e-02,  1.7185e-03, -9.4757e-03],\n",
       "           [-2.1194e-02, -2.5742e-02,  6.7101e-03],\n",
       "           [ 1.2833e-02,  1.9588e-03,  4.8599e-03]],\n",
       " \n",
       "          [[-2.2400e-02, -1.9928e-02, -2.1957e-02],\n",
       "           [-2.6184e-02,  1.1185e-02,  4.9553e-03],\n",
       "           [ 2.7466e-03, -6.1455e-03,  6.5765e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7481e-03,  7.7591e-03, -2.1698e-02],\n",
       "           [-2.7222e-02, -1.8188e-02, -3.2684e-02],\n",
       "           [-1.0849e-02, -4.7798e-03,  3.7308e-03]],\n",
       " \n",
       "          [[ 2.0782e-02,  1.9547e-02, -1.2444e-02],\n",
       "           [ 1.9970e-03,  2.2568e-02,  4.2114e-03],\n",
       "           [ 3.4122e-03, -3.8662e-03, -7.2708e-03]],\n",
       " \n",
       "          [[-8.1711e-03, -1.5961e-02,  9.5520e-03],\n",
       "           [-1.8768e-02, -1.8372e-02, -1.0490e-03],\n",
       "           [-8.5220e-03,  4.4708e-03,  1.4526e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.4704e-02, -3.3966e-02, -2.8030e-02],\n",
       "           [-2.7359e-02, -8.2321e-03, -7.1602e-03],\n",
       "           [-2.8534e-02, -2.2507e-02, -2.4109e-02]],\n",
       " \n",
       "          [[ 3.1624e-03,  3.2578e-03,  1.4519e-02],\n",
       "           [ 2.0737e-02, -1.0590e-02, -3.2520e-03],\n",
       "           [ 3.1414e-03,  1.1200e-02, -7.5302e-03]],\n",
       " \n",
       "          [[-1.0788e-02, -5.2032e-03,  1.7715e-02],\n",
       "           [-8.5526e-03, -2.4338e-03, -8.4076e-03],\n",
       "           [ 8.0681e-04,  2.4628e-02, -1.3218e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.1719e-02,  2.1317e-02,  3.5889e-02],\n",
       "           [ 1.9882e-02,  1.8250e-02,  1.1505e-02],\n",
       "           [ 3.1082e-02,  1.8906e-02,  4.1473e-02]],\n",
       " \n",
       "          [[-1.2939e-02, -2.5620e-02,  6.9160e-03],\n",
       "           [ 6.2981e-03, -1.7242e-02, -3.6869e-03],\n",
       "           [-9.4299e-03, -2.8320e-02, -2.1027e-02]],\n",
       " \n",
       "          [[ 1.5732e-02,  1.5030e-02, -1.1192e-02],\n",
       "           [ 1.6510e-02,  3.6640e-03,  1.3306e-02],\n",
       "           [-1.2314e-02, -1.0735e-02,  1.3313e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.5144e-02, -2.8915e-02, -3.5736e-02],\n",
       "           [ 4.4861e-03, -4.2725e-03, -3.7231e-02],\n",
       "           [-2.6199e-02, -2.5879e-02, -1.1169e-02]],\n",
       " \n",
       "          [[-6.8130e-03,  9.5444e-03,  3.0785e-03],\n",
       "           [-2.7370e-03,  9.4833e-03,  2.0660e-02],\n",
       "           [ 1.8784e-02,  6.0997e-03,  3.5763e-03]],\n",
       " \n",
       "          [[-3.9864e-03,  1.5602e-02, -2.7695e-03],\n",
       "           [ 3.2349e-02, -1.1757e-02, -2.5272e-03],\n",
       "           [ 5.0964e-03,  6.3286e-03,  1.7578e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.1772e-02,  1.7700e-02,  1.3008e-02],\n",
       "           [ 2.5131e-02,  1.8291e-03,  1.8173e-02],\n",
       "           [-6.1989e-03,  1.4297e-02,  1.2306e-02]],\n",
       " \n",
       "          [[-1.4206e-02, -2.4246e-02, -1.5854e-02],\n",
       "           [-4.1351e-02, -1.6861e-02, -1.0872e-02],\n",
       "           [-2.3697e-02, -1.9485e-02, -2.0004e-02]],\n",
       " \n",
       "          [[ 1.0979e-02,  5.9471e-03,  2.4628e-02],\n",
       "           [ 3.6659e-03, -6.8970e-03,  1.4328e-02],\n",
       "           [-7.3662e-03,  6.1035e-03, -3.0365e-03]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_3_0_op.lora_up.weight': tensor([[[[ 0.0016]],\n",
       " \n",
       "          [[ 0.0083]],\n",
       " \n",
       "          [[ 0.0007]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0088]],\n",
       " \n",
       "          [[ 0.0090]],\n",
       " \n",
       "          [[ 0.0162]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0156]],\n",
       " \n",
       "          [[-0.0246]],\n",
       " \n",
       "          [[ 0.0171]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0257]],\n",
       " \n",
       "          [[-0.0292]],\n",
       " \n",
       "          [[-0.0341]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0297]],\n",
       " \n",
       "          [[-0.0269]],\n",
       " \n",
       "          [[ 0.0265]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0273]],\n",
       " \n",
       "          [[-0.0316]],\n",
       " \n",
       "          [[-0.0119]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0077]],\n",
       " \n",
       "          [[ 0.0048]],\n",
       " \n",
       "          [[ 0.0135]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0157]],\n",
       " \n",
       "          [[-0.0059]],\n",
       " \n",
       "          [[-0.0059]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0006]],\n",
       " \n",
       "          [[-0.0025]],\n",
       " \n",
       "          [[ 0.0119]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0048]],\n",
       " \n",
       "          [[ 0.0043]],\n",
       " \n",
       "          [[ 0.0064]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0025]],\n",
       " \n",
       "          [[-0.0092]],\n",
       " \n",
       "          [[-0.0056]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0133]],\n",
       " \n",
       "          [[-0.0053]],\n",
       " \n",
       "          [[-0.0146]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_emb_layers_1.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_emb_layers_1.lora_down.weight': tensor([[-0.0159,  0.0144,  0.0265,  ..., -0.0095,  0.0209,  0.0362],\n",
       "         [ 0.0288,  0.0146,  0.0271,  ..., -0.0176,  0.0131, -0.0130],\n",
       "         [-0.0068,  0.0019, -0.0170,  ..., -0.0282,  0.0123, -0.0145],\n",
       "         ...,\n",
       "         [-0.0077,  0.0150, -0.0045,  ..., -0.0291,  0.0194,  0.0274],\n",
       "         [ 0.0170, -0.0138,  0.0055,  ..., -0.0254, -0.0188,  0.0096],\n",
       "         [ 0.0270, -0.0187,  0.0083,  ..., -0.0190,  0.0134,  0.0136]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_emb_layers_1.lora_up.weight': tensor([[-1.4145e-02, -1.8829e-02, -1.6464e-02,  ..., -1.4671e-02,\n",
       "          -1.5434e-02, -2.1912e-02],\n",
       "         [ 1.9264e-03,  5.0735e-03,  6.8283e-03,  ...,  6.6109e-03,\n",
       "          -4.3249e-04,  9.1705e-03],\n",
       "         [ 2.2705e-02,  1.2413e-02,  1.3359e-02,  ...,  7.4921e-03,\n",
       "           5.9547e-03,  1.2062e-02],\n",
       "         ...,\n",
       "         [ 6.5079e-03,  4.6492e-06, -4.2725e-03,  ...,  3.8910e-03,\n",
       "           2.9469e-04, -5.6038e-03],\n",
       "         [ 1.7639e-02,  2.3544e-02,  2.3468e-02,  ...,  2.1133e-02,\n",
       "           1.5961e-02,  2.2552e-02],\n",
       "         [ 8.5068e-03,  1.9722e-03,  5.2261e-03,  ...,  1.2634e-02,\n",
       "           7.0343e-03,  4.1428e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_in_layers_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_in_layers_2.lora_down.weight': tensor([[[[-5.0430e-03,  1.7990e-02,  9.1553e-04],\n",
       "           [ 1.1772e-02,  5.9853e-03,  1.2352e-02],\n",
       "           [ 1.3641e-02,  7.7915e-04,  1.9348e-02]],\n",
       " \n",
       "          [[-5.1308e-03,  2.2217e-02,  1.7075e-02],\n",
       "           [-1.1581e-02, -1.1642e-02, -4.7989e-03],\n",
       "           [-6.6185e-03,  1.1505e-02,  9.1553e-03]],\n",
       " \n",
       "          [[-1.0475e-02, -2.0051e-04,  7.9346e-03],\n",
       "           [-2.2690e-02, -1.4236e-02, -1.1665e-02],\n",
       "           [-1.6663e-02, -2.2705e-02, -2.2461e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.7288e-02,  2.8419e-03, -9.1705e-03],\n",
       "           [ 7.1945e-03, -1.2825e-02,  2.1042e-02],\n",
       "           [-5.5237e-03,  1.4626e-02, -2.4986e-03]],\n",
       " \n",
       "          [[-2.1042e-02, -5.9853e-03,  2.0428e-03],\n",
       "           [-2.0798e-02, -3.1555e-02, -2.1530e-02],\n",
       "           [-2.4841e-02, -1.2039e-02,  5.3101e-03]],\n",
       " \n",
       "          [[-9.9564e-03,  6.0959e-03, -9.9411e-03],\n",
       "           [ 8.5831e-03, -3.1834e-03, -2.5620e-02],\n",
       "           [-1.9180e-02,  4.4022e-03,  1.4717e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.1620e-02, -1.0101e-02, -2.2964e-02],\n",
       "           [-2.0233e-02, -1.9241e-02, -9.4757e-03],\n",
       "           [ 1.4839e-03, -2.4078e-02, -1.1688e-02]],\n",
       " \n",
       "          [[-3.8505e-05,  1.7044e-02,  2.0771e-03],\n",
       "           [-5.6839e-03, -4.2305e-03,  3.2978e-03],\n",
       "           [ 2.3300e-02,  2.8870e-02,  2.8625e-02]],\n",
       " \n",
       "          [[ 2.7435e-02,  2.4750e-02,  1.3298e-02],\n",
       "           [ 1.8143e-02,  1.0002e-02,  3.1174e-02],\n",
       "           [ 1.3161e-02,  1.6556e-02,  6.7863e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.1189e-02,  2.5818e-02,  4.2152e-03],\n",
       "           [ 2.9495e-02,  2.3712e-02,  1.6418e-02],\n",
       "           [ 3.2623e-02,  1.7838e-02,  1.6571e-02]],\n",
       " \n",
       "          [[-2.1057e-02,  7.2594e-03, -1.3359e-02],\n",
       "           [ 1.6708e-02, -1.4595e-02,  5.8594e-03],\n",
       "           [-1.3552e-03,  2.4629e-04, -9.0179e-03]],\n",
       " \n",
       "          [[-5.4970e-03,  1.7914e-02, -2.3232e-03],\n",
       "           [ 1.2711e-02,  1.2123e-02,  1.7029e-02],\n",
       "           [-9.8419e-03, -1.0574e-02,  1.3065e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 6.4049e-03, -2.9202e-03, -2.0584e-02],\n",
       "           [-1.0063e-02, -1.7792e-02, -2.0721e-02],\n",
       "           [ 4.0932e-03, -1.1101e-02, -9.3613e-03]],\n",
       " \n",
       "          [[-2.4338e-02,  7.2441e-03, -1.0918e-02],\n",
       "           [ 2.0508e-02, -5.3596e-03,  1.5955e-03],\n",
       "           [ 1.6312e-02, -2.9488e-03,  3.3150e-03]],\n",
       " \n",
       "          [[ 8.8882e-03,  1.1436e-02, -1.6556e-02],\n",
       "           [-1.4343e-02, -9.5596e-03,  8.2626e-03],\n",
       "           [-8.6823e-03,  1.3687e-02,  1.3939e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.8426e-04, -7.4921e-03, -9.3384e-03],\n",
       "           [ 3.5496e-03, -2.3899e-03, -7.6714e-03],\n",
       "           [ 9.1324e-03,  1.5503e-02, -1.1566e-02]],\n",
       " \n",
       "          [[ 2.7740e-02,  2.8061e-02,  2.7344e-02],\n",
       "           [ 2.7145e-02,  4.0802e-02,  3.0106e-02],\n",
       "           [ 2.8427e-02,  2.9678e-02,  1.3596e-02]],\n",
       " \n",
       "          [[ 3.6530e-02,  3.4119e-02,  2.5665e-02],\n",
       "           [ 1.8600e-02,  3.0807e-02,  2.4719e-02],\n",
       "           [ 4.5967e-03, -3.1972e-04,  1.4374e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.3971e-03,  2.0523e-02,  1.1024e-02],\n",
       "           [ 6.3934e-03, -1.6953e-02,  5.1537e-03],\n",
       "           [-3.9268e-04, -1.4030e-02,  2.2011e-03]],\n",
       " \n",
       "          [[ 2.9648e-02,  4.1747e-04,  1.1024e-02],\n",
       "           [-1.3390e-02, -7.4120e-03,  1.0063e-02],\n",
       "           [-1.8101e-03,  7.5607e-03, -8.7833e-04]],\n",
       " \n",
       "          [[ 1.1854e-03,  9.4986e-04,  8.7023e-06],\n",
       "           [ 7.8735e-03, -1.0849e-02, -1.8204e-02],\n",
       "           [-8.7204e-03, -7.2098e-03, -2.1423e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.1199e-03, -6.1760e-03,  1.7349e-02],\n",
       "           [-1.4679e-02, -2.7847e-03, -8.3542e-04],\n",
       "           [ 1.9264e-03,  2.7218e-03,  1.0330e-02]],\n",
       " \n",
       "          [[-4.8828e-03, -2.7451e-02, -3.2196e-02],\n",
       "           [-1.8631e-02, -2.7634e-02, -4.8187e-02],\n",
       "           [-2.7023e-02, -1.4442e-02, -3.0945e-02]],\n",
       " \n",
       "          [[-2.9541e-02,  4.3869e-03, -4.5853e-03],\n",
       "           [-2.4170e-02, -1.7349e-02, -2.6245e-02],\n",
       "           [-5.2223e-03, -1.5053e-02, -1.5295e-04]]],\n",
       " \n",
       " \n",
       "         [[[-7.3013e-03, -1.3969e-02, -8.5068e-03],\n",
       "           [-2.0432e-02, -4.0016e-03,  4.7722e-03],\n",
       "           [-6.7139e-03,  5.2032e-03, -1.9867e-02]],\n",
       " \n",
       "          [[-1.9669e-02, -2.1591e-02, -2.1896e-02],\n",
       "           [ 9.6893e-03, -1.3359e-02, -5.1041e-03],\n",
       "           [ 2.2079e-02,  1.2695e-02,  4.2763e-03]],\n",
       " \n",
       "          [[-6.6872e-03,  8.6288e-03,  7.8583e-03],\n",
       "           [ 1.9318e-02,  1.7023e-03,  2.0569e-02],\n",
       "           [ 1.4313e-02, -5.8937e-03,  9.3842e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.3565e-02,  1.1301e-03, -1.7365e-02],\n",
       "           [-7.8125e-03,  2.4891e-03,  3.5515e-03],\n",
       "           [ 1.6613e-03,  8.4610e-03, -2.3682e-02]],\n",
       " \n",
       "          [[-1.2636e-03,  3.9196e-04,  9.0027e-03],\n",
       "           [ 1.2573e-02,  8.9951e-03,  4.4670e-03],\n",
       "           [ 3.2532e-02,  1.7410e-02,  2.5635e-02]],\n",
       " \n",
       "          [[ 3.5229e-03,  2.5406e-02,  2.7924e-02],\n",
       "           [ 2.1072e-02,  1.6266e-02,  1.9104e-02],\n",
       "           [-3.7575e-03, -1.4191e-02, -1.3733e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.2400e-02, -2.2110e-02, -3.4351e-03],\n",
       "           [-3.5858e-02, -2.2339e-02, -2.3071e-02],\n",
       "           [-4.3121e-02, -3.6621e-02, -1.2024e-02]],\n",
       " \n",
       "          [[-5.1193e-03,  4.5280e-03,  1.0300e-02],\n",
       "           [ 1.8234e-02, -3.8738e-03, -1.4595e-02],\n",
       "           [ 1.6281e-02,  1.4221e-02,  8.0032e-03]],\n",
       " \n",
       "          [[ 1.9699e-02, -9.8190e-03,  1.2302e-03],\n",
       "           [ 2.1172e-03, -3.7651e-03,  2.1393e-02],\n",
       "           [ 2.4063e-02,  2.5040e-02,  1.5442e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0925e-02, -2.1423e-02,  3.4695e-03],\n",
       "           [-7.9651e-03, -3.5187e-02, -9.9258e-03],\n",
       "           [-1.3054e-02, -2.5940e-02,  5.1079e-03]],\n",
       " \n",
       "          [[-2.8183e-02, -2.3117e-02, -2.7603e-02],\n",
       "           [-1.7033e-03, -4.3449e-03, -8.0719e-03],\n",
       "           [ 6.8703e-03,  1.9426e-03,  1.9627e-03]],\n",
       " \n",
       "          [[-4.2534e-03, -8.0872e-03,  2.9802e-04],\n",
       "           [-4.9353e-04,  1.0033e-02,  1.1597e-02],\n",
       "           [ 4.8714e-03, -1.9714e-02, -2.3697e-02]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_in_layers_2.lora_up.weight': tensor([[[[-0.0187]],\n",
       " \n",
       "          [[ 0.0062]],\n",
       " \n",
       "          [[ 0.0174]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0163]],\n",
       " \n",
       "          [[ 0.0156]],\n",
       " \n",
       "          [[ 0.0103]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0045]],\n",
       " \n",
       "          [[-0.0029]],\n",
       " \n",
       "          [[-0.0117]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0094]],\n",
       " \n",
       "          [[-0.0008]],\n",
       " \n",
       "          [[ 0.0097]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0165]],\n",
       " \n",
       "          [[-0.0209]],\n",
       " \n",
       "          [[-0.0144]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0131]],\n",
       " \n",
       "          [[-0.0114]],\n",
       " \n",
       "          [[-0.0055]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0065]],\n",
       " \n",
       "          [[ 0.0018]],\n",
       " \n",
       "          [[-0.0031]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0005]],\n",
       " \n",
       "          [[ 0.0058]],\n",
       " \n",
       "          [[ 0.0082]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0041]],\n",
       " \n",
       "          [[-0.0030]],\n",
       " \n",
       "          [[-0.0088]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0046]],\n",
       " \n",
       "          [[-0.0044]],\n",
       " \n",
       "          [[ 0.0040]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0209]],\n",
       " \n",
       "          [[-0.0187]],\n",
       " \n",
       "          [[-0.0085]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0160]],\n",
       " \n",
       "          [[-0.0207]],\n",
       " \n",
       "          [[-0.0253]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_out_layers_3.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_out_layers_3.lora_down.weight': tensor([[[[ 1.0223e-02,  1.6251e-02,  1.9028e-02],\n",
       "           [ 5.5809e-03,  3.0556e-03,  5.9724e-05],\n",
       "           [ 1.7334e-02,  1.3649e-02,  5.2109e-03]],\n",
       " \n",
       "          [[-5.8136e-03, -1.5808e-02, -1.9409e-02],\n",
       "           [-2.6672e-02, -1.5808e-02, -2.8915e-02],\n",
       "           [-1.2222e-02, -2.0035e-02, -3.0304e-02]],\n",
       " \n",
       "          [[ 5.0201e-03,  1.1330e-02, -5.9433e-03],\n",
       "           [ 6.7215e-03,  3.1681e-03,  7.6218e-03],\n",
       "           [ 4.6654e-03, -1.4580e-02, -1.2306e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.1543e-04,  5.3825e-03,  1.7212e-02],\n",
       "           [ 3.7746e-03,  2.4223e-03, -8.9824e-05],\n",
       "           [ 1.7578e-02,  1.1932e-02,  1.2169e-02]],\n",
       " \n",
       "          [[-5.4436e-03, -7.6714e-03,  8.8577e-03],\n",
       "           [-8.7738e-03, -6.2141e-03, -1.0014e-03],\n",
       "           [-1.4694e-02, -1.1467e-02,  3.1586e-03]],\n",
       " \n",
       "          [[ 1.3893e-02,  7.8201e-04,  4.9286e-03],\n",
       "           [ 6.9542e-03,  1.0986e-02, -3.7313e-04],\n",
       "           [-1.9016e-03, -6.4583e-03, -7.8812e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5736e-03, -5.4054e-03, -1.3840e-02],\n",
       "           [-1.0887e-02, -2.1687e-03, -6.0654e-04],\n",
       "           [-1.3523e-03, -1.0132e-02,  2.8400e-03]],\n",
       " \n",
       "          [[-2.1957e-02, -7.5645e-03, -5.9814e-03],\n",
       "           [-1.1932e-02, -1.5450e-02, -1.9012e-02],\n",
       "           [-1.4099e-02, -8.7585e-03, -1.4290e-02]],\n",
       " \n",
       "          [[-7.2975e-03, -1.9928e-02, -4.5128e-03],\n",
       "           [-1.4877e-03,  1.1185e-02, -9.6359e-03],\n",
       "           [-9.0561e-03, -1.5697e-03, -1.4687e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.8158e-02,  1.4236e-02,  3.4847e-03],\n",
       "           [ 2.1057e-02,  1.5930e-02,  1.5450e-02],\n",
       "           [ 3.1189e-02,  1.9562e-02,  1.8036e-02]],\n",
       " \n",
       "          [[-1.7197e-02, -1.3062e-02, -2.3060e-03],\n",
       "           [-8.5831e-03, -1.7548e-03,  9.4833e-03],\n",
       "           [-3.7689e-03, -1.7948e-03,  5.2299e-03]],\n",
       " \n",
       "          [[-4.1122e-03,  1.1772e-02, -4.0207e-03],\n",
       "           [-5.0163e-04, -5.4893e-03,  9.3842e-03],\n",
       "           [ 9.5749e-03,  7.0419e-03, -2.8634e-04]]],\n",
       " \n",
       " \n",
       "         [[[-1.3176e-02,  7.8659e-03,  5.2719e-03],\n",
       "           [ 2.2449e-03, -1.0590e-02,  6.2408e-03],\n",
       "           [-7.0038e-03, -3.5172e-03,  1.1253e-02]],\n",
       " \n",
       "          [[ 1.8606e-03,  1.8326e-02,  7.1526e-03],\n",
       "           [ 1.1261e-02,  1.3206e-02,  8.4839e-03],\n",
       "           [ 1.2291e-02,  2.5711e-02,  1.2718e-02]],\n",
       " \n",
       "          [[-5.6038e-03, -5.8937e-03, -1.1368e-02],\n",
       "           [ 8.9035e-03,  6.1913e-03, -7.2441e-03],\n",
       "           [ 1.2787e-02,  1.4030e-02,  6.8321e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.4923e-02,  2.9373e-03, -3.4690e-04],\n",
       "           [-1.2573e-02, -1.2672e-02, -1.5793e-02],\n",
       "           [-2.1378e-02,  4.0603e-04, -1.7014e-02]],\n",
       " \n",
       "          [[ 3.0994e-03,  1.9714e-02,  1.1993e-02],\n",
       "           [ 1.6907e-02,  4.1695e-03,  2.8572e-03],\n",
       "           [ 1.9180e-02,  6.6299e-03,  1.6037e-02]],\n",
       " \n",
       "          [[-1.2369e-03, -1.1276e-02, -1.0399e-02],\n",
       "           [-1.9104e-02, -3.4771e-03,  6.4087e-03],\n",
       "           [-2.0172e-02, -1.7185e-03, -8.9188e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-8.7690e-04,  1.1269e-02,  4.7760e-03],\n",
       "           [-8.7280e-03,  2.6722e-03, -8.4610e-03],\n",
       "           [-3.5629e-03,  7.3700e-03,  1.7643e-03]],\n",
       " \n",
       "          [[-5.0583e-03, -1.2962e-02, -1.1917e-02],\n",
       "           [-1.1017e-02, -2.1088e-02, -2.2583e-02],\n",
       "           [-3.0777e-02, -1.6907e-02, -1.4191e-02]],\n",
       " \n",
       "          [[ 1.4557e-02,  1.3590e-03,  7.2823e-03],\n",
       "           [-1.0757e-02,  6.8283e-03,  2.7790e-03],\n",
       "           [-1.4244e-02, -4.6692e-03, -1.0357e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.8725e-03, -3.6201e-03,  3.3913e-03],\n",
       "           [-4.3559e-04,  9.6655e-04, -1.1688e-04],\n",
       "           [ 8.1329e-03,  1.8021e-02,  1.5511e-02]],\n",
       " \n",
       "          [[ 2.7046e-03, -1.8448e-02,  5.4893e-03],\n",
       "           [ 5.9586e-03, -1.2407e-03,  8.2092e-03],\n",
       "           [-1.6422e-03, -2.0721e-02,  3.3226e-03]],\n",
       " \n",
       "          [[-5.4789e-04,  1.1566e-02, -1.1034e-03],\n",
       "           [ 3.5095e-03,  1.7960e-02, -4.9667e-03],\n",
       "           [ 5.6992e-03,  1.9501e-02,  1.2421e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.2681e-03,  1.4572e-02, -9.5749e-03],\n",
       "           [ 2.9755e-03,  1.3151e-03, -9.9640e-03],\n",
       "           [ 1.5343e-02, -2.6970e-03,  1.4198e-04]],\n",
       " \n",
       "          [[-5.9929e-03, -2.7451e-02, -1.8829e-02],\n",
       "           [-9.3155e-03, -2.0523e-02, -1.8036e-02],\n",
       "           [-1.6846e-02, -2.8870e-02, -2.9175e-02]],\n",
       " \n",
       "          [[ 1.9516e-02,  9.1171e-03,  2.1496e-03],\n",
       "           [-1.5717e-02,  1.8890e-02,  9.2545e-03],\n",
       "           [ 2.5063e-03, -1.3794e-02,  3.2234e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.8888e-03,  1.1688e-02,  2.0782e-02],\n",
       "           [ 1.3153e-02,  1.6296e-02,  1.0704e-02],\n",
       "           [ 1.4305e-02,  3.5419e-03,  8.6212e-03]],\n",
       " \n",
       "          [[-3.0041e-03, -4.4785e-03,  4.9133e-03],\n",
       "           [ 2.6584e-04, -2.0645e-02, -1.8759e-03],\n",
       "           [-1.7258e-02, -9.4299e-03, -5.6839e-03]],\n",
       " \n",
       "          [[ 2.1713e-02,  2.2949e-02,  1.4107e-02],\n",
       "           [ 1.1360e-02,  7.4463e-03,  1.6205e-02],\n",
       "           [ 2.6306e-02,  9.8572e-03,  1.3762e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.4296e-03, -3.7365e-03,  1.2848e-02],\n",
       "           [-1.0780e-02,  4.5052e-03, -7.3929e-03],\n",
       "           [ 4.1046e-03, -8.1787e-03, -6.7711e-03]],\n",
       " \n",
       "          [[ 1.5030e-02,  1.4488e-02,  7.4120e-03],\n",
       "           [ 2.9999e-02,  1.7792e-02,  3.5248e-02],\n",
       "           [ 3.3142e-02,  3.9368e-02,  3.0273e-02]],\n",
       " \n",
       "          [[ 4.8218e-03, -1.8234e-03, -1.6251e-03],\n",
       "           [-2.3782e-04,  2.0203e-02,  4.7874e-03],\n",
       "           [ 7.2937e-03,  1.1520e-02,  1.8723e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.7145e-02,  2.4796e-05, -1.7624e-02],\n",
       "           [-8.3923e-03, -6.2714e-03, -1.2657e-02],\n",
       "           [-2.8000e-02, -2.7374e-02, -3.3131e-03]],\n",
       " \n",
       "          [[-2.6836e-03,  2.3003e-03,  6.4201e-03],\n",
       "           [ 7.7744e-03,  2.0721e-02,  7.3547e-03],\n",
       "           [ 1.9257e-02,  6.4430e-03,  3.4008e-03]],\n",
       " \n",
       "          [[-1.2215e-02, -5.6114e-03, -1.0704e-02],\n",
       "           [-2.0248e-02, -1.5732e-02, -3.3627e-03],\n",
       "           [-1.2596e-02,  1.7223e-03, -1.0529e-02]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_out_layers_3.lora_up.weight': tensor([[[[-0.0001]],\n",
       " \n",
       "          [[-0.0014]],\n",
       " \n",
       "          [[ 0.0015]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0021]],\n",
       " \n",
       "          [[ 0.0020]],\n",
       " \n",
       "          [[-0.0084]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0106]],\n",
       " \n",
       "          [[ 0.0024]],\n",
       " \n",
       "          [[-0.0005]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0058]],\n",
       " \n",
       "          [[ 0.0108]],\n",
       " \n",
       "          [[-0.0039]]],\n",
       " \n",
       " \n",
       "         [[[-0.0066]],\n",
       " \n",
       "          [[ 0.0052]],\n",
       " \n",
       "          [[ 0.0160]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0120]],\n",
       " \n",
       "          [[-0.0090]],\n",
       " \n",
       "          [[ 0.0126]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0097]],\n",
       " \n",
       "          [[ 0.0186]],\n",
       " \n",
       "          [[-0.0103]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0143]],\n",
       " \n",
       "          [[ 0.0130]],\n",
       " \n",
       "          [[-0.0082]]],\n",
       " \n",
       " \n",
       "         [[[-0.0014]],\n",
       " \n",
       "          [[ 0.0097]],\n",
       " \n",
       "          [[-0.0003]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0006]],\n",
       " \n",
       "          [[ 0.0018]],\n",
       " \n",
       "          [[ 0.0032]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0165]],\n",
       " \n",
       "          [[ 0.0062]],\n",
       " \n",
       "          [[-0.0177]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0184]],\n",
       " \n",
       "          [[ 0.0138]],\n",
       " \n",
       "          [[-0.0296]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_skip_connection.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_skip_connection.lora_down.weight': tensor([[[[ 0.0189]],\n",
       " \n",
       "          [[-0.0479]],\n",
       " \n",
       "          [[ 0.0157]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0435]],\n",
       " \n",
       "          [[-0.0590]],\n",
       " \n",
       "          [[-0.0126]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0529]],\n",
       " \n",
       "          [[-0.0410]],\n",
       " \n",
       "          [[-0.0002]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0036]],\n",
       " \n",
       "          [[ 0.0311]],\n",
       " \n",
       "          [[-0.0344]]],\n",
       " \n",
       " \n",
       "         [[[-0.0496]],\n",
       " \n",
       "          [[ 0.0165]],\n",
       " \n",
       "          [[ 0.0229]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0083]],\n",
       " \n",
       "          [[ 0.0034]],\n",
       " \n",
       "          [[-0.0022]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0513]],\n",
       " \n",
       "          [[ 0.0246]],\n",
       " \n",
       "          [[ 0.0083]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0345]],\n",
       " \n",
       "          [[-0.0011]],\n",
       " \n",
       "          [[-0.0035]]],\n",
       " \n",
       " \n",
       "         [[[-0.0240]],\n",
       " \n",
       "          [[ 0.0078]],\n",
       " \n",
       "          [[-0.0191]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0149]],\n",
       " \n",
       "          [[-0.0076]],\n",
       " \n",
       "          [[-0.0411]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0383]],\n",
       " \n",
       "          [[-0.0762]],\n",
       " \n",
       "          [[-0.0183]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0123]],\n",
       " \n",
       "          [[ 0.0104]],\n",
       " \n",
       "          [[ 0.0141]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_0_skip_connection.lora_up.weight': tensor([[[[ 0.0044]],\n",
       " \n",
       "          [[ 0.0083]],\n",
       " \n",
       "          [[-0.0092]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0079]],\n",
       " \n",
       "          [[ 0.0015]],\n",
       " \n",
       "          [[-0.0233]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0157]],\n",
       " \n",
       "          [[-0.0100]],\n",
       " \n",
       "          [[ 0.0223]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0013]],\n",
       " \n",
       "          [[ 0.0049]],\n",
       " \n",
       "          [[-0.0034]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0120]],\n",
       " \n",
       "          [[-0.0122]],\n",
       " \n",
       "          [[ 0.0224]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0011]],\n",
       " \n",
       "          [[-0.0025]],\n",
       " \n",
       "          [[ 0.0153]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0074]],\n",
       " \n",
       "          [[-0.0125]],\n",
       " \n",
       "          [[ 0.0043]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0142]],\n",
       " \n",
       "          [[-0.0011]],\n",
       " \n",
       "          [[-0.0100]]],\n",
       " \n",
       " \n",
       "         [[[-0.0056]],\n",
       " \n",
       "          [[ 0.0180]],\n",
       " \n",
       "          [[-0.0112]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0156]],\n",
       " \n",
       "          [[-0.0085]],\n",
       " \n",
       "          [[-0.0056]]],\n",
       " \n",
       " \n",
       "         [[[-0.0208]],\n",
       " \n",
       "          [[ 0.0106]],\n",
       " \n",
       "          [[-0.0112]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0215]],\n",
       " \n",
       "          [[-0.0088]],\n",
       " \n",
       "          [[-0.0057]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_proj_in.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_proj_in.lora_down.weight': tensor([[-0.0218, -0.0377, -0.0120,  ..., -0.0238,  0.0161,  0.0227],\n",
       "         [ 0.0253,  0.0243, -0.0409,  ..., -0.0129, -0.0304, -0.0030],\n",
       "         [-0.0097,  0.0277, -0.0130,  ...,  0.0184, -0.0152, -0.0226],\n",
       "         ...,\n",
       "         [-0.0238,  0.0365, -0.0158,  ...,  0.0069, -0.0143,  0.0147],\n",
       "         [ 0.0575,  0.0291,  0.0424,  ..., -0.0288, -0.0340, -0.0582],\n",
       "         [-0.0131,  0.0267, -0.0359,  ..., -0.0221,  0.0448, -0.0217]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_proj_in.lora_up.weight': tensor([[-5.8899e-03, -1.6006e-02,  3.7766e-03,  ...,  4.9858e-03,\n",
       "          -1.6060e-03, -1.2085e-02],\n",
       "         [-1.2268e-02, -7.4310e-03, -2.5284e-02,  ...,  7.2021e-03,\n",
       "          -1.1238e-02,  3.2318e-02],\n",
       "         [ 7.1945e-03,  3.5934e-03, -8.3389e-03,  ..., -1.3199e-02,\n",
       "          -2.9659e-03, -6.3121e-05],\n",
       "         ...,\n",
       "         [ 4.0398e-03,  1.9178e-03, -1.7242e-02,  ..., -1.9043e-02,\n",
       "          -2.0279e-02,  1.8219e-02],\n",
       "         [ 4.6730e-03,  1.1208e-02,  8.0338e-03,  ...,  3.6163e-03,\n",
       "          -1.3969e-02,  1.2131e-02],\n",
       "         [-6.9389e-03,  1.6434e-02, -6.6528e-03,  ..., -3.6125e-03,\n",
       "          -6.1874e-03, -7.0763e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_proj_out.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_proj_out.lora_down.weight': tensor([[-0.0092,  0.0203,  0.0256,  ...,  0.0247,  0.0194, -0.0284],\n",
       "         [-0.0173,  0.0461, -0.0393,  ...,  0.0274,  0.0195,  0.0202],\n",
       "         [-0.0311, -0.0278,  0.0390,  ...,  0.0016,  0.0132, -0.0138],\n",
       "         ...,\n",
       "         [ 0.0012,  0.0062,  0.0088,  ..., -0.0313, -0.0338, -0.0062],\n",
       "         [-0.0031, -0.0182,  0.0215,  ...,  0.0054,  0.0140,  0.0223],\n",
       "         [ 0.0188,  0.0299,  0.0368,  ..., -0.0191, -0.0150, -0.0207]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_proj_out.lora_up.weight': tensor([[-0.0078,  0.0089, -0.0036,  ..., -0.0153,  0.0069, -0.0243],\n",
       "         [-0.0212,  0.0167, -0.0151,  ..., -0.0043, -0.0126, -0.0378],\n",
       "         [-0.0005,  0.0125, -0.0052,  ..., -0.0238, -0.0018, -0.0062],\n",
       "         ...,\n",
       "         [ 0.0074,  0.0099, -0.0074,  ..., -0.0096,  0.0089,  0.0020],\n",
       "         [-0.0184,  0.0149, -0.0055,  ..., -0.0048,  0.0029, -0.0092],\n",
       "         [ 0.0054, -0.0158, -0.0028,  ...,  0.0007,  0.0128,  0.0287]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_k.lora_down.weight': tensor([[-0.0420, -0.0242,  0.0271,  ..., -0.0402,  0.0282,  0.0011],\n",
       "         [ 0.0318, -0.0103, -0.0092,  ...,  0.0253,  0.0014,  0.0180],\n",
       "         [-0.0215,  0.0219, -0.0142,  ...,  0.0171,  0.0027, -0.0283],\n",
       "         ...,\n",
       "         [-0.0209, -0.0192, -0.0033,  ..., -0.0218, -0.0485,  0.0560],\n",
       "         [-0.0291,  0.0263, -0.0207,  ..., -0.0091, -0.0246,  0.0079],\n",
       "         [ 0.0218, -0.0349, -0.0098,  ..., -0.0148, -0.0142, -0.0099]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_k.lora_up.weight': tensor([[ 2.1378e-02, -9.1553e-03, -3.8509e-03,  ...,  2.5787e-03,\n",
       "          -1.8072e-04, -1.5656e-02],\n",
       "         [ 7.4501e-03, -2.7023e-02, -3.3498e-04,  ..., -1.8982e-02,\n",
       "          -6.7749e-03, -9.4757e-03],\n",
       "         [-6.9847e-03,  1.8768e-02,  2.8000e-02,  ..., -1.6815e-02,\n",
       "          -4.2267e-03, -6.3438e-03],\n",
       "         ...,\n",
       "         [-1.2047e-02,  1.4313e-02,  1.3908e-02,  ...,  6.1691e-05,\n",
       "           2.1667e-02,  2.3300e-02],\n",
       "         [-2.6166e-05, -5.0449e-04,  1.7593e-02,  ...,  4.2610e-03,\n",
       "           2.5063e-03, -7.1449e-03],\n",
       "         [ 1.5747e-02, -3.6621e-02, -2.3590e-02,  ...,  1.5732e-02,\n",
       "          -1.0414e-02, -8.9188e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight': tensor([[ 2.9802e-04,  2.0447e-02, -2.7908e-02,  ...,  4.6692e-02,\n",
       "          -1.4824e-02, -4.7791e-02],\n",
       "         [ 3.0960e-02,  2.7885e-03,  7.5035e-03,  ...,  1.8890e-02,\n",
       "          -5.4810e-02, -1.6541e-02],\n",
       "         [ 1.2489e-02, -1.2634e-02, -2.5681e-02,  ...,  1.0788e-02,\n",
       "          -2.4170e-02, -8.7662e-03],\n",
       "         ...,\n",
       "         [ 1.3817e-02,  1.7609e-02,  2.7008e-03,  ...,  4.0009e-02,\n",
       "           2.6688e-02, -4.7302e-04],\n",
       "         [ 8.2474e-03, -1.9592e-02, -2.5101e-02,  ..., -1.0010e-02,\n",
       "           4.6753e-02,  3.2187e-05],\n",
       "         [ 3.3844e-02, -4.3526e-03, -9.6512e-03,  ..., -4.1931e-02,\n",
       "           3.2013e-02, -5.2261e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight': tensor([[-0.0027, -0.0197,  0.0004,  ..., -0.0021,  0.0185,  0.0101],\n",
       "         [ 0.0310, -0.0052,  0.0215,  ...,  0.0037,  0.0082, -0.0206],\n",
       "         [ 0.0067,  0.0134, -0.0005,  ...,  0.0032, -0.0014,  0.0012],\n",
       "         ...,\n",
       "         [ 0.0260, -0.0009,  0.0147,  ...,  0.0314, -0.0040, -0.0296],\n",
       "         [-0.0108,  0.0077, -0.0169,  ..., -0.0136,  0.0031,  0.0073],\n",
       "         [-0.0030, -0.0280,  0.0067,  ..., -0.0023, -0.0177, -0.0011]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_q.lora_down.weight': tensor([[ 1.8188e-02, -1.2947e-02,  3.5675e-02,  ..., -1.7120e-02,\n",
       "          -3.7384e-02, -5.2261e-03],\n",
       "         [ 5.2392e-05, -3.7880e-03,  3.1525e-02,  ..., -5.2460e-02,\n",
       "          -5.5618e-03, -1.6983e-02],\n",
       "         [ 1.3959e-04,  4.2633e-02,  7.3280e-03,  ..., -5.2704e-02,\n",
       "          -3.3112e-02, -2.9282e-02],\n",
       "         ...,\n",
       "         [ 1.1795e-02, -9.8038e-03,  3.3417e-02,  ..., -3.4943e-02,\n",
       "           3.3325e-02, -4.1107e-02],\n",
       "         [ 1.3412e-02,  2.6520e-02, -2.1088e-02,  ..., -2.2598e-02,\n",
       "           4.7913e-03,  5.1605e-02],\n",
       "         [-4.6272e-03, -2.1912e-02,  4.1168e-02,  ...,  1.4503e-02,\n",
       "           1.3466e-03, -2.8976e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_q.lora_up.weight': tensor([[ 0.0121,  0.0231, -0.0211,  ..., -0.0296, -0.0090, -0.0037],\n",
       "         [-0.0217,  0.0146,  0.0082,  ..., -0.0057, -0.0139, -0.0013],\n",
       "         [ 0.0107,  0.0128, -0.0138,  ...,  0.0117,  0.0162, -0.0165],\n",
       "         ...,\n",
       "         [-0.0155,  0.0021,  0.0143,  ...,  0.0169,  0.0210, -0.0143],\n",
       "         [-0.0119, -0.0178,  0.0091,  ...,  0.0161,  0.0055, -0.0084],\n",
       "         [-0.0038, -0.0200,  0.0120,  ..., -0.0013,  0.0253, -0.0226]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_v.lora_down.weight': tensor([[-0.0083,  0.0023, -0.0154,  ..., -0.0233, -0.0236, -0.0354],\n",
       "         [ 0.0295,  0.0441, -0.0227,  ...,  0.0256,  0.0267, -0.0217],\n",
       "         [ 0.0029, -0.0658,  0.0077,  ...,  0.0102,  0.0304, -0.0129],\n",
       "         ...,\n",
       "         [ 0.0012,  0.0417,  0.0307,  ..., -0.0164,  0.0428, -0.0294],\n",
       "         [ 0.0417, -0.0235, -0.0058,  ...,  0.0238, -0.0292,  0.0153],\n",
       "         [ 0.0067, -0.0387, -0.0190,  ...,  0.0082, -0.0422, -0.0052]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_v.lora_up.weight': tensor([[-0.0008,  0.0020, -0.0043,  ...,  0.0183, -0.0034,  0.0071],\n",
       "         [-0.0232,  0.0310, -0.0254,  ..., -0.0114,  0.0116, -0.0027],\n",
       "         [-0.0211,  0.0177, -0.0154,  ..., -0.0059, -0.0074,  0.0086],\n",
       "         ...,\n",
       "         [-0.0021, -0.0001, -0.0104,  ...,  0.0124, -0.0021, -0.0069],\n",
       "         [ 0.0049, -0.0106, -0.0048,  ..., -0.0103,  0.0098,  0.0119],\n",
       "         [ 0.0260, -0.0098,  0.0287,  ...,  0.0141, -0.0005,  0.0063]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_k.lora_down.weight': tensor([[-0.0370,  0.0147,  0.0207,  ..., -0.0279,  0.0213,  0.0105],\n",
       "         [-0.0340,  0.0002,  0.0047,  ...,  0.0049,  0.0313, -0.0085],\n",
       "         [-0.0025, -0.0014,  0.0153,  ..., -0.0240,  0.0206,  0.0060],\n",
       "         ...,\n",
       "         [ 0.0362, -0.0173, -0.0229,  ...,  0.0219, -0.0476,  0.0058],\n",
       "         [ 0.0004, -0.0212, -0.0130,  ..., -0.0056,  0.0365,  0.0272],\n",
       "         [ 0.0323, -0.0069, -0.0122,  ...,  0.0054, -0.0411, -0.0203]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_k.lora_up.weight': tensor([[-0.0188, -0.0094, -0.0110,  ...,  0.0149, -0.0057,  0.0031],\n",
       "         [-0.0138, -0.0135, -0.0129,  ...,  0.0143, -0.0134,  0.0115],\n",
       "         [-0.0379, -0.0332, -0.0287,  ...,  0.0373, -0.0215,  0.0243],\n",
       "         ...,\n",
       "         [ 0.0525,  0.0313,  0.0391,  ..., -0.0464,  0.0207, -0.0112],\n",
       "         [ 0.0103,  0.0007,  0.0011,  ..., -0.0062, -0.0067,  0.0099],\n",
       "         [-0.0046, -0.0040, -0.0118,  ...,  0.0066, -0.0129,  0.0080]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight': tensor([[-0.0189, -0.0076,  0.0323,  ..., -0.0142, -0.0181, -0.0255],\n",
       "         [-0.0361,  0.0225, -0.0260,  ..., -0.0242,  0.0323, -0.0049],\n",
       "         [-0.0228, -0.0192, -0.0155,  ..., -0.0392, -0.0463,  0.0199],\n",
       "         ...,\n",
       "         [ 0.0391,  0.0404,  0.0004,  ...,  0.0298,  0.0131, -0.0209],\n",
       "         [ 0.0142,  0.0224, -0.0058,  ..., -0.0282,  0.0441,  0.0257],\n",
       "         [-0.0031,  0.0276, -0.0307,  ...,  0.0124,  0.0143, -0.0262]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight': tensor([[-1.7776e-03, -1.7672e-03, -1.0742e-02,  ..., -1.7838e-02,\n",
       "           1.1040e-02,  1.0544e-02],\n",
       "         [ 1.1681e-02, -2.1545e-02,  3.6602e-03,  ..., -1.1467e-02,\n",
       "           1.8239e-05, -3.6812e-03],\n",
       "         [-4.5052e-03, -1.1806e-03,  9.6741e-03,  ...,  4.5624e-03,\n",
       "           7.8773e-04,  1.0386e-03],\n",
       "         ...,\n",
       "         [ 9.1457e-04,  1.0620e-02, -1.0979e-02,  ..., -1.2253e-02,\n",
       "           4.8866e-03,  5.4550e-03],\n",
       "         [-4.0092e-03, -9.0170e-04,  9.9258e-03,  ...,  1.7960e-02,\n",
       "          -4.2076e-03,  8.4534e-03],\n",
       "         [-3.9711e-03,  2.6512e-03,  2.9240e-03,  ..., -2.0771e-03,\n",
       "           4.4975e-03,  1.1314e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_q.lora_down.weight': tensor([[-4.2847e-02, -2.7863e-02, -3.8849e-02,  ..., -5.5275e-03,\n",
       "          -2.0081e-02,  4.6234e-02],\n",
       "         [-3.4332e-02,  3.0212e-02,  1.8753e-02,  ...,  1.2772e-02,\n",
       "          -3.3691e-02,  2.4185e-02],\n",
       "         [-1.2815e-04,  3.5133e-03,  1.1787e-02,  ..., -4.6661e-02,\n",
       "          -6.0974e-02,  4.7943e-02],\n",
       "         ...,\n",
       "         [-2.0309e-02,  1.2032e-02, -5.0068e-06,  ...,  2.2095e-02,\n",
       "           4.3365e-02, -4.6997e-02],\n",
       "         [ 5.8624e-02,  1.9867e-02, -2.4521e-02,  ..., -1.1086e-02,\n",
       "          -7.3051e-03, -6.5063e-02],\n",
       "         [-2.3712e-02, -6.9160e-03, -2.8915e-02,  ...,  3.6194e-02,\n",
       "           3.5034e-02, -5.7739e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_q.lora_up.weight': tensor([[-3.8483e-02, -1.1721e-03, -3.7903e-02,  ...,  3.4912e-02,\n",
       "           2.2842e-02,  3.7445e-02],\n",
       "         [ 1.4526e-02, -3.3875e-02, -4.4703e-06,  ...,  2.6855e-03,\n",
       "          -4.5776e-03, -5.3368e-03],\n",
       "         [ 6.9008e-03,  1.5060e-02,  1.8097e-02,  ..., -1.9333e-02,\n",
       "          -1.7899e-02, -1.3878e-02],\n",
       "         ...,\n",
       "         [-1.1604e-02,  5.6610e-03, -8.1482e-03,  ..., -1.1663e-03,\n",
       "           7.8583e-03,  2.5970e-02],\n",
       "         [-1.2665e-02,  1.0780e-02, -1.7776e-02,  ...,  1.7456e-02,\n",
       "           1.1803e-02,  3.8635e-02],\n",
       "         [ 8.6212e-03, -1.5274e-02,  6.7482e-03,  ..., -8.7051e-03,\n",
       "          -4.1008e-03, -1.5793e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_v.lora_down.weight': tensor([[ 3.9101e-03,  1.6052e-02, -2.8629e-03,  ..., -4.0955e-02,\n",
       "          -8.8806e-03, -1.7776e-02],\n",
       "         [-1.0834e-02,  9.7427e-03, -4.5471e-03,  ...,  1.2054e-03,\n",
       "          -2.3178e-02, -9.1019e-03],\n",
       "         [-1.5419e-02,  1.3704e-03,  8.0395e-04,  ..., -1.9312e-03,\n",
       "          -1.7118e-03,  4.4518e-03],\n",
       "         ...,\n",
       "         [-3.7022e-03,  1.9464e-03, -1.5335e-02,  ..., -7.0000e-03,\n",
       "           9.1019e-03, -5.9700e-03],\n",
       "         [ 2.3453e-02,  1.2665e-02, -1.2732e-03,  ...,  1.4372e-03,\n",
       "           1.7822e-05, -1.6235e-02],\n",
       "         [ 5.2757e-03,  1.3100e-02, -2.1042e-02,  ..., -1.2184e-02,\n",
       "           1.2569e-03, -1.9638e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_attn2_to_v.lora_up.weight': tensor([[ 0.0119,  0.0067,  0.0068,  ..., -0.0084,  0.0039,  0.0001],\n",
       "         [ 0.0068,  0.0049, -0.0219,  ...,  0.0053, -0.0126,  0.0068],\n",
       "         [-0.0164,  0.0115,  0.0057,  ...,  0.0046,  0.0113,  0.0129],\n",
       "         ...,\n",
       "         [ 0.0180, -0.0029, -0.0012,  ...,  0.0060,  0.0023, -0.0030],\n",
       "         [ 0.0063,  0.0101, -0.0115,  ..., -0.0208, -0.0052,  0.0084],\n",
       "         [-0.0065,  0.0071, -0.0113,  ..., -0.0034, -0.0065,  0.0089]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight': tensor([[ 0.0005, -0.0328, -0.0395,  ..., -0.0117,  0.0092,  0.0097],\n",
       "         [-0.0033, -0.0040,  0.0077,  ..., -0.0328, -0.0422,  0.0217],\n",
       "         [ 0.0311, -0.0265, -0.0259,  ..., -0.0601,  0.0266,  0.0023],\n",
       "         ...,\n",
       "         [ 0.0314,  0.0160,  0.0620,  ...,  0.0253,  0.0222, -0.0336],\n",
       "         [ 0.0133,  0.0326, -0.0500,  ...,  0.0156, -0.0299, -0.0217],\n",
       "         [ 0.0218, -0.0309,  0.0331,  ..., -0.0067,  0.0241, -0.0112]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight': tensor([[-0.0095, -0.0148,  0.0026,  ..., -0.0002,  0.0093, -0.0008],\n",
       "         [-0.0276,  0.0112, -0.0219,  ...,  0.0134, -0.0187,  0.0229],\n",
       "         [ 0.0167, -0.0206,  0.0249,  ..., -0.0236,  0.0256, -0.0495],\n",
       "         ...,\n",
       "         [-0.0179,  0.0194, -0.0100,  ...,  0.0216, -0.0145,  0.0151],\n",
       "         [ 0.0267, -0.0054,  0.0177,  ..., -0.0298,  0.0024, -0.0042],\n",
       "         [ 0.0149, -0.0008,  0.0135,  ...,  0.0105,  0.0012,  0.0018]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_2.lora_down.weight': tensor([[ 0.0100, -0.0239,  0.0183,  ..., -0.0336, -0.0102, -0.0072],\n",
       "         [-0.0195,  0.0256, -0.0001,  ...,  0.0085,  0.0293, -0.0031],\n",
       "         [-0.0119, -0.0155,  0.0078,  ..., -0.0105, -0.0158,  0.0175],\n",
       "         ...,\n",
       "         [ 0.0039, -0.0064, -0.0020,  ...,  0.0038,  0.0244,  0.0034],\n",
       "         [-0.0066,  0.0022, -0.0114,  ..., -0.0029, -0.0061,  0.0060],\n",
       "         [-0.0152, -0.0108, -0.0053,  ...,  0.0054,  0.0027,  0.0164]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_2.lora_up.weight': tensor([[-6.3362e-03, -2.4378e-04, -1.3266e-03,  ...,  6.0768e-03,\n",
       "           2.1172e-03,  1.5480e-02],\n",
       "         [ 8.4076e-03,  9.3555e-04,  6.1264e-03,  ..., -3.9635e-03,\n",
       "           3.0098e-03,  2.2583e-03],\n",
       "         [ 1.2321e-02,  1.7563e-02,  1.4740e-02,  ..., -7.5417e-03,\n",
       "          -1.2115e-02, -6.5956e-03],\n",
       "         ...,\n",
       "         [-3.9825e-03,  1.5991e-02, -3.4695e-03,  ...,  1.0628e-02,\n",
       "          -9.4771e-05, -3.2845e-03],\n",
       "         [ 1.0538e-03, -4.8790e-03, -9.5215e-03,  ...,  6.4430e-03,\n",
       "           7.2021e-03,  4.6921e-03],\n",
       "         [ 8.5297e-03,  1.0880e-02,  1.2178e-03,  ..., -1.7242e-03,\n",
       "          -7.8125e-03, -1.2383e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_k.lora_down.weight': tensor([[ 0.0349, -0.0304,  0.0293,  ..., -0.0706, -0.0395,  0.0388],\n",
       "         [ 0.0102, -0.0173,  0.0023,  ...,  0.0283, -0.0386,  0.0038],\n",
       "         [-0.0308, -0.0119, -0.0300,  ..., -0.0455,  0.0443, -0.0411],\n",
       "         ...,\n",
       "         [ 0.0266,  0.0318, -0.0092,  ...,  0.0367, -0.0531,  0.0077],\n",
       "         [-0.0243, -0.0106,  0.0169,  ...,  0.0896, -0.0382,  0.0156],\n",
       "         [ 0.0423,  0.0156, -0.0091,  ..., -0.0338, -0.0098,  0.0042]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_k.lora_up.weight': tensor([[ 0.0008,  0.0024,  0.0013,  ...,  0.0035,  0.0058,  0.0007],\n",
       "         [-0.0037,  0.0217,  0.0062,  ...,  0.0068, -0.0017, -0.0153],\n",
       "         [-0.0188, -0.0202, -0.0028,  ..., -0.0078,  0.0098, -0.0128],\n",
       "         ...,\n",
       "         [-0.0066,  0.0019,  0.0162,  ..., -0.0214, -0.0007, -0.0017],\n",
       "         [ 0.0141,  0.0003, -0.0089,  ...,  0.0154,  0.0022, -0.0122],\n",
       "         [-0.0079,  0.0059,  0.0090,  ..., -0.0079,  0.0006, -0.0158]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_out_0.lora_down.weight': tensor([[-0.0117,  0.0585, -0.0056,  ...,  0.0428, -0.0424, -0.0061],\n",
       "         [-0.0071,  0.0212, -0.0677,  ..., -0.0250,  0.0454,  0.0232],\n",
       "         [ 0.0050, -0.0222, -0.0276,  ...,  0.0305, -0.0171, -0.0380],\n",
       "         ...,\n",
       "         [ 0.0004,  0.0166, -0.0366,  ...,  0.0103, -0.0401,  0.0102],\n",
       "         [ 0.0316, -0.0081,  0.0284,  ...,  0.0142,  0.0251,  0.0532],\n",
       "         [ 0.0469, -0.0046, -0.0269,  ...,  0.0326,  0.0304, -0.0414]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_out_0.lora_up.weight': tensor([[ 0.0055,  0.0020,  0.0197,  ..., -0.0075,  0.0046,  0.0166],\n",
       "         [-0.0008, -0.0299, -0.0025,  ..., -0.0200,  0.0270, -0.0015],\n",
       "         [ 0.0040,  0.0062,  0.0035,  ...,  0.0090, -0.0083,  0.0089],\n",
       "         ...,\n",
       "         [ 0.0004,  0.0129,  0.0015,  ...,  0.0160,  0.0082,  0.0029],\n",
       "         [-0.0035,  0.0164,  0.0142,  ..., -0.0130,  0.0094,  0.0257],\n",
       "         [-0.0042,  0.0147, -0.0054,  ...,  0.0162, -0.0373,  0.0090]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_q.lora_down.weight': tensor([[-0.0229, -0.0231,  0.0682,  ...,  0.0475, -0.0383,  0.0131],\n",
       "         [ 0.0376, -0.0123,  0.0253,  ..., -0.0242, -0.0015,  0.0415],\n",
       "         [ 0.0220,  0.0041,  0.0347,  ..., -0.0306,  0.0424,  0.0129],\n",
       "         ...,\n",
       "         [ 0.0260, -0.0128,  0.0241,  ..., -0.0499,  0.0129,  0.0226],\n",
       "         [-0.0146, -0.0378,  0.0078,  ..., -0.0067, -0.0017,  0.0353],\n",
       "         [ 0.0245, -0.0112,  0.0188,  ..., -0.0021,  0.0263,  0.0012]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_q.lora_up.weight': tensor([[-0.0202, -0.0123, -0.0109,  ..., -0.0139,  0.0188,  0.0078],\n",
       "         [-0.0121,  0.0169, -0.0176,  ..., -0.0441,  0.0201,  0.0126],\n",
       "         [ 0.0026,  0.0159, -0.0116,  ..., -0.0260,  0.0265, -0.0104],\n",
       "         ...,\n",
       "         [ 0.0207, -0.0034, -0.0023,  ..., -0.0032,  0.0025, -0.0094],\n",
       "         [-0.0266, -0.0027,  0.0255,  ...,  0.0214, -0.0245,  0.0030],\n",
       "         [-0.0284, -0.0062,  0.0234,  ...,  0.0090, -0.0025, -0.0046]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_v.lora_down.weight': tensor([[ 0.0310,  0.0173,  0.0067,  ..., -0.0128, -0.0007, -0.0313],\n",
       "         [-0.0044,  0.0618, -0.0115,  ..., -0.0312, -0.0242,  0.0152],\n",
       "         [ 0.0115, -0.0210,  0.0135,  ..., -0.0151, -0.0483, -0.0179],\n",
       "         ...,\n",
       "         [-0.0128, -0.0349,  0.0159,  ...,  0.0395,  0.0066,  0.0251],\n",
       "         [-0.0231,  0.0392, -0.0307,  ..., -0.0469,  0.0199, -0.0007],\n",
       "         [-0.0401,  0.0384, -0.0103,  ..., -0.0021,  0.0271,  0.0084]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_v.lora_up.weight': tensor([[ 0.0188, -0.0009,  0.0068,  ...,  0.0173,  0.0011, -0.0325],\n",
       "         [ 0.0253, -0.0039,  0.0016,  ...,  0.0217, -0.0186, -0.0205],\n",
       "         [ 0.0097, -0.0030, -0.0036,  ...,  0.0208, -0.0106, -0.0098],\n",
       "         ...,\n",
       "         [ 0.0051, -0.0060, -0.0217,  ...,  0.0194, -0.0050, -0.0256],\n",
       "         [-0.0262, -0.0111,  0.0057,  ..., -0.0121,  0.0162,  0.0024],\n",
       "         [-0.0264,  0.0111, -0.0153,  ..., -0.0341,  0.0080,  0.0300]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_k.lora_down.weight': tensor([[-0.0142,  0.0041, -0.0047,  ..., -0.0108,  0.0333, -0.0020],\n",
       "         [-0.0165,  0.0065, -0.0018,  ...,  0.0117,  0.0047,  0.0083],\n",
       "         [ 0.0167,  0.0007,  0.0149,  ...,  0.0171,  0.0021,  0.0119],\n",
       "         ...,\n",
       "         [-0.0315,  0.0195,  0.0060,  ..., -0.0101, -0.0078, -0.0028],\n",
       "         [ 0.0115, -0.0085,  0.0060,  ...,  0.0094,  0.0149, -0.0189],\n",
       "         [-0.0229,  0.0204, -0.0097,  ..., -0.0180, -0.0196, -0.0103]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_k.lora_up.weight': tensor([[-0.0064, -0.0008,  0.0056,  ...,  0.0096,  0.0110,  0.0262],\n",
       "         [ 0.0124,  0.0023, -0.0039,  ..., -0.0217, -0.0244, -0.0263],\n",
       "         [ 0.0274,  0.0085, -0.0144,  ..., -0.0239, -0.0257, -0.0261],\n",
       "         ...,\n",
       "         [ 0.0083,  0.0075, -0.0143,  ...,  0.0027, -0.0043,  0.0032],\n",
       "         [-0.0223, -0.0153,  0.0233,  ..., -0.0038, -0.0354, -0.0441],\n",
       "         [ 0.0096,  0.0038, -0.0118,  ..., -0.0155, -0.0020, -0.0247]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_out_0.lora_down.weight': tensor([[-0.0212, -0.0015, -0.0198,  ...,  0.0018, -0.0137,  0.0289],\n",
       "         [-0.0375, -0.0017, -0.0136,  ..., -0.0405,  0.0060, -0.0060],\n",
       "         [-0.0337,  0.0058,  0.0321,  ...,  0.0270,  0.0284,  0.0232],\n",
       "         ...,\n",
       "         [-0.0261, -0.0063, -0.0359,  ..., -0.0081, -0.0239,  0.0015],\n",
       "         [ 0.0205,  0.0520,  0.0404,  ...,  0.0389, -0.0125, -0.0255],\n",
       "         [-0.0300,  0.0334,  0.0308,  ...,  0.0218, -0.0008, -0.0012]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_out_0.lora_up.weight': tensor([[ 0.0069, -0.0060,  0.0010,  ..., -0.0260, -0.0107,  0.0044],\n",
       "         [ 0.0010,  0.0040,  0.0035,  ...,  0.0135, -0.0216,  0.0041],\n",
       "         [-0.0103,  0.0152,  0.0174,  ..., -0.0149, -0.0066, -0.0143],\n",
       "         ...,\n",
       "         [-0.0132,  0.0138,  0.0071,  ...,  0.0059, -0.0070, -0.0065],\n",
       "         [-0.0088,  0.0182,  0.0221,  ..., -0.0018, -0.0084, -0.0132],\n",
       "         [ 0.0048, -0.0200, -0.0124,  ..., -0.0095, -0.0030,  0.0111]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_q.lora_down.weight': tensor([[ 0.0694,  0.0271,  0.0536,  ..., -0.0015,  0.0393, -0.0293],\n",
       "         [ 0.0544, -0.0174,  0.0218,  ...,  0.0218,  0.0285, -0.0731],\n",
       "         [-0.0142,  0.0154,  0.0626,  ...,  0.0369, -0.0377, -0.0309],\n",
       "         ...,\n",
       "         [ 0.0413, -0.0421, -0.0188,  ..., -0.0246, -0.0110, -0.0407],\n",
       "         [ 0.0087,  0.0108, -0.0605,  ...,  0.0173, -0.0352, -0.0021],\n",
       "         [ 0.0153,  0.0019, -0.0078,  ...,  0.0070,  0.0038, -0.0337]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_q.lora_up.weight': tensor([[-0.0017,  0.0122, -0.0181,  ...,  0.0477, -0.0081, -0.0199],\n",
       "         [ 0.0154,  0.0025,  0.0197,  ..., -0.0155, -0.0077,  0.0217],\n",
       "         [-0.0216, -0.0314, -0.0018,  ..., -0.0171,  0.0094, -0.0083],\n",
       "         ...,\n",
       "         [-0.0102, -0.0217, -0.0060,  ...,  0.0040, -0.0021,  0.0135],\n",
       "         [-0.0113,  0.0337,  0.0034,  ...,  0.0111,  0.0016, -0.0243],\n",
       "         [ 0.0184,  0.0220, -0.0004,  ...,  0.0176,  0.0016, -0.0177]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_v.lora_down.weight': tensor([[-1.5518e-02,  1.0201e-02, -3.6831e-03,  ...,  3.6373e-03,\n",
       "           2.4147e-03,  1.7197e-02],\n",
       "         [ 1.1414e-02, -2.1423e-02, -9.5901e-03,  ..., -4.0779e-03,\n",
       "           1.4275e-02, -6.7520e-03],\n",
       "         [-1.5030e-02, -2.0309e-02,  1.5495e-02,  ...,  1.3113e-03,\n",
       "           3.6240e-03,  1.3969e-02],\n",
       "         ...,\n",
       "         [ 2.1118e-02,  1.7872e-03,  1.5945e-02,  ...,  1.5869e-02,\n",
       "           6.5193e-03,  1.0025e-02],\n",
       "         [-1.4648e-03,  1.6357e-02,  1.4198e-02,  ...,  1.0437e-02,\n",
       "           1.0996e-03,  1.2894e-02],\n",
       "         [ 4.5300e-05, -1.9440e-02,  1.9474e-03,  ...,  6.7978e-03,\n",
       "          -5.8441e-03,  1.0155e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_attn2_to_v.lora_up.weight': tensor([[-0.0036,  0.0055, -0.0048,  ..., -0.0006, -0.0030,  0.0029],\n",
       "         [-0.0103,  0.0098, -0.0131,  ..., -0.0103, -0.0107,  0.0104],\n",
       "         [ 0.0051, -0.0121,  0.0084,  ...,  0.0164,  0.0096, -0.0171],\n",
       "         ...,\n",
       "         [ 0.0148, -0.0152,  0.0137,  ...,  0.0178,  0.0053, -0.0161],\n",
       "         [-0.0043,  0.0043, -0.0059,  ..., -0.0018, -0.0093,  0.0034],\n",
       "         [-0.0073,  0.0090, -0.0065,  ..., -0.0085, -0.0029,  0.0078]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_0_proj.lora_down.weight': tensor([[-0.0151,  0.0185, -0.0402,  ...,  0.0167, -0.0145,  0.0215],\n",
       "         [ 0.0334,  0.0106, -0.0141,  ..., -0.0518,  0.0100, -0.0261],\n",
       "         [-0.0007, -0.0230,  0.0031,  ..., -0.0046, -0.0201, -0.0341],\n",
       "         ...,\n",
       "         [-0.0182,  0.0089,  0.0225,  ..., -0.0249,  0.0240,  0.0272],\n",
       "         [ 0.0041, -0.0222, -0.0072,  ..., -0.0340,  0.0275, -0.0163],\n",
       "         [ 0.0342, -0.0074,  0.0152,  ...,  0.0332,  0.0140, -0.0025]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_0_proj.lora_up.weight': tensor([[ 1.5823e-02, -3.5896e-03,  7.5760e-03,  ..., -1.0139e-02,\n",
       "           2.4246e-02,  1.4259e-02],\n",
       "         [-9.8190e-03, -2.4384e-02,  7.9651e-03,  ...,  2.1530e-02,\n",
       "          -1.3809e-02, -3.0579e-02],\n",
       "         [-3.0994e-06, -2.7008e-03, -1.9970e-03,  ..., -6.4812e-03,\n",
       "           1.1147e-02,  1.6617e-02],\n",
       "         ...,\n",
       "         [ 4.9553e-03, -9.5367e-03,  2.8625e-02,  ...,  1.9211e-02,\n",
       "          -2.1805e-02, -1.2083e-03],\n",
       "         [ 7.1068e-03, -8.4839e-03,  2.7390e-02,  ...,  2.6627e-02,\n",
       "          -9.7656e-03, -1.0262e-02],\n",
       "         [-8.8739e-04,  2.5955e-02,  4.6326e-02,  ...,  3.6526e-04,\n",
       "          -6.3286e-03, -6.9008e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_2.lora_down.weight': tensor([[ 0.0140, -0.0188, -0.0029,  ..., -0.0066,  0.0163,  0.0228],\n",
       "         [ 0.0206, -0.0204,  0.0073,  ..., -0.0055,  0.0029,  0.0284],\n",
       "         [ 0.0195,  0.0087,  0.0077,  ...,  0.0117,  0.0180, -0.0027],\n",
       "         ...,\n",
       "         [ 0.0071, -0.0074, -0.0067,  ..., -0.0156, -0.0216,  0.0213],\n",
       "         [ 0.0128,  0.0175,  0.0049,  ...,  0.0025,  0.0021,  0.0111],\n",
       "         [ 0.0210,  0.0102,  0.0110,  ..., -0.0041, -0.0161, -0.0132]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_2.lora_up.weight': tensor([[-3.6068e-03, -3.1013e-03, -6.7482e-03,  ..., -2.7771e-03,\n",
       "          -3.2043e-03, -4.6844e-03],\n",
       "         [ 7.1144e-04,  2.3484e-05,  1.2383e-02,  ...,  5.7297e-03,\n",
       "          -1.5991e-02, -1.7593e-02],\n",
       "         [ 9.6207e-03, -8.0633e-04, -4.8332e-03,  ..., -1.1462e-04,\n",
       "           1.6922e-02,  2.5501e-03],\n",
       "         ...,\n",
       "         [-1.2405e-02, -4.6768e-03,  7.2784e-03,  ...,  1.5516e-03,\n",
       "          -1.4351e-02, -7.7667e-03],\n",
       "         [ 7.3204e-03,  8.4991e-03,  9.4604e-03,  ...,  6.0234e-03,\n",
       "          -2.1042e-02, -1.0117e-02],\n",
       "         [ 6.5880e-03,  1.2985e-02,  2.8763e-03,  ...,  2.1648e-03,\n",
       "           1.1665e-02, -1.9226e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_0_emb_layers_1.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_0_emb_layers_1.lora_down.weight': tensor([[ 0.0126, -0.0005,  0.0057,  ..., -0.0121, -0.0069, -0.0264],\n",
       "         [ 0.0058,  0.0066, -0.0064,  ...,  0.0309,  0.0016,  0.0222],\n",
       "         [ 0.0385, -0.0180, -0.0149,  ..., -0.0223, -0.0144,  0.0186],\n",
       "         ...,\n",
       "         [-0.0382, -0.0046,  0.0037,  ..., -0.0062,  0.0139, -0.0126],\n",
       "         [ 0.0011,  0.0402,  0.0254,  ...,  0.0045,  0.0070,  0.0073],\n",
       "         [ 0.0062,  0.0144,  0.0160,  ...,  0.0276, -0.0044, -0.0139]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_0_emb_layers_1.lora_up.weight': tensor([[-0.0188, -0.0101,  0.0175,  ...,  0.0162, -0.0279, -0.0134],\n",
       "         [-0.0057,  0.0021,  0.0331,  ..., -0.0226, -0.0256,  0.0006],\n",
       "         [ 0.0065, -0.0024, -0.0149,  ...,  0.0061,  0.0144, -0.0002],\n",
       "         ...,\n",
       "         [ 0.0306, -0.0098, -0.0288,  ...,  0.0154,  0.0390, -0.0120],\n",
       "         [-0.0036,  0.0075, -0.0037,  ..., -0.0034,  0.0074,  0.0007],\n",
       "         [ 0.0043,  0.0045,  0.0033,  ..., -0.0039, -0.0127,  0.0055]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_0_in_layers_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_0_in_layers_2.lora_down.weight': tensor([[[[-0.0130, -0.0017, -0.0121],\n",
       "           [-0.0052,  0.0119, -0.0156],\n",
       "           [-0.0238, -0.0227, -0.0271]],\n",
       " \n",
       "          [[-0.0116, -0.0146, -0.0348],\n",
       "           [-0.0325, -0.0340, -0.0144],\n",
       "           [-0.0190, -0.0169, -0.0107]],\n",
       " \n",
       "          [[ 0.0081, -0.0062,  0.0032],\n",
       "           [-0.0055, -0.0001, -0.0047],\n",
       "           [-0.0011,  0.0032, -0.0047]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0098,  0.0038, -0.0200],\n",
       "           [-0.0014,  0.0169,  0.0057],\n",
       "           [-0.0109, -0.0117,  0.0109]],\n",
       " \n",
       "          [[ 0.0128, -0.0188,  0.0140],\n",
       "           [ 0.0030,  0.0050,  0.0023],\n",
       "           [ 0.0024, -0.0066,  0.0138]],\n",
       " \n",
       "          [[ 0.0002, -0.0033, -0.0090],\n",
       "           [-0.0067,  0.0109, -0.0044],\n",
       "           [-0.0044,  0.0214,  0.0170]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0049, -0.0013,  0.0052],\n",
       "           [-0.0007, -0.0105,  0.0087],\n",
       "           [ 0.0081,  0.0088,  0.0231]],\n",
       " \n",
       "          [[ 0.0482,  0.0366,  0.0391],\n",
       "           [ 0.0218,  0.0529,  0.0203],\n",
       "           [ 0.0218,  0.0298,  0.0356]],\n",
       " \n",
       "          [[ 0.0012,  0.0028, -0.0049],\n",
       "           [ 0.0004,  0.0146,  0.0047],\n",
       "           [ 0.0118,  0.0085, -0.0147]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0097,  0.0097,  0.0079],\n",
       "           [-0.0079,  0.0006, -0.0237],\n",
       "           [ 0.0064, -0.0104, -0.0055]],\n",
       " \n",
       "          [[ 0.0093,  0.0157,  0.0036],\n",
       "           [ 0.0081,  0.0016,  0.0008],\n",
       "           [ 0.0090, -0.0090, -0.0085]],\n",
       " \n",
       "          [[-0.0010, -0.0124, -0.0133],\n",
       "           [-0.0114, -0.0139, -0.0219],\n",
       "           [ 0.0159, -0.0216, -0.0079]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0117, -0.0092,  0.0176],\n",
       "           [ 0.0018, -0.0093,  0.0062],\n",
       "           [ 0.0134,  0.0215,  0.0184]],\n",
       " \n",
       "          [[ 0.0312,  0.0290,  0.0294],\n",
       "           [ 0.0321,  0.0217,  0.0059],\n",
       "           [ 0.0397,  0.0349,  0.0208]],\n",
       " \n",
       "          [[-0.0047,  0.0067, -0.0074],\n",
       "           [-0.0023, -0.0023, -0.0128],\n",
       "           [ 0.0032, -0.0159,  0.0015]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0088, -0.0038, -0.0027],\n",
       "           [ 0.0158,  0.0108, -0.0112],\n",
       "           [ 0.0090, -0.0049, -0.0002]],\n",
       " \n",
       "          [[ 0.0108,  0.0060, -0.0113],\n",
       "           [ 0.0202, -0.0013,  0.0192],\n",
       "           [-0.0059,  0.0162,  0.0181]],\n",
       " \n",
       "          [[ 0.0044, -0.0029,  0.0070],\n",
       "           [-0.0085, -0.0198, -0.0121],\n",
       "           [-0.0033, -0.0249, -0.0105]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0199,  0.0159,  0.0071],\n",
       "           [ 0.0216, -0.0026,  0.0110],\n",
       "           [ 0.0140,  0.0176,  0.0278]],\n",
       " \n",
       "          [[ 0.0136,  0.0191,  0.0274],\n",
       "           [ 0.0366,  0.0315,  0.0044],\n",
       "           [ 0.0230,  0.0086,  0.0094]],\n",
       " \n",
       "          [[-0.0098,  0.0003, -0.0168],\n",
       "           [ 0.0070,  0.0117, -0.0060],\n",
       "           [ 0.0111,  0.0124,  0.0028]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0054,  0.0143,  0.0123],\n",
       "           [ 0.0226, -0.0123, -0.0116],\n",
       "           [ 0.0073,  0.0070, -0.0061]],\n",
       " \n",
       "          [[-0.0076,  0.0054, -0.0032],\n",
       "           [-0.0038, -0.0044, -0.0033],\n",
       "           [ 0.0007,  0.0012, -0.0116]],\n",
       " \n",
       "          [[-0.0210, -0.0005,  0.0084],\n",
       "           [-0.0139, -0.0086, -0.0095],\n",
       "           [ 0.0094, -0.0242, -0.0137]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0113,  0.0082,  0.0065],\n",
       "           [ 0.0278, -0.0006,  0.0238],\n",
       "           [ 0.0361,  0.0191,  0.0249]],\n",
       " \n",
       "          [[ 0.0162,  0.0171,  0.0180],\n",
       "           [ 0.0359,  0.0409,  0.0140],\n",
       "           [ 0.0257,  0.0323,  0.0092]],\n",
       " \n",
       "          [[-0.0122, -0.0076, -0.0097],\n",
       "           [ 0.0199, -0.0063,  0.0021],\n",
       "           [ 0.0168,  0.0138,  0.0082]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0069,  0.0142,  0.0231],\n",
       "           [ 0.0189,  0.0024,  0.0101],\n",
       "           [ 0.0166,  0.0066,  0.0075]],\n",
       " \n",
       "          [[-0.0118,  0.0005, -0.0065],\n",
       "           [ 0.0041, -0.0089,  0.0032],\n",
       "           [ 0.0076,  0.0056,  0.0047]],\n",
       " \n",
       "          [[-0.0052, -0.0148, -0.0058],\n",
       "           [-0.0124, -0.0058,  0.0070],\n",
       "           [-0.0054, -0.0217,  0.0084]]],\n",
       " \n",
       " \n",
       "         [[[-0.0337, -0.0240, -0.0092],\n",
       "           [-0.0117,  0.0088, -0.0231],\n",
       "           [-0.0400, -0.0268, -0.0156]],\n",
       " \n",
       "          [[-0.0156, -0.0059, -0.0246],\n",
       "           [-0.0214, -0.0206, -0.0047],\n",
       "           [-0.0215, -0.0163, -0.0262]],\n",
       " \n",
       "          [[-0.0128, -0.0116,  0.0069],\n",
       "           [-0.0088,  0.0025, -0.0071],\n",
       "           [ 0.0049, -0.0087,  0.0001]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0069, -0.0035, -0.0089],\n",
       "           [-0.0086,  0.0144,  0.0005],\n",
       "           [-0.0073, -0.0014,  0.0090]],\n",
       " \n",
       "          [[ 0.0157, -0.0027,  0.0149],\n",
       "           [ 0.0151,  0.0067, -0.0077],\n",
       "           [-0.0057,  0.0067, -0.0027]],\n",
       " \n",
       "          [[ 0.0186,  0.0028,  0.0021],\n",
       "           [-0.0029,  0.0103,  0.0103],\n",
       "           [-0.0067,  0.0144,  0.0175]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_0_in_layers_2.lora_up.weight': tensor([[[[-0.0089]],\n",
       " \n",
       "          [[ 0.0109]],\n",
       " \n",
       "          [[ 0.0180]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0182]],\n",
       " \n",
       "          [[ 0.0153]],\n",
       " \n",
       "          [[-0.0154]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0168]],\n",
       " \n",
       "          [[-0.0223]],\n",
       " \n",
       "          [[-0.0110]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0067]],\n",
       " \n",
       "          [[-0.0067]],\n",
       " \n",
       "          [[ 0.0159]]],\n",
       " \n",
       " \n",
       "         [[[-0.0052]],\n",
       " \n",
       "          [[ 0.0194]],\n",
       " \n",
       "          [[ 0.0123]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0069]],\n",
       " \n",
       "          [[ 0.0076]],\n",
       " \n",
       "          [[-0.0052]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0021]],\n",
       " \n",
       "          [[ 0.0167]],\n",
       " \n",
       "          [[ 0.0028]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0029]],\n",
       " \n",
       "          [[-0.0057]],\n",
       " \n",
       "          [[ 0.0025]]],\n",
       " \n",
       " \n",
       "         [[[-0.0029]],\n",
       " \n",
       "          [[ 0.0234]],\n",
       " \n",
       "          [[ 0.0167]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0089]],\n",
       " \n",
       "          [[ 0.0053]],\n",
       " \n",
       "          [[-0.0018]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0023]],\n",
       " \n",
       "          [[-0.0003]],\n",
       " \n",
       "          [[ 0.0009]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0036]],\n",
       " \n",
       "          [[-0.0074]],\n",
       " \n",
       "          [[ 0.0062]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_0_out_layers_3.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_0_out_layers_3.lora_down.weight': tensor([[[[-7.9880e-03, -4.2305e-03,  1.0040e-02],\n",
       "           [-1.0117e-02, -8.1406e-03, -5.7259e-03],\n",
       "           [-1.5140e-04,  1.1391e-02, -1.2764e-02]],\n",
       " \n",
       "          [[ 4.9553e-03,  5.2910e-03,  7.2212e-03],\n",
       "           [ 8.0338e-03,  7.5483e-04,  5.0926e-03],\n",
       "           [ 6.8808e-04, -1.0818e-02, -1.6159e-02]],\n",
       " \n",
       "          [[ 2.0466e-03, -9.2163e-03,  1.5099e-02],\n",
       "           [ 2.1114e-03,  7.0381e-04,  1.7395e-02],\n",
       "           [ 5.7449e-03,  8.6365e-03, -5.7888e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.1534e-02, -3.0060e-02, -3.8666e-02],\n",
       "           [-4.0253e-02, -3.6102e-02, -3.6407e-02],\n",
       "           [-3.7292e-02, -4.0009e-02, -3.2227e-02]],\n",
       " \n",
       "          [[-1.0780e-02, -1.5404e-02,  1.1650e-02],\n",
       "           [ 1.6510e-02, -1.8215e-03,  2.1378e-02],\n",
       "           [ 5.1231e-03,  3.1166e-03,  1.5488e-02]],\n",
       " \n",
       "          [[-1.3779e-02,  2.3384e-03, -1.1635e-02],\n",
       "           [ 2.3994e-03,  4.9210e-03, -4.3106e-03],\n",
       "           [-5.3749e-03,  1.0513e-02, -3.1757e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 7.1106e-03, -5.4665e-03,  1.0262e-02],\n",
       "           [-4.2610e-03, -8.0414e-03, -4.7951e-03],\n",
       "           [-7.3471e-03, -2.6989e-03,  9.6817e-03]],\n",
       " \n",
       "          [[-3.2711e-03, -5.4016e-03, -4.9438e-03],\n",
       "           [ 1.2039e-02, -1.1292e-03,  1.6037e-02],\n",
       "           [-3.7403e-03,  9.2773e-03,  1.0490e-02]],\n",
       " \n",
       "          [[ 9.6588e-03,  9.7733e-03, -1.1134e-04],\n",
       "           [-1.1971e-02, -7.1335e-03, -2.6932e-02],\n",
       "           [-9.2316e-03,  9.5797e-04, -1.9867e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.7129e-02,  5.9753e-02,  5.9753e-02],\n",
       "           [ 5.5542e-02,  5.0964e-02,  4.6936e-02],\n",
       "           [ 3.3966e-02,  3.8849e-02,  3.6896e-02]],\n",
       " \n",
       "          [[ 3.3855e-03,  8.2703e-03, -6.3057e-03],\n",
       "           [-4.0474e-03, -7.2708e-03,  8.5115e-04],\n",
       "           [ 5.9128e-03,  1.1429e-02, -1.0452e-03]],\n",
       " \n",
       "          [[ 5.9624e-03, -6.4125e-03,  3.6087e-03],\n",
       "           [-2.2564e-03, -1.0048e-02, -7.4482e-04],\n",
       "           [ 6.8092e-03, -7.5340e-03,  6.5744e-05]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0574e-02, -4.1695e-03, -1.4427e-02],\n",
       "           [-2.1381e-03, -1.0010e-02,  4.2343e-03],\n",
       "           [-3.6507e-03, -8.4991e-03, -5.6171e-04]],\n",
       " \n",
       "          [[ 1.3527e-02,  7.6332e-03,  1.7685e-02],\n",
       "           [ 7.3395e-03,  1.7090e-02,  8.2703e-03],\n",
       "           [-9.2545e-03,  3.8300e-03, -8.0643e-03]],\n",
       " \n",
       "          [[-1.2482e-02,  1.2886e-02,  1.9028e-02],\n",
       "           [ 1.1505e-02,  2.3575e-03,  1.4412e-02],\n",
       "           [ 1.0590e-02,  1.7670e-02,  1.7441e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.4891e-02, -2.9434e-02, -4.8615e-02],\n",
       "           [-3.3234e-02, -4.5197e-02, -2.7908e-02],\n",
       "           [-3.3295e-02, -1.1398e-02, -2.4384e-02]],\n",
       " \n",
       "          [[ 1.3580e-02,  1.2840e-02,  1.1986e-02],\n",
       "           [ 6.5308e-03,  4.0531e-05,  1.5129e-02],\n",
       "           [ 4.1275e-03, -8.5220e-03, -8.9025e-04]],\n",
       " \n",
       "          [[ 3.9368e-03, -1.4816e-02,  1.0824e-03],\n",
       "           [-5.6610e-03, -1.4267e-02,  3.9215e-03],\n",
       "           [ 1.1848e-02, -6.8207e-03,  5.3444e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-8.1558e-03,  2.0695e-03, -8.6517e-03],\n",
       "           [-1.8291e-03,  9.5940e-04,  1.0178e-02],\n",
       "           [-4.3488e-03,  1.6651e-03, -1.0170e-02]],\n",
       " \n",
       "          [[ 3.4695e-03,  1.9913e-02,  2.5959e-03],\n",
       "           [ 1.2093e-02, -2.2354e-03,  1.2751e-03],\n",
       "           [ 1.5625e-02,  6.0005e-03, -1.8570e-02]],\n",
       " \n",
       "          [[-1.4982e-03,  1.9245e-03,  3.5744e-03],\n",
       "           [-4.2114e-03,  7.4539e-03,  2.3605e-02],\n",
       "           [ 5.4169e-03,  1.4133e-03,  3.1189e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.3192e-02, -2.9190e-02, -5.0354e-02],\n",
       "           [-3.4943e-02, -2.7435e-02, -3.6682e-02],\n",
       "           [-2.1240e-02, -2.4368e-02, -3.4912e-02]],\n",
       " \n",
       "          [[-9.3079e-03,  2.1744e-04, -1.6689e-03],\n",
       "           [-9.3918e-03, -5.2376e-03,  6.2523e-03],\n",
       "           [-1.3969e-02, -7.8430e-03, -8.3542e-03]],\n",
       " \n",
       "          [[-1.4183e-02, -9.9487e-03, -1.2520e-02],\n",
       "           [-9.0790e-03,  7.5989e-03,  1.1070e-02],\n",
       "           [ 1.2123e-02,  7.4997e-03,  1.2100e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.4763e-03, -9.6893e-03, -1.4465e-02],\n",
       "           [-1.3176e-02,  9.5901e-03, -9.2363e-04],\n",
       "           [-3.1300e-03,  2.6474e-03,  1.2535e-02]],\n",
       " \n",
       "          [[-3.9062e-03,  1.3245e-02, -1.2505e-02],\n",
       "           [ 4.4899e-03,  9.8114e-03, -1.5015e-02],\n",
       "           [-5.5008e-03, -3.2749e-03, -9.5215e-03]],\n",
       " \n",
       "          [[-1.7441e-02, -1.7807e-02,  2.5482e-02],\n",
       "           [ 6.3753e-04, -2.9774e-03,  2.1561e-02],\n",
       "           [-4.0283e-03, -1.6846e-02,  1.6205e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.3060e-02, -3.9642e-02, -2.1637e-02],\n",
       "           [-4.4098e-02, -2.7695e-02, -3.1372e-02],\n",
       "           [-4.1443e-02, -3.0624e-02, -2.0096e-02]],\n",
       " \n",
       "          [[ 1.5228e-02, -1.5518e-02,  3.3340e-03],\n",
       "           [ 3.1128e-03, -9.5892e-04,  1.6571e-02],\n",
       "           [ 1.6281e-02,  7.4615e-03,  5.5542e-03]],\n",
       " \n",
       "          [[ 3.5019e-03,  1.3390e-02,  7.7782e-03],\n",
       "           [-2.2297e-03,  3.3493e-03,  1.5656e-02],\n",
       "           [ 5.1422e-03,  9.8953e-03,  4.0359e-03]]],\n",
       " \n",
       " \n",
       "         [[[-4.7264e-03, -3.8548e-03, -6.7711e-03],\n",
       "           [-7.9803e-03,  5.7373e-03, -3.8505e-04],\n",
       "           [ 4.3945e-03, -9.6359e-03, -9.8801e-03]],\n",
       " \n",
       "          [[ 8.2779e-03,  1.2230e-02,  1.7288e-02],\n",
       "           [ 9.4528e-03,  6.3286e-03,  1.3329e-02],\n",
       "           [ 1.9274e-03,  2.1500e-02,  1.1658e-02]],\n",
       " \n",
       "          [[-2.5616e-03, -1.1158e-03, -2.0844e-02],\n",
       "           [ 5.9624e-03, -4.8332e-03, -8.1635e-03],\n",
       "           [-8.0872e-03,  6.4507e-03, -2.8137e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.2603e-02,  4.3701e-02,  3.6041e-02],\n",
       "           [ 3.6774e-02,  2.8839e-02,  2.4628e-02],\n",
       "           [ 2.6581e-02,  1.6220e-02,  3.6621e-02]],\n",
       " \n",
       "          [[ 3.9711e-03, -1.0500e-03,  9.3765e-03],\n",
       "           [-2.7885e-03,  6.4850e-03, -1.9062e-04],\n",
       "           [ 5.2605e-03, -1.5659e-03, -1.1505e-02]],\n",
       " \n",
       "          [[-4.3678e-03, -4.8523e-03, -1.0376e-02],\n",
       "           [-3.9005e-03, -1.6022e-02,  6.0349e-03],\n",
       "           [-5.9319e-03,  6.8169e-03, -1.5121e-02]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_0_out_layers_3.lora_up.weight': tensor([[[[ 0.0128]],\n",
       " \n",
       "          [[-0.0065]],\n",
       " \n",
       "          [[ 0.0010]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0074]],\n",
       " \n",
       "          [[ 0.0177]],\n",
       " \n",
       "          [[-0.0179]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0002]],\n",
       " \n",
       "          [[-0.0042]],\n",
       " \n",
       "          [[-0.0001]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0001]],\n",
       " \n",
       "          [[ 0.0053]],\n",
       " \n",
       "          [[-0.0101]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0245]],\n",
       " \n",
       "          [[ 0.0057]],\n",
       " \n",
       "          [[ 0.0081]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0117]],\n",
       " \n",
       "          [[ 0.0213]],\n",
       " \n",
       "          [[-0.0153]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0251]],\n",
       " \n",
       "          [[-0.0179]],\n",
       " \n",
       "          [[ 0.0248]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0238]],\n",
       " \n",
       "          [[ 0.0202]],\n",
       " \n",
       "          [[-0.0239]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0075]],\n",
       " \n",
       "          [[ 0.0032]],\n",
       " \n",
       "          [[-0.0033]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0041]],\n",
       " \n",
       "          [[ 0.0075]],\n",
       " \n",
       "          [[-0.0080]]],\n",
       " \n",
       " \n",
       "         [[[-0.0103]],\n",
       " \n",
       "          [[-0.0002]],\n",
       " \n",
       "          [[ 0.0072]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0042]],\n",
       " \n",
       "          [[-0.0122]],\n",
       " \n",
       "          [[ 0.0100]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_proj_in.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_proj_in.lora_down.weight': tensor([[ 0.0007,  0.0052,  0.0065,  ...,  0.0301, -0.0113, -0.0004],\n",
       "         [-0.0177, -0.0335,  0.0350,  ..., -0.0364,  0.0355, -0.0124],\n",
       "         [ 0.0048, -0.0317,  0.0093,  ..., -0.0115,  0.0194, -0.0090],\n",
       "         ...,\n",
       "         [-0.0239,  0.0352, -0.0206,  ...,  0.0540,  0.0081,  0.0288],\n",
       "         [ 0.0033,  0.0463,  0.0319,  ..., -0.0094, -0.0013,  0.0244],\n",
       "         [ 0.0082,  0.0147, -0.0084,  ..., -0.0081, -0.0069, -0.0327]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_proj_in.lora_up.weight': tensor([[-0.0060,  0.0082, -0.0181,  ...,  0.0097,  0.0164, -0.0072],\n",
       "         [ 0.0097,  0.0202, -0.0042,  ...,  0.0099,  0.0280,  0.0070],\n",
       "         [ 0.0146,  0.0007,  0.0029,  ..., -0.0039,  0.0148,  0.0021],\n",
       "         ...,\n",
       "         [-0.0086,  0.0003,  0.0091,  ...,  0.0286, -0.0096, -0.0007],\n",
       "         [ 0.0381,  0.0251, -0.0068,  ...,  0.0036,  0.0263, -0.0206],\n",
       "         [ 0.0103,  0.0005, -0.0021,  ..., -0.0024, -0.0081, -0.0016]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_proj_out.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_proj_out.lora_down.weight': tensor([[-0.0483, -0.0030, -0.0190,  ...,  0.0011, -0.0043, -0.0316],\n",
       "         [ 0.0041,  0.0167, -0.0357,  ..., -0.0114, -0.0131,  0.0259],\n",
       "         [-0.0128, -0.0370,  0.0285,  ..., -0.0098,  0.0218,  0.0344],\n",
       "         ...,\n",
       "         [-0.0098,  0.0195,  0.0311,  ..., -0.0107, -0.0483, -0.0430],\n",
       "         [-0.0071,  0.0203,  0.0323,  ..., -0.0180,  0.0435, -0.0042],\n",
       "         [ 0.0095,  0.0134,  0.0106,  ...,  0.0069,  0.0342, -0.0145]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_proj_out.lora_up.weight': tensor([[ 0.0134,  0.0104, -0.0144,  ..., -0.0068, -0.0096, -0.0280],\n",
       "         [ 0.0079,  0.0004, -0.0010,  ..., -0.0009, -0.0009, -0.0069],\n",
       "         [ 0.0042, -0.0095, -0.0008,  ...,  0.0014,  0.0103,  0.0042],\n",
       "         ...,\n",
       "         [ 0.0074,  0.0051,  0.0004,  ...,  0.0052, -0.0217,  0.0092],\n",
       "         [-0.0114,  0.0100,  0.0014,  ...,  0.0027,  0.0041, -0.0127],\n",
       "         [ 0.0014, -0.0080,  0.0108,  ...,  0.0217, -0.0347, -0.0003]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_k.lora_down.weight': tensor([[-0.0247, -0.0235, -0.0144,  ...,  0.0345, -0.0300,  0.0155],\n",
       "         [-0.0453, -0.0185, -0.0261,  ...,  0.0377,  0.0223,  0.0346],\n",
       "         [ 0.0356, -0.0065, -0.0213,  ..., -0.0267,  0.0219,  0.0191],\n",
       "         ...,\n",
       "         [-0.0214,  0.0130, -0.0182,  ...,  0.0159, -0.0025,  0.0224],\n",
       "         [-0.0207,  0.0108,  0.0001,  ...,  0.0092,  0.0212,  0.0177],\n",
       "         [ 0.0089,  0.0063, -0.0054,  ...,  0.0301,  0.0196,  0.0004]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_k.lora_up.weight': tensor([[-0.0064, -0.0036,  0.0011,  ..., -0.0106, -0.0090,  0.0026],\n",
       "         [-0.0115, -0.0147,  0.0197,  ..., -0.0183, -0.0071, -0.0184],\n",
       "         [ 0.0068,  0.0021, -0.0165,  ..., -0.0017,  0.0120,  0.0165],\n",
       "         ...,\n",
       "         [ 0.0039,  0.0067, -0.0304,  ...,  0.0300, -0.0037,  0.0282],\n",
       "         [ 0.0034, -0.0041, -0.0257,  ...,  0.0052, -0.0008,  0.0131],\n",
       "         [-0.0190,  0.0004,  0.0126,  ..., -0.0030, -0.0129,  0.0190]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight': tensor([[ 0.0191,  0.0022,  0.0035,  ...,  0.0002,  0.0331, -0.0052],\n",
       "         [ 0.0426,  0.0234,  0.0253,  ...,  0.0057, -0.0240, -0.0308],\n",
       "         [ 0.0004, -0.0155,  0.0292,  ..., -0.0354,  0.0519, -0.0109],\n",
       "         ...,\n",
       "         [ 0.0436,  0.0271,  0.0226,  ...,  0.0406, -0.0244,  0.0269],\n",
       "         [ 0.0325, -0.0017,  0.0241,  ..., -0.0215,  0.0424, -0.0508],\n",
       "         [ 0.0491,  0.0420, -0.0243,  ..., -0.0102,  0.0272,  0.0027]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight': tensor([[ 0.0020, -0.0224, -0.0157,  ..., -0.0080, -0.0070,  0.0078],\n",
       "         [ 0.0254,  0.0168, -0.0284,  ...,  0.0183, -0.0107,  0.0086],\n",
       "         [-0.0093, -0.0006,  0.0092,  ..., -0.0026,  0.0142,  0.0042],\n",
       "         ...,\n",
       "         [-0.0092, -0.0098, -0.0002,  ...,  0.0192, -0.0260,  0.0046],\n",
       "         [ 0.0286,  0.0121, -0.0319,  ...,  0.0275, -0.0243,  0.0247],\n",
       "         [-0.0033, -0.0041,  0.0148,  ...,  0.0229,  0.0208,  0.0050]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_q.lora_down.weight': tensor([[-0.0264,  0.0640, -0.0145,  ..., -0.0432,  0.0024, -0.0155],\n",
       "         [-0.0122, -0.0098, -0.0493,  ..., -0.0136, -0.0018,  0.0116],\n",
       "         [ 0.0329,  0.0517, -0.0333,  ..., -0.0514, -0.0157, -0.0453],\n",
       "         ...,\n",
       "         [-0.0354, -0.0138, -0.0114,  ...,  0.0044, -0.0269, -0.0003],\n",
       "         [-0.0443,  0.0277, -0.0095,  ..., -0.0275,  0.0010,  0.0186],\n",
       "         [-0.0286, -0.0467, -0.0215,  ..., -0.0423,  0.0073, -0.0027]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_q.lora_up.weight': tensor([[-0.0046,  0.0156,  0.0194,  ..., -0.0066, -0.0002, -0.0067],\n",
       "         [-0.0109,  0.0044,  0.0207,  ...,  0.0155,  0.0059, -0.0097],\n",
       "         [ 0.0091, -0.0063, -0.0089,  ...,  0.0195,  0.0054,  0.0251],\n",
       "         ...,\n",
       "         [ 0.0200,  0.0087,  0.0249,  ...,  0.0208,  0.0300, -0.0042],\n",
       "         [ 0.0388,  0.0169,  0.0406,  ...,  0.0087,  0.0338, -0.0150],\n",
       "         [ 0.0190,  0.0044,  0.0007,  ...,  0.0159, -0.0059,  0.0018]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_v.lora_down.weight': tensor([[-0.0139,  0.0432,  0.0328,  ..., -0.0144, -0.0156,  0.0325],\n",
       "         [-0.0099, -0.0428,  0.0316,  ...,  0.0190, -0.0094,  0.0330],\n",
       "         [-0.0061,  0.0428,  0.0010,  ..., -0.0004, -0.0195,  0.0192],\n",
       "         ...,\n",
       "         [ 0.0046,  0.0027,  0.0127,  ...,  0.0445, -0.0049,  0.0087],\n",
       "         [-0.0051, -0.0215, -0.0100,  ...,  0.0008,  0.0480, -0.0239],\n",
       "         [ 0.0277,  0.0220, -0.0270,  ..., -0.0447, -0.0401, -0.0023]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_v.lora_up.weight': tensor([[ 0.0080, -0.0146, -0.0062,  ..., -0.0007,  0.0038, -0.0081],\n",
       "         [ 0.0087,  0.0119,  0.0130,  ...,  0.0018, -0.0085,  0.0066],\n",
       "         [-0.0101,  0.0266, -0.0020,  ...,  0.0167, -0.0163,  0.0214],\n",
       "         ...,\n",
       "         [-0.0028,  0.0149, -0.0195,  ...,  0.0171, -0.0232,  0.0102],\n",
       "         [ 0.0194, -0.0071,  0.0104,  ..., -0.0003, -0.0014, -0.0134],\n",
       "         [ 0.0164,  0.0057, -0.0121,  ...,  0.0157,  0.0243, -0.0375]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_k.lora_down.weight': tensor([[-8.6823e-03, -3.9291e-03,  8.2092e-03,  ...,  7.1526e-03,\n",
       "          -1.4496e-02, -2.1347e-02],\n",
       "         [ 7.0076e-03,  2.7847e-02, -2.6230e-02,  ..., -8.8577e-03,\n",
       "           3.2368e-03, -2.2629e-02],\n",
       "         [-2.6749e-02,  2.0905e-02,  7.1411e-03,  ..., -3.6163e-03,\n",
       "          -2.2369e-02, -3.9490e-02],\n",
       "         ...,\n",
       "         [ 7.2060e-03, -3.1708e-02,  3.0563e-02,  ..., -7.1754e-03,\n",
       "          -1.0246e-02,  2.7649e-02],\n",
       "         [-1.8005e-02,  3.5217e-02, -1.3870e-02,  ...,  8.8513e-05,\n",
       "          -3.3512e-03, -3.1830e-02],\n",
       "         [-1.2444e-02, -1.2398e-03, -1.9745e-02,  ...,  2.0386e-02,\n",
       "           1.0971e-02, -3.0304e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_k.lora_up.weight': tensor([[ 0.0005, -0.0072, -0.0081,  ...,  0.0093, -0.0075, -0.0055],\n",
       "         [-0.0062, -0.0004, -0.0007,  ...,  0.0025, -0.0004, -0.0030],\n",
       "         [-0.0059, -0.0087, -0.0092,  ...,  0.0090, -0.0088, -0.0081],\n",
       "         ...,\n",
       "         [ 0.0116,  0.0155,  0.0159,  ..., -0.0171,  0.0153,  0.0149],\n",
       "         [-0.0249, -0.0255, -0.0255,  ...,  0.0276, -0.0253, -0.0277],\n",
       "         [-0.0031, -0.0108, -0.0122,  ...,  0.0125, -0.0121, -0.0114]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight': tensor([[-0.0070, -0.0377,  0.0100,  ..., -0.0424, -0.0060,  0.0248],\n",
       "         [ 0.0296, -0.0193, -0.0166,  ...,  0.0160, -0.0273, -0.0207],\n",
       "         [-0.0348, -0.0070,  0.0224,  ..., -0.0378, -0.0174,  0.0131],\n",
       "         ...,\n",
       "         [-0.0044, -0.0220,  0.0252,  ...,  0.0106, -0.0113,  0.0195],\n",
       "         [ 0.0148,  0.0142, -0.0033,  ..., -0.0072,  0.0151,  0.0334],\n",
       "         [-0.0012, -0.0195, -0.0249,  ..., -0.0177,  0.0292,  0.0196]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight': tensor([[ 0.0022,  0.0128,  0.0161,  ..., -0.0028, -0.0034, -0.0110],\n",
       "         [ 0.0106,  0.0011,  0.0051,  ..., -0.0003,  0.0025,  0.0179],\n",
       "         [-0.0074, -0.0071, -0.0064,  ..., -0.0035, -0.0099,  0.0099],\n",
       "         ...,\n",
       "         [-0.0007,  0.0142,  0.0102,  ..., -0.0027, -0.0113, -0.0119],\n",
       "         [ 0.0027,  0.0041,  0.0062,  ...,  0.0029,  0.0036, -0.0189],\n",
       "         [ 0.0103, -0.0070, -0.0079,  ...,  0.0086,  0.0188,  0.0095]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_q.lora_down.weight': tensor([[-0.0189,  0.0082, -0.0086,  ..., -0.0067,  0.0345, -0.0137],\n",
       "         [-0.0180,  0.0081, -0.0021,  ..., -0.0075, -0.0066, -0.0112],\n",
       "         [-0.0034,  0.0370,  0.0151,  ..., -0.0371, -0.0015,  0.0250],\n",
       "         ...,\n",
       "         [ 0.0090,  0.0502, -0.0260,  ...,  0.0050, -0.0163,  0.0372],\n",
       "         [-0.0128, -0.0045,  0.0161,  ...,  0.0518,  0.0114,  0.0160],\n",
       "         [-0.0463, -0.0335, -0.0497,  ...,  0.0080, -0.0013, -0.0154]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_q.lora_up.weight': tensor([[ 2.1553e-03,  9.4032e-04, -7.7553e-03,  ...,  6.1512e-04,\n",
       "           9.5062e-03,  9.7179e-04],\n",
       "         [-2.9736e-03, -1.7500e-03,  4.9706e-03,  ...,  1.5535e-03,\n",
       "          -5.1155e-03, -3.0398e-06],\n",
       "         [-2.6703e-03,  1.3494e-04,  3.8834e-03,  ...,  2.8343e-03,\n",
       "          -3.9139e-03,  3.6888e-03],\n",
       "         ...,\n",
       "         [ 1.2260e-02, -4.4403e-03,  1.6953e-02,  ..., -1.2789e-03,\n",
       "          -2.3651e-02, -2.1912e-02],\n",
       "         [-5.6686e-03, -6.2180e-03,  1.8188e-02,  ...,  3.6983e-03,\n",
       "          -1.0345e-02, -2.6443e-02],\n",
       "         [-8.1100e-03, -3.4733e-03, -8.9569e-03,  ..., -1.2379e-03,\n",
       "           1.5579e-02, -1.2398e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_v.lora_down.weight': tensor([[ 0.0228,  0.0143,  0.0075,  ...,  0.0097, -0.0248,  0.0131],\n",
       "         [ 0.0126, -0.0140, -0.0104,  ...,  0.0355, -0.0036, -0.0100],\n",
       "         [ 0.0066,  0.0139,  0.0138,  ...,  0.0121,  0.0029,  0.0255],\n",
       "         ...,\n",
       "         [-0.0149, -0.0160,  0.0186,  ..., -0.0248,  0.0188, -0.0108],\n",
       "         [-0.0142,  0.0112,  0.0064,  ..., -0.0062,  0.0096,  0.0122],\n",
       "         [ 0.0078,  0.0184,  0.0010,  ...,  0.0388, -0.0033, -0.0155]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_attn2_to_v.lora_up.weight': tensor([[ 0.0094,  0.0162, -0.0160,  ..., -0.0198,  0.0129,  0.0021],\n",
       "         [ 0.0003,  0.0092, -0.0068,  ..., -0.0105,  0.0065,  0.0098],\n",
       "         [ 0.0043,  0.0062, -0.0002,  ..., -0.0020,  0.0062, -0.0008],\n",
       "         ...,\n",
       "         [-0.0055, -0.0266,  0.0119,  ...,  0.0216, -0.0031, -0.0204],\n",
       "         [-0.0003, -0.0144,  0.0318,  ...,  0.0162, -0.0359, -0.0179],\n",
       "         [-0.0150,  0.0148, -0.0043,  ..., -0.0100, -0.0190,  0.0051]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight': tensor([[-0.0030, -0.0067,  0.0261,  ...,  0.0149,  0.0560,  0.0399],\n",
       "         [ 0.0300, -0.0484,  0.0371,  ...,  0.0168,  0.0049,  0.0342],\n",
       "         [-0.0383, -0.0094,  0.0234,  ...,  0.0354, -0.0313, -0.0268],\n",
       "         ...,\n",
       "         [ 0.0418, -0.0142, -0.0286,  ...,  0.0160, -0.0582,  0.0416],\n",
       "         [-0.0449, -0.0250, -0.0079,  ...,  0.0445, -0.0075,  0.0237],\n",
       "         [-0.0073,  0.0247, -0.0012,  ...,  0.0071, -0.0042,  0.0114]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight': tensor([[ 0.0061, -0.0115, -0.0002,  ..., -0.0073,  0.0093, -0.0084],\n",
       "         [-0.0079, -0.0198,  0.0181,  ..., -0.0032,  0.0253,  0.0103],\n",
       "         [-0.0143,  0.0044, -0.0225,  ...,  0.0108, -0.0079,  0.0293],\n",
       "         ...,\n",
       "         [ 0.0228,  0.0092, -0.0038,  ...,  0.0134, -0.0125, -0.0116],\n",
       "         [-0.0189, -0.0224,  0.0176,  ...,  0.0235,  0.0218,  0.0269],\n",
       "         [ 0.0080, -0.0226,  0.0394,  ..., -0.0016, -0.0057,  0.0160]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_2.lora_down.weight': tensor([[ 0.0155,  0.0143,  0.0053,  ..., -0.0324,  0.0311, -0.0160],\n",
       "         [-0.0219, -0.0088, -0.0358,  ..., -0.0026, -0.0106,  0.0023],\n",
       "         [ 0.0041,  0.0132,  0.0056,  ..., -0.0251,  0.0273, -0.0008],\n",
       "         ...,\n",
       "         [ 0.0106,  0.0237, -0.0172,  ..., -0.0038,  0.0241,  0.0010],\n",
       "         [-0.0199, -0.0138,  0.0143,  ...,  0.0040,  0.0085,  0.0154],\n",
       "         [-0.0182,  0.0077,  0.0050,  ..., -0.0045, -0.0135, -0.0280]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_2.lora_up.weight': tensor([[-0.0215,  0.0157, -0.0104,  ...,  0.0026, -0.0126,  0.0059],\n",
       "         [-0.0160,  0.0042, -0.0041,  ..., -0.0118,  0.0052, -0.0062],\n",
       "         [ 0.0045, -0.0009,  0.0047,  ..., -0.0016, -0.0123, -0.0192],\n",
       "         ...,\n",
       "         [ 0.0203, -0.0220,  0.0062,  ..., -0.0251,  0.0110, -0.0263],\n",
       "         [ 0.0312, -0.0193,  0.0061,  ..., -0.0029,  0.0109,  0.0194],\n",
       "         [-0.0075,  0.0032,  0.0004,  ...,  0.0071, -0.0115,  0.0305]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_k.lora_down.weight': tensor([[ 1.2733e-02,  2.1591e-02, -1.5579e-02,  ...,  2.8152e-02,\n",
       "           8.5831e-03,  2.4384e-02],\n",
       "         [-1.2009e-02, -6.5117e-03,  2.9160e-02,  ...,  2.6352e-02,\n",
       "           4.0436e-03,  5.7793e-03],\n",
       "         [ 1.5554e-03, -1.1223e-02, -3.2135e-02,  ...,  7.8278e-03,\n",
       "           1.4465e-02,  4.5288e-02],\n",
       "         ...,\n",
       "         [ 3.7937e-03,  1.5411e-02, -5.0781e-02,  ...,  1.2383e-02,\n",
       "          -3.5187e-02,  7.8619e-05],\n",
       "         [-3.0670e-02, -1.4626e-02,  2.6291e-02,  ..., -5.7602e-03,\n",
       "           3.8879e-02,  3.8727e-02],\n",
       "         [ 5.3558e-02, -4.3304e-02, -1.1864e-02,  ..., -2.1988e-02,\n",
       "          -4.3274e-02,  1.4374e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_k.lora_up.weight': tensor([[ 0.0110, -0.0086,  0.0024,  ..., -0.0004,  0.0068,  0.0102],\n",
       "         [-0.0183,  0.0111,  0.0302,  ...,  0.0056, -0.0021,  0.0126],\n",
       "         [-0.0072, -0.0096, -0.0101,  ...,  0.0131, -0.0226,  0.0241],\n",
       "         ...,\n",
       "         [-0.0144, -0.0158,  0.0149,  ...,  0.0119, -0.0218, -0.0073],\n",
       "         [-0.0007,  0.0071, -0.0148,  ...,  0.0126, -0.0116,  0.0151],\n",
       "         [-0.0060,  0.0022, -0.0072,  ..., -0.0078,  0.0037, -0.0135]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_out_0.lora_down.weight': tensor([[-0.0247,  0.0290,  0.0260,  ...,  0.0035,  0.0291, -0.0283],\n",
       "         [ 0.0263,  0.0334, -0.0041,  ..., -0.0097, -0.0012,  0.0408],\n",
       "         [ 0.0254, -0.0225,  0.0071,  ...,  0.0214, -0.0062,  0.0050],\n",
       "         ...,\n",
       "         [-0.0245,  0.0117,  0.0047,  ...,  0.0389,  0.0167, -0.0146],\n",
       "         [-0.0169,  0.0091, -0.0042,  ...,  0.0279, -0.0105, -0.0192],\n",
       "         [ 0.0477, -0.0162,  0.0007,  ...,  0.0100,  0.0254, -0.0218]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_out_0.lora_up.weight': tensor([[-0.0050, -0.0052, -0.0027,  ..., -0.0089,  0.0184,  0.0144],\n",
       "         [-0.0190, -0.0104,  0.0176,  ..., -0.0055,  0.0266,  0.0133],\n",
       "         [ 0.0107,  0.0101, -0.0006,  ..., -0.0167, -0.0033, -0.0128],\n",
       "         ...,\n",
       "         [ 0.0047, -0.0046,  0.0097,  ...,  0.0175,  0.0089,  0.0091],\n",
       "         [-0.0377, -0.0140,  0.0240,  ...,  0.0221,  0.0345,  0.0299],\n",
       "         [-0.0016, -0.0114,  0.0013,  ..., -0.0146,  0.0151, -0.0105]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_q.lora_down.weight': tensor([[ 0.0172,  0.0142, -0.0542,  ...,  0.0289,  0.0025, -0.0003],\n",
       "         [ 0.0356,  0.0626, -0.0295,  ...,  0.0183,  0.0280, -0.0168],\n",
       "         [-0.0539,  0.0313, -0.0106,  ...,  0.0068, -0.0074,  0.0374],\n",
       "         ...,\n",
       "         [-0.0044,  0.0119, -0.0402,  ..., -0.0008, -0.0019,  0.0053],\n",
       "         [ 0.0631,  0.0385,  0.0053,  ...,  0.0026,  0.0360,  0.0022],\n",
       "         [-0.0341,  0.0268, -0.0350,  ...,  0.0406, -0.0101,  0.0446]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_q.lora_up.weight': tensor([[-1.3550e-02,  3.2961e-05,  2.9774e-03,  ..., -6.1722e-03,\n",
       "          -4.5280e-03,  2.5970e-02],\n",
       "         [ 1.8875e-02, -1.1627e-02,  2.1011e-02,  ..., -8.0643e-03,\n",
       "           5.0087e-03,  2.0638e-03],\n",
       "         [-1.9714e-02, -1.0658e-02,  3.0947e-04,  ..., -1.1566e-02,\n",
       "           7.0724e-03,  1.3512e-02],\n",
       "         ...,\n",
       "         [ 1.2550e-02, -5.4932e-03, -2.8954e-03,  ...,  1.5358e-02,\n",
       "          -4.1237e-03, -7.3433e-03],\n",
       "         [ 2.7222e-02,  1.1597e-02,  2.1088e-02,  ...,  7.4120e-03,\n",
       "          -9.0103e-03,  3.0533e-02],\n",
       "         [-1.3817e-02,  7.9880e-03,  2.8717e-02,  ...,  3.0289e-03,\n",
       "           4.8447e-03, -1.3741e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_v.lora_down.weight': tensor([[-1.7891e-03,  6.4011e-03,  2.1827e-04,  ...,  1.2657e-02,\n",
       "          -1.8784e-02,  6.8626e-03],\n",
       "         [ 3.1738e-02, -3.0403e-03, -3.5034e-02,  ..., -1.1223e-02,\n",
       "          -4.7684e-05,  9.4910e-03],\n",
       "         [ 4.8876e-04,  3.2745e-02,  5.7297e-03,  ...,  3.6987e-02,\n",
       "           4.2725e-02,  1.8997e-02],\n",
       "         ...,\n",
       "         [ 1.0742e-02, -2.1210e-02,  2.3590e-02,  ..., -1.2749e-02,\n",
       "          -1.4458e-02,  1.0384e-02],\n",
       "         [ 3.1586e-02, -1.1490e-02, -3.0365e-02,  ..., -4.8370e-02,\n",
       "          -2.1545e-02, -1.4412e-02],\n",
       "         [ 2.5375e-02, -2.2354e-02, -1.6678e-02,  ..., -1.9028e-02,\n",
       "           1.4320e-02,  4.7577e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_v.lora_up.weight': tensor([[ 2.9624e-05, -3.6354e-03,  6.0997e-03,  ..., -9.0866e-03,\n",
       "          -2.3834e-02, -3.8376e-03],\n",
       "         [ 1.3725e-02,  2.0813e-02,  8.8196e-03,  ..., -1.5152e-02,\n",
       "           1.9028e-02, -2.0081e-02],\n",
       "         [-7.3318e-03,  4.9248e-03,  4.8370e-03,  ...,  5.9223e-04,\n",
       "           1.5915e-02,  3.8757e-03],\n",
       "         ...,\n",
       "         [-1.4982e-03, -1.0780e-02, -1.9684e-03,  ...,  5.1231e-03,\n",
       "          -1.8967e-02,  6.2408e-03],\n",
       "         [-7.3700e-03,  1.6830e-02,  1.5640e-02,  ..., -1.2238e-02,\n",
       "           7.6828e-03, -1.0918e-02],\n",
       "         [-1.3687e-02,  2.8229e-03, -9.5139e-03,  ...,  8.1635e-03,\n",
       "           2.2385e-02,  1.9669e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_k.lora_down.weight': tensor([[-0.0024, -0.0060,  0.0251,  ..., -0.0418,  0.0264, -0.0013],\n",
       "         [ 0.0350, -0.0087,  0.0018,  ...,  0.0301, -0.0178, -0.0022],\n",
       "         [ 0.0182, -0.0095,  0.0045,  ..., -0.0026,  0.0075,  0.0162],\n",
       "         ...,\n",
       "         [-0.0337,  0.0066,  0.0296,  ..., -0.0429,  0.0040, -0.0322],\n",
       "         [ 0.0088, -0.0098, -0.0009,  ...,  0.0117,  0.0012,  0.0073],\n",
       "         [-0.0483,  0.0249,  0.0291,  ..., -0.0262,  0.0029, -0.0270]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_k.lora_up.weight': tensor([[-0.0363,  0.0279, -0.0339,  ...,  0.0090, -0.0277,  0.0167],\n",
       "         [ 0.0032, -0.0060,  0.0103,  ..., -0.0055,  0.0057, -0.0045],\n",
       "         [-0.0203,  0.0015, -0.0115,  ...,  0.0143, -0.0239,  0.0167],\n",
       "         ...,\n",
       "         [-0.0427,  0.0173, -0.0175,  ..., -0.0046, -0.0178, -0.0055],\n",
       "         [-0.0122,  0.0080, -0.0026,  ..., -0.0156,  0.0007, -0.0188],\n",
       "         [ 0.0272, -0.0078,  0.0075,  ..., -0.0043,  0.0141, -0.0096]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_out_0.lora_down.weight': tensor([[-0.0009, -0.0367,  0.0315,  ...,  0.0036, -0.0036,  0.0080],\n",
       "         [-0.0072,  0.0079, -0.0411,  ...,  0.0191,  0.0284,  0.0271],\n",
       "         [ 0.0154,  0.0356,  0.0235,  ..., -0.0183, -0.0150,  0.0338],\n",
       "         ...,\n",
       "         [ 0.0011,  0.0004,  0.0460,  ...,  0.0305, -0.0041, -0.0104],\n",
       "         [ 0.0236,  0.0332,  0.0065,  ...,  0.0186,  0.0199,  0.0288],\n",
       "         [ 0.0113, -0.0100, -0.0104,  ...,  0.0410, -0.0154,  0.0228]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_out_0.lora_up.weight': tensor([[-0.0068,  0.0113,  0.0169,  ..., -0.0160, -0.0012, -0.0037],\n",
       "         [-0.0069,  0.0105, -0.0077,  ..., -0.0108, -0.0077,  0.0007],\n",
       "         [-0.0139,  0.0121, -0.0040,  ..., -0.0102, -0.0064,  0.0060],\n",
       "         ...,\n",
       "         [ 0.0034, -0.0153,  0.0071,  ..., -0.0172, -0.0138, -0.0066],\n",
       "         [-0.0082, -0.0032, -0.0126,  ...,  0.0034,  0.0068,  0.0061],\n",
       "         [-0.0227,  0.0233, -0.0170,  ..., -0.0229,  0.0048, -0.0002]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_q.lora_down.weight': tensor([[ 0.0439, -0.0139,  0.0382,  ...,  0.0171,  0.0157, -0.0430],\n",
       "         [-0.0360,  0.0208,  0.0269,  ..., -0.0187, -0.0251,  0.0490],\n",
       "         [ 0.0377,  0.0556,  0.0301,  ..., -0.0258, -0.0279,  0.0195],\n",
       "         ...,\n",
       "         [ 0.0184, -0.0118, -0.0167,  ..., -0.0232,  0.0346, -0.0169],\n",
       "         [ 0.0340, -0.0109, -0.0456,  ..., -0.0095, -0.0139, -0.0488],\n",
       "         [-0.0119, -0.0168, -0.0411,  ..., -0.0207,  0.0049, -0.0357]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_q.lora_up.weight': tensor([[ 0.0081,  0.0341, -0.0103,  ...,  0.0209, -0.0224, -0.0068],\n",
       "         [ 0.0039, -0.0231,  0.0241,  ..., -0.0411,  0.0249,  0.0068],\n",
       "         [ 0.0177, -0.0203,  0.0153,  ..., -0.0387,  0.0211,  0.0188],\n",
       "         ...,\n",
       "         [-0.0008,  0.0212, -0.0149,  ..., -0.0074,  0.0049, -0.0010],\n",
       "         [ 0.0041, -0.0299, -0.0057,  ..., -0.0006,  0.0022,  0.0082],\n",
       "         [-0.0070,  0.0348, -0.0010,  ...,  0.0029,  0.0036, -0.0088]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_v.lora_down.weight': tensor([[ 0.0105, -0.0113,  0.0049,  ..., -0.0059, -0.0049,  0.0097],\n",
       "         [ 0.0198,  0.0114, -0.0197,  ..., -0.0170, -0.0041,  0.0089],\n",
       "         [ 0.0057,  0.0175,  0.0132,  ...,  0.0246, -0.0100, -0.0160],\n",
       "         ...,\n",
       "         [-0.0101,  0.0164,  0.0020,  ...,  0.0264, -0.0074, -0.0209],\n",
       "         [ 0.0085, -0.0179,  0.0064,  ..., -0.0120,  0.0181, -0.0172],\n",
       "         [-0.0278, -0.0120,  0.0184,  ..., -0.0092, -0.0025,  0.0153]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_attn2_to_v.lora_up.weight': tensor([[-2.0905e-02, -2.0096e-02,  1.2291e-02,  ..., -1.9821e-02,\n",
       "          -6.4430e-03, -1.6876e-02],\n",
       "         [-3.0090e-02, -2.5238e-02,  2.0309e-02,  ..., -1.7609e-02,\n",
       "          -1.4648e-02, -1.5656e-02],\n",
       "         [ 9.9182e-03,  1.5173e-03,  1.1377e-03,  ...,  1.6708e-02,\n",
       "          -1.4961e-02,  4.7073e-03],\n",
       "         ...,\n",
       "         [ 8.7051e-03,  8.9407e-04,  8.3313e-03,  ...,  7.7744e-03,\n",
       "          -8.6403e-04,  4.4107e-05],\n",
       "         [ 6.5193e-03, -8.0643e-03,  1.2398e-02,  ...,  8.6746e-03,\n",
       "          -9.2850e-03,  1.5587e-02],\n",
       "         [ 2.6932e-03, -4.3564e-03,  6.2065e-03,  ...,  7.6752e-03,\n",
       "          -8.4457e-03, -2.1229e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_0_proj.lora_down.weight': tensor([[ 0.0075, -0.0111, -0.0054,  ...,  0.0052, -0.0240,  0.0404],\n",
       "         [ 0.0136, -0.0010,  0.0233,  ..., -0.0552, -0.0356, -0.0080],\n",
       "         [-0.0289,  0.0015, -0.0114,  ...,  0.0106,  0.0100, -0.0023],\n",
       "         ...,\n",
       "         [ 0.0231,  0.0551, -0.0485,  ...,  0.0046, -0.0362,  0.0022],\n",
       "         [ 0.0365,  0.0029,  0.0119,  ...,  0.0283,  0.0216,  0.0225],\n",
       "         [-0.0071,  0.0242,  0.0098,  ...,  0.0516,  0.0136,  0.0098]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_0_proj.lora_up.weight': tensor([[ 9.1934e-03,  4.3869e-05,  1.1566e-02,  ...,  7.3814e-03,\n",
       "          -1.7746e-02, -3.1677e-02],\n",
       "         [ 6.9199e-03, -4.4556e-03,  3.0155e-03,  ...,  1.2894e-02,\n",
       "           4.7112e-03,  1.2398e-02],\n",
       "         [-4.6883e-03,  4.3564e-03, -5.8937e-03,  ..., -1.8930e-04,\n",
       "          -6.0234e-03,  1.3514e-03],\n",
       "         ...,\n",
       "         [-1.3916e-02, -1.7181e-02,  1.5884e-02,  ..., -4.9171e-03,\n",
       "          -8.2092e-03,  8.6517e-03],\n",
       "         [-1.7868e-02, -1.2085e-02, -3.5038e-03,  ...,  2.2447e-04,\n",
       "           4.3213e-02,  2.6657e-02],\n",
       "         [-2.2354e-02, -1.2535e-02,  7.5674e-04,  ..., -1.7883e-02,\n",
       "          -1.1740e-03,  8.7967e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_2.lora_down.weight': tensor([[ 0.0285,  0.0099, -0.0192,  ..., -0.0121,  0.0113, -0.0010],\n",
       "         [ 0.0023, -0.0223, -0.0029,  ..., -0.0333, -0.0258,  0.0107],\n",
       "         [-0.0062,  0.0134,  0.0475,  ..., -0.0007, -0.0268, -0.0041],\n",
       "         ...,\n",
       "         [ 0.0107,  0.0008,  0.0078,  ..., -0.0077,  0.0331,  0.0136],\n",
       "         [ 0.0119, -0.0202,  0.0239,  ...,  0.0146, -0.0139,  0.0135],\n",
       "         [ 0.0045,  0.0277,  0.0225,  ...,  0.0280,  0.0160, -0.0127]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_2.lora_up.weight': tensor([[-0.0029,  0.0024,  0.0089,  ..., -0.0121, -0.0005,  0.0121],\n",
       "         [ 0.0038, -0.0246,  0.0242,  ..., -0.0028, -0.0013,  0.0094],\n",
       "         [-0.0096, -0.0056, -0.0097,  ...,  0.0076,  0.0074,  0.0147],\n",
       "         ...,\n",
       "         [ 0.0184,  0.0155, -0.0040,  ...,  0.0119, -0.0229,  0.0210],\n",
       "         [-0.0020,  0.0086,  0.0145,  ...,  0.0152, -0.0244,  0.0091],\n",
       "         [-0.0039, -0.0228, -0.0020,  ...,  0.0097, -0.0118,  0.0139]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_6_0_op.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_6_0_op.lora_down.weight': tensor([[[[ 1.5991e-02, -9.4604e-03, -1.1932e-02],\n",
       "           [-8.9035e-03, -7.7477e-03, -4.6417e-02],\n",
       "           [ 6.8665e-03,  7.9989e-05, -1.9302e-02]],\n",
       " \n",
       "          [[ 2.6260e-02, -2.0905e-02,  1.2268e-02],\n",
       "           [-1.5602e-02, -2.9663e-02, -1.8982e-02],\n",
       "           [ 6.7062e-03,  5.2681e-03, -1.0429e-02]],\n",
       " \n",
       "          [[-9.0256e-03, -2.8534e-03, -3.9864e-03],\n",
       "           [ 7.8087e-03,  9.1248e-03, -2.6749e-02],\n",
       "           [-6.6566e-03, -1.7090e-02, -9.4376e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.1057e-03, -2.0480e-04, -5.7030e-03],\n",
       "           [-1.2817e-02,  1.7090e-02,  1.6571e-02],\n",
       "           [-2.5589e-02, -1.5976e-02, -2.6535e-02]],\n",
       " \n",
       "          [[ 2.0676e-03,  1.6630e-04, -2.7227e-04],\n",
       "           [-3.1261e-03,  9.4604e-03, -5.4512e-03],\n",
       "           [ 7.9346e-04, -8.4534e-03, -3.1719e-03]],\n",
       " \n",
       "          [[-1.8143e-02,  8.3084e-03,  9.7513e-04],\n",
       "           [-3.4332e-03,  9.4891e-04,  1.7319e-02],\n",
       "           [-1.2064e-03,  6.5117e-03, -1.1063e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.0182e-02, -3.2196e-03, -1.9241e-02],\n",
       "           [-7.9193e-03,  1.6266e-02, -1.6068e-02],\n",
       "           [-3.7727e-03,  1.1276e-02,  8.4381e-03]],\n",
       " \n",
       "          [[ 6.1703e-04, -9.9335e-03,  1.9016e-03],\n",
       "           [ 5.5237e-03, -5.1727e-03,  5.7125e-04],\n",
       "           [-4.0474e-03,  2.2182e-03, -1.0284e-02]],\n",
       " \n",
       "          [[ 2.0275e-03, -1.0567e-03, -1.5686e-02],\n",
       "           [-1.1101e-02, -2.7561e-03, -3.3951e-03],\n",
       "           [ 7.5150e-03, -6.8321e-03,  3.0088e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.3471e-03, -1.3714e-03, -1.2375e-02],\n",
       "           [ 3.6640e-03,  1.5251e-02,  1.3443e-02],\n",
       "           [ 2.4002e-02, -5.0087e-03, -5.2719e-03]],\n",
       " \n",
       "          [[-3.3081e-02, -2.0096e-02, -1.7303e-02],\n",
       "           [-3.2349e-03, -8.8577e-03, -2.6291e-02],\n",
       "           [-1.5915e-02,  2.3022e-03, -1.7563e-02]],\n",
       " \n",
       "          [[-2.3804e-02, -5.2185e-03, -8.0948e-03],\n",
       "           [-3.1342e-02, -1.3184e-02, -9.3842e-03],\n",
       "           [-2.2984e-03,  1.5167e-02, -9.3889e-04]]],\n",
       " \n",
       " \n",
       "         [[[-2.5848e-02,  2.1042e-02,  4.8523e-03],\n",
       "           [ 3.1509e-03, -8.2474e-03,  1.9775e-02],\n",
       "           [-1.3626e-02,  5.0468e-03,  5.0163e-04]],\n",
       " \n",
       "          [[ 5.3368e-03,  3.0762e-02,  1.4511e-02],\n",
       "           [ 1.0330e-02,  9.0179e-03,  6.3210e-03],\n",
       "           [ 9.3231e-03,  1.8311e-02, -4.3716e-03]],\n",
       " \n",
       "          [[-1.1282e-03,  2.5253e-02,  1.4915e-02],\n",
       "           [ 9.9792e-03,  2.3468e-02,  1.5579e-02],\n",
       "           [ 2.8503e-02,  1.6785e-02,  3.3203e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.5019e-03,  1.9958e-02, -1.8854e-03],\n",
       "           [-1.3626e-02,  1.0796e-02, -3.9520e-03],\n",
       "           [-1.2787e-02,  1.9119e-02,  1.3779e-02]],\n",
       " \n",
       "          [[ 4.0741e-02,  4.9500e-02,  2.3224e-02],\n",
       "           [ 2.7802e-02,  2.8183e-02,  3.6774e-02],\n",
       "           [ 5.1178e-02,  2.9129e-02,  2.4048e-02]],\n",
       " \n",
       "          [[-6.1378e-03,  5.6839e-03, -1.4442e-02],\n",
       "           [-2.2018e-02, -1.0147e-02, -1.1826e-02],\n",
       "           [-2.5845e-03, -1.6586e-02,  2.9659e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 2.5528e-02, -1.8646e-02, -1.8265e-02],\n",
       "           [-2.0618e-03,  4.6959e-03, -2.3468e-02],\n",
       "           [-9.5291e-03,  2.4567e-03, -1.1215e-02]],\n",
       " \n",
       "          [[ 1.3199e-02, -3.1952e-02, -2.7657e-03],\n",
       "           [-7.4692e-03, -1.8921e-02,  6.6795e-03],\n",
       "           [-3.5858e-03, -6.3171e-03, -1.6861e-02]],\n",
       " \n",
       "          [[-6.1836e-03, -1.5129e-02, -1.9226e-02],\n",
       "           [-1.0674e-02, -4.0550e-03, -2.0660e-02],\n",
       "           [-1.8845e-02, -1.0895e-02, -1.9089e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-9.4681e-03, -8.7118e-04,  9.0942e-03],\n",
       "           [ 2.2621e-03, -1.2543e-02,  4.9019e-03],\n",
       "           [ 1.0729e-03, -1.1696e-02, -2.0752e-02]],\n",
       " \n",
       "          [[-3.1082e-02, -3.2013e-02, -1.7883e-02],\n",
       "           [-2.6855e-02, -3.0956e-03, -1.6266e-02],\n",
       "           [-1.7471e-02, -3.1433e-03, -6.4659e-03]],\n",
       " \n",
       "          [[-1.3893e-02, -3.0689e-03, -1.8723e-02],\n",
       "           [-2.8931e-02,  3.3722e-03, -1.8555e-02],\n",
       "           [-2.2949e-02,  1.5049e-03, -3.4904e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 5.4283e-03,  2.5467e-02, -7.4730e-03],\n",
       "           [-1.2312e-03, -7.7744e-03, -2.9388e-02],\n",
       "           [ 3.8815e-03,  1.9943e-02, -1.6953e-02]],\n",
       " \n",
       "          [[ 7.8354e-03, -7.3242e-03,  9.5825e-03],\n",
       "           [-1.9588e-03, -1.6617e-02, -1.1139e-02],\n",
       "           [-5.2929e-04, -1.4587e-02,  5.7268e-04]],\n",
       " \n",
       "          [[ 8.4534e-03, -2.9388e-02, -1.7181e-02],\n",
       "           [-1.0368e-02, -5.1155e-03, -8.6670e-03],\n",
       "           [-1.0841e-02, -5.7678e-03,  3.0956e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6190e-02,  9.8038e-03, -1.5869e-02],\n",
       "           [ 5.8899e-03,  1.2459e-02,  8.3618e-03],\n",
       "           [-1.6159e-02, -2.1561e-02, -7.4654e-03]],\n",
       " \n",
       "          [[-1.5289e-02,  6.2828e-03, -1.2680e-02],\n",
       "           [-6.4621e-03, -6.6719e-03, -1.9852e-02],\n",
       "           [-1.3306e-02, -7.0419e-03, -1.2558e-02]],\n",
       " \n",
       "          [[-2.6947e-02,  5.0659e-03, -8.5175e-05],\n",
       "           [-1.2367e-02, -3.0308e-03, -1.1463e-03],\n",
       "           [-1.7365e-02, -1.1002e-02, -1.4442e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.9180e-02, -2.0103e-03,  1.9623e-02],\n",
       "           [ 1.4732e-02,  1.5282e-02,  4.7424e-02],\n",
       "           [ 1.5991e-02,  1.6464e-02,  1.4565e-02]],\n",
       " \n",
       "          [[-1.1330e-03,  1.6815e-02,  3.1376e-03],\n",
       "           [ 1.1192e-02,  2.0248e-02,  1.9669e-02],\n",
       "           [ 1.2215e-02,  7.6561e-03,  8.4229e-03]],\n",
       " \n",
       "          [[-4.6844e-03,  3.0792e-02,  1.9302e-02],\n",
       "           [ 1.3962e-02,  2.1133e-02,  3.1281e-02],\n",
       "           [ 4.4174e-03,  4.3854e-02,  1.1787e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0628e-02,  6.5575e-03, -1.2047e-02],\n",
       "           [ 8.7891e-03,  4.0512e-03,  1.4641e-02],\n",
       "           [-2.9640e-03,  2.8824e-02,  8.2779e-03]],\n",
       " \n",
       "          [[-2.1954e-03,  1.8982e-02,  4.1008e-03],\n",
       "           [ 2.3026e-02,  2.1378e-02,  1.5793e-02],\n",
       "           [ 2.0035e-02,  1.4923e-02,  1.7395e-02]],\n",
       " \n",
       "          [[ 1.5594e-02,  1.1429e-02, -4.9019e-03],\n",
       "           [ 3.3722e-03,  5.2376e-03, -1.5984e-03],\n",
       "           [-7.9803e-03, -3.7708e-03,  9.9716e-03]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_6_0_op.lora_up.weight': tensor([[[[ 0.0152]],\n",
       " \n",
       "          [[ 0.0153]],\n",
       " \n",
       "          [[-0.0120]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0057]],\n",
       " \n",
       "          [[ 0.0239]],\n",
       " \n",
       "          [[-0.0092]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0067]],\n",
       " \n",
       "          [[-0.0196]],\n",
       " \n",
       "          [[ 0.0035]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0262]],\n",
       " \n",
       "          [[-0.0042]],\n",
       " \n",
       "          [[ 0.0073]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0005]],\n",
       " \n",
       "          [[ 0.0046]],\n",
       " \n",
       "          [[ 0.0112]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0016]],\n",
       " \n",
       "          [[ 0.0051]],\n",
       " \n",
       "          [[ 0.0065]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0004]],\n",
       " \n",
       "          [[ 0.0005]],\n",
       " \n",
       "          [[ 0.0045]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0054]],\n",
       " \n",
       "          [[ 0.0056]],\n",
       " \n",
       "          [[ 0.0029]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0112]],\n",
       " \n",
       "          [[ 0.0046]],\n",
       " \n",
       "          [[-0.0167]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0046]],\n",
       " \n",
       "          [[ 0.0038]],\n",
       " \n",
       "          [[-0.0043]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0195]],\n",
       " \n",
       "          [[ 0.0259]],\n",
       " \n",
       "          [[-0.0491]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0259]],\n",
       " \n",
       "          [[ 0.0210]],\n",
       " \n",
       "          [[-0.0251]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_emb_layers_1.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_emb_layers_1.lora_down.weight': tensor([[-0.0337, -0.0049, -0.0078,  ...,  0.0233,  0.0169, -0.0193],\n",
       "         [ 0.0193,  0.0049,  0.0335,  ..., -0.0374, -0.0312,  0.0220],\n",
       "         [-0.0014, -0.0104,  0.0072,  ...,  0.0122, -0.0150,  0.0199],\n",
       "         ...,\n",
       "         [-0.0008, -0.0265, -0.0149,  ..., -0.0328, -0.0233,  0.0171],\n",
       "         [-0.0225,  0.0366,  0.0168,  ...,  0.0210,  0.0200,  0.0183],\n",
       "         [ 0.0264, -0.0014,  0.0045,  ...,  0.0131, -0.0039,  0.0388]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_emb_layers_1.lora_up.weight': tensor([[-0.0041,  0.0080,  0.0041,  ..., -0.0006, -0.0043,  0.0040],\n",
       "         [ 0.0018, -0.0003, -0.0052,  ..., -0.0071,  0.0017, -0.0018],\n",
       "         [ 0.0053, -0.0041, -0.0052,  ..., -0.0062,  0.0054, -0.0052],\n",
       "         ...,\n",
       "         [ 0.0204, -0.0103, -0.0178,  ..., -0.0222,  0.0185, -0.0197],\n",
       "         [-0.0078, -0.0009,  0.0097,  ...,  0.0139, -0.0074,  0.0072],\n",
       "         [-0.0050, -0.0020,  0.0052,  ...,  0.0074, -0.0042,  0.0065]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_in_layers_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_in_layers_2.lora_down.weight': tensor([[[[ 1.2489e-02,  4.0283e-02,  1.7227e-02],\n",
       "           [ 3.6499e-02,  3.8239e-02,  1.8661e-02],\n",
       "           [ 2.6443e-02,  3.7292e-02,  2.7985e-02]],\n",
       " \n",
       "          [[ 3.6240e-03,  1.1131e-02, -1.1688e-02],\n",
       "           [ 2.5730e-03, -1.7441e-02, -6.6986e-03],\n",
       "           [ 7.5989e-03, -7.6065e-03,  7.7591e-03]],\n",
       " \n",
       "          [[-1.9028e-02,  1.4503e-02,  7.6981e-03],\n",
       "           [-6.1111e-03, -6.5727e-03,  1.2543e-02],\n",
       "           [-1.5755e-03,  2.3880e-03, -1.3466e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.1391e-02,  2.3712e-02,  1.4313e-02],\n",
       "           [ 4.6997e-03,  5.7487e-03,  1.4366e-02],\n",
       "           [ 2.7817e-02,  2.8519e-02,  2.0493e-02]],\n",
       " \n",
       "          [[-9.5224e-04,  1.1688e-02, -1.7853e-02],\n",
       "           [-8.8959e-03, -1.0056e-02,  6.0806e-03],\n",
       "           [-8.5735e-04, -1.3855e-02, -1.1063e-02]],\n",
       " \n",
       "          [[ 1.7899e-02,  1.0735e-02,  8.4839e-03],\n",
       "           [ 1.4000e-02,  1.2169e-02,  3.4943e-03],\n",
       "           [ 2.0504e-05,  2.4048e-02,  2.6989e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 4.5715e-02,  3.8086e-02,  4.8248e-02],\n",
       "           [ 4.6234e-02,  6.4758e-02,  4.0100e-02],\n",
       "           [ 4.2725e-02,  4.9530e-02,  5.1086e-02]],\n",
       " \n",
       "          [[ 9.6283e-03,  7.9346e-03,  4.9782e-03],\n",
       "           [ 1.7500e-03, -6.4201e-03, -9.7809e-03],\n",
       "           [-6.4697e-03, -1.7639e-02,  1.1292e-03]],\n",
       " \n",
       "          [[ 1.7670e-02,  1.5251e-02,  3.1891e-02],\n",
       "           [ 1.2878e-02,  2.2888e-02,  9.6741e-03],\n",
       "           [ 1.0559e-02,  1.8494e-02,  8.7509e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.2095e-02,  1.3969e-02,  3.0945e-02],\n",
       "           [ 9.7961e-03,  1.9485e-02,  3.6438e-02],\n",
       "           [ 2.6474e-02,  3.9642e-02,  2.2690e-02]],\n",
       " \n",
       "          [[ 1.8082e-02, -4.5700e-03, -7.8869e-04],\n",
       "           [-9.5844e-05,  1.1574e-02,  1.1055e-02],\n",
       "           [ 1.9028e-02,  1.1299e-02,  1.5404e-02]],\n",
       " \n",
       "          [[ 3.2166e-02,  2.5406e-02,  1.4702e-02],\n",
       "           [ 1.5121e-02,  2.7557e-02,  2.6062e-02],\n",
       "           [ 2.3300e-02,  3.5797e-02,  2.6291e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.4582e-02,  3.1494e-02,  3.8483e-02],\n",
       "           [ 2.4963e-02,  5.6335e-02,  3.2806e-02],\n",
       "           [ 3.9948e-02,  5.1758e-02,  2.2644e-02]],\n",
       " \n",
       "          [[ 4.4785e-03,  9.6054e-03, -6.7825e-03],\n",
       "           [-7.6532e-04,  1.8203e-04,  1.0826e-02],\n",
       "           [-5.0697e-03,  1.2825e-02, -1.8368e-03]],\n",
       " \n",
       "          [[-2.0561e-03,  1.7395e-02,  2.2034e-02],\n",
       "           [ 1.4565e-02,  8.2474e-03,  1.6846e-02],\n",
       "           [ 3.9787e-03,  5.6076e-03,  1.4290e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.3023e-02,  2.8091e-02,  1.4008e-02],\n",
       "           [ 2.0645e-02,  2.1561e-02,  1.2489e-02],\n",
       "           [ 1.2947e-02,  3.2166e-02,  1.5358e-02]],\n",
       " \n",
       "          [[-2.0065e-03, -6.7863e-03, -1.0292e-02],\n",
       "           [-6.1989e-03,  8.4839e-03,  9.4757e-03],\n",
       "           [ 1.2459e-02, -1.9407e-03,  3.9291e-03]],\n",
       " \n",
       "          [[ 1.3428e-02,  1.9028e-02,  1.9852e-02],\n",
       "           [-1.3304e-04,  1.8463e-02,  1.0826e-02],\n",
       "           [ 7.0610e-03,  2.1118e-02,  1.0017e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 2.0844e-02,  4.7577e-02,  3.1219e-02],\n",
       "           [ 4.0833e-02,  6.1401e-02,  4.4312e-02],\n",
       "           [ 5.0385e-02,  4.9194e-02,  3.9215e-02]],\n",
       " \n",
       "          [[ 4.6196e-03,  5.0812e-03,  9.2316e-03],\n",
       "           [ 3.8223e-03, -7.8278e-03, -1.6861e-02],\n",
       "           [ 1.5991e-02,  7.4806e-03,  3.9368e-03]],\n",
       " \n",
       "          [[ 1.0841e-02,  1.9623e-02,  2.0905e-02],\n",
       "           [-1.7738e-03,  8.4763e-03, -3.6983e-03],\n",
       "           [ 1.2619e-02,  1.8616e-02,  1.5617e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.3260e-02,  1.2970e-02,  3.0869e-02],\n",
       "           [ 2.4277e-02,  2.5848e-02,  1.7426e-02],\n",
       "           [ 2.6321e-02,  2.8458e-02,  2.6993e-02]],\n",
       " \n",
       "          [[ 9.3231e-03,  4.2763e-03,  9.9106e-03],\n",
       "           [ 8.9798e-03,  7.4501e-03,  1.4618e-02],\n",
       "           [ 8.6594e-03,  1.1589e-02,  4.4098e-03]],\n",
       " \n",
       "          [[ 5.4359e-03,  1.7731e-02,  1.2619e-02],\n",
       "           [ 7.5951e-03,  8.3923e-03,  2.5513e-02],\n",
       "           [ 1.5244e-02,  9.0485e-03,  7.1487e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.8839e-02, -4.9164e-02, -3.6499e-02],\n",
       "           [-3.3569e-02, -5.9692e-02, -4.7241e-02],\n",
       "           [-3.7384e-02, -5.1758e-02, -4.1199e-02]],\n",
       " \n",
       "          [[-8.9874e-03,  1.1086e-02,  3.5934e-03],\n",
       "           [ 7.0496e-03,  3.3054e-03,  1.2444e-02],\n",
       "           [-2.7924e-03, -2.1210e-03,  1.4992e-02]],\n",
       " \n",
       "          [[-1.0551e-02, -1.4763e-02, -2.9022e-02],\n",
       "           [-1.3206e-02, -2.0645e-02, -1.3008e-03],\n",
       "           [-3.1769e-02, -2.6367e-02, -2.4017e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.6617e-02, -3.7109e-02, -1.6312e-02],\n",
       "           [-1.9669e-02, -2.7191e-02, -3.2379e-02],\n",
       "           [-1.0727e-02, -2.2156e-02, -2.7069e-02]],\n",
       " \n",
       "          [[-1.6464e-02, -3.6945e-03,  4.7607e-03],\n",
       "           [-7.5874e-03, -2.0294e-03, -1.3664e-02],\n",
       "           [-2.7939e-02, -3.2825e-03, -1.3618e-02]],\n",
       " \n",
       "          [[-2.9526e-02, -1.7639e-02, -2.9694e-02],\n",
       "           [-1.4038e-02, -1.5732e-02, -1.8097e-02],\n",
       "           [-1.0368e-02, -3.2349e-02, -2.8214e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.6566e-03,  8.5678e-03, -1.3702e-02],\n",
       "           [-1.1854e-03, -1.2222e-02, -7.8506e-03],\n",
       "           [-3.0460e-03,  7.3624e-03,  8.0338e-03]],\n",
       " \n",
       "          [[-2.5284e-02, -2.5101e-02, -2.0447e-02],\n",
       "           [-3.2990e-02, -6.8016e-03, -2.0981e-02],\n",
       "           [-2.9816e-02, -1.8509e-02, -4.1580e-03]],\n",
       " \n",
       "          [[ 7.9422e-03, -1.3451e-02, -2.2507e-02],\n",
       "           [ 9.9258e-03,  1.5808e-02, -7.5607e-03],\n",
       "           [-1.6956e-03,  1.6413e-03,  1.2375e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.4748e-02, -5.9357e-03,  7.4196e-03],\n",
       "           [ 6.4507e-03,  2.8591e-03, -8.3313e-03],\n",
       "           [-3.3646e-03, -1.3863e-02, -3.4271e-02]],\n",
       " \n",
       "          [[ 1.4420e-02,  1.3916e-02,  1.2970e-02],\n",
       "           [ 4.9667e-03,  2.3621e-02, -2.4071e-03],\n",
       "           [ 1.6693e-02,  1.7273e-02,  2.3441e-03]],\n",
       " \n",
       "          [[ 2.0157e-02,  2.7481e-02,  1.3161e-02],\n",
       "           [ 8.8196e-03,  2.1698e-02,  1.4076e-02],\n",
       "           [ 7.3814e-03, -1.1543e-02,  1.2344e-02]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_in_layers_2.lora_up.weight': tensor([[[[-6.4735e-03]],\n",
       " \n",
       "          [[-1.0826e-02]],\n",
       " \n",
       "          [[-1.3161e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.2451e-02]],\n",
       " \n",
       "          [[ 4.2992e-03]],\n",
       " \n",
       "          [[ 1.4410e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.5463e-03]],\n",
       " \n",
       "          [[-3.4404e-04]],\n",
       " \n",
       "          [[ 7.3195e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.0123e-04]],\n",
       " \n",
       "          [[-6.5660e-04]],\n",
       " \n",
       "          [[-4.8637e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 4.2992e-03]],\n",
       " \n",
       "          [[ 8.4686e-03]],\n",
       " \n",
       "          [[ 4.6425e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.2180e-03]],\n",
       " \n",
       "          [[-6.9389e-03]],\n",
       " \n",
       "          [[ 3.5095e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.6159e-02]],\n",
       " \n",
       "          [[ 1.5213e-02]],\n",
       " \n",
       "          [[ 1.4977e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6647e-02]],\n",
       " \n",
       "          [[-1.4961e-02]],\n",
       " \n",
       "          [[-1.3847e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.4321e-03]],\n",
       " \n",
       "          [[ 2.6932e-03]],\n",
       " \n",
       "          [[ 3.5515e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.2332e-03]],\n",
       " \n",
       "          [[-6.7616e-04]],\n",
       " \n",
       "          [[-3.7460e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.9293e-03]],\n",
       " \n",
       "          [[-2.6836e-03]],\n",
       " \n",
       "          [[-2.6321e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3961e-05]],\n",
       " \n",
       "          [[ 3.2635e-03]],\n",
       " \n",
       "          [[-2.0782e-02]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_out_layers_3.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_out_layers_3.lora_down.weight': tensor([[[[ 0.0027,  0.0027, -0.0015],\n",
       "           [-0.0037, -0.0089, -0.0030],\n",
       "           [-0.0024,  0.0064,  0.0013]],\n",
       " \n",
       "          [[-0.0053,  0.0009, -0.0066],\n",
       "           [-0.0079, -0.0002,  0.0070],\n",
       "           [ 0.0042,  0.0049,  0.0082]],\n",
       " \n",
       "          [[ 0.0117,  0.0231,  0.0176],\n",
       "           [ 0.0048,  0.0186,  0.0161],\n",
       "           [ 0.0083,  0.0118,  0.0186]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0113, -0.0002, -0.0015],\n",
       "           [ 0.0037,  0.0042,  0.0020],\n",
       "           [ 0.0088, -0.0050,  0.0081]],\n",
       " \n",
       "          [[ 0.0007,  0.0018,  0.0062],\n",
       "           [ 0.0019,  0.0011,  0.0076],\n",
       "           [ 0.0026, -0.0008,  0.0043]],\n",
       " \n",
       "          [[ 0.0013,  0.0016,  0.0079],\n",
       "           [ 0.0051,  0.0023, -0.0045],\n",
       "           [-0.0061, -0.0015,  0.0056]]],\n",
       " \n",
       " \n",
       "         [[[-0.0061, -0.0071,  0.0099],\n",
       "           [ 0.0141,  0.0066,  0.0179],\n",
       "           [-0.0016, -0.0089,  0.0027]],\n",
       " \n",
       "          [[-0.0077, -0.0174, -0.0017],\n",
       "           [ 0.0024, -0.0197, -0.0196],\n",
       "           [-0.0067, -0.0236, -0.0099]],\n",
       " \n",
       "          [[-0.0184, -0.0212, -0.0159],\n",
       "           [-0.0106, -0.0131, -0.0149],\n",
       "           [-0.0221, -0.0233, -0.0211]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0076, -0.0002,  0.0047],\n",
       "           [-0.0013, -0.0024,  0.0012],\n",
       "           [ 0.0053,  0.0034,  0.0030]],\n",
       " \n",
       "          [[-0.0005, -0.0055, -0.0163],\n",
       "           [-0.0153, -0.0132, -0.0133],\n",
       "           [-0.0142, -0.0096, -0.0172]],\n",
       " \n",
       "          [[-0.0154, -0.0104, -0.0097],\n",
       "           [-0.0055, -0.0125, -0.0137],\n",
       "           [-0.0071, -0.0162, -0.0167]]],\n",
       " \n",
       " \n",
       "         [[[-0.0101, -0.0164, -0.0030],\n",
       "           [-0.0229, -0.0263, -0.0272],\n",
       "           [-0.0150,  0.0021, -0.0019]],\n",
       " \n",
       "          [[ 0.0014,  0.0095, -0.0038],\n",
       "           [ 0.0036,  0.0161,  0.0218],\n",
       "           [-0.0017,  0.0033,  0.0206]],\n",
       " \n",
       "          [[ 0.0215,  0.0255,  0.0112],\n",
       "           [ 0.0210,  0.0293,  0.0081],\n",
       "           [ 0.0292,  0.0231,  0.0078]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0057, -0.0075,  0.0061],\n",
       "           [ 0.0063,  0.0082, -0.0041],\n",
       "           [ 0.0156,  0.0030,  0.0133]],\n",
       " \n",
       "          [[ 0.0156,  0.0155,  0.0167],\n",
       "           [ 0.0202,  0.0081,  0.0141],\n",
       "           [ 0.0140,  0.0117,  0.0295]],\n",
       " \n",
       "          [[ 0.0014, -0.0045,  0.0015],\n",
       "           [-0.0116, -0.0079, -0.0001],\n",
       "           [-0.0088,  0.0039,  0.0058]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0099, -0.0032,  0.0157],\n",
       "           [ 0.0238,  0.0120,  0.0306],\n",
       "           [ 0.0227,  0.0071,  0.0057]],\n",
       " \n",
       "          [[-0.0215,  0.0036, -0.0105],\n",
       "           [-0.0132, -0.0168, -0.0205],\n",
       "           [-0.0155, -0.0243, -0.0179]],\n",
       " \n",
       "          [[-0.0092, -0.0137,  0.0064],\n",
       "           [-0.0058, -0.0053, -0.0053],\n",
       "           [-0.0206, -0.0178, -0.0030]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0086,  0.0094, -0.0034],\n",
       "           [-0.0022,  0.0058,  0.0033],\n",
       "           [-0.0083, -0.0060, -0.0129]],\n",
       " \n",
       "          [[-0.0036, -0.0146, -0.0141],\n",
       "           [-0.0091, -0.0136, -0.0079],\n",
       "           [-0.0117, -0.0175, -0.0219]],\n",
       " \n",
       "          [[-0.0088, -0.0137, -0.0018],\n",
       "           [-0.0043,  0.0120,  0.0091],\n",
       "           [-0.0044, -0.0024, -0.0085]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0116,  0.0077,  0.0020],\n",
       "           [ 0.0193,  0.0163,  0.0072],\n",
       "           [ 0.0154,  0.0016, -0.0023]],\n",
       " \n",
       "          [[-0.0106, -0.0139, -0.0160],\n",
       "           [-0.0114, -0.0232, -0.0097],\n",
       "           [-0.0165, -0.0200, -0.0217]],\n",
       " \n",
       "          [[-0.0226, -0.0195, -0.0071],\n",
       "           [-0.0078, -0.0113, -0.0220],\n",
       "           [-0.0215, -0.0110, -0.0217]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0108, -0.0037, -0.0058],\n",
       "           [-0.0017,  0.0117, -0.0125],\n",
       "           [-0.0054, -0.0059, -0.0048]],\n",
       " \n",
       "          [[-0.0026, -0.0018, -0.0128],\n",
       "           [-0.0096, -0.0049, -0.0192],\n",
       "           [-0.0056, -0.0111, -0.0160]],\n",
       " \n",
       "          [[-0.0017, -0.0022,  0.0018],\n",
       "           [ 0.0082, -0.0059, -0.0003],\n",
       "           [ 0.0081, -0.0023,  0.0020]]],\n",
       " \n",
       " \n",
       "         [[[-0.0123, -0.0213, -0.0181],\n",
       "           [-0.0321, -0.0258, -0.0220],\n",
       "           [-0.0176, -0.0075, -0.0085]],\n",
       " \n",
       "          [[ 0.0374,  0.0193,  0.0312],\n",
       "           [ 0.0290,  0.0347,  0.0429],\n",
       "           [ 0.0320,  0.0321,  0.0263]],\n",
       " \n",
       "          [[ 0.0300,  0.0233,  0.0143],\n",
       "           [ 0.0186,  0.0203,  0.0228],\n",
       "           [ 0.0291,  0.0296,  0.0244]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0051, -0.0062,  0.0130],\n",
       "           [ 0.0053, -0.0023,  0.0071],\n",
       "           [ 0.0070, -0.0049,  0.0073]],\n",
       " \n",
       "          [[ 0.0243,  0.0130,  0.0241],\n",
       "           [ 0.0307,  0.0204,  0.0323],\n",
       "           [ 0.0256,  0.0346,  0.0273]],\n",
       " \n",
       "          [[ 0.0221,  0.0149,  0.0148],\n",
       "           [ 0.0185,  0.0159,  0.0161],\n",
       "           [ 0.0084,  0.0241,  0.0074]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_out_layers_3.lora_up.weight': tensor([[[[-0.0127]],\n",
       " \n",
       "          [[ 0.0201]],\n",
       " \n",
       "          [[-0.0197]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0241]],\n",
       " \n",
       "          [[ 0.0182]],\n",
       " \n",
       "          [[-0.0301]]],\n",
       " \n",
       " \n",
       "         [[[-0.0014]],\n",
       " \n",
       "          [[ 0.0066]],\n",
       " \n",
       "          [[-0.0161]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0179]],\n",
       " \n",
       "          [[ 0.0083]],\n",
       " \n",
       "          [[-0.0149]]],\n",
       " \n",
       " \n",
       "         [[[-0.0031]],\n",
       " \n",
       "          [[ 0.0089]],\n",
       " \n",
       "          [[ 0.0013]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0050]],\n",
       " \n",
       "          [[ 0.0028]],\n",
       " \n",
       "          [[-0.0051]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0112]],\n",
       " \n",
       "          [[-0.0162]],\n",
       " \n",
       "          [[ 0.0030]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0151]],\n",
       " \n",
       "          [[-0.0159]],\n",
       " \n",
       "          [[ 0.0136]]],\n",
       " \n",
       " \n",
       "         [[[-0.0046]],\n",
       " \n",
       "          [[ 0.0055]],\n",
       " \n",
       "          [[-0.0046]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0102]],\n",
       " \n",
       "          [[ 0.0113]],\n",
       " \n",
       "          [[-0.0213]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0180]],\n",
       " \n",
       "          [[-0.0149]],\n",
       " \n",
       "          [[ 0.0176]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0256]],\n",
       " \n",
       "          [[-0.0185]],\n",
       " \n",
       "          [[ 0.0160]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_skip_connection.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_skip_connection.lora_down.weight': tensor([[[[-0.0397]],\n",
       " \n",
       "          [[ 0.0072]],\n",
       " \n",
       "          [[-0.0204]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0315]],\n",
       " \n",
       "          [[ 0.0365]],\n",
       " \n",
       "          [[ 0.0084]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0384]],\n",
       " \n",
       "          [[ 0.0480]],\n",
       " \n",
       "          [[-0.0075]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0154]],\n",
       " \n",
       "          [[ 0.0318]],\n",
       " \n",
       "          [[ 0.0410]]],\n",
       " \n",
       " \n",
       "         [[[-0.0225]],\n",
       " \n",
       "          [[ 0.0451]],\n",
       " \n",
       "          [[-0.0398]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0106]],\n",
       " \n",
       "          [[-0.0113]],\n",
       " \n",
       "          [[-0.0281]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0020]],\n",
       " \n",
       "          [[-0.0535]],\n",
       " \n",
       "          [[-0.0319]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0105]],\n",
       " \n",
       "          [[ 0.0069]],\n",
       " \n",
       "          [[-0.0261]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0217]],\n",
       " \n",
       "          [[-0.0428]],\n",
       " \n",
       "          [[-0.0018]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0176]],\n",
       " \n",
       "          [[ 0.0464]],\n",
       " \n",
       "          [[ 0.0262]]],\n",
       " \n",
       " \n",
       "         [[[-0.0246]],\n",
       " \n",
       "          [[-0.0097]],\n",
       " \n",
       "          [[-0.0102]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0134]],\n",
       " \n",
       "          [[ 0.0045]],\n",
       " \n",
       "          [[ 0.0110]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_0_skip_connection.lora_up.weight': tensor([[[[-0.0084]],\n",
       " \n",
       "          [[-0.0080]],\n",
       " \n",
       "          [[-0.0142]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0148]],\n",
       " \n",
       "          [[ 0.0013]],\n",
       " \n",
       "          [[-0.0076]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0161]],\n",
       " \n",
       "          [[-0.0055]],\n",
       " \n",
       "          [[ 0.0121]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0129]],\n",
       " \n",
       "          [[ 0.0089]],\n",
       " \n",
       "          [[-0.0035]]],\n",
       " \n",
       " \n",
       "         [[[-0.0082]],\n",
       " \n",
       "          [[ 0.0063]],\n",
       " \n",
       "          [[ 0.0040]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0105]],\n",
       " \n",
       "          [[ 0.0034]],\n",
       " \n",
       "          [[-0.0085]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0014]],\n",
       " \n",
       "          [[-0.0110]],\n",
       " \n",
       "          [[-0.0038]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0078]],\n",
       " \n",
       "          [[-0.0126]],\n",
       " \n",
       "          [[ 0.0082]]],\n",
       " \n",
       " \n",
       "         [[[-0.0072]],\n",
       " \n",
       "          [[ 0.0018]],\n",
       " \n",
       "          [[-0.0058]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0093]],\n",
       " \n",
       "          [[-0.0001]],\n",
       " \n",
       "          [[ 0.0182]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0395]],\n",
       " \n",
       "          [[-0.0137]],\n",
       " \n",
       "          [[-0.0155]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0185]],\n",
       " \n",
       "          [[-0.0132]],\n",
       " \n",
       "          [[ 0.0119]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_proj_in.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_proj_in.lora_down.weight': tensor([[ 0.0245, -0.0164,  0.0200,  ...,  0.0124, -0.0321, -0.0275],\n",
       "         [-0.0272,  0.0253,  0.0201,  ...,  0.0064,  0.0262,  0.0077],\n",
       "         [ 0.0226, -0.0051,  0.0101,  ..., -0.0058,  0.0287, -0.0084],\n",
       "         ...,\n",
       "         [-0.0188, -0.0050,  0.0181,  ...,  0.0255,  0.0290,  0.0179],\n",
       "         [ 0.0214,  0.0162,  0.0196,  ...,  0.0176,  0.0167, -0.0313],\n",
       "         [ 0.0271, -0.0199,  0.0009,  ...,  0.0264,  0.0071,  0.0008]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_proj_in.lora_up.weight': tensor([[ 4.5776e-03,  3.6926e-03,  8.3237e-03,  ..., -1.8177e-03,\n",
       "           6.7444e-03,  7.2002e-04],\n",
       "         [-3.4065e-03,  9.1019e-03, -4.8447e-03,  ...,  9.5749e-04,\n",
       "           5.6152e-03,  3.3016e-03],\n",
       "         [ 4.1885e-03,  1.9547e-02,  7.1068e-03,  ...,  5.4359e-03,\n",
       "           1.6281e-02,  1.6998e-02],\n",
       "         ...,\n",
       "         [-1.0612e-02,  1.4954e-03, -3.5896e-03,  ...,  3.0403e-03,\n",
       "           7.6103e-03, -7.3967e-03],\n",
       "         [ 1.6708e-02,  2.5528e-02, -1.0094e-02,  ...,  1.1604e-02,\n",
       "           2.8915e-02,  1.5274e-02],\n",
       "         [-9.6817e-03,  2.0325e-02, -5.1003e-03,  ..., -8.0032e-03,\n",
       "           9.5215e-03,  8.5533e-05]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_proj_out.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_proj_out.lora_down.weight': tensor([[-8.8882e-03, -6.8521e-04,  2.3346e-02,  ..., -1.0368e-02,\n",
       "           5.9814e-03,  2.5894e-02],\n",
       "         [ 3.9291e-03,  2.6047e-02, -6.5956e-03,  ..., -3.0838e-02,\n",
       "           1.5327e-02,  1.3412e-02],\n",
       "         [ 1.4198e-02,  2.3804e-02,  2.3651e-03,  ...,  2.1286e-02,\n",
       "           1.9989e-03,  1.3374e-02],\n",
       "         ...,\n",
       "         [ 8.8120e-04, -3.0975e-02, -1.4579e-04,  ..., -9.0332e-03,\n",
       "           1.8799e-02, -7.4005e-03],\n",
       "         [ 4.8375e-04, -1.3039e-02, -5.9624e-03,  ..., -3.5553e-02,\n",
       "          -1.5251e-02, -3.4454e-02],\n",
       "         [-2.9144e-02,  5.7077e-04, -4.8279e-02,  ..., -2.1763e-03,\n",
       "          -5.1260e-06,  2.4170e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_proj_out.lora_up.weight': tensor([[ 0.0216,  0.0146,  0.0056,  ...,  0.0024,  0.0155,  0.0061],\n",
       "         [-0.0068, -0.0123, -0.0103,  ..., -0.0140, -0.0177, -0.0201],\n",
       "         [-0.0087, -0.0010, -0.0006,  ..., -0.0026,  0.0036,  0.0087],\n",
       "         ...,\n",
       "         [ 0.0064, -0.0120, -0.0124,  ...,  0.0050, -0.0094,  0.0070],\n",
       "         [-0.0018, -0.0216, -0.0196,  ...,  0.0070, -0.0150, -0.0136],\n",
       "         [-0.0138, -0.0028,  0.0008,  ...,  0.0016, -0.0067, -0.0162]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_k.lora_down.weight': tensor([[-0.0085, -0.0068,  0.0411,  ...,  0.0035,  0.0047, -0.0168],\n",
       "         [-0.0116,  0.0061,  0.0219,  ..., -0.0073, -0.0130, -0.0331],\n",
       "         [ 0.0058, -0.0344,  0.0316,  ..., -0.0218, -0.0241,  0.0299],\n",
       "         ...,\n",
       "         [ 0.0118, -0.0032,  0.0322,  ...,  0.0082, -0.0276, -0.0345],\n",
       "         [-0.0015,  0.0049, -0.0005,  ..., -0.0172, -0.0257, -0.0328],\n",
       "         [ 0.0365, -0.0011,  0.0223,  ..., -0.0062,  0.0036, -0.0293]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_k.lora_up.weight': tensor([[-0.0208,  0.0073,  0.0063,  ..., -0.0205,  0.0113, -0.0083],\n",
       "         [ 0.0101, -0.0026,  0.0081,  ...,  0.0081, -0.0114, -0.0019],\n",
       "         [ 0.0347, -0.0087, -0.0112,  ..., -0.0153, -0.0172, -0.0232],\n",
       "         ...,\n",
       "         [ 0.0101,  0.0095,  0.0091,  ...,  0.0064, -0.0149,  0.0074],\n",
       "         [-0.0175,  0.0082, -0.0183,  ...,  0.0156, -0.0021, -0.0071],\n",
       "         [ 0.0052,  0.0099,  0.0112,  ..., -0.0028,  0.0064, -0.0205]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight': tensor([[ 0.0300,  0.0025, -0.0115,  ...,  0.0223, -0.0133, -0.0055],\n",
       "         [ 0.0137,  0.0036,  0.0122,  ..., -0.0060, -0.0248, -0.0254],\n",
       "         [-0.0044, -0.0058,  0.0030,  ..., -0.0091, -0.0140, -0.0009],\n",
       "         ...,\n",
       "         [-0.0161, -0.0345,  0.0240,  ..., -0.0130, -0.0279,  0.0062],\n",
       "         [-0.0231, -0.0128,  0.0066,  ..., -0.0244, -0.0013, -0.0078],\n",
       "         [-0.0110, -0.0176,  0.0091,  ...,  0.0019, -0.0125,  0.0148]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight': tensor([[-3.1776e-03,  1.7226e-05,  5.9853e-03,  ..., -9.6512e-03,\n",
       "           4.3869e-03, -1.0712e-02],\n",
       "         [ 9.1248e-03,  1.0345e-02, -3.8624e-04,  ..., -1.2253e-02,\n",
       "           1.5812e-03,  1.8173e-02],\n",
       "         [ 2.8000e-03,  1.7273e-02,  7.2670e-03,  ..., -2.3308e-03,\n",
       "          -1.5202e-03,  7.1430e-04],\n",
       "         ...,\n",
       "         [-1.1574e-02, -5.0011e-03, -1.2901e-02,  ..., -5.5084e-03,\n",
       "          -9.7275e-03,  8.6365e-03],\n",
       "         [ 1.8661e-02,  1.7395e-02, -1.0597e-02,  ...,  3.5133e-03,\n",
       "           2.6970e-03, -6.6833e-03],\n",
       "         [ 1.0406e-02,  1.4633e-02,  2.8057e-03,  ...,  1.5898e-03,\n",
       "           2.1636e-04,  1.4961e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_q.lora_down.weight': tensor([[ 0.0066, -0.0277, -0.0017,  ..., -0.0421, -0.0026,  0.0178],\n",
       "         [-0.0421, -0.0021,  0.0211,  ...,  0.0032,  0.0031, -0.0057],\n",
       "         [-0.0202,  0.0055, -0.0012,  ..., -0.0223, -0.0165,  0.0143],\n",
       "         ...,\n",
       "         [ 0.0057, -0.0043, -0.0171,  ...,  0.0072, -0.0090,  0.0173],\n",
       "         [-0.0231,  0.0326,  0.0206,  ...,  0.0093,  0.0282,  0.0301],\n",
       "         [-0.0163, -0.0382, -0.0376,  ...,  0.0043, -0.0323,  0.0140]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_q.lora_up.weight': tensor([[-0.0119, -0.0043,  0.0036,  ...,  0.0151,  0.0201,  0.0122],\n",
       "         [ 0.0163,  0.0030, -0.0080,  ..., -0.0058, -0.0003, -0.0228],\n",
       "         [-0.0079, -0.0046, -0.0031,  ...,  0.0064,  0.0059,  0.0052],\n",
       "         ...,\n",
       "         [-0.0009, -0.0044,  0.0058,  ..., -0.0100,  0.0029, -0.0081],\n",
       "         [-0.0129,  0.0189, -0.0157,  ..., -0.0021,  0.0160,  0.0050],\n",
       "         [-0.0249,  0.0108, -0.0122,  ...,  0.0034,  0.0211, -0.0101]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_v.lora_down.weight': tensor([[ 0.0036,  0.0353,  0.0204,  ...,  0.0107, -0.0213, -0.0278],\n",
       "         [ 0.0397,  0.0031, -0.0126,  ...,  0.0146, -0.0514, -0.0198],\n",
       "         [ 0.0044, -0.0297,  0.0109,  ..., -0.0105, -0.0070,  0.0262],\n",
       "         ...,\n",
       "         [ 0.0191,  0.0008,  0.0101,  ...,  0.0018,  0.0064,  0.0280],\n",
       "         [-0.0246,  0.0004,  0.0150,  ...,  0.0123,  0.0145,  0.0135],\n",
       "         [-0.0026,  0.0027,  0.0246,  ..., -0.0014,  0.0026,  0.0241]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_v.lora_up.weight': tensor([[-2.8534e-03, -2.8789e-05, -1.7891e-03,  ..., -8.5449e-04,\n",
       "          -8.8348e-03, -4.7088e-04],\n",
       "         [-7.6256e-03, -1.2016e-02,  8.6136e-03,  ...,  1.7044e-02,\n",
       "          -9.9564e-03,  8.1940e-03],\n",
       "         [ 1.9703e-03, -6.2764e-05,  5.9547e-03,  ..., -2.5024e-03,\n",
       "          -1.2074e-03, -1.3649e-02],\n",
       "         ...,\n",
       "         [ 9.4604e-03,  2.3117e-02, -8.7357e-03,  ..., -3.4008e-03,\n",
       "           1.6937e-02, -1.5221e-03],\n",
       "         [ 3.5858e-03,  9.3079e-03, -5.7106e-03,  ..., -3.2520e-04,\n",
       "           4.1294e-04, -5.3062e-03],\n",
       "         [-1.3687e-02, -5.5351e-03, -1.0628e-02,  ..., -7.0915e-03,\n",
       "           4.3640e-03,  5.1451e-04]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_k.lora_down.weight': tensor([[-0.0031,  0.0005, -0.0104,  ...,  0.0035,  0.0211, -0.0102],\n",
       "         [ 0.0064, -0.0209,  0.0142,  ...,  0.0158, -0.0003, -0.0059],\n",
       "         [-0.0135, -0.0113, -0.0130,  ...,  0.0285, -0.0114, -0.0042],\n",
       "         ...,\n",
       "         [-0.0087,  0.0098, -0.0107,  ..., -0.0024, -0.0060, -0.0004],\n",
       "         [-0.0007,  0.0116,  0.0073,  ..., -0.0071, -0.0130,  0.0178],\n",
       "         [-0.0169, -0.0187,  0.0047,  ..., -0.0201,  0.0003, -0.0098]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_k.lora_up.weight': tensor([[-0.0040, -0.0317, -0.0051,  ..., -0.0019, -0.0222,  0.0080],\n",
       "         [ 0.0043, -0.0325,  0.0083,  ..., -0.0011, -0.0153,  0.0086],\n",
       "         [ 0.0022,  0.0184,  0.0006,  ...,  0.0031,  0.0121, -0.0089],\n",
       "         ...,\n",
       "         [-0.0087,  0.0050, -0.0064,  ..., -0.0097, -0.0026,  0.0058],\n",
       "         [ 0.0019,  0.0194,  0.0063,  ..., -0.0058,  0.0126,  0.0044],\n",
       "         [-0.0142, -0.0104, -0.0131,  ..., -0.0192, -0.0075,  0.0144]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight': tensor([[-2.6642e-02,  1.3103e-03, -6.3782e-03,  ...,  2.5520e-03,\n",
       "           2.6428e-02,  1.1948e-02],\n",
       "         [-6.3057e-03, -2.4765e-02,  1.8356e-02,  ...,  1.5915e-02,\n",
       "          -7.1793e-03,  4.8180e-03],\n",
       "         [ 1.5236e-02, -1.0124e-02, -3.1395e-03,  ...,  1.8982e-02,\n",
       "           3.7632e-03,  1.3573e-02],\n",
       "         ...,\n",
       "         [ 1.3397e-02, -4.3035e-05, -6.5689e-03,  ...,  2.5696e-02,\n",
       "           4.0221e-04, -2.1515e-02],\n",
       "         [-2.0645e-02, -2.0294e-02, -6.8378e-04,  ..., -2.5726e-02,\n",
       "           5.1460e-03,  2.4750e-02],\n",
       "         [ 2.3453e-02, -1.9516e-02,  4.3106e-03,  ...,  2.3918e-03,\n",
       "          -1.7502e-02, -1.8768e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight': tensor([[-0.0257, -0.0063,  0.0002,  ..., -0.0072, -0.0091,  0.0133],\n",
       "         [-0.0093,  0.0086, -0.0047,  ..., -0.0013, -0.0190,  0.0035],\n",
       "         [-0.0018,  0.0074,  0.0024,  ..., -0.0023, -0.0211,  0.0008],\n",
       "         ...,\n",
       "         [ 0.0253, -0.0068,  0.0039,  ...,  0.0092,  0.0031, -0.0072],\n",
       "         [-0.0173,  0.0102,  0.0017,  ..., -0.0017, -0.0053,  0.0062],\n",
       "         [-0.0039,  0.0153, -0.0208,  ..., -0.0162,  0.0178,  0.0117]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_q.lora_down.weight': tensor([[-0.0375,  0.0219, -0.0359,  ...,  0.0228,  0.0111, -0.0007],\n",
       "         [ 0.0209,  0.0025, -0.0093,  ...,  0.0001,  0.0053,  0.0583],\n",
       "         [-0.0031,  0.0189,  0.0321,  ..., -0.0275, -0.0203,  0.0205],\n",
       "         ...,\n",
       "         [-0.0006,  0.0179,  0.0254,  ...,  0.0242, -0.0129,  0.0278],\n",
       "         [-0.0048, -0.0129, -0.0315,  ...,  0.0009,  0.0046, -0.0200],\n",
       "         [ 0.0120, -0.0151, -0.0030,  ..., -0.0306, -0.0154, -0.0140]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_q.lora_up.weight': tensor([[-0.0108, -0.0094, -0.0193,  ..., -0.0080, -0.0022,  0.0070],\n",
       "         [-0.0150, -0.0037, -0.0103,  ..., -0.0003, -0.0061,  0.0011],\n",
       "         [ 0.0098,  0.0147,  0.0207,  ...,  0.0078, -0.0003, -0.0068],\n",
       "         ...,\n",
       "         [ 0.0190, -0.0195, -0.0116,  ..., -0.0222,  0.0092,  0.0020],\n",
       "         [-0.0183,  0.0096,  0.0046,  ...,  0.0120, -0.0081, -0.0031],\n",
       "         [ 0.0239, -0.0109, -0.0070,  ..., -0.0098,  0.0104,  0.0096]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_v.lora_down.weight': tensor([[ 0.0157,  0.0180, -0.0116,  ...,  0.0210,  0.0082,  0.0157],\n",
       "         [-0.0146, -0.0110, -0.0132,  ..., -0.0010,  0.0060, -0.0226],\n",
       "         [ 0.0145, -0.0208,  0.0113,  ...,  0.0078,  0.0009,  0.0181],\n",
       "         ...,\n",
       "         [ 0.0124, -0.0096, -0.0207,  ..., -0.0244,  0.0033, -0.0164],\n",
       "         [-0.0088,  0.0115,  0.0187,  ...,  0.0020, -0.0059,  0.0127],\n",
       "         [ 0.0033,  0.0041,  0.0036,  ...,  0.0196,  0.0025, -0.0215]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_attn2_to_v.lora_up.weight': tensor([[ 0.0027, -0.0023, -0.0109,  ...,  0.0035, -0.0018,  0.0004],\n",
       "         [ 0.0123, -0.0018, -0.0163,  ..., -0.0006, -0.0026,  0.0044],\n",
       "         [-0.0291, -0.0307,  0.0245,  ..., -0.0270,  0.0293, -0.0287],\n",
       "         ...,\n",
       "         [ 0.0193,  0.0205, -0.0062,  ...,  0.0117, -0.0175,  0.0227],\n",
       "         [ 0.0155,  0.0122, -0.0181,  ...,  0.0047, -0.0202,  0.0139],\n",
       "         [ 0.0006,  0.0016, -0.0165,  ...,  0.0158, -0.0092,  0.0033]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight': tensor([[ 0.0117,  0.0245, -0.0179,  ...,  0.0038,  0.0037,  0.0238],\n",
       "         [-0.0347,  0.0035,  0.0220,  ...,  0.0021, -0.0252, -0.0265],\n",
       "         [ 0.0268, -0.0073,  0.0118,  ...,  0.0072,  0.0624,  0.0315],\n",
       "         ...,\n",
       "         [-0.0111, -0.0129,  0.0286,  ..., -0.0266, -0.0455, -0.0016],\n",
       "         [ 0.0398, -0.0076, -0.0327,  ...,  0.0249,  0.0052, -0.0189],\n",
       "         [ 0.0325, -0.0047,  0.0190,  ...,  0.0004,  0.0275,  0.0011]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight': tensor([[ 0.0047,  0.0001, -0.0055,  ..., -0.0027,  0.0081,  0.0026],\n",
       "         [-0.0132,  0.0018, -0.0044,  ...,  0.0044, -0.0086, -0.0318],\n",
       "         [-0.0210,  0.0282, -0.0248,  ...,  0.0165,  0.0022, -0.0380],\n",
       "         ...,\n",
       "         [ 0.0170, -0.0064,  0.0192,  ..., -0.0090, -0.0036,  0.0134],\n",
       "         [-0.0207, -0.0005, -0.0125,  ...,  0.0043,  0.0195, -0.0148],\n",
       "         [ 0.0254,  0.0166, -0.0115,  ...,  0.0388,  0.0314,  0.0113]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_2.lora_down.weight': tensor([[ 0.0265, -0.0223, -0.0161,  ...,  0.0080,  0.0067,  0.0130],\n",
       "         [-0.0036, -0.0160,  0.0017,  ..., -0.0103, -0.0065, -0.0399],\n",
       "         [ 0.0172,  0.0178,  0.0052,  ...,  0.0042, -0.0057,  0.0187],\n",
       "         ...,\n",
       "         [-0.0022, -0.0124,  0.0149,  ..., -0.0033,  0.0042, -0.0295],\n",
       "         [-0.0050, -0.0120, -0.0043,  ..., -0.0040,  0.0031, -0.0194],\n",
       "         [ 0.0095, -0.0173, -0.0244,  ...,  0.0030,  0.0005, -0.0163]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_2.lora_up.weight': tensor([[ 0.0133,  0.0008, -0.0132,  ...,  0.0070, -0.0035, -0.0175],\n",
       "         [ 0.0169, -0.0048,  0.0152,  ..., -0.0080, -0.0135, -0.0138],\n",
       "         [ 0.0151, -0.0144,  0.0244,  ..., -0.0095, -0.0131, -0.0078],\n",
       "         ...,\n",
       "         [ 0.0227, -0.0043,  0.0039,  ...,  0.0105,  0.0021,  0.0283],\n",
       "         [ 0.0138, -0.0025, -0.0017,  ..., -0.0191, -0.0194,  0.0032],\n",
       "         [-0.0070,  0.0062, -0.0097,  ..., -0.0046,  0.0012,  0.0083]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_k.lora_down.weight': tensor([[-0.0160, -0.0253, -0.0333,  ..., -0.0255, -0.0230, -0.0198],\n",
       "         [ 0.0136, -0.0242, -0.0226,  ...,  0.0295, -0.0391, -0.0200],\n",
       "         [ 0.0151,  0.0056, -0.0004,  ...,  0.0122, -0.0282, -0.0239],\n",
       "         ...,\n",
       "         [ 0.0234,  0.0039, -0.0078,  ..., -0.0331,  0.0029,  0.0267],\n",
       "         [-0.0468, -0.0360, -0.0119,  ...,  0.0403, -0.0421, -0.0139],\n",
       "         [ 0.0071,  0.0365,  0.0187,  ...,  0.0042,  0.0360, -0.0207]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_k.lora_up.weight': tensor([[ 0.0094,  0.0024, -0.0149,  ...,  0.0019,  0.0177, -0.0013],\n",
       "         [ 0.0133,  0.0226, -0.0207,  ...,  0.0145,  0.0198, -0.0049],\n",
       "         [ 0.0215,  0.0226,  0.0007,  ...,  0.0007,  0.0160, -0.0084],\n",
       "         ...,\n",
       "         [ 0.0163,  0.0145,  0.0125,  ...,  0.0065, -0.0044, -0.0035],\n",
       "         [-0.0075, -0.0065, -0.0056,  ...,  0.0124,  0.0082,  0.0091],\n",
       "         [ 0.0045,  0.0196, -0.0046,  ..., -0.0133,  0.0032, -0.0142]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_out_0.lora_down.weight': tensor([[-0.0100,  0.0006, -0.0228,  ..., -0.0153, -0.0169, -0.0087],\n",
       "         [-0.0020,  0.0151, -0.0118,  ...,  0.0029, -0.0056, -0.0209],\n",
       "         [-0.0128,  0.0182,  0.0026,  ..., -0.0224,  0.0007, -0.0152],\n",
       "         ...,\n",
       "         [ 0.0097, -0.0198,  0.0256,  ..., -0.0281,  0.0430, -0.0188],\n",
       "         [ 0.0330, -0.0042,  0.0025,  ..., -0.0030, -0.0033,  0.0037],\n",
       "         [ 0.0190,  0.0161, -0.0205,  ..., -0.0093,  0.0170, -0.0237]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_out_0.lora_up.weight': tensor([[-1.7609e-02,  1.2390e-02,  5.0201e-03,  ...,  9.3231e-03,\n",
       "           7.8888e-03, -3.0842e-03],\n",
       "         [-2.2797e-02,  1.1940e-02,  8.9340e-03,  ...,  4.0405e-02,\n",
       "          -2.0401e-02, -1.6098e-02],\n",
       "         [-3.7231e-02,  5.2910e-03, -3.3379e-06,  ...,  1.5312e-02,\n",
       "           1.4343e-03, -9.0485e-03],\n",
       "         ...,\n",
       "         [ 1.9028e-02, -6.6071e-03, -1.6541e-02,  ...,  2.0313e-03,\n",
       "          -9.1400e-03,  4.9057e-03],\n",
       "         [-7.2670e-03, -4.1237e-03,  2.4414e-03,  ...,  2.4002e-02,\n",
       "          -2.2675e-02, -7.4081e-03],\n",
       "         [ 4.3640e-03, -1.6388e-02, -1.6830e-02,  ...,  9.1095e-03,\n",
       "          -1.3092e-02,  9.1248e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_q.lora_down.weight': tensor([[ 1.7334e-02,  1.1330e-02,  4.5433e-03,  ...,  1.1734e-02,\n",
       "           4.3365e-02, -2.6062e-02],\n",
       "         [ 1.8158e-02, -7.7133e-03,  2.7145e-02,  ...,  3.1555e-02,\n",
       "           6.3667e-03, -2.0050e-02],\n",
       "         [-9.9258e-03,  2.5467e-02, -5.3444e-03,  ...,  4.1626e-02,\n",
       "          -1.2024e-02,  3.2768e-03],\n",
       "         ...,\n",
       "         [-2.0103e-03,  1.4717e-02,  2.9411e-03,  ...,  1.0384e-02,\n",
       "           3.5370e-02, -1.9562e-02],\n",
       "         [ 1.1551e-02,  6.4507e-03,  4.0283e-02,  ..., -7.0143e-04,\n",
       "          -8.7662e-03, -4.3259e-03],\n",
       "         [ 1.8570e-02, -1.9836e-02,  1.6174e-02,  ...,  5.1918e-03,\n",
       "           4.3755e-03, -2.0087e-05]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_q.lora_up.weight': tensor([[ 9.3155e-03, -1.7805e-03, -9.1782e-03,  ...,  1.1963e-02,\n",
       "          -1.1444e-02,  2.3132e-02],\n",
       "         [-1.3649e-02, -3.8648e-04, -2.5711e-02,  ..., -2.0275e-03,\n",
       "          -1.6556e-02,  3.0472e-02],\n",
       "         [ 5.4970e-03, -2.3224e-02,  6.2752e-03,  ...,  7.0496e-03,\n",
       "           2.3975e-03,  2.7866e-03],\n",
       "         ...,\n",
       "         [-1.3680e-02, -3.1677e-02, -2.0203e-02,  ..., -1.0307e-02,\n",
       "           1.4365e-05,  1.6953e-02],\n",
       "         [ 1.1620e-02,  3.2959e-02,  1.5236e-02,  ...,  2.8519e-02,\n",
       "          -4.2572e-03, -7.4806e-03],\n",
       "         [ 2.1179e-02,  7.1182e-03,  8.8425e-03,  ..., -2.3193e-03,\n",
       "           3.5267e-03, -2.7115e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_v.lora_down.weight': tensor([[ 0.0316, -0.0240,  0.0155,  ..., -0.0125, -0.0234,  0.0326],\n",
       "         [ 0.0170, -0.0236,  0.0235,  ...,  0.0174,  0.0061,  0.0003],\n",
       "         [ 0.0195, -0.0098,  0.0231,  ...,  0.0125, -0.0181,  0.0445],\n",
       "         ...,\n",
       "         [ 0.0159, -0.0018,  0.0005,  ...,  0.0074,  0.0087,  0.0046],\n",
       "         [ 0.0293, -0.0118,  0.0201,  ..., -0.0143,  0.0146, -0.0116],\n",
       "         [ 0.0224, -0.0154,  0.0237,  ..., -0.0260, -0.0195,  0.0366]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_v.lora_up.weight': tensor([[-0.0175, -0.0092, -0.0069,  ..., -0.0096, -0.0128, -0.0096],\n",
       "         [-0.0011, -0.0048, -0.0033,  ..., -0.0139, -0.0096, -0.0014],\n",
       "         [ 0.0218, -0.0125, -0.0159,  ..., -0.0152,  0.0070, -0.0159],\n",
       "         ...,\n",
       "         [-0.0333, -0.0015,  0.0061,  ...,  0.0021,  0.0133, -0.0040],\n",
       "         [-0.0312, -0.0069, -0.0022,  ..., -0.0118,  0.0020, -0.0122],\n",
       "         [ 0.0376, -0.0031, -0.0090,  ..., -0.0115, -0.0083, -0.0028]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_k.lora_down.weight': tensor([[-0.0072, -0.0047, -0.0113,  ..., -0.0067,  0.0098,  0.0134],\n",
       "         [ 0.0068, -0.0189, -0.0066,  ..., -0.0107,  0.0082,  0.0044],\n",
       "         [-0.0133, -0.0077, -0.0180,  ...,  0.0076,  0.0088,  0.0213],\n",
       "         ...,\n",
       "         [-0.0145,  0.0054, -0.0243,  ...,  0.0110, -0.0002, -0.0159],\n",
       "         [ 0.0255,  0.0102,  0.0054,  ..., -0.0149, -0.0204,  0.0238],\n",
       "         [-0.0039, -0.0121, -0.0031,  ..., -0.0112,  0.0082,  0.0049]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_k.lora_up.weight': tensor([[ 0.0057, -0.0278, -0.0248,  ...,  0.0283, -0.0269, -0.0291],\n",
       "         [-0.0012, -0.0341, -0.0239,  ...,  0.0259, -0.0255, -0.0158],\n",
       "         [-0.0285, -0.0028,  0.0074,  ..., -0.0023,  0.0077,  0.0105],\n",
       "         ...,\n",
       "         [-0.0042,  0.0008,  0.0086,  ..., -0.0024,  0.0053, -0.0029],\n",
       "         [-0.0113, -0.0148, -0.0207,  ...,  0.0153, -0.0230, -0.0178],\n",
       "         [ 0.0192,  0.0041,  0.0043,  ..., -0.0099,  0.0030, -0.0101]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_out_0.lora_down.weight': tensor([[ 0.0181,  0.0179, -0.0065,  ..., -0.0163, -0.0232, -0.0257],\n",
       "         [ 0.0007,  0.0225, -0.0325,  ..., -0.0128,  0.0262, -0.0009],\n",
       "         [-0.0030,  0.0002,  0.0108,  ...,  0.0248,  0.0118,  0.0168],\n",
       "         ...,\n",
       "         [-0.0279, -0.0107,  0.0035,  ..., -0.0024,  0.0004, -0.0024],\n",
       "         [ 0.0214,  0.0186,  0.0246,  ..., -0.0202,  0.0020,  0.0311],\n",
       "         [ 0.0219, -0.0283, -0.0062,  ..., -0.0099,  0.0085,  0.0203]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_out_0.lora_up.weight': tensor([[ 0.0114,  0.0104, -0.0100,  ..., -0.0202, -0.0111, -0.0128],\n",
       "         [ 0.0170,  0.0173, -0.0155,  ..., -0.0051, -0.0149, -0.0171],\n",
       "         [-0.0018, -0.0082, -0.0030,  ..., -0.0105, -0.0009, -0.0025],\n",
       "         ...,\n",
       "         [-0.0070, -0.0095,  0.0076,  ...,  0.0225,  0.0097,  0.0082],\n",
       "         [ 0.0035, -0.0054, -0.0042,  ..., -0.0115, -0.0044, -0.0058],\n",
       "         [ 0.0020,  0.0040, -0.0072,  ...,  0.0020, -0.0072, -0.0050]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_q.lora_down.weight': tensor([[ 0.0156, -0.0179,  0.0038,  ..., -0.0047, -0.0256, -0.0024],\n",
       "         [-0.0091, -0.0128,  0.0033,  ..., -0.0203,  0.0219,  0.0224],\n",
       "         [-0.0323, -0.0135, -0.0310,  ...,  0.0270,  0.0131, -0.0025],\n",
       "         ...,\n",
       "         [-0.0079,  0.0383, -0.0244,  ...,  0.0179,  0.0172,  0.0143],\n",
       "         [-0.0309, -0.0399, -0.0154,  ..., -0.0500, -0.0052, -0.0441],\n",
       "         [-0.0593, -0.0279, -0.0207,  ..., -0.0100,  0.0208, -0.0296]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_q.lora_up.weight': tensor([[ 0.0261, -0.0306, -0.0222,  ..., -0.0231,  0.0045, -0.0083],\n",
       "         [-0.0231,  0.0293,  0.0216,  ...,  0.0212, -0.0080,  0.0053],\n",
       "         [-0.0247,  0.0318,  0.0199,  ...,  0.0213, -0.0077,  0.0083],\n",
       "         ...,\n",
       "         [-0.0166,  0.0023,  0.0143,  ...,  0.0079, -0.0198,  0.0198],\n",
       "         [ 0.0067, -0.0042, -0.0015,  ...,  0.0013,  0.0028, -0.0259],\n",
       "         [-0.0068,  0.0098,  0.0085,  ...,  0.0043, -0.0031,  0.0266]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_v.lora_down.weight': tensor([[ 0.0027, -0.0077,  0.0036,  ...,  0.0278,  0.0092,  0.0199],\n",
       "         [-0.0053,  0.0262, -0.0266,  ...,  0.0120,  0.0044,  0.0151],\n",
       "         [ 0.0169, -0.0020,  0.0035,  ...,  0.0017, -0.0317,  0.0088],\n",
       "         ...,\n",
       "         [ 0.0278,  0.0225,  0.0042,  ...,  0.0286, -0.0016,  0.0268],\n",
       "         [ 0.0125,  0.0205, -0.0052,  ...,  0.0273, -0.0186,  0.0224],\n",
       "         [-0.0294,  0.0163,  0.0196,  ..., -0.0032, -0.0116, -0.0345]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_attn2_to_v.lora_up.weight': tensor([[ 0.0056,  0.0054,  0.0053,  ...,  0.0048,  0.0037, -0.0046],\n",
       "         [ 0.0042, -0.0047,  0.0035,  ...,  0.0056,  0.0101, -0.0070],\n",
       "         [-0.0129, -0.0111, -0.0127,  ..., -0.0127, -0.0130,  0.0127],\n",
       "         ...,\n",
       "         [ 0.0139,  0.0191,  0.0138,  ...,  0.0131,  0.0122, -0.0127],\n",
       "         [ 0.0126,  0.0093,  0.0116,  ...,  0.0124,  0.0128, -0.0128],\n",
       "         [ 0.0092,  0.0119,  0.0098,  ...,  0.0098,  0.0099, -0.0091]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_0_proj.lora_down.weight': tensor([[ 0.0167, -0.0097, -0.0406,  ...,  0.0112, -0.0221, -0.0188],\n",
       "         [ 0.0246,  0.0315,  0.0061,  ..., -0.0410,  0.0336,  0.0243],\n",
       "         [-0.0056,  0.0363,  0.0216,  ..., -0.0162, -0.0191,  0.0191],\n",
       "         ...,\n",
       "         [ 0.0094, -0.0023, -0.0119,  ..., -0.0148, -0.0117, -0.0296],\n",
       "         [-0.0429,  0.0219, -0.0053,  ...,  0.0033, -0.0172,  0.0034],\n",
       "         [-0.0166, -0.0062,  0.0089,  ..., -0.0159, -0.0131, -0.0342]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_0_proj.lora_up.weight': tensor([[-0.0032,  0.0025,  0.0014,  ..., -0.0003, -0.0002,  0.0013],\n",
       "         [ 0.0023,  0.0039,  0.0131,  ..., -0.0050,  0.0257, -0.0146],\n",
       "         [-0.0031,  0.0108,  0.0144,  ..., -0.0147,  0.0091, -0.0166],\n",
       "         ...,\n",
       "         [ 0.0013,  0.0037, -0.0026,  ..., -0.0084,  0.0024, -0.0063],\n",
       "         [ 0.0194, -0.0066, -0.0471,  ...,  0.0187, -0.0482,  0.0247],\n",
       "         [-0.0050, -0.0081, -0.0033,  ..., -0.0097, -0.0087,  0.0065]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_2.lora_down.weight': tensor([[ 0.0228,  0.0051, -0.0059,  ..., -0.0098, -0.0223,  0.0197],\n",
       "         [ 0.0191,  0.0025, -0.0233,  ..., -0.0109, -0.0134,  0.0079],\n",
       "         [-0.0125, -0.0072, -0.0063,  ...,  0.0021,  0.0200, -0.0158],\n",
       "         ...,\n",
       "         [ 0.0200,  0.0110, -0.0021,  ...,  0.0029, -0.0364,  0.0106],\n",
       "         [ 0.0049, -0.0065,  0.0011,  ...,  0.0065,  0.0210, -0.0037],\n",
       "         [ 0.0133,  0.0175, -0.0300,  ..., -0.0053, -0.0395, -0.0084]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_2.lora_up.weight': tensor([[-0.0058,  0.0156,  0.0012,  ...,  0.0032,  0.0087,  0.0023],\n",
       "         [ 0.0013,  0.0025,  0.0149,  ..., -0.0138, -0.0015, -0.0027],\n",
       "         [-0.0156,  0.0106,  0.0057,  ..., -0.0104,  0.0151, -0.0141],\n",
       "         ...,\n",
       "         [ 0.0171,  0.0262, -0.0260,  ...,  0.0223, -0.0159,  0.0226],\n",
       "         [-0.0091,  0.0041,  0.0059,  ..., -0.0082,  0.0140,  0.0039],\n",
       "         [-0.0069, -0.0010,  0.0115,  ..., -0.0033,  0.0054,  0.0081]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_k.lora_down.weight': tensor([[-0.0099, -0.0021, -0.0355,  ..., -0.0286,  0.0209,  0.0217],\n",
       "         [-0.0230, -0.0083,  0.0219,  ..., -0.0308,  0.0231, -0.0176],\n",
       "         [-0.0129,  0.0286,  0.0201,  ...,  0.0083,  0.0462,  0.0319],\n",
       "         ...,\n",
       "         [-0.0330, -0.0080, -0.0008,  ..., -0.0229, -0.0149,  0.0144],\n",
       "         [ 0.0401, -0.0180,  0.0352,  ...,  0.0291,  0.0126,  0.0261],\n",
       "         [ 0.0079,  0.0358, -0.0028,  ..., -0.0131, -0.0303,  0.0249]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_k.lora_up.weight': tensor([[ 0.0200, -0.0020, -0.0253,  ...,  0.0084, -0.0105, -0.0188],\n",
       "         [-0.0112,  0.0024, -0.0045,  ...,  0.0021, -0.0208,  0.0052],\n",
       "         [ 0.0235, -0.0128, -0.0288,  ...,  0.0045, -0.0188, -0.0390],\n",
       "         ...,\n",
       "         [-0.0134, -0.0095,  0.0009,  ..., -0.0003,  0.0199,  0.0082],\n",
       "         [-0.0022,  0.0160,  0.0029,  ..., -0.0079, -0.0022,  0.0013],\n",
       "         [-0.0313,  0.0007, -0.0157,  ...,  0.0088, -0.0051,  0.0038]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_out_0.lora_down.weight': tensor([[ 1.0818e-02, -2.2144e-03,  3.3975e-06,  ...,  1.4519e-02,\n",
       "          -4.6173e-02,  1.9699e-02],\n",
       "         [-3.6530e-02, -1.1612e-02, -2.5845e-03,  ..., -1.7441e-02,\n",
       "           4.3365e-02,  2.9793e-03],\n",
       "         [ 2.5558e-03,  2.2949e-02, -1.0658e-02,  ..., -3.9246e-02,\n",
       "           4.4281e-02,  1.1932e-02],\n",
       "         ...,\n",
       "         [ 1.0132e-02, -4.4189e-02, -1.7853e-03,  ..., -1.6510e-02,\n",
       "          -4.1077e-02,  1.5083e-02],\n",
       "         [-1.3916e-02, -1.1034e-03, -1.6739e-02,  ...,  5.7945e-03,\n",
       "          -7.7896e-03,  5.3619e-02],\n",
       "         [-1.9455e-04,  2.3468e-02,  6.9761e-04,  ..., -1.8206e-03,\n",
       "          -3.1143e-02, -7.8888e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_out_0.lora_up.weight': tensor([[ 0.0108, -0.0193, -0.0195,  ...,  0.0167, -0.0028,  0.0219],\n",
       "         [ 0.0084, -0.0229, -0.0034,  ..., -0.0042,  0.0025,  0.0322],\n",
       "         [ 0.0035, -0.0202,  0.0002,  ..., -0.0103,  0.0154, -0.0034],\n",
       "         ...,\n",
       "         [-0.0277,  0.0156,  0.0178,  ...,  0.0143,  0.0256, -0.0184],\n",
       "         [ 0.0223, -0.0113, -0.0055,  ...,  0.0055, -0.0138,  0.0182],\n",
       "         [ 0.0024, -0.0116,  0.0181,  ..., -0.0041,  0.0003, -0.0035]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_q.lora_down.weight': tensor([[ 0.0040,  0.0079, -0.0053,  ...,  0.0478, -0.0157,  0.0015],\n",
       "         [-0.0059, -0.0225,  0.0158,  ..., -0.0071, -0.0403, -0.0184],\n",
       "         [-0.0051,  0.0190,  0.0231,  ..., -0.0058,  0.0079,  0.0014],\n",
       "         ...,\n",
       "         [-0.0041, -0.0186,  0.0033,  ..., -0.0167, -0.0129,  0.0130],\n",
       "         [ 0.0135, -0.0175,  0.0083,  ..., -0.0179, -0.0148, -0.0105],\n",
       "         [-0.0477, -0.0090,  0.0337,  ..., -0.0026, -0.0047,  0.0312]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_q.lora_up.weight': tensor([[-1.2512e-02, -2.8900e-02,  1.6678e-02,  ..., -1.6098e-02,\n",
       "           8.9884e-05, -7.2441e-03],\n",
       "         [ 7.9498e-03,  2.6566e-02,  5.4741e-03,  ...,  1.2642e-02,\n",
       "          -9.0075e-04,  1.4076e-02],\n",
       "         [-8.8501e-03, -1.4397e-02, -7.2021e-03,  ...,  6.3095e-03,\n",
       "          -1.2665e-02,  1.5125e-03],\n",
       "         ...,\n",
       "         [-2.0370e-02, -2.3483e-02,  2.6047e-02,  ..., -5.3358e-04,\n",
       "           1.0452e-02,  1.2985e-02],\n",
       "         [ 2.9572e-02,  1.2436e-02,  3.5877e-03,  ...,  1.9470e-02,\n",
       "          -4.5180e-04, -1.6983e-02],\n",
       "         [-3.0472e-02,  1.9424e-02,  9.2926e-03,  ..., -1.4542e-02,\n",
       "           3.6438e-02,  8.2245e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_v.lora_down.weight': tensor([[ 0.0176,  0.0096, -0.0337,  ..., -0.0150, -0.0102, -0.0332],\n",
       "         [ 0.0104, -0.0288, -0.0406,  ...,  0.0323,  0.0076, -0.0098],\n",
       "         [-0.0266,  0.0229, -0.0268,  ...,  0.0257,  0.0179, -0.0177],\n",
       "         ...,\n",
       "         [ 0.0021,  0.0122,  0.0436,  ...,  0.0188,  0.0007,  0.0060],\n",
       "         [-0.0444,  0.0322, -0.0552,  ...,  0.0126, -0.0162, -0.0038],\n",
       "         [ 0.0107, -0.0275,  0.0039,  ..., -0.0292, -0.0260, -0.0132]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_v.lora_up.weight': tensor([[ 4.4441e-03,  7.5989e-03,  2.8702e-02,  ..., -1.7090e-02,\n",
       "           3.6652e-02,  6.9695e-03],\n",
       "         [-2.4815e-03, -1.9627e-03,  3.2074e-02,  ..., -1.7853e-02,\n",
       "           1.4816e-02, -6.7902e-03],\n",
       "         [-1.6434e-02,  2.2354e-02,  1.5640e-02,  ..., -3.1799e-02,\n",
       "           2.3636e-02, -8.0261e-03],\n",
       "         ...,\n",
       "         [ 3.6964e-03,  5.0392e-03,  1.4565e-02,  ..., -2.0859e-02,\n",
       "           9.0551e-04, -1.0956e-02],\n",
       "         [ 2.1000e-03,  2.8496e-03, -6.5918e-03,  ...,  6.8588e-03,\n",
       "           4.7386e-05, -2.2217e-02],\n",
       "         [ 2.1423e-02,  6.4468e-03,  3.3112e-03,  ...,  1.7136e-02,\n",
       "           7.6904e-03,  4.0970e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_k.lora_down.weight': tensor([[ 0.0036, -0.0220, -0.0030,  ..., -0.0195, -0.0082, -0.0202],\n",
       "         [-0.0186, -0.0088, -0.0192,  ...,  0.0260, -0.0245,  0.0144],\n",
       "         [ 0.0238, -0.0224,  0.0022,  ...,  0.0185,  0.0227, -0.0120],\n",
       "         ...,\n",
       "         [-0.0115, -0.0088, -0.0135,  ..., -0.0064,  0.0060,  0.0135],\n",
       "         [-0.0184, -0.0207, -0.0200,  ...,  0.0090,  0.0164,  0.0106],\n",
       "         [-0.0147, -0.0142, -0.0262,  ..., -0.0124,  0.0081, -0.0158]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_k.lora_up.weight': tensor([[-0.0038, -0.0049,  0.0208,  ...,  0.0044, -0.0036, -0.0147],\n",
       "         [ 0.0079, -0.0071,  0.0049,  ...,  0.0072,  0.0064,  0.0005],\n",
       "         [-0.0034,  0.0077, -0.0022,  ..., -0.0095, -0.0037,  0.0054],\n",
       "         ...,\n",
       "         [-0.0042,  0.0055, -0.0168,  ..., -0.0049, -0.0028,  0.0140],\n",
       "         [ 0.0020,  0.0061, -0.0135,  ..., -0.0087,  0.0004,  0.0093],\n",
       "         [ 0.0230, -0.0182, -0.0014,  ...,  0.0189,  0.0233, -0.0007]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_out_0.lora_down.weight': tensor([[-0.0163, -0.0329,  0.0161,  ...,  0.0331, -0.0121, -0.0193],\n",
       "         [ 0.0099, -0.0257,  0.0214,  ...,  0.0011,  0.0183, -0.0257],\n",
       "         [-0.0219, -0.0042,  0.0125,  ...,  0.0522,  0.0280, -0.0257],\n",
       "         ...,\n",
       "         [-0.0140,  0.0329, -0.0350,  ..., -0.0626, -0.0375, -0.0203],\n",
       "         [ 0.0273, -0.0034, -0.0152,  ..., -0.0389, -0.0287, -0.0200],\n",
       "         [ 0.0073, -0.0016,  0.0407,  ...,  0.0158,  0.0422, -0.0180]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_out_0.lora_up.weight': tensor([[ 0.0237,  0.0079,  0.0158,  ..., -0.0169, -0.0154,  0.0131],\n",
       "         [-0.0199,  0.0066,  0.0214,  ..., -0.0228, -0.0161,  0.0163],\n",
       "         [-0.0098, -0.0101, -0.0016,  ..., -0.0003, -0.0026, -0.0045],\n",
       "         ...,\n",
       "         [-0.0278, -0.0229, -0.0113,  ...,  0.0133,  0.0272, -0.0163],\n",
       "         [-0.0202, -0.0162, -0.0050,  ...,  0.0065, -0.0186, -0.0113],\n",
       "         [-0.0056,  0.0089,  0.0020,  ..., -0.0002, -0.0120,  0.0038]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_q.lora_down.weight': tensor([[ 0.0122,  0.0096,  0.0513,  ..., -0.0013,  0.0324,  0.0146],\n",
       "         [-0.0017, -0.0165,  0.0144,  ...,  0.0179,  0.0327,  0.0127],\n",
       "         [-0.0058,  0.0208, -0.0046,  ..., -0.0012,  0.0230, -0.0102],\n",
       "         ...,\n",
       "         [ 0.0138, -0.0017, -0.0241,  ...,  0.0110,  0.0102, -0.0262],\n",
       "         [-0.0207,  0.0082, -0.0313,  ...,  0.0403,  0.0121,  0.0139],\n",
       "         [ 0.0401, -0.0238, -0.0040,  ...,  0.0271,  0.0338,  0.0111]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_q.lora_up.weight': tensor([[ 0.0004, -0.0026, -0.0079,  ..., -0.0042,  0.0100,  0.0029],\n",
       "         [-0.0017, -0.0052, -0.0064,  ..., -0.0060,  0.0091,  0.0015],\n",
       "         [-0.0047, -0.0057, -0.0042,  ..., -0.0032,  0.0070,  0.0012],\n",
       "         ...,\n",
       "         [-0.0389, -0.0021,  0.0466,  ..., -0.0087, -0.0113,  0.0066],\n",
       "         [-0.0340, -0.0117,  0.0161,  ..., -0.0048,  0.0065,  0.0032],\n",
       "         [ 0.0148, -0.0032,  0.0144,  ..., -0.0046, -0.0056,  0.0103]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_v.lora_down.weight': tensor([[ 0.0082,  0.0018,  0.0127,  ..., -0.0169, -0.0093, -0.0236],\n",
       "         [-0.0024,  0.0258, -0.0125,  ..., -0.0067,  0.0117,  0.0066],\n",
       "         [-0.0085, -0.0256, -0.0047,  ...,  0.0248, -0.0054, -0.0392],\n",
       "         ...,\n",
       "         [ 0.0213,  0.0233,  0.0152,  ...,  0.0208, -0.0089,  0.0059],\n",
       "         [-0.0138,  0.0066, -0.0206,  ...,  0.0023,  0.0066,  0.0195],\n",
       "         [ 0.0259,  0.0050, -0.0140,  ..., -0.0098, -0.0114,  0.0154]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_attn2_to_v.lora_up.weight': tensor([[ 0.0131, -0.0133,  0.0093,  ..., -0.0135, -0.0153, -0.0142],\n",
       "         [-0.0106,  0.0111, -0.0196,  ...,  0.0122,  0.0189,  0.0117],\n",
       "         [ 0.0074, -0.0125, -0.0023,  ..., -0.0110, -0.0088, -0.0088],\n",
       "         ...,\n",
       "         [ 0.0132, -0.0110,  0.0065,  ..., -0.0120, -0.0155, -0.0130],\n",
       "         [-0.0052,  0.0083, -0.0146,  ...,  0.0063,  0.0025,  0.0034],\n",
       "         [-0.0018,  0.0034,  0.0050,  ...,  0.0034, -0.0010,  0.0029]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_0_proj.lora_down.weight': tensor([[ 0.0179, -0.0037,  0.0137,  ..., -0.0056, -0.0005, -0.0134],\n",
       "         [-0.0166,  0.0158, -0.0024,  ...,  0.0083,  0.0005, -0.0149],\n",
       "         [ 0.0109,  0.0108, -0.0467,  ..., -0.0020,  0.0093, -0.0026],\n",
       "         ...,\n",
       "         [-0.0150, -0.0014,  0.0236,  ..., -0.0115, -0.0177, -0.0044],\n",
       "         [ 0.0465,  0.0024, -0.0073,  ..., -0.0067, -0.0121,  0.0104],\n",
       "         [-0.0175, -0.0562,  0.0452,  ..., -0.0082, -0.0033,  0.0015]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_0_proj.lora_up.weight': tensor([[-0.0022,  0.0063, -0.0003,  ..., -0.0098,  0.0060, -0.0057],\n",
       "         [ 0.0033,  0.0058,  0.0171,  ..., -0.0050,  0.0086, -0.0235],\n",
       "         [ 0.0263, -0.0175, -0.0089,  ...,  0.0172, -0.0021,  0.0120],\n",
       "         ...,\n",
       "         [-0.0174,  0.0212,  0.0066,  ..., -0.0107, -0.0029,  0.0045],\n",
       "         [ 0.0126, -0.0202, -0.0124,  ...,  0.0121,  0.0031,  0.0160],\n",
       "         [-0.0009,  0.0106,  0.0093,  ..., -0.0048, -0.0385, -0.0052]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_2.lora_down.weight': tensor([[ 0.0022, -0.0271,  0.0394,  ..., -0.0317,  0.0254, -0.0204],\n",
       "         [-0.0001, -0.0398, -0.0068,  ...,  0.0101,  0.0082, -0.0238],\n",
       "         [-0.0051, -0.0273,  0.0276,  ...,  0.0031,  0.0187, -0.0094],\n",
       "         ...,\n",
       "         [ 0.0127, -0.0406,  0.0048,  ..., -0.0198,  0.0147, -0.0434],\n",
       "         [-0.0032, -0.0116, -0.0210,  ..., -0.0126, -0.0078, -0.0235],\n",
       "         [ 0.0072,  0.0382, -0.0144,  ...,  0.0199, -0.0109,  0.0420]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_2.lora_up.weight': tensor([[ 0.0133, -0.0006,  0.0133,  ..., -0.0150, -0.0004,  0.0149],\n",
       "         [ 0.0053,  0.0298,  0.0097,  ...,  0.0096,  0.0083, -0.0173],\n",
       "         [ 0.0235,  0.0021,  0.0134,  ..., -0.0001,  0.0269, -0.0122],\n",
       "         ...,\n",
       "         [-0.0223, -0.0330, -0.0334,  ..., -0.0225, -0.0091,  0.0275],\n",
       "         [ 0.0138,  0.0123,  0.0209,  ...,  0.0163,  0.0174, -0.0132],\n",
       "         [ 0.0125,  0.0108,  0.0078,  ...,  0.0240,  0.0179, -0.0217]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_k.lora_down.weight': tensor([[ 0.0251,  0.0277, -0.0354,  ..., -0.0289, -0.0086, -0.0172],\n",
       "         [ 0.0240,  0.0185, -0.0217,  ..., -0.0136, -0.0180,  0.0142],\n",
       "         [-0.0123,  0.0164, -0.0062,  ..., -0.0144, -0.0250,  0.0075],\n",
       "         ...,\n",
       "         [ 0.0061,  0.0217,  0.0491,  ...,  0.0012,  0.0438,  0.0100],\n",
       "         [-0.0053,  0.0073,  0.0239,  ...,  0.0190, -0.0052,  0.0224],\n",
       "         [-0.0508, -0.0182,  0.0267,  ...,  0.0312,  0.0022,  0.0157]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_k.lora_up.weight': tensor([[ 0.0177,  0.0410,  0.0102,  ..., -0.0119, -0.0525, -0.0132],\n",
       "         [ 0.0030,  0.0284,  0.0062,  ..., -0.0061, -0.0206, -0.0065],\n",
       "         [ 0.0077,  0.0250,  0.0070,  ..., -0.0053, -0.0096, -0.0084],\n",
       "         ...,\n",
       "         [-0.0157,  0.0090, -0.0158,  ..., -0.0029,  0.0025,  0.0033],\n",
       "         [ 0.0372,  0.0046,  0.0364,  ...,  0.0072,  0.0081,  0.0143],\n",
       "         [-0.0453,  0.0188, -0.0620,  ...,  0.0116, -0.0168, -0.0170]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_out_0.lora_down.weight': tensor([[ 0.0055, -0.0005,  0.0057,  ..., -0.0104, -0.0479, -0.0086],\n",
       "         [-0.0457, -0.0078,  0.0181,  ...,  0.0257,  0.0172, -0.0057],\n",
       "         [-0.0153,  0.0039, -0.0063,  ..., -0.0107,  0.0211, -0.0217],\n",
       "         ...,\n",
       "         [-0.0172,  0.0029, -0.0296,  ...,  0.0109,  0.0281,  0.0297],\n",
       "         [ 0.0234, -0.0085,  0.0095,  ..., -0.0201,  0.0085,  0.0313],\n",
       "         [ 0.0248, -0.0208, -0.0064,  ...,  0.0222, -0.0126,  0.0208]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_out_0.lora_up.weight': tensor([[ 0.0134, -0.0064, -0.0182,  ..., -0.0269, -0.0043,  0.0236],\n",
       "         [-0.0187,  0.0167, -0.0058,  ..., -0.0108, -0.0209,  0.0070],\n",
       "         [ 0.0004,  0.0078,  0.0032,  ...,  0.0015, -0.0039,  0.0026],\n",
       "         ...,\n",
       "         [ 0.0124, -0.0085,  0.0221,  ...,  0.0324,  0.0379, -0.0298],\n",
       "         [-0.0047, -0.0075, -0.0165,  ..., -0.0133, -0.0040,  0.0083],\n",
       "         [-0.0010, -0.0026,  0.0022,  ...,  0.0080,  0.0108,  0.0042]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_q.lora_down.weight': tensor([[ 0.0112,  0.0327, -0.0153,  ..., -0.0009, -0.0484, -0.0263],\n",
       "         [ 0.0314,  0.0122, -0.0115,  ..., -0.0215,  0.0265,  0.0209],\n",
       "         [ 0.0018, -0.0158, -0.0237,  ...,  0.0063, -0.0068, -0.0105],\n",
       "         ...,\n",
       "         [ 0.0151, -0.0142, -0.0037,  ...,  0.0273,  0.0294,  0.0107],\n",
       "         [ 0.0156, -0.0341, -0.0292,  ...,  0.0069,  0.0396,  0.0367],\n",
       "         [-0.0221, -0.0494, -0.0018,  ..., -0.0020, -0.0436, -0.0132]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_q.lora_up.weight': tensor([[ 3.4882e-02, -1.9274e-03,  2.4581e-04,  ..., -3.1376e-03,\n",
       "           1.1475e-02,  1.1932e-02],\n",
       "         [ 3.1464e-02, -9.9869e-03,  8.3847e-03,  ...,  7.8812e-03,\n",
       "           1.4168e-02, -1.5564e-03],\n",
       "         [-3.7262e-02,  1.1208e-02,  1.8196e-03,  ...,  1.0201e-02,\n",
       "           1.6083e-02, -2.2736e-02],\n",
       "         ...,\n",
       "         [-6.5002e-03,  1.0445e-02, -1.6037e-02,  ..., -1.0437e-02,\n",
       "           2.7481e-02,  1.3266e-03],\n",
       "         [-1.1284e-02, -1.0977e-03, -2.2095e-02,  ...,  3.0624e-02,\n",
       "          -5.1975e-04, -2.2415e-02],\n",
       "         [-1.3550e-02,  4.8790e-03, -1.0986e-02,  ...,  1.3092e-02,\n",
       "          -4.0174e-05, -3.7811e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_v.lora_down.weight': tensor([[-0.0185, -0.0227, -0.0012,  ..., -0.0090, -0.0065,  0.0073],\n",
       "         [-0.0099,  0.0166, -0.0112,  ...,  0.0406,  0.0380,  0.0223],\n",
       "         [-0.0093, -0.0088,  0.0567,  ..., -0.0122, -0.0031, -0.0038],\n",
       "         ...,\n",
       "         [-0.0347,  0.0142,  0.0291,  ..., -0.0428, -0.0068, -0.0061],\n",
       "         [-0.0027,  0.0010,  0.0191,  ...,  0.0158, -0.0042,  0.0081],\n",
       "         [ 0.0094, -0.0043, -0.0216,  ..., -0.0108, -0.0455, -0.0303]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_v.lora_up.weight': tensor([[-0.0033,  0.0143, -0.0116,  ...,  0.0014, -0.0011,  0.0009],\n",
       "         [-0.0057, -0.0034, -0.0203,  ..., -0.0022,  0.0040, -0.0282],\n",
       "         [-0.0194, -0.0248,  0.0148,  ...,  0.0144,  0.0302, -0.0335],\n",
       "         ...,\n",
       "         [-0.0034,  0.0047, -0.0019,  ...,  0.0180,  0.0015,  0.0020],\n",
       "         [ 0.0010,  0.0144, -0.0064,  ..., -0.0083, -0.0034, -0.0051],\n",
       "         [-0.0274,  0.0071, -0.0267,  ..., -0.0219,  0.0187, -0.0064]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_k.lora_down.weight': tensor([[ 0.0023,  0.0056, -0.0218,  ...,  0.0148,  0.0090, -0.0256],\n",
       "         [-0.0156,  0.0246,  0.0113,  ...,  0.0030,  0.0198,  0.0062],\n",
       "         [ 0.0195, -0.0252,  0.0053,  ...,  0.0024, -0.0045,  0.0033],\n",
       "         ...,\n",
       "         [-0.0005, -0.0089, -0.0201,  ...,  0.0183, -0.0175,  0.0079],\n",
       "         [-0.0187,  0.0094,  0.0184,  ..., -0.0027, -0.0102,  0.0062],\n",
       "         [ 0.0066,  0.0149,  0.0083,  ..., -0.0023,  0.0029,  0.0128]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_k.lora_up.weight': tensor([[ 0.0070, -0.0126, -0.0456,  ..., -0.0212,  0.0142,  0.0010],\n",
       "         [-0.0008, -0.0102, -0.0396,  ..., -0.0121,  0.0116, -0.0033],\n",
       "         [ 0.0107, -0.0096, -0.0116,  ..., -0.0123,  0.0118,  0.0023],\n",
       "         ...,\n",
       "         [-0.0015,  0.0018,  0.0097,  ...,  0.0029, -0.0027,  0.0131],\n",
       "         [ 0.0106, -0.0129, -0.0161,  ...,  0.0103,  0.0078, -0.0004],\n",
       "         [ 0.0067, -0.0065, -0.0140,  ...,  0.0020,  0.0041,  0.0017]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_out_0.lora_down.weight': tensor([[ 0.0042,  0.0255, -0.0309,  ...,  0.0105,  0.0025, -0.0109],\n",
       "         [-0.0219,  0.0127, -0.0281,  ...,  0.0072, -0.0013, -0.0041],\n",
       "         [ 0.0179, -0.0016,  0.0058,  ...,  0.0099,  0.0073,  0.0280],\n",
       "         ...,\n",
       "         [ 0.0274, -0.0001,  0.0060,  ...,  0.0054,  0.0004, -0.0066],\n",
       "         [ 0.0005,  0.0062, -0.0122,  ..., -0.0064,  0.0119,  0.0246],\n",
       "         [-0.0165,  0.0138,  0.0143,  ...,  0.0107, -0.0149,  0.0265]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_out_0.lora_up.weight': tensor([[ 0.0276,  0.0194,  0.0289,  ...,  0.0204,  0.0186,  0.0254],\n",
       "         [ 0.0134,  0.0196,  0.0201,  ...,  0.0169, -0.0050, -0.0013],\n",
       "         [ 0.0199,  0.0118,  0.0012,  ...,  0.0130,  0.0004,  0.0178],\n",
       "         ...,\n",
       "         [-0.0345, -0.0312, -0.0219,  ..., -0.0295, -0.0343,  0.0037],\n",
       "         [-0.0092, -0.0081, -0.0085,  ..., -0.0116, -0.0009, -0.0040],\n",
       "         [-0.0068, -0.0029, -0.0167,  ..., -0.0059, -0.0055, -0.0153]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_q.lora_down.weight': tensor([[ 0.0356,  0.0505,  0.0036,  ..., -0.0157,  0.0493,  0.0256],\n",
       "         [ 0.0111, -0.0243,  0.0381,  ...,  0.0294, -0.0555,  0.0145],\n",
       "         [-0.0375, -0.0371,  0.0188,  ...,  0.0410, -0.0026, -0.0083],\n",
       "         ...,\n",
       "         [-0.0194, -0.0122,  0.0251,  ..., -0.0049, -0.0084, -0.0479],\n",
       "         [ 0.0013, -0.0043,  0.0075,  ...,  0.0034,  0.0432,  0.0022],\n",
       "         [-0.0010,  0.0144, -0.0270,  ..., -0.0073,  0.0091,  0.0314]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_q.lora_up.weight': tensor([[ 0.0051,  0.0247,  0.0107,  ..., -0.0024, -0.0022,  0.0267],\n",
       "         [ 0.0060,  0.0086, -0.0003,  ..., -0.0105,  0.0014,  0.0244],\n",
       "         [-0.0369,  0.0162,  0.0274,  ..., -0.0185, -0.0368,  0.0120],\n",
       "         ...,\n",
       "         [ 0.0080, -0.0023,  0.0059,  ..., -0.0070, -0.0138,  0.0093],\n",
       "         [-0.0071,  0.0052,  0.0032,  ..., -0.0182, -0.0021,  0.0144],\n",
       "         [-0.0096,  0.0033, -0.0020,  ..., -0.0079,  0.0082,  0.0063]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_v.lora_down.weight': tensor([[ 0.0050, -0.0051, -0.0309,  ..., -0.0247, -0.0031,  0.0108],\n",
       "         [ 0.0004, -0.0135,  0.0217,  ...,  0.0302,  0.0320, -0.0153],\n",
       "         [-0.0133,  0.0060,  0.0292,  ..., -0.0041,  0.0221,  0.0080],\n",
       "         ...,\n",
       "         [ 0.0070, -0.0009,  0.0080,  ..., -0.0010, -0.0334,  0.0145],\n",
       "         [ 0.0058,  0.0178,  0.0110,  ..., -0.0309, -0.0021, -0.0075],\n",
       "         [ 0.0022,  0.0025,  0.0291,  ..., -0.0155, -0.0091,  0.0137]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_attn2_to_v.lora_up.weight': tensor([[-0.0236,  0.0166,  0.0226,  ..., -0.0235, -0.0191,  0.0251],\n",
       "         [ 0.0014,  0.0029,  0.0033,  ..., -0.0020, -0.0020,  0.0018],\n",
       "         [ 0.0310, -0.0199, -0.0238,  ...,  0.0304,  0.0277, -0.0281],\n",
       "         ...,\n",
       "         [ 0.0127, -0.0175, -0.0185,  ...,  0.0132,  0.0157,  0.0029],\n",
       "         [ 0.0054, -0.0030, -0.0022,  ...,  0.0021,  0.0029, -0.0069],\n",
       "         [ 0.0132, -0.0117, -0.0151,  ...,  0.0134,  0.0120, -0.0101]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_0_proj.lora_down.weight': tensor([[ 0.0363, -0.0087,  0.0305,  ..., -0.0132,  0.0154, -0.0104],\n",
       "         [ 0.0391,  0.0146,  0.0204,  ..., -0.0474,  0.0033,  0.0153],\n",
       "         [-0.0449,  0.0297, -0.0424,  ...,  0.0064, -0.0046,  0.0167],\n",
       "         ...,\n",
       "         [-0.0166,  0.0212,  0.0046,  ..., -0.0228,  0.0055, -0.0266],\n",
       "         [-0.0063, -0.0219,  0.0156,  ...,  0.0074, -0.0119,  0.0177],\n",
       "         [-0.0377, -0.0221, -0.0047,  ...,  0.0146, -0.0269, -0.0187]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_0_proj.lora_up.weight': tensor([[-1.4938e-02, -4.8828e-04, -1.1511e-03,  ...,  2.2471e-04,\n",
       "           2.4277e-02,  1.5671e-02],\n",
       "         [-1.3977e-02, -2.4536e-02, -1.1879e-02,  ...,  2.3499e-02,\n",
       "           1.4160e-02,  1.1917e-02],\n",
       "         [-2.4750e-02,  1.9670e-05,  5.6229e-03,  ..., -1.2390e-02,\n",
       "           2.4353e-02,  2.1317e-02],\n",
       "         ...,\n",
       "         [ 4.3488e-02, -7.1192e-04, -3.5645e-02,  ..., -2.5650e-02,\n",
       "          -2.9739e-02, -3.3844e-02],\n",
       "         [ 2.1038e-03, -6.6261e-03, -8.6288e-03,  ...,  1.3863e-02,\n",
       "          -4.3488e-03, -1.0216e-02],\n",
       "         [ 7.8917e-04, -3.9721e-04,  5.3635e-03,  ..., -1.1566e-02,\n",
       "          -2.6436e-03,  4.4479e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_2.lora_down.weight': tensor([[-0.0229, -0.0086,  0.0118,  ..., -0.0162,  0.0076, -0.0163],\n",
       "         [-0.0233, -0.0084, -0.0172,  ...,  0.0041, -0.0052,  0.0008],\n",
       "         [ 0.0081,  0.0194, -0.0105,  ...,  0.0188, -0.0191, -0.0051],\n",
       "         ...,\n",
       "         [ 0.0115, -0.0025, -0.0050,  ...,  0.0130, -0.0250, -0.0096],\n",
       "         [-0.0037, -0.0304,  0.0054,  ...,  0.0048,  0.0129, -0.0155],\n",
       "         [-0.0050, -0.0060,  0.0307,  ..., -0.0375,  0.0135,  0.0046]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_2.lora_up.weight': tensor([[ 3.7506e-02,  1.4969e-02, -3.4058e-02,  ..., -2.0630e-02,\n",
       "           3.4729e-02,  2.8656e-02],\n",
       "         [ 8.1406e-03, -5.3215e-03, -9.3002e-03,  ..., -1.1292e-02,\n",
       "           3.4714e-03, -6.4087e-03],\n",
       "         [-8.6517e-03,  2.0790e-04,  6.8903e-05,  ..., -1.3618e-02,\n",
       "          -1.4091e-02, -6.1150e-03],\n",
       "         ...,\n",
       "         [-5.8517e-03, -8.6441e-03,  5.8365e-03,  ...,  8.3389e-03,\n",
       "          -2.2945e-03,  7.5188e-03],\n",
       "         [-2.7618e-03, -2.1477e-03, -6.7520e-03,  ..., -1.9821e-02,\n",
       "           2.3842e-03,  7.2250e-03],\n",
       "         [ 2.8648e-03,  1.8478e-02, -8.9264e-03,  ...,  5.3024e-03,\n",
       "           4.1962e-03,  9.7198e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_k.lora_down.weight': tensor([[-3.6221e-03, -1.0674e-02, -4.2763e-03,  ..., -2.4643e-02,\n",
       "           4.4037e-02,  1.4175e-02],\n",
       "         [-5.2124e-02,  8.6365e-03, -3.2959e-02,  ...,  2.4338e-02,\n",
       "          -1.0017e-02,  1.1574e-02],\n",
       "         [-1.2154e-02, -2.8244e-02,  1.2283e-02,  ...,  2.2324e-02,\n",
       "           1.5381e-02,  2.1866e-02],\n",
       "         ...,\n",
       "         [ 2.0504e-03, -2.0920e-02,  3.9787e-03,  ...,  9.5487e-05,\n",
       "           4.7913e-02, -3.0960e-02],\n",
       "         [-1.9333e-02, -2.0538e-02, -6.8970e-03,  ...,  4.4189e-02,\n",
       "          -4.9286e-02,  1.4343e-02],\n",
       "         [ 1.3046e-02, -4.2267e-02,  1.4038e-02,  ...,  3.6469e-02,\n",
       "           1.0170e-02, -8.8654e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_k.lora_up.weight': tensor([[-0.0280, -0.0226,  0.0255,  ..., -0.0009,  0.0142,  0.0005],\n",
       "         [-0.0251, -0.0109,  0.0144,  ...,  0.0005,  0.0259,  0.0265],\n",
       "         [ 0.0302, -0.0031, -0.0167,  ...,  0.0089, -0.0271, -0.0250],\n",
       "         ...,\n",
       "         [ 0.0186,  0.0258, -0.0060,  ...,  0.0201, -0.0080,  0.0086],\n",
       "         [-0.0302, -0.0159,  0.0137,  ..., -0.0024,  0.0238,  0.0039],\n",
       "         [-0.0287, -0.0127,  0.0041,  ..., -0.0120,  0.0311,  0.0073]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_out_0.lora_down.weight': tensor([[ 0.0146, -0.0018,  0.0018,  ...,  0.0058, -0.0402,  0.0201],\n",
       "         [-0.0369, -0.0052,  0.0187,  ..., -0.0243, -0.0349,  0.0299],\n",
       "         [-0.0064,  0.0364, -0.0316,  ..., -0.0242, -0.0341,  0.0008],\n",
       "         ...,\n",
       "         [-0.0320,  0.0084,  0.0089,  ...,  0.0042, -0.0089,  0.0054],\n",
       "         [-0.0377,  0.0114,  0.0277,  ...,  0.0102,  0.0175, -0.0067],\n",
       "         [ 0.0237,  0.0161, -0.0039,  ..., -0.0271, -0.0058, -0.0180]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_out_0.lora_up.weight': tensor([[ 2.1839e-03, -3.7193e-03,  1.5991e-02,  ...,  4.5891e-03,\n",
       "          -2.9205e-02, -4.7668e-02],\n",
       "         [-1.7563e-02, -1.5556e-02, -2.1805e-02,  ..., -3.1509e-03,\n",
       "           2.7313e-03,  1.1902e-02],\n",
       "         [ 3.0937e-03, -8.8501e-03, -2.0889e-02,  ..., -2.1172e-03,\n",
       "           1.6947e-03,  1.8219e-02],\n",
       "         ...,\n",
       "         [ 9.4986e-03,  1.2711e-02, -2.8915e-02,  ...,  1.2810e-02,\n",
       "           2.0859e-02,  3.2959e-02],\n",
       "         [-4.2877e-03,  1.2146e-02, -1.4290e-02,  ...,  1.2344e-02,\n",
       "          -7.6714e-03, -1.8143e-02],\n",
       "         [ 9.0179e-03,  1.1909e-02, -9.8495e-03,  ...,  1.3573e-02,\n",
       "           6.7532e-05,  6.2561e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_q.lora_down.weight': tensor([[-0.0087, -0.0193, -0.0073,  ...,  0.0071,  0.0014, -0.0188],\n",
       "         [ 0.0027,  0.0056, -0.0501,  ...,  0.0232, -0.0753,  0.0284],\n",
       "         [-0.0079, -0.0304, -0.0032,  ..., -0.0108, -0.0031,  0.0533],\n",
       "         ...,\n",
       "         [-0.0234, -0.0268, -0.0561,  ...,  0.0059, -0.0048, -0.0068],\n",
       "         [ 0.0019, -0.0098,  0.0088,  ...,  0.0446,  0.0273, -0.0267],\n",
       "         [ 0.0324, -0.0164,  0.0020,  ...,  0.0290, -0.0131, -0.0323]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_q.lora_up.weight': tensor([[ 0.0016, -0.0026, -0.0025,  ...,  0.0202, -0.0267, -0.0115],\n",
       "         [-0.0118, -0.0004, -0.0133,  ..., -0.0169,  0.0173, -0.0036],\n",
       "         [-0.0223, -0.0045, -0.0163,  ..., -0.0304,  0.0292,  0.0238],\n",
       "         ...,\n",
       "         [-0.0200, -0.0215, -0.0277,  ..., -0.0306,  0.0192,  0.0233],\n",
       "         [-0.0041,  0.0137, -0.0005,  ...,  0.0049, -0.0027,  0.0112],\n",
       "         [-0.0063, -0.0147, -0.0078,  ..., -0.0065,  0.0057,  0.0288]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_v.lora_down.weight': tensor([[ 0.0407, -0.0364,  0.0300,  ..., -0.0004, -0.0294,  0.0137],\n",
       "         [ 0.0226,  0.0080, -0.0079,  ..., -0.0098, -0.0378,  0.0105],\n",
       "         [-0.0374,  0.0309, -0.0073,  ..., -0.0075,  0.0362, -0.0133],\n",
       "         ...,\n",
       "         [ 0.0230, -0.0061,  0.0339,  ..., -0.0079, -0.0294, -0.0366],\n",
       "         [-0.0292, -0.0039, -0.0247,  ...,  0.0322,  0.0221, -0.0088],\n",
       "         [ 0.0163, -0.0079,  0.0179,  ..., -0.0147, -0.0565,  0.0262]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_v.lora_up.weight': tensor([[ 0.0116,  0.0131, -0.0359,  ...,  0.0158, -0.0183,  0.0186],\n",
       "         [-0.0079,  0.0033, -0.0111,  ...,  0.0027,  0.0085, -0.0080],\n",
       "         [ 0.0123,  0.0073,  0.0147,  ...,  0.0029, -0.0049, -0.0014],\n",
       "         ...,\n",
       "         [-0.0085, -0.0017, -0.0018,  ..., -0.0002,  0.0123, -0.0098],\n",
       "         [ 0.0172,  0.0098,  0.0033,  ...,  0.0131, -0.0131,  0.0130],\n",
       "         [ 0.0210,  0.0190, -0.0105,  ...,  0.0208, -0.0227,  0.0216]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_k.lora_down.weight': tensor([[-0.0018,  0.0433, -0.0120,  ...,  0.0056,  0.0138, -0.0315],\n",
       "         [-0.0022, -0.0060, -0.0066,  ...,  0.0062, -0.0111, -0.0077],\n",
       "         [ 0.0007,  0.0411, -0.0404,  ..., -0.0105,  0.0334, -0.0254],\n",
       "         ...,\n",
       "         [ 0.0026,  0.0256, -0.0070,  ...,  0.0062,  0.0269, -0.0135],\n",
       "         [ 0.0050,  0.0081, -0.0048,  ...,  0.0025,  0.0201,  0.0051],\n",
       "         [ 0.0162, -0.0469,  0.0034,  ..., -0.0255, -0.0176,  0.0470]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_k.lora_up.weight': tensor([[ 0.0244, -0.0276, -0.0007,  ..., -0.0224, -0.0199, -0.0250],\n",
       "         [-0.0205, -0.0164, -0.0301,  ..., -0.0172, -0.0263,  0.0250],\n",
       "         [ 0.0350,  0.0039,  0.0239,  ...,  0.0036,  0.0140, -0.0382],\n",
       "         ...,\n",
       "         [-0.0256, -0.0132, -0.0259,  ..., -0.0129, -0.0157,  0.0249],\n",
       "         [ 0.0306,  0.0155,  0.0299,  ...,  0.0136,  0.0175, -0.0291],\n",
       "         [ 0.0302,  0.0147,  0.0294,  ...,  0.0143,  0.0188, -0.0301]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_out_0.lora_down.weight': tensor([[ 0.0251,  0.0041,  0.0004,  ..., -0.0307, -0.0084, -0.0186],\n",
       "         [ 0.0047,  0.0028, -0.0386,  ..., -0.0182,  0.0098, -0.0165],\n",
       "         [-0.0089,  0.0168,  0.0132,  ...,  0.0223, -0.0214,  0.0025],\n",
       "         ...,\n",
       "         [ 0.0043, -0.0079,  0.0240,  ..., -0.0146,  0.0231,  0.0183],\n",
       "         [ 0.0276, -0.0126,  0.0095,  ..., -0.0140, -0.0129,  0.0073],\n",
       "         [-0.0217, -0.0142, -0.0074,  ...,  0.0223,  0.0139, -0.0213]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_out_0.lora_up.weight': tensor([[-1.9943e-02, -1.9699e-02,  9.8190e-03,  ...,  1.9608e-02,\n",
       "           3.0182e-02, -7.8278e-03],\n",
       "         [-1.9485e-02, -1.6907e-02,  1.3664e-02,  ...,  1.7258e-02,\n",
       "           1.6586e-02, -1.3748e-02],\n",
       "         [-3.1412e-05, -5.3558e-03,  1.4740e-02,  ...,  4.6921e-03,\n",
       "          -2.8343e-03, -2.9053e-02],\n",
       "         ...,\n",
       "         [ 1.8341e-02,  1.4618e-02, -1.2596e-02,  ..., -1.5701e-02,\n",
       "          -1.4130e-02, -6.4507e-03],\n",
       "         [ 3.3340e-03, -1.4377e-04, -1.5509e-04,  ..., -4.5490e-04,\n",
       "           1.6623e-03,  9.2850e-03],\n",
       "         [ 1.1841e-02,  5.9624e-03,  2.6932e-03,  ..., -7.4997e-03,\n",
       "          -1.8524e-02,  5.1689e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_q.lora_down.weight': tensor([[-0.0410, -0.0471,  0.0203,  ..., -0.0212,  0.0365,  0.0214],\n",
       "         [ 0.0252,  0.0466,  0.0008,  ...,  0.0163, -0.0302,  0.0255],\n",
       "         [ 0.0296, -0.0012,  0.0388,  ..., -0.0108,  0.0010, -0.0045],\n",
       "         ...,\n",
       "         [-0.0075,  0.0140,  0.0392,  ...,  0.0306, -0.0065, -0.0006],\n",
       "         [ 0.0334, -0.0385, -0.0071,  ..., -0.0455,  0.0007,  0.0220],\n",
       "         [ 0.0045,  0.0367,  0.0057,  ...,  0.0329, -0.0141, -0.0092]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_q.lora_up.weight': tensor([[ 8.0643e-03, -8.2932e-03,  1.5396e-02,  ...,  1.8740e-03,\n",
       "           6.5651e-03, -6.8016e-03],\n",
       "         [-1.6556e-02,  2.6932e-02, -2.4643e-03,  ...,  1.4526e-02,\n",
       "          -2.2766e-02,  1.1398e-02],\n",
       "         [ 5.0774e-03, -2.5883e-03,  6.7749e-03,  ...,  9.1553e-03,\n",
       "           3.7968e-05,  5.7678e-03],\n",
       "         ...,\n",
       "         [ 1.8631e-02, -2.3987e-02, -5.5122e-03,  ..., -3.8414e-03,\n",
       "           1.0033e-02,  7.8201e-03],\n",
       "         [-1.6693e-02,  2.1912e-02,  4.4022e-03,  ...,  2.8439e-03,\n",
       "          -9.3079e-03, -7.4959e-03],\n",
       "         [ 1.3809e-02, -8.9188e-03,  6.8359e-03,  ..., -2.1698e-02,\n",
       "           1.3718e-02, -1.7029e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_v.lora_down.weight': tensor([[-0.0217, -0.0019,  0.0215,  ..., -0.0304, -0.0139,  0.0064],\n",
       "         [-0.0101,  0.0120, -0.0195,  ...,  0.0334, -0.0231,  0.0254],\n",
       "         [ 0.0197, -0.0077, -0.0098,  ..., -0.0036, -0.0144,  0.0193],\n",
       "         ...,\n",
       "         [ 0.0047,  0.0031,  0.0057,  ...,  0.0009, -0.0150,  0.0029],\n",
       "         [ 0.0003, -0.0135, -0.0169,  ...,  0.0124,  0.0002, -0.0091],\n",
       "         [-0.0182, -0.0119,  0.0115,  ..., -0.0293, -0.0109,  0.0097]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_attn2_to_v.lora_up.weight': tensor([[-0.0090,  0.0095,  0.0062,  ...,  0.0072, -0.0069, -0.0079],\n",
       "         [-0.0018,  0.0004, -0.0018,  ..., -0.0014, -0.0016,  0.0003],\n",
       "         [ 0.0086, -0.0117, -0.0096,  ..., -0.0163,  0.0066,  0.0132],\n",
       "         ...,\n",
       "         [ 0.0300, -0.0290, -0.0256,  ..., -0.0493,  0.0225,  0.0374],\n",
       "         [-0.0050,  0.0063,  0.0073,  ...,  0.0168, -0.0026, -0.0122],\n",
       "         [ 0.0267, -0.0253, -0.0249,  ..., -0.0473,  0.0215,  0.0362]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_0_proj.lora_down.weight': tensor([[ 2.6718e-02,  1.0193e-02, -1.3374e-02,  ...,  1.4008e-02,\n",
       "           1.9058e-02,  2.7405e-02],\n",
       "         [-1.5717e-03,  5.9547e-03,  3.2318e-02,  ...,  4.8676e-03,\n",
       "           5.5504e-03, -3.5744e-03],\n",
       "         [-9.3155e-03, -1.1162e-02,  2.5513e-02,  ..., -6.9084e-03,\n",
       "           5.6572e-03, -3.6926e-02],\n",
       "         ...,\n",
       "         [-4.3152e-02,  4.1321e-02, -3.8757e-02,  ..., -1.2993e-02,\n",
       "           1.5930e-02, -6.7711e-05],\n",
       "         [ 3.2410e-02, -7.1106e-03,  3.1204e-02,  ...,  2.0187e-02,\n",
       "          -4.5715e-02, -2.5879e-02],\n",
       "         [ 4.1779e-02, -6.2141e-03,  3.1235e-02,  ..., -1.3878e-02,\n",
       "           4.9171e-03, -2.2583e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_0_proj.lora_up.weight': tensor([[ 0.0116,  0.0084,  0.0154,  ..., -0.0086,  0.0040, -0.0024],\n",
       "         [ 0.0083,  0.0127,  0.0081,  ..., -0.0087,  0.0066,  0.0067],\n",
       "         [-0.0182, -0.0138,  0.0227,  ...,  0.0089,  0.0136, -0.0198],\n",
       "         ...,\n",
       "         [ 0.0044,  0.0038, -0.0117,  ..., -0.0015, -0.0079,  0.0112],\n",
       "         [-0.0055,  0.0024, -0.0106,  ...,  0.0274, -0.0251, -0.0008],\n",
       "         [ 0.0137,  0.0251,  0.0178,  ...,  0.0500, -0.0304,  0.0150]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_2.lora_down.weight': tensor([[ 0.0305, -0.0191,  0.0023,  ..., -0.0200, -0.0010, -0.0043],\n",
       "         [-0.0195, -0.0159,  0.0030,  ...,  0.0087,  0.0055, -0.0067],\n",
       "         [-0.0084,  0.0041, -0.0109,  ..., -0.0486, -0.0241,  0.0077],\n",
       "         ...,\n",
       "         [ 0.0117, -0.0012, -0.0174,  ..., -0.0202,  0.0018,  0.0238],\n",
       "         [ 0.0257,  0.0276,  0.0088,  ..., -0.0013, -0.0074, -0.0040],\n",
       "         [ 0.0025, -0.0230, -0.0294,  ..., -0.0098, -0.0135,  0.0131]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_2.lora_up.weight': tensor([[ 0.0277, -0.0136,  0.0024,  ...,  0.0369,  0.0038, -0.0252],\n",
       "         [ 0.0121,  0.0079,  0.0065,  ...,  0.0126, -0.0098,  0.0137],\n",
       "         [-0.0037,  0.0030, -0.0018,  ..., -0.0139, -0.0071, -0.0072],\n",
       "         ...,\n",
       "         [-0.0215,  0.0089, -0.0334,  ..., -0.0279, -0.0206,  0.0057],\n",
       "         [ 0.0081, -0.0063, -0.0023,  ...,  0.0086,  0.0026, -0.0154],\n",
       "         [-0.0044, -0.0031, -0.0157,  ..., -0.0123, -0.0003, -0.0087]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_k.lora_down.weight': tensor([[-0.0341, -0.0150,  0.0163,  ..., -0.0332, -0.0221,  0.0244],\n",
       "         [ 0.0256, -0.0332, -0.0349,  ..., -0.0087, -0.0320, -0.0053],\n",
       "         [ 0.0059,  0.0110, -0.0257,  ...,  0.0387, -0.0654, -0.0445],\n",
       "         ...,\n",
       "         [-0.0111, -0.0580,  0.0230,  ..., -0.0010, -0.0062,  0.0006],\n",
       "         [-0.0147,  0.0226,  0.0296,  ..., -0.0047,  0.0121, -0.0352],\n",
       "         [ 0.0463,  0.0161, -0.0234,  ...,  0.0166,  0.0159, -0.0061]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_k.lora_up.weight': tensor([[-0.0071,  0.0086,  0.0118,  ..., -0.0013,  0.0086,  0.0184],\n",
       "         [-0.0132, -0.0093, -0.0164,  ..., -0.0005,  0.0116,  0.0033],\n",
       "         [ 0.0004, -0.0092, -0.0201,  ...,  0.0002,  0.0055,  0.0059],\n",
       "         ...,\n",
       "         [ 0.0131,  0.0068,  0.0062,  ...,  0.0125, -0.0118,  0.0046],\n",
       "         [ 0.0063, -0.0168, -0.0159,  ..., -0.0071,  0.0266,  0.0015],\n",
       "         [ 0.0081,  0.0155,  0.0080,  ...,  0.0213, -0.0240, -0.0120]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_out_0.lora_down.weight': tensor([[-0.0115, -0.0538,  0.0023,  ..., -0.0438,  0.0366, -0.0034],\n",
       "         [-0.0291,  0.0279,  0.0160,  ...,  0.0234,  0.0116, -0.0107],\n",
       "         [-0.0276, -0.0050,  0.0356,  ..., -0.0497,  0.0359, -0.0035],\n",
       "         ...,\n",
       "         [-0.0020, -0.0023, -0.0547,  ...,  0.0003, -0.0393, -0.0295],\n",
       "         [-0.0005,  0.0435,  0.0229,  ..., -0.0223,  0.0354,  0.0078],\n",
       "         [-0.0355,  0.0131,  0.0272,  ...,  0.0041,  0.0131, -0.0161]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_out_0.lora_up.weight': tensor([[-1.6541e-02,  2.9449e-02, -7.4043e-03,  ..., -3.0479e-03,\n",
       "           1.8509e-02,  3.4607e-02],\n",
       "         [-2.1942e-02,  2.2106e-03, -1.7593e-02,  ...,  2.3071e-02,\n",
       "          -2.7786e-02,  1.5884e-02],\n",
       "         [ 1.4496e-03,  3.7909e-05,  1.5549e-02,  ..., -5.4665e-03,\n",
       "           1.5076e-02, -9.2850e-03],\n",
       "         ...,\n",
       "         [ 2.6459e-02, -9.6817e-03,  2.3212e-03,  ...,  1.0696e-02,\n",
       "           1.5621e-03, -1.9135e-02],\n",
       "         [-2.4628e-02,  1.2222e-02, -5.4932e-03,  ...,  1.7715e-02,\n",
       "          -1.4679e-02,  8.7128e-03],\n",
       "         [ 5.2490e-03, -1.7838e-02,  7.5073e-03,  ...,  1.7593e-02,\n",
       "          -3.3550e-03, -6.4964e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_q.lora_down.weight': tensor([[ 0.0190, -0.0315, -0.0076,  ..., -0.0041,  0.0177,  0.0072],\n",
       "         [-0.0464,  0.0275, -0.0298,  ..., -0.0131, -0.0135, -0.0018],\n",
       "         [-0.0340, -0.0104, -0.0073,  ...,  0.0102, -0.0328, -0.0016],\n",
       "         ...,\n",
       "         [-0.0468,  0.0152,  0.0152,  ...,  0.0209, -0.0123,  0.0350],\n",
       "         [-0.0459,  0.0213,  0.0106,  ..., -0.0097, -0.0536,  0.0162],\n",
       "         [ 0.0192,  0.0155,  0.0015,  ...,  0.0189, -0.0076, -0.0153]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_q.lora_up.weight': tensor([[ 0.0043, -0.0108,  0.0018,  ..., -0.0008,  0.0092,  0.0341],\n",
       "         [ 0.0137, -0.0107, -0.0035,  ..., -0.0010,  0.0006,  0.0351],\n",
       "         [ 0.0121, -0.0036, -0.0077,  ..., -0.0094, -0.0263, -0.0083],\n",
       "         ...,\n",
       "         [-0.0226,  0.0125,  0.0223,  ...,  0.0312,  0.0106, -0.0096],\n",
       "         [-0.0251,  0.0149,  0.0337,  ...,  0.0317,  0.0249,  0.0199],\n",
       "         [-0.0191,  0.0032,  0.0115,  ...,  0.0158,  0.0221, -0.0192]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_v.lora_down.weight': tensor([[-0.0019,  0.0187,  0.0046,  ...,  0.0074, -0.0047,  0.0126],\n",
       "         [-0.0100, -0.0079,  0.0051,  ...,  0.0302,  0.0093,  0.0110],\n",
       "         [ 0.0163,  0.0329, -0.0182,  ...,  0.0037, -0.0216,  0.0038],\n",
       "         ...,\n",
       "         [ 0.0241, -0.0350,  0.0186,  ..., -0.0044, -0.0066, -0.0095],\n",
       "         [ 0.0239,  0.0008,  0.0410,  ...,  0.0178, -0.0249, -0.0051],\n",
       "         [ 0.0127,  0.0199,  0.0081,  ...,  0.0235,  0.0181, -0.0154]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_v.lora_up.weight': tensor([[ 0.0139,  0.0311, -0.0145,  ...,  0.0077,  0.0009,  0.0174],\n",
       "         [ 0.0086,  0.0031,  0.0004,  ..., -0.0014, -0.0074,  0.0056],\n",
       "         [ 0.0043, -0.0109,  0.0070,  ..., -0.0075, -0.0151, -0.0149],\n",
       "         ...,\n",
       "         [-0.0205, -0.0079, -0.0036,  ..., -0.0160,  0.0086, -0.0195],\n",
       "         [-0.0040, -0.0052, -0.0067,  ...,  0.0304,  0.0204,  0.0050],\n",
       "         [ 0.0181,  0.0244, -0.0331,  ...,  0.0203,  0.0171,  0.0183]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_k.lora_down.weight': tensor([[ 0.0490, -0.0077,  0.0202,  ..., -0.0148, -0.0096,  0.0093],\n",
       "         [-0.0240, -0.0014, -0.0255,  ...,  0.0009, -0.0194, -0.0105],\n",
       "         [ 0.0110, -0.0377,  0.0406,  ..., -0.0107,  0.0011,  0.0101],\n",
       "         ...,\n",
       "         [-0.0125, -0.0056,  0.0114,  ..., -0.0150,  0.0467,  0.0004],\n",
       "         [-0.0287,  0.0262, -0.0381,  ...,  0.0229,  0.0216, -0.0241],\n",
       "         [-0.0081,  0.0155, -0.0065,  ..., -0.0316,  0.0282,  0.0053]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_k.lora_up.weight': tensor([[-0.0133,  0.0189, -0.0233,  ..., -0.0088,  0.0278, -0.0077],\n",
       "         [ 0.0068, -0.0228,  0.0310,  ...,  0.0111, -0.0324,  0.0117],\n",
       "         [-0.0153,  0.0230, -0.0242,  ..., -0.0131,  0.0263, -0.0119],\n",
       "         ...,\n",
       "         [-0.0227, -0.0053, -0.0146,  ...,  0.0251,  0.0164,  0.0226],\n",
       "         [-0.0218, -0.0104, -0.0103,  ...,  0.0257,  0.0154,  0.0238],\n",
       "         [ 0.0217,  0.0021,  0.0162,  ..., -0.0169, -0.0193, -0.0153]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_out_0.lora_down.weight': tensor([[-0.0159, -0.0133,  0.0126,  ...,  0.0125,  0.0018, -0.0120],\n",
       "         [ 0.0148, -0.0170, -0.0237,  ...,  0.0018,  0.0178, -0.0016],\n",
       "         [-0.0236, -0.0177,  0.0264,  ..., -0.0152, -0.0278,  0.0075],\n",
       "         ...,\n",
       "         [-0.0092,  0.0047, -0.0348,  ..., -0.0249, -0.0057, -0.0175],\n",
       "         [ 0.0162, -0.0167,  0.0322,  ..., -0.0104,  0.0010, -0.0224],\n",
       "         [-0.0246,  0.0204, -0.0110,  ..., -0.0283, -0.0133,  0.0031]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_out_0.lora_up.weight': tensor([[-0.0061,  0.0081, -0.0134,  ...,  0.0294, -0.0077,  0.0153],\n",
       "         [ 0.0239,  0.0028, -0.0088,  ...,  0.0178, -0.0119,  0.0054],\n",
       "         [-0.0131,  0.0057, -0.0089,  ..., -0.0022, -0.0121,  0.0018],\n",
       "         ...,\n",
       "         [ 0.0067, -0.0102,  0.0099,  ..., -0.0010,  0.0075, -0.0186],\n",
       "         [ 0.0042, -0.0076,  0.0047,  ...,  0.0028,  0.0020, -0.0090],\n",
       "         [-0.0204, -0.0014,  0.0044,  ..., -0.0162,  0.0046, -0.0093]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_q.lora_down.weight': tensor([[-0.0217, -0.0384, -0.0105,  ...,  0.0217,  0.0383,  0.0103],\n",
       "         [-0.0369,  0.0375,  0.0014,  ...,  0.0158,  0.0339, -0.0282],\n",
       "         [ 0.0057, -0.0149, -0.0253,  ..., -0.0010,  0.0341,  0.0287],\n",
       "         ...,\n",
       "         [-0.0302,  0.0245, -0.0429,  ..., -0.0258,  0.0066, -0.0048],\n",
       "         [ 0.0064, -0.0249,  0.0017,  ...,  0.0031,  0.0111,  0.0022],\n",
       "         [-0.0180, -0.0089, -0.0044,  ..., -0.0123, -0.0021,  0.0267]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_q.lora_up.weight': tensor([[-0.0235,  0.0224,  0.0230,  ...,  0.0243, -0.0265,  0.0149],\n",
       "         [ 0.0214, -0.0208, -0.0234,  ..., -0.0259,  0.0202, -0.0143],\n",
       "         [ 0.0124, -0.0017,  0.0052,  ...,  0.0072,  0.0175,  0.0015],\n",
       "         ...,\n",
       "         [-0.0072, -0.0087,  0.0017,  ..., -0.0192,  0.0191,  0.0013],\n",
       "         [ 0.0024, -0.0122,  0.0153,  ...,  0.0144,  0.0075, -0.0032],\n",
       "         [ 0.0012,  0.0001,  0.0016,  ...,  0.0160, -0.0101, -0.0050]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_v.lora_down.weight': tensor([[ 0.0151, -0.0084, -0.0169,  ..., -0.0184, -0.0027,  0.0226],\n",
       "         [ 0.0288, -0.0001, -0.0200,  ..., -0.0222, -0.0020,  0.0123],\n",
       "         [ 0.0228,  0.0062, -0.0117,  ...,  0.0080, -0.0098, -0.0021],\n",
       "         ...,\n",
       "         [ 0.0112,  0.0221, -0.0220,  ...,  0.0060, -0.0191,  0.0140],\n",
       "         [-0.0075,  0.0197, -0.0181,  ..., -0.0083, -0.0208, -0.0223],\n",
       "         [ 0.0099,  0.0193, -0.0102,  ...,  0.0080, -0.0215,  0.0256]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_attn2_to_v.lora_up.weight': tensor([[ 0.0012, -0.0123, -0.0070,  ..., -0.0115, -0.0100, -0.0099],\n",
       "         [-0.0100, -0.0096, -0.0056,  ..., -0.0088, -0.0005, -0.0085],\n",
       "         [ 0.0178,  0.0256,  0.0213,  ...,  0.0242,  0.0181,  0.0228],\n",
       "         ...,\n",
       "         [-0.0101, -0.0211, -0.0187,  ..., -0.0203, -0.0097, -0.0195],\n",
       "         [-0.0074, -0.0190, -0.0187,  ..., -0.0194, -0.0129, -0.0173],\n",
       "         [-0.0092,  0.0036,  0.0030,  ...,  0.0079,  0.0012,  0.0087]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_0_proj.lora_down.weight': tensor([[-6.0730e-03, -8.1778e-05,  2.7466e-02,  ..., -1.4206e-02,\n",
       "          -7.4158e-03,  1.1276e-02],\n",
       "         [-1.0429e-02, -3.6591e-02, -2.5368e-03,  ..., -4.1626e-02,\n",
       "          -9.0179e-03,  1.5495e-02],\n",
       "         [-6.6605e-03, -8.3303e-04, -8.3084e-03,  ...,  1.9501e-02,\n",
       "          -4.3583e-04, -1.1253e-02],\n",
       "         ...,\n",
       "         [-2.8076e-03,  2.0615e-02, -5.1079e-03,  ..., -3.8147e-02,\n",
       "          -3.5614e-02, -1.7273e-02],\n",
       "         [ 7.0915e-03,  3.4637e-02, -1.8860e-02,  ...,  3.4393e-02,\n",
       "           1.6220e-02,  2.0935e-02],\n",
       "         [-4.2877e-02, -1.0773e-02,  4.3945e-03,  ...,  2.0096e-02,\n",
       "           5.9357e-03,  2.6520e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_0_proj.lora_up.weight': tensor([[ 0.0030, -0.0012, -0.0118,  ...,  0.0086, -0.0013, -0.0077],\n",
       "         [-0.0173,  0.0275,  0.0184,  ..., -0.0103, -0.0169,  0.0325],\n",
       "         [ 0.0230, -0.0253, -0.0284,  ..., -0.0022,  0.0256, -0.0153],\n",
       "         ...,\n",
       "         [ 0.0165, -0.0228, -0.0121,  ...,  0.0105,  0.0215, -0.0132],\n",
       "         [ 0.0038,  0.0096, -0.0076,  ...,  0.0116,  0.0008,  0.0104],\n",
       "         [ 0.0399, -0.0172, -0.0484,  ...,  0.0203,  0.0334, -0.0380]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_2.lora_down.weight': tensor([[-0.0184,  0.0009, -0.0174,  ...,  0.0035,  0.0082,  0.0026],\n",
       "         [ 0.0071,  0.0181,  0.0204,  ..., -0.0016, -0.0318, -0.0233],\n",
       "         [-0.0016, -0.0088,  0.0377,  ..., -0.0282, -0.0278, -0.0220],\n",
       "         ...,\n",
       "         [ 0.0179, -0.0186, -0.0108,  ..., -0.0156, -0.0287, -0.0043],\n",
       "         [-0.0319,  0.0291, -0.0187,  ..., -0.0089, -0.0044,  0.0162],\n",
       "         [ 0.0186, -0.0254,  0.0179,  ..., -0.0071,  0.0064, -0.0155]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_2.lora_up.weight': tensor([[ 0.0167, -0.0159, -0.0147,  ..., -0.0009,  0.0129, -0.0140],\n",
       "         [ 0.0066, -0.0085, -0.0001,  ...,  0.0097,  0.0113, -0.0129],\n",
       "         [-0.0056,  0.0158, -0.0057,  ..., -0.0049,  0.0005, -0.0023],\n",
       "         ...,\n",
       "         [-0.0213,  0.0159,  0.0115,  ...,  0.0080, -0.0070,  0.0032],\n",
       "         [ 0.0045, -0.0020, -0.0031,  ..., -0.0107,  0.0005,  0.0010],\n",
       "         [-0.0126,  0.0237,  0.0150,  ...,  0.0105, -0.0059,  0.0080]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_k.lora_down.weight': tensor([[ 5.7755e-03,  4.4556e-03, -1.7746e-02,  ...,  2.2797e-02,\n",
       "           8.0948e-03,  2.9602e-02],\n",
       "         [-2.7206e-02,  2.1877e-03, -1.8721e-03,  ...,  2.8854e-02,\n",
       "          -4.7379e-03, -8.0490e-03],\n",
       "         [-2.4757e-03,  3.2845e-03, -9.4681e-03,  ...,  1.1024e-02,\n",
       "          -4.4060e-03,  2.2156e-02],\n",
       "         ...,\n",
       "         [-2.4166e-03,  1.2657e-02,  8.4229e-03,  ...,  2.7504e-03,\n",
       "          -1.3451e-02,  1.3092e-02],\n",
       "         [ 4.9896e-03,  1.5327e-02,  2.7504e-03,  ..., -1.7105e-02,\n",
       "           7.7019e-03, -4.3488e-03],\n",
       "         [-3.2990e-02, -9.2268e-05, -2.4185e-02,  ...,  4.2648e-03,\n",
       "          -4.2236e-02, -8.1100e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_k.lora_up.weight': tensor([[ 1.1772e-02,  6.5689e-03,  1.4015e-02,  ..., -1.4351e-02,\n",
       "          -5.1003e-03,  2.0462e-02],\n",
       "         [ 3.7136e-03, -6.3744e-03, -5.3062e-03,  ..., -4.2868e-04,\n",
       "          -2.0733e-03,  7.9269e-03],\n",
       "         [-9.3384e-03, -8.6136e-03,  1.5945e-02,  ..., -2.6970e-03,\n",
       "          -2.4376e-03,  6.7902e-03],\n",
       "         ...,\n",
       "         [ 1.6159e-02,  1.2436e-02,  4.2542e-02,  ..., -1.2978e-02,\n",
       "          -1.5160e-02,  2.6703e-02],\n",
       "         [ 8.2970e-05, -1.5884e-02, -8.8730e-03,  ...,  8.7814e-03,\n",
       "           2.2278e-02, -1.2291e-02],\n",
       "         [ 9.1629e-03,  6.8665e-03,  2.2659e-02,  ...,  4.0703e-03,\n",
       "          -1.5190e-02,  6.7940e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_out_0.lora_down.weight': tensor([[ 0.0194, -0.0022, -0.0361,  ...,  0.0022, -0.0278,  0.0321],\n",
       "         [-0.0086, -0.0123, -0.0051,  ..., -0.0181,  0.0181,  0.0257],\n",
       "         [ 0.0024,  0.0218,  0.0244,  ...,  0.0193,  0.0319, -0.0189],\n",
       "         ...,\n",
       "         [-0.0204,  0.0031, -0.0272,  ..., -0.0104,  0.0025,  0.0228],\n",
       "         [ 0.0070, -0.0305, -0.0429,  ..., -0.0018, -0.0136,  0.0067],\n",
       "         [-0.0479, -0.0056,  0.0236,  ..., -0.0067,  0.0045, -0.0165]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_out_0.lora_up.weight': tensor([[-0.0073,  0.0144, -0.0020,  ..., -0.0035,  0.0127,  0.0209],\n",
       "         [ 0.0041,  0.0043,  0.0260,  ..., -0.0121, -0.0139,  0.0132],\n",
       "         [-0.0014,  0.0029, -0.0022,  ...,  0.0010,  0.0027, -0.0021],\n",
       "         ...,\n",
       "         [-0.0333, -0.0058, -0.0205,  ...,  0.0143,  0.0186, -0.0123],\n",
       "         [ 0.0060, -0.0012,  0.0048,  ...,  0.0021, -0.0119,  0.0025],\n",
       "         [-0.0147, -0.0057, -0.0129,  ..., -0.0024,  0.0013, -0.0071]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_q.lora_down.weight': tensor([[ 0.0312, -0.0202,  0.0221,  ..., -0.0002,  0.0226,  0.0081],\n",
       "         [-0.0143, -0.0255,  0.0234,  ..., -0.0051,  0.0246,  0.0083],\n",
       "         [-0.0222,  0.0116,  0.0128,  ...,  0.0114, -0.0303, -0.0019],\n",
       "         ...,\n",
       "         [-0.0262, -0.0305, -0.0220,  ..., -0.0182, -0.0054,  0.0296],\n",
       "         [-0.0165,  0.0135, -0.0260,  ..., -0.0017,  0.0287,  0.0399],\n",
       "         [-0.0083, -0.0265, -0.0031,  ...,  0.0300, -0.0025,  0.0133]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_q.lora_up.weight': tensor([[ 1.2634e-02,  2.5635e-02, -8.3160e-03,  ..., -2.0752e-02,\n",
       "           2.4567e-02,  2.4475e-02],\n",
       "         [-6.3515e-03, -1.0780e-02,  2.2202e-03,  ...,  1.2596e-02,\n",
       "          -1.8501e-03, -1.3092e-02],\n",
       "         [ 1.3565e-02, -2.2171e-02, -9.6512e-03,  ..., -6.6490e-03,\n",
       "           7.1487e-03,  4.8218e-03],\n",
       "         ...,\n",
       "         [-2.0630e-02,  1.0849e-02,  1.6937e-02,  ..., -1.3695e-02,\n",
       "           1.1925e-02,  1.9211e-02],\n",
       "         [ 1.4275e-02, -1.7443e-03,  9.7156e-05,  ...,  2.8778e-02,\n",
       "           1.3763e-02, -2.8030e-02],\n",
       "         [ 1.0977e-03,  6.6757e-03, -9.7885e-03,  ..., -6.3248e-03,\n",
       "           1.9932e-03,  6.6605e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_v.lora_down.weight': tensor([[ 0.0042, -0.0179,  0.0348,  ...,  0.0099, -0.0267,  0.0373],\n",
       "         [ 0.0194,  0.0362, -0.0082,  ..., -0.0441,  0.0060,  0.0084],\n",
       "         [-0.0197, -0.0526, -0.0016,  ..., -0.0200, -0.0270,  0.0090],\n",
       "         ...,\n",
       "         [-0.0031,  0.0060,  0.0045,  ..., -0.0197, -0.0350,  0.0395],\n",
       "         [-0.0077,  0.0450,  0.0057,  ..., -0.0517, -0.0211, -0.0031],\n",
       "         [ 0.0113, -0.0098, -0.0205,  ..., -0.0209,  0.0346, -0.0179]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_v.lora_up.weight': tensor([[ 0.0079, -0.0155,  0.0039,  ...,  0.0087, -0.0036, -0.0027],\n",
       "         [ 0.0231, -0.0042, -0.0121,  ...,  0.0235,  0.0132, -0.0296],\n",
       "         [-0.0410,  0.0179, -0.0048,  ..., -0.0055, -0.0076,  0.0168],\n",
       "         ...,\n",
       "         [-0.0219, -0.0217,  0.0346,  ..., -0.0220, -0.0216,  0.0055],\n",
       "         [ 0.0069,  0.0115, -0.0046,  ...,  0.0082,  0.0131,  0.0064],\n",
       "         [ 0.0028,  0.0100, -0.0119,  ...,  0.0024,  0.0262,  0.0102]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_k.lora_down.weight': tensor([[-0.0059, -0.0098, -0.0241,  ...,  0.0089, -0.0221,  0.0125],\n",
       "         [-0.0123, -0.0076,  0.0185,  ...,  0.0074, -0.0063, -0.0080],\n",
       "         [ 0.0104,  0.0123,  0.0088,  ..., -0.0090, -0.0088, -0.0107],\n",
       "         ...,\n",
       "         [-0.0133,  0.0243, -0.0187,  ..., -0.0168,  0.0095,  0.0023],\n",
       "         [-0.0068, -0.0141,  0.0099,  ...,  0.0095,  0.0168, -0.0043],\n",
       "         [-0.0025, -0.0107,  0.0100,  ..., -0.0129,  0.0187, -0.0181]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_k.lora_up.weight': tensor([[ 1.9409e-02,  1.3840e-02,  1.2215e-02,  ..., -9.0485e-03,\n",
       "          -1.3359e-02,  1.5976e-02],\n",
       "         [-3.5248e-03, -5.9624e-03,  1.3924e-03,  ...,  8.9035e-03,\n",
       "           1.3247e-03, -2.0401e-02],\n",
       "         [ 8.2703e-03,  9.7122e-03,  3.9558e-03,  ..., -1.9501e-02,\n",
       "          -5.3787e-03,  2.1072e-02],\n",
       "         ...,\n",
       "         [ 1.0834e-03, -3.0174e-03, -1.2708e-04,  ...,  1.5469e-03,\n",
       "          -1.1349e-03, -2.9984e-03],\n",
       "         [-6.8665e-04, -4.4518e-03, -1.0643e-03,  ...,  3.2687e-04,\n",
       "           7.5054e-04,  7.6103e-03],\n",
       "         [ 3.2005e-03, -2.3003e-03,  3.4981e-03,  ..., -3.1948e-05,\n",
       "          -5.6801e-03, -2.4052e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_out_0.lora_down.weight': tensor([[ 0.0148,  0.0239, -0.0204,  ...,  0.0210, -0.0002,  0.0011],\n",
       "         [-0.0175,  0.0136,  0.0018,  ..., -0.0258,  0.0012,  0.0268],\n",
       "         [ 0.0239, -0.0133,  0.0306,  ..., -0.0265, -0.0013, -0.0125],\n",
       "         ...,\n",
       "         [ 0.0019,  0.0260,  0.0071,  ...,  0.0099, -0.0115,  0.0204],\n",
       "         [-0.0134,  0.0282,  0.0174,  ..., -0.0223, -0.0182,  0.0013],\n",
       "         [-0.0117,  0.0079,  0.0010,  ..., -0.0236,  0.0229, -0.0034]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_out_0.lora_up.weight': tensor([[-0.0076,  0.0070, -0.0080,  ..., -0.0116, -0.0116,  0.0016],\n",
       "         [-0.0079,  0.0069, -0.0074,  ..., -0.0110,  0.0005,  0.0174],\n",
       "         [-0.0025, -0.0172, -0.0028,  ...,  0.0009,  0.0047, -0.0283],\n",
       "         ...,\n",
       "         [ 0.0109,  0.0048,  0.0099,  ...,  0.0092,  0.0124,  0.0022],\n",
       "         [ 0.0025,  0.0030,  0.0028,  ...,  0.0020, -0.0087,  0.0055],\n",
       "         [ 0.0096,  0.0101,  0.0070,  ...,  0.0145,  0.0181,  0.0019]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_q.lora_down.weight': tensor([[-2.6855e-02,  1.8341e-02,  2.5940e-02,  ..., -1.2604e-02,\n",
       "          -1.8127e-02, -1.7151e-02],\n",
       "         [-3.0457e-02,  2.5055e-02, -3.7804e-03,  ...,  3.3915e-05,\n",
       "           2.6199e-02, -2.2171e-02],\n",
       "         [ 2.2369e-02,  4.8485e-03, -1.6068e-02,  ..., -2.8564e-02,\n",
       "          -3.0167e-02, -1.3336e-02],\n",
       "         ...,\n",
       "         [-7.6151e-04,  2.5360e-02, -1.6174e-02,  ...,  3.1433e-02,\n",
       "          -3.5828e-02,  1.8143e-02],\n",
       "         [ 1.9608e-02,  3.6438e-02,  2.1332e-02,  ...,  2.2964e-02,\n",
       "          -4.5624e-02, -2.3361e-02],\n",
       "         [ 2.4529e-03, -1.6724e-02, -3.7048e-02,  ..., -2.5909e-02,\n",
       "          -7.9117e-03, -2.4662e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_q.lora_up.weight': tensor([[-0.0110, -0.0188,  0.0096,  ...,  0.0300,  0.0132, -0.0150],\n",
       "         [ 0.0112,  0.0169,  0.0042,  ..., -0.0204, -0.0023,  0.0135],\n",
       "         [ 0.0148,  0.0167, -0.0221,  ..., -0.0290, -0.0246, -0.0002],\n",
       "         ...,\n",
       "         [ 0.0162,  0.0097, -0.0082,  ..., -0.0007,  0.0144, -0.0108],\n",
       "         [-0.0003, -0.0029,  0.0030,  ...,  0.0012,  0.0098,  0.0074],\n",
       "         [ 0.0156,  0.0050, -0.0127,  ...,  0.0069,  0.0137, -0.0089]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_v.lora_down.weight': tensor([[-9.0408e-03, -1.6434e-02, -1.7487e-02,  ..., -2.8030e-02,\n",
       "           6.8779e-03,  1.2474e-02],\n",
       "         [ 2.8114e-03, -1.5526e-02, -4.6968e-05,  ..., -1.8646e-02,\n",
       "           2.1729e-02,  1.5244e-02],\n",
       "         [-8.3160e-03,  2.3346e-02,  1.4427e-02,  ..., -4.0169e-03,\n",
       "           1.4793e-02, -1.0010e-02],\n",
       "         ...,\n",
       "         [ 1.6434e-02,  8.5144e-03,  2.2110e-02,  ..., -1.1597e-02,\n",
       "          -7.8201e-03,  2.2079e-02],\n",
       "         [ 1.1520e-02, -1.6661e-03, -7.1945e-03,  ..., -1.6800e-02,\n",
       "          -1.7288e-02,  1.8127e-02],\n",
       "         [ 5.8899e-03, -8.2550e-03, -7.6866e-03,  ...,  5.5313e-03,\n",
       "          -1.0277e-02,  1.6327e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_attn2_to_v.lora_up.weight': tensor([[ 0.0073, -0.0155, -0.0043,  ...,  0.0148,  0.0056, -0.0186],\n",
       "         [-0.0020, -0.0018,  0.0051,  ..., -0.0026,  0.0006,  0.0018],\n",
       "         [-0.0021, -0.0029, -0.0013,  ..., -0.0055, -0.0025, -0.0075],\n",
       "         ...,\n",
       "         [-0.0556, -0.0318,  0.0191,  ..., -0.0336, -0.0464,  0.0192],\n",
       "         [-0.0097, -0.0062,  0.0117,  ..., -0.0024, -0.0096,  0.0005],\n",
       "         [-0.0107, -0.0244,  0.0069,  ..., -0.0065, -0.0090, -0.0044]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_0_proj.lora_down.weight': tensor([[-0.0269,  0.0119, -0.0010,  ...,  0.0299, -0.0340,  0.0044],\n",
       "         [-0.0382,  0.0163,  0.0079,  ...,  0.0052, -0.0080,  0.0068],\n",
       "         [-0.0344, -0.0141, -0.0170,  ..., -0.0056, -0.0132, -0.0061],\n",
       "         ...,\n",
       "         [-0.0395, -0.0025,  0.0193,  ...,  0.0111, -0.0129,  0.0202],\n",
       "         [-0.0421, -0.0046,  0.0059,  ..., -0.0070,  0.0279,  0.0018],\n",
       "         [ 0.0113, -0.0001,  0.0279,  ...,  0.0138,  0.0333,  0.0041]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_0_proj.lora_up.weight': tensor([[-2.4719e-02, -2.0691e-02, -1.7624e-02,  ...,  1.0910e-02,\n",
       "          -2.1362e-02,  1.8188e-02],\n",
       "         [ 2.0599e-02,  3.5248e-02,  1.9775e-02,  ...,  1.1192e-02,\n",
       "          -1.0979e-02, -3.1052e-02],\n",
       "         [ 8.5526e-03,  1.4114e-02,  1.4328e-02,  ..., -9.2392e-03,\n",
       "           4.7417e-03, -1.4544e-03],\n",
       "         ...,\n",
       "         [ 2.0351e-03, -6.6032e-03,  8.2932e-03,  ...,  2.5375e-02,\n",
       "          -3.0380e-02, -1.2741e-02],\n",
       "         [ 5.6190e-03,  2.4521e-02, -2.2829e-05,  ...,  1.1162e-02,\n",
       "           1.1854e-03, -1.2947e-02],\n",
       "         [-6.1684e-03,  2.5883e-03,  1.8835e-05,  ...,  7.8354e-03,\n",
       "           9.3002e-03, -9.4452e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_2.lora_down.weight': tensor([[-0.0027, -0.0178,  0.0004,  ...,  0.0117,  0.0307,  0.0010],\n",
       "         [-0.0108,  0.0002,  0.0018,  ...,  0.0237,  0.0162,  0.0168],\n",
       "         [ 0.0345,  0.0073, -0.0067,  ..., -0.0019, -0.0119,  0.0035],\n",
       "         ...,\n",
       "         [ 0.0032,  0.0093,  0.0004,  ...,  0.0162, -0.0074,  0.0104],\n",
       "         [-0.0017,  0.0031, -0.0093,  ..., -0.0020, -0.0332,  0.0128],\n",
       "         [-0.0098,  0.0002, -0.0115,  ...,  0.0207,  0.0112, -0.0255]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_2.lora_up.weight': tensor([[ 0.0250,  0.0243, -0.0279,  ...,  0.0087, -0.0231,  0.0010],\n",
       "         [ 0.0104, -0.0028, -0.0077,  ...,  0.0045,  0.0021,  0.0158],\n",
       "         [-0.0042,  0.0027,  0.0013,  ..., -0.0072, -0.0043, -0.0127],\n",
       "         ...,\n",
       "         [-0.0029,  0.0071, -0.0086,  ...,  0.0047,  0.0003,  0.0050],\n",
       "         [-0.0019,  0.0058,  0.0056,  ...,  0.0026, -0.0020, -0.0083],\n",
       "         [-0.0024,  0.0011, -0.0060,  ...,  0.0058, -0.0107,  0.0166]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_k.lora_down.weight': tensor([[-0.0136,  0.0137,  0.0298,  ...,  0.0117,  0.0587,  0.0466],\n",
       "         [-0.0221, -0.0112, -0.0256,  ...,  0.0128,  0.0167, -0.0098],\n",
       "         [-0.0117, -0.0253, -0.0053,  ...,  0.0123, -0.0171, -0.0024],\n",
       "         ...,\n",
       "         [ 0.0110, -0.0168, -0.0142,  ..., -0.0412, -0.0442, -0.0284],\n",
       "         [ 0.0262, -0.0559, -0.0110,  ..., -0.0370, -0.0053, -0.0240],\n",
       "         [-0.0093, -0.0419, -0.0370,  ..., -0.0387, -0.0081, -0.0105]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_k.lora_up.weight': tensor([[ 0.0178,  0.0233, -0.0010,  ..., -0.0147, -0.0278, -0.0215],\n",
       "         [ 0.0214,  0.0329, -0.0107,  ..., -0.0266, -0.0508, -0.0301],\n",
       "         [ 0.0322,  0.0505, -0.0304,  ..., -0.0269, -0.0020, -0.0224],\n",
       "         ...,\n",
       "         [ 0.0367,  0.0093, -0.0225,  ..., -0.0155,  0.0172, -0.0425],\n",
       "         [ 0.0068, -0.0233,  0.0092,  ...,  0.0115,  0.0026,  0.0172],\n",
       "         [ 0.0042, -0.0073, -0.0010,  ...,  0.0117, -0.0034,  0.0075]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_out_0.lora_down.weight': tensor([[-4.4159e-02, -2.4506e-02,  1.7471e-02,  ...,  5.4398e-03,\n",
       "           2.7390e-02,  1.5205e-02],\n",
       "         [ 1.4290e-02,  5.1239e-02,  1.2047e-02,  ...,  2.0462e-02,\n",
       "          -8.5068e-03,  2.1243e-04],\n",
       "         [-1.1536e-02, -1.2337e-02,  2.6321e-02,  ..., -3.8757e-02,\n",
       "           1.1513e-02,  4.3182e-03],\n",
       "         ...,\n",
       "         [ 5.9845e-02,  7.4097e-02,  8.4972e-04,  ...,  3.9154e-02,\n",
       "          -1.1177e-02, -7.5817e-05],\n",
       "         [ 3.7628e-02,  9.0179e-03, -2.6291e-02,  ...,  4.0100e-02,\n",
       "           3.2043e-03, -1.5175e-02],\n",
       "         [-1.5419e-02, -4.4708e-02,  1.7303e-02,  ..., -1.1692e-03,\n",
       "           2.7237e-03,  8.3923e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_out_0.lora_up.weight': tensor([[-0.0023, -0.0048,  0.0075,  ...,  0.0014, -0.0018,  0.0025],\n",
       "         [ 0.0152, -0.0113,  0.0131,  ..., -0.0159, -0.0111, -0.0108],\n",
       "         [-0.0102, -0.0034, -0.0024,  ...,  0.0056,  0.0056, -0.0011],\n",
       "         ...,\n",
       "         [-0.0186,  0.0044, -0.0135,  ...,  0.0339,  0.0281, -0.0214],\n",
       "         [ 0.0250, -0.0198, -0.0099,  ..., -0.0187, -0.0307,  0.0287],\n",
       "         [-0.0006, -0.0149, -0.0235,  ...,  0.0219,  0.0116,  0.0085]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_q.lora_down.weight': tensor([[ 0.0102,  0.0302,  0.0299,  ..., -0.0230, -0.0136, -0.0105],\n",
       "         [-0.0019,  0.0057,  0.0128,  ...,  0.0447,  0.0156, -0.0128],\n",
       "         [ 0.0170, -0.0236,  0.0054,  ...,  0.0013,  0.0553,  0.0182],\n",
       "         ...,\n",
       "         [-0.0382, -0.0235, -0.0008,  ..., -0.0146,  0.0155, -0.0010],\n",
       "         [-0.0370, -0.0215, -0.0097,  ...,  0.0061, -0.0236,  0.0080],\n",
       "         [ 0.0084,  0.0317, -0.0286,  ..., -0.0133, -0.0076, -0.0179]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_q.lora_up.weight': tensor([[-7.8888e-03, -6.5842e-03,  9.9258e-03,  ...,  4.2648e-03,\n",
       "           2.1286e-02, -2.8610e-03],\n",
       "         [-7.9346e-03,  2.5749e-03,  1.1986e-02,  ..., -1.7456e-02,\n",
       "          -1.4046e-02, -2.4521e-02],\n",
       "         [ 7.5150e-03,  1.6983e-02, -4.4594e-03,  ..., -2.4780e-02,\n",
       "          -1.5381e-02, -2.3666e-02],\n",
       "         ...,\n",
       "         [-2.7527e-02, -7.8735e-03,  4.2572e-03,  ...,  1.3527e-02,\n",
       "          -3.1319e-03,  1.5251e-02],\n",
       "         [ 2.6489e-02,  1.5213e-02,  1.0597e-02,  ..., -5.2643e-03,\n",
       "          -4.3144e-03,  9.3043e-05],\n",
       "         [-1.0443e-03,  3.4149e-02,  4.0207e-03,  ..., -9.5367e-03,\n",
       "          -2.5085e-02, -1.7319e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_v.lora_down.weight': tensor([[-0.0078, -0.0123, -0.0128,  ...,  0.0416, -0.0044, -0.0244],\n",
       "         [ 0.0067,  0.0258,  0.0205,  ...,  0.0351, -0.0283, -0.0200],\n",
       "         [-0.0008, -0.0097, -0.0176,  ..., -0.0126,  0.0447,  0.0074],\n",
       "         ...,\n",
       "         [ 0.0057,  0.0195,  0.0272,  ...,  0.0255, -0.0144,  0.0113],\n",
       "         [-0.0197,  0.0081, -0.0021,  ..., -0.0130,  0.0287,  0.0434],\n",
       "         [-0.0261, -0.0439,  0.0454,  ...,  0.0141, -0.0131,  0.0112]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_v.lora_up.weight': tensor([[-0.0288,  0.0052, -0.0043,  ...,  0.0053,  0.0312, -0.0051],\n",
       "         [ 0.0198,  0.0079, -0.0041,  ...,  0.0106, -0.0148,  0.0178],\n",
       "         [ 0.0068, -0.0031,  0.0058,  ..., -0.0124,  0.0145, -0.0102],\n",
       "         ...,\n",
       "         [ 0.0054, -0.0090,  0.0014,  ...,  0.0006, -0.0095,  0.0045],\n",
       "         [-0.0057,  0.0035, -0.0128,  ...,  0.0195, -0.0145,  0.0089],\n",
       "         [ 0.0243,  0.0102,  0.0148,  ..., -0.0142,  0.0010, -0.0050]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_k.lora_down.weight': tensor([[-0.0156,  0.0144, -0.0086,  ..., -0.0053,  0.0041,  0.0202],\n",
       "         [-0.0068,  0.0062, -0.0174,  ...,  0.0153, -0.0175, -0.0051],\n",
       "         [-0.0097, -0.0101, -0.0100,  ..., -0.0056,  0.0171,  0.0015],\n",
       "         ...,\n",
       "         [ 0.0157, -0.0249, -0.0172,  ...,  0.0237,  0.0087, -0.0045],\n",
       "         [ 0.0112,  0.0097, -0.0038,  ...,  0.0066,  0.0044, -0.0067],\n",
       "         [ 0.0118, -0.0100, -0.0148,  ..., -0.0187,  0.0116, -0.0145]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_k.lora_up.weight': tensor([[ 2.6443e-02, -3.2837e-02, -3.2959e-02,  ...,  3.0991e-02,\n",
       "           3.5065e-02, -3.3752e-02],\n",
       "         [ 3.0365e-02, -3.6682e-02, -3.5614e-02,  ...,  3.5065e-02,\n",
       "           3.9917e-02, -3.7262e-02],\n",
       "         [-1.4069e-02,  2.8854e-02,  2.7573e-02,  ..., -2.5467e-02,\n",
       "          -3.3783e-02,  2.8473e-02],\n",
       "         ...,\n",
       "         [ 4.7646e-03, -8.1253e-03, -5.2643e-03,  ..., -4.0472e-05,\n",
       "           7.4387e-03, -5.6419e-03],\n",
       "         [-7.3051e-03,  1.0406e-02,  8.6594e-03,  ..., -1.6470e-03,\n",
       "          -1.0544e-02,  7.9880e-03],\n",
       "         [-1.7338e-03,  6.4316e-03,  6.0844e-03,  ...,  1.2489e-02,\n",
       "          -1.2636e-03,  2.2297e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_out_0.lora_down.weight': tensor([[-0.0025, -0.0128,  0.0014,  ..., -0.0040, -0.0013,  0.0098],\n",
       "         [ 0.0204,  0.0429, -0.0122,  ...,  0.0180,  0.0080, -0.0208],\n",
       "         [-0.0132,  0.0081, -0.0172,  ...,  0.0127, -0.0033, -0.0231],\n",
       "         ...,\n",
       "         [ 0.0108,  0.0211, -0.0104,  ...,  0.0054, -0.0237,  0.0153],\n",
       "         [ 0.0244,  0.0224,  0.0081,  ...,  0.0041,  0.0155,  0.0207],\n",
       "         [-0.0039,  0.0085, -0.0262,  ...,  0.0342,  0.0041, -0.0006]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_out_0.lora_up.weight': tensor([[ 0.0009,  0.0052,  0.0161,  ...,  0.0072, -0.0013, -0.0068],\n",
       "         [ 0.0006,  0.0105, -0.0015,  ...,  0.0074,  0.0083, -0.0045],\n",
       "         [-0.0034, -0.0020, -0.0211,  ..., -0.0010,  0.0035,  0.0052],\n",
       "         ...,\n",
       "         [-0.0026,  0.0079, -0.0112,  ...,  0.0073,  0.0179,  0.0017],\n",
       "         [ 0.0072, -0.0022, -0.0110,  ..., -0.0058,  0.0213, -0.0095],\n",
       "         [-0.0014, -0.0108, -0.0161,  ..., -0.0086, -0.0020,  0.0034]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_q.lora_down.weight': tensor([[-0.0350,  0.0132,  0.0258,  ...,  0.0460, -0.0087, -0.0021],\n",
       "         [-0.0079,  0.0045, -0.0100,  ...,  0.0389,  0.0382,  0.0317],\n",
       "         [-0.0031,  0.0262,  0.0187,  ..., -0.0027,  0.0439,  0.0037],\n",
       "         ...,\n",
       "         [ 0.0420,  0.0356, -0.0002,  ..., -0.0468, -0.0301, -0.0064],\n",
       "         [ 0.0228, -0.0150, -0.0448,  ...,  0.0131, -0.0255, -0.0104],\n",
       "         [ 0.0065,  0.0216,  0.0143,  ..., -0.0368,  0.0322,  0.0223]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_q.lora_up.weight': tensor([[-0.0071, -0.0161, -0.0061,  ..., -0.0044,  0.0036,  0.0053],\n",
       "         [-0.0177, -0.0108, -0.0242,  ...,  0.0172,  0.0105, -0.0248],\n",
       "         [ 0.0059, -0.0015, -0.0062,  ...,  0.0186,  0.0098, -0.0099],\n",
       "         ...,\n",
       "         [ 0.0285,  0.0248,  0.0038,  ..., -0.0087, -0.0073, -0.0072],\n",
       "         [-0.0314, -0.0282, -0.0391,  ...,  0.0059,  0.0249, -0.0272],\n",
       "         [ 0.0139,  0.0101, -0.0082,  ...,  0.0107,  0.0032, -0.0194]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_v.lora_down.weight': tensor([[ 0.0054,  0.0195, -0.0264,  ...,  0.0104, -0.0049,  0.0037],\n",
       "         [ 0.0027, -0.0259,  0.0018,  ...,  0.0159,  0.0213,  0.0171],\n",
       "         [-0.0115,  0.0078, -0.0021,  ...,  0.0141,  0.0192, -0.0129],\n",
       "         ...,\n",
       "         [-0.0114,  0.0210, -0.0060,  ..., -0.0242, -0.0244,  0.0041],\n",
       "         [ 0.0137, -0.0135,  0.0008,  ...,  0.0077, -0.0161,  0.0158],\n",
       "         [-0.0122,  0.0222, -0.0106,  ..., -0.0262, -0.0151,  0.0132]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_attn2_to_v.lora_up.weight': tensor([[ 0.0154, -0.0176, -0.0035,  ..., -0.0025,  0.0062, -0.0022],\n",
       "         [ 0.0049,  0.0026,  0.0121,  ...,  0.0117, -0.0136,  0.0102],\n",
       "         [-0.0104,  0.0243, -0.0054,  ..., -0.0057,  0.0020, -0.0060],\n",
       "         ...,\n",
       "         [-0.0049,  0.0248,  0.0060,  ...,  0.0051, -0.0080,  0.0080],\n",
       "         [ 0.0092,  0.0039,  0.0111,  ...,  0.0065, -0.0068,  0.0038],\n",
       "         [ 0.0034, -0.0155, -0.0086,  ..., -0.0053,  0.0113, -0.0035]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_0_proj.lora_down.weight': tensor([[ 0.0155,  0.0186,  0.0077,  ..., -0.0048, -0.0195,  0.0187],\n",
       "         [-0.0115,  0.0300,  0.0266,  ...,  0.0180,  0.0009,  0.0314],\n",
       "         [ 0.0255, -0.0305,  0.0114,  ..., -0.0282, -0.0279, -0.0061],\n",
       "         ...,\n",
       "         [ 0.0272, -0.0169,  0.0129,  ..., -0.0274,  0.0025,  0.0045],\n",
       "         [ 0.0182,  0.0138,  0.0208,  ..., -0.0079,  0.0204,  0.0240],\n",
       "         [-0.0091,  0.0142, -0.0170,  ..., -0.0228,  0.0234,  0.0088]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_0_proj.lora_up.weight': tensor([[-1.9608e-02,  2.2598e-02,  2.4673e-02,  ...,  2.9053e-02,\n",
       "          -1.3075e-03,  2.4277e-02],\n",
       "         [-2.5673e-03, -7.3891e-03, -1.1948e-02,  ...,  1.1551e-02,\n",
       "           1.5533e-02,  4.6310e-03],\n",
       "         [ 1.3153e-02, -1.8021e-02, -1.3008e-02,  ..., -1.8555e-02,\n",
       "           2.1835e-02, -2.7237e-03],\n",
       "         ...,\n",
       "         [ 4.1084e-03,  5.7220e-03,  1.4183e-02,  ..., -2.9587e-02,\n",
       "           1.7319e-02, -2.7313e-03],\n",
       "         [-2.8372e-05,  1.0347e-03,  2.4963e-02,  ..., -3.9520e-03,\n",
       "          -3.0518e-02, -7.2327e-03],\n",
       "         [-3.1586e-02,  1.3496e-02, -1.0368e-02,  ...,  2.9175e-02,\n",
       "          -8.8501e-03,  1.6251e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_2.lora_down.weight': tensor([[ 0.0015,  0.0071, -0.0134,  ..., -0.0076, -0.0173,  0.0041],\n",
       "         [-0.0095, -0.0013, -0.0292,  ...,  0.0082, -0.0297,  0.0283],\n",
       "         [-0.0357,  0.0090, -0.0205,  ...,  0.0100, -0.0294,  0.0117],\n",
       "         ...,\n",
       "         [-0.0267,  0.0096, -0.0190,  ..., -0.0005, -0.0372,  0.0099],\n",
       "         [ 0.0236,  0.0060,  0.0116,  ...,  0.0229,  0.0242, -0.0137],\n",
       "         [-0.0050, -0.0129,  0.0203,  ...,  0.0264,  0.0409,  0.0090]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_2.lora_up.weight': tensor([[ 0.0205, -0.0057, -0.0075,  ..., -0.0116,  0.0055,  0.0126],\n",
       "         [-0.0085,  0.0028,  0.0025,  ...,  0.0021, -0.0072, -0.0088],\n",
       "         [ 0.0095, -0.0003,  0.0084,  ...,  0.0049, -0.0115,  0.0045],\n",
       "         ...,\n",
       "         [ 0.0154,  0.0109,  0.0179,  ...,  0.0049, -0.0179, -0.0089],\n",
       "         [-0.0178, -0.0227, -0.0198,  ..., -0.0073,  0.0252,  0.0104],\n",
       "         [-0.0043, -0.0172, -0.0023,  ..., -0.0035,  0.0111,  0.0232]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_k.lora_down.weight': tensor([[ 0.0310,  0.0116,  0.0373,  ...,  0.0171,  0.0193, -0.0105],\n",
       "         [ 0.0049, -0.0618,  0.0125,  ..., -0.0294,  0.0157,  0.0393],\n",
       "         [ 0.0551, -0.0050,  0.0201,  ..., -0.0043,  0.0296,  0.0315],\n",
       "         ...,\n",
       "         [ 0.0069,  0.0123,  0.0191,  ...,  0.0037,  0.0102,  0.0160],\n",
       "         [ 0.0211, -0.0065,  0.0175,  ...,  0.0349, -0.0151, -0.0198],\n",
       "         [-0.0006,  0.0182, -0.0150,  ...,  0.0241, -0.0269, -0.0148]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_k.lora_up.weight': tensor([[-0.0643,  0.0140, -0.0324,  ..., -0.0386, -0.0587, -0.0637],\n",
       "         [-0.0347,  0.0028, -0.0298,  ..., -0.0191, -0.0294, -0.0266],\n",
       "         [ 0.0697, -0.0146,  0.0416,  ...,  0.0406,  0.0579,  0.0612],\n",
       "         ...,\n",
       "         [ 0.0163,  0.0172,  0.0222,  ..., -0.0323, -0.0008, -0.0395],\n",
       "         [ 0.0073, -0.0020,  0.0051,  ..., -0.0086,  0.0054, -0.0085],\n",
       "         [ 0.0100, -0.0085, -0.0003,  ...,  0.0114,  0.0080,  0.0090]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_out_0.lora_down.weight': tensor([[ 0.0317,  0.0408, -0.0359,  ..., -0.0119,  0.0095,  0.0280],\n",
       "         [ 0.0039, -0.0539,  0.0029,  ..., -0.0212, -0.0423,  0.0036],\n",
       "         [-0.0245, -0.0252,  0.0107,  ..., -0.0093,  0.0031,  0.0065],\n",
       "         ...,\n",
       "         [-0.0068, -0.0078,  0.0049,  ..., -0.0056, -0.0036, -0.0036],\n",
       "         [-0.0234, -0.0072,  0.0145,  ...,  0.0026, -0.0042, -0.0246],\n",
       "         [ 0.0041, -0.0098, -0.0186,  ..., -0.0267,  0.0359, -0.0141]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_out_0.lora_up.weight': tensor([[-0.0075,  0.0066,  0.0172,  ...,  0.0056,  0.0140, -0.0070],\n",
       "         [ 0.0221, -0.0337, -0.0135,  ..., -0.0299, -0.0147,  0.0157],\n",
       "         [-0.0063,  0.0041,  0.0086,  ...,  0.0047,  0.0146, -0.0050],\n",
       "         ...,\n",
       "         [-0.0135,  0.0081,  0.0129,  ...,  0.0133,  0.0176, -0.0194],\n",
       "         [ 0.0075, -0.0083,  0.0080,  ..., -0.0182, -0.0095,  0.0042],\n",
       "         [ 0.0121, -0.0031,  0.0167,  ...,  0.0027, -0.0173,  0.0039]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_q.lora_down.weight': tensor([[-9.6817e-03,  1.3802e-02,  5.0697e-03,  ..., -8.5473e-05,\n",
       "           1.3611e-02,  2.2087e-03],\n",
       "         [ 1.2665e-02,  2.2106e-03, -3.6865e-02,  ..., -4.1595e-02,\n",
       "          -9.8419e-03,  2.1229e-03],\n",
       "         [-1.6342e-02,  1.8158e-02,  5.3048e-06,  ...,  1.4183e-02,\n",
       "           1.9684e-02, -1.4282e-02],\n",
       "         ...,\n",
       "         [ 2.0630e-02, -5.8716e-02, -9.1095e-03,  ..., -2.2156e-02,\n",
       "          -2.2736e-02, -3.0396e-02],\n",
       "         [ 1.1131e-02,  9.7179e-04, -1.2283e-02,  ...,  6.8855e-03,\n",
       "          -7.0035e-05,  6.5956e-03],\n",
       "         [ 1.2352e-02,  1.1024e-02, -3.0632e-03,  ..., -2.6108e-02,\n",
       "          -3.4241e-02, -1.5808e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_q.lora_up.weight': tensor([[-0.0379, -0.0768,  0.0806,  ..., -0.0228, -0.0383,  0.0403],\n",
       "         [-0.0005, -0.0261,  0.0248,  ..., -0.0281, -0.0127,  0.0155],\n",
       "         [ 0.0286,  0.0658, -0.0646,  ...,  0.0024,  0.0260, -0.0276],\n",
       "         ...,\n",
       "         [ 0.0036,  0.0106, -0.0204,  ...,  0.0089,  0.0051, -0.0137],\n",
       "         [-0.0032,  0.0165, -0.0202,  ...,  0.0129,  0.0094, -0.0082],\n",
       "         [ 0.0037, -0.0133,  0.0302,  ..., -0.0215, -0.0056,  0.0100]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_v.lora_down.weight': tensor([[ 0.0428,  0.0221, -0.0204,  ...,  0.0199, -0.0121,  0.0042],\n",
       "         [-0.0130,  0.0094,  0.0324,  ..., -0.0223,  0.0129,  0.0080],\n",
       "         [ 0.0005, -0.0386,  0.0361,  ...,  0.0238, -0.0079,  0.0163],\n",
       "         ...,\n",
       "         [-0.0081,  0.0081, -0.0109,  ...,  0.0197,  0.0036, -0.0373],\n",
       "         [-0.0329,  0.0184, -0.0079,  ..., -0.0415, -0.0143, -0.0080],\n",
       "         [ 0.0295,  0.0298, -0.0317,  ...,  0.0047, -0.0213, -0.0107]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_v.lora_up.weight': tensor([[-0.0138, -0.0255, -0.0080,  ...,  0.0148, -0.0114,  0.0108],\n",
       "         [-0.0111, -0.0048, -0.0177,  ...,  0.0237,  0.0074, -0.0008],\n",
       "         [-0.0003,  0.0279,  0.0062,  ..., -0.0151,  0.0095, -0.0066],\n",
       "         ...,\n",
       "         [ 0.0073,  0.0102, -0.0125,  ...,  0.0131,  0.0126,  0.0033],\n",
       "         [ 0.0100,  0.0138, -0.0058,  ..., -0.0071, -0.0013, -0.0039],\n",
       "         [-0.0063, -0.0038, -0.0133,  ...,  0.0215, -0.0077,  0.0088]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_k.lora_down.weight': tensor([[-0.0139, -0.0055, -0.0080,  ..., -0.0102, -0.0261,  0.0039],\n",
       "         [-0.0141, -0.0031, -0.0094,  ..., -0.0166,  0.0020, -0.0006],\n",
       "         [-0.0006, -0.0183, -0.0190,  ..., -0.0209,  0.0075, -0.0168],\n",
       "         ...,\n",
       "         [-0.0086, -0.0136,  0.0149,  ..., -0.0049, -0.0047, -0.0274],\n",
       "         [ 0.0336, -0.0067,  0.0059,  ..., -0.0079,  0.0330,  0.0130],\n",
       "         [-0.0116,  0.0210,  0.0069,  ...,  0.0038, -0.0204, -0.0225]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_k.lora_up.weight': tensor([[ 0.0131, -0.0133, -0.0008,  ...,  0.0128, -0.0055,  0.0123],\n",
       "         [-0.0087,  0.0084, -0.0015,  ..., -0.0099,  0.0061, -0.0099],\n",
       "         [-0.0181,  0.0182, -0.0035,  ..., -0.0119,  0.0080, -0.0150],\n",
       "         ...,\n",
       "         [ 0.0161, -0.0073, -0.0116,  ..., -0.0124,  0.0155, -0.0051],\n",
       "         [ 0.0126, -0.0082, -0.0085,  ..., -0.0045,  0.0001,  0.0018],\n",
       "         [ 0.0321, -0.0144, -0.0079,  ...,  0.0032, -0.0094,  0.0201]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_out_0.lora_down.weight': tensor([[ 0.0209,  0.0323, -0.0027,  ..., -0.0008,  0.0213,  0.0049],\n",
       "         [-0.0191,  0.0173, -0.0036,  ...,  0.0102, -0.0176,  0.0245],\n",
       "         [-0.0024,  0.0289,  0.0309,  ...,  0.0016,  0.0132,  0.0175],\n",
       "         ...,\n",
       "         [ 0.0090,  0.0010, -0.0214,  ..., -0.0160,  0.0201,  0.0374],\n",
       "         [ 0.0289,  0.0316, -0.0105,  ...,  0.0249, -0.0011,  0.0204],\n",
       "         [ 0.0133,  0.0165,  0.0074,  ..., -0.0048, -0.0208,  0.0065]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_out_0.lora_up.weight': tensor([[-0.0074, -0.0069,  0.0010,  ...,  0.0034, -0.0089,  0.0013],\n",
       "         [ 0.0084,  0.0087, -0.0023,  ..., -0.0028,  0.0096, -0.0023],\n",
       "         [-0.0075, -0.0079, -0.0153,  ..., -0.0187, -0.0093, -0.0183],\n",
       "         ...,\n",
       "         [-0.0055, -0.0044, -0.0070,  ..., -0.0081, -0.0032, -0.0056],\n",
       "         [-0.0037, -0.0042,  0.0032,  ...,  0.0008, -0.0013,  0.0031],\n",
       "         [ 0.0054,  0.0051,  0.0033,  ...,  0.0024,  0.0067,  0.0012]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_q.lora_down.weight': tensor([[-0.0147, -0.0455,  0.0055,  ..., -0.0027, -0.0468, -0.0348],\n",
       "         [ 0.0338, -0.0171,  0.0220,  ...,  0.0066,  0.0044,  0.0001],\n",
       "         [-0.0011, -0.0476, -0.0005,  ..., -0.0159, -0.0447,  0.0106],\n",
       "         ...,\n",
       "         [ 0.0123, -0.0120, -0.0122,  ...,  0.0019,  0.0046,  0.0147],\n",
       "         [-0.0217, -0.0363, -0.0067,  ..., -0.0257,  0.0113,  0.0148],\n",
       "         [-0.0235, -0.0128, -0.0139,  ...,  0.0079,  0.0164, -0.0209]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_q.lora_up.weight': tensor([[ 0.0203,  0.0174,  0.0129,  ..., -0.0119,  0.0183,  0.0226],\n",
       "         [-0.0155, -0.0181, -0.0051,  ...,  0.0024, -0.0105, -0.0255],\n",
       "         [-0.0104, -0.0177,  0.0037,  ..., -0.0039, -0.0049, -0.0272],\n",
       "         ...,\n",
       "         [ 0.0009, -0.0024,  0.0164,  ..., -0.0015, -0.0187, -0.0118],\n",
       "         [ 0.0021, -0.0048,  0.0116,  ..., -0.0125, -0.0114,  0.0039],\n",
       "         [-0.0087,  0.0064, -0.0158,  ...,  0.0126,  0.0100, -0.0026]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_v.lora_down.weight': tensor([[-0.0025,  0.0270,  0.0081,  ...,  0.0075, -0.0151, -0.0124],\n",
       "         [ 0.0198, -0.0111,  0.0169,  ..., -0.0205, -0.0003, -0.0155],\n",
       "         [ 0.0055, -0.0048, -0.0039,  ..., -0.0261, -0.0207, -0.0156],\n",
       "         ...,\n",
       "         [ 0.0035,  0.0128,  0.0165,  ..., -0.0029,  0.0108,  0.0056],\n",
       "         [ 0.0184, -0.0040, -0.0069,  ..., -0.0040,  0.0031, -0.0145],\n",
       "         [ 0.0053, -0.0043,  0.0095,  ...,  0.0167,  0.0024,  0.0020]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_attn2_to_v.lora_up.weight': tensor([[-0.0152,  0.0077, -0.0126,  ...,  0.0152, -0.0104,  0.0215],\n",
       "         [ 0.0038,  0.0009,  0.0098,  ...,  0.0024,  0.0004,  0.0027],\n",
       "         [ 0.0162,  0.0347,  0.0079,  ..., -0.0396,  0.0062, -0.0207],\n",
       "         ...,\n",
       "         [-0.0091, -0.0173, -0.0116,  ...,  0.0157,  0.0039,  0.0063],\n",
       "         [ 0.0173,  0.0179,  0.0107,  ..., -0.0267,  0.0094, -0.0259],\n",
       "         [-0.0042, -0.0062, -0.0019,  ...,  0.0086, -0.0079,  0.0044]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_0_proj.lora_down.weight': tensor([[ 0.0250, -0.0363, -0.0007,  ...,  0.0403, -0.0084,  0.0209],\n",
       "         [ 0.0082, -0.0121, -0.0255,  ...,  0.0133, -0.0142,  0.0282],\n",
       "         [-0.0194, -0.0042,  0.0137,  ...,  0.0328,  0.0096,  0.0133],\n",
       "         ...,\n",
       "         [-0.0333, -0.0280, -0.0344,  ...,  0.0087, -0.0077, -0.0159],\n",
       "         [-0.0049, -0.0043, -0.0114,  ...,  0.0162, -0.0125,  0.0232],\n",
       "         [ 0.0172, -0.0031,  0.0007,  ..., -0.0193,  0.0104, -0.0167]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_0_proj.lora_up.weight': tensor([[ 0.0164,  0.0141, -0.0110,  ..., -0.0018, -0.0024,  0.0009],\n",
       "         [ 0.0007, -0.0074,  0.0072,  ..., -0.0055,  0.0070, -0.0039],\n",
       "         [-0.0001, -0.0018,  0.0405,  ..., -0.0137,  0.0095, -0.0076],\n",
       "         ...,\n",
       "         [-0.0462, -0.0304, -0.0100,  ..., -0.0090, -0.0286,  0.0525],\n",
       "         [ 0.0164,  0.0177,  0.0125,  ..., -0.0039,  0.0019, -0.0019],\n",
       "         [ 0.0272, -0.0047,  0.0081,  ..., -0.0387,  0.0158, -0.0097]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_2.lora_down.weight': tensor([[ 0.0175,  0.0090, -0.0245,  ...,  0.0131,  0.0098,  0.0143],\n",
       "         [-0.0304, -0.0241,  0.0158,  ..., -0.0397, -0.0426,  0.0054],\n",
       "         [ 0.0127,  0.0110,  0.0005,  ..., -0.0008,  0.0031, -0.0315],\n",
       "         ...,\n",
       "         [-0.0043, -0.0005, -0.0041,  ..., -0.0192,  0.0231,  0.0073],\n",
       "         [-0.0327, -0.0162,  0.0183,  ..., -0.0100, -0.0020,  0.0161],\n",
       "         [ 0.0258,  0.0062, -0.0023,  ..., -0.0131,  0.0020, -0.0148]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_2.lora_up.weight': tensor([[-0.0146,  0.0376,  0.0018,  ..., -0.0078,  0.0302, -0.0071],\n",
       "         [-0.0016,  0.0008,  0.0094,  ...,  0.0051, -0.0209,  0.0008],\n",
       "         [ 0.0096, -0.0094, -0.0021,  ..., -0.0130, -0.0018, -0.0073],\n",
       "         ...,\n",
       "         [ 0.0050, -0.0143,  0.0021,  ...,  0.0042,  0.0086, -0.0038],\n",
       "         [-0.0181,  0.0175,  0.0057,  ..., -0.0148, -0.0038,  0.0194],\n",
       "         [-0.0155, -0.0034,  0.0095,  ...,  0.0129, -0.0105,  0.0258]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_k.lora_down.weight': tensor([[ 0.0301,  0.0133,  0.0068,  ...,  0.0324,  0.0166,  0.0013],\n",
       "         [-0.0038, -0.0193,  0.0364,  ..., -0.0123,  0.0325, -0.0247],\n",
       "         [ 0.0158,  0.0153, -0.0186,  ...,  0.0098,  0.0244, -0.0108],\n",
       "         ...,\n",
       "         [ 0.0325,  0.0087,  0.0266,  ..., -0.0516,  0.0068, -0.0004],\n",
       "         [ 0.0049, -0.0028,  0.0053,  ...,  0.0042,  0.0102, -0.0217],\n",
       "         [-0.0002, -0.0364,  0.0293,  ...,  0.0485, -0.0285, -0.0136]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_k.lora_up.weight': tensor([[-1.3351e-02, -1.5427e-02,  5.2605e-03,  ...,  1.4931e-02,\n",
       "           7.5579e-05,  6.2943e-04],\n",
       "         [-6.1569e-03,  2.5253e-03,  1.3092e-02,  ..., -5.4131e-03,\n",
       "          -2.2629e-02, -9.8801e-03],\n",
       "         [-2.3518e-03,  1.6983e-02, -1.0719e-02,  ...,  1.5650e-03,\n",
       "          -2.5845e-04, -6.0310e-03],\n",
       "         ...,\n",
       "         [ 2.3132e-02, -9.4757e-03, -2.2049e-02,  ..., -1.6571e-02,\n",
       "           4.2053e-02,  2.3392e-02],\n",
       "         [-1.7456e-02, -1.0818e-02,  3.0701e-02,  ...,  1.0643e-02,\n",
       "          -2.1667e-02, -2.9327e-02],\n",
       "         [-1.6006e-02, -1.6190e-02,  2.5772e-02,  ...,  3.5038e-03,\n",
       "          -1.9516e-02, -2.5772e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_out_0.lora_down.weight': tensor([[ 0.0395, -0.0015, -0.0026,  ...,  0.0425,  0.0059, -0.0092],\n",
       "         [-0.0238, -0.0118, -0.0082,  ...,  0.0322,  0.0148,  0.0037],\n",
       "         [-0.0046, -0.0159,  0.0002,  ..., -0.0030, -0.0038,  0.0120],\n",
       "         ...,\n",
       "         [-0.0510, -0.0178, -0.0238,  ...,  0.0104, -0.0281,  0.0253],\n",
       "         [ 0.0363,  0.0085, -0.0154,  ..., -0.0340, -0.0082,  0.0006],\n",
       "         [-0.0107,  0.0306,  0.0078,  ...,  0.0392,  0.0298, -0.0030]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_out_0.lora_up.weight': tensor([[-0.0031, -0.0004, -0.0096,  ..., -0.0065, -0.0065,  0.0035],\n",
       "         [ 0.0002, -0.0052,  0.0217,  ..., -0.0048,  0.0121, -0.0112],\n",
       "         [ 0.0100,  0.0051, -0.0026,  ..., -0.0119, -0.0208,  0.0178],\n",
       "         ...,\n",
       "         [-0.0198,  0.0336, -0.0228,  ...,  0.0277, -0.0153,  0.0033],\n",
       "         [ 0.0119, -0.0097,  0.0036,  ..., -0.0068,  0.0064, -0.0010],\n",
       "         [ 0.0361,  0.0049,  0.0296,  ..., -0.0298, -0.0110, -0.0037]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_q.lora_down.weight': tensor([[-1.8692e-02, -4.1122e-03, -2.4887e-02,  ...,  1.4944e-03,\n",
       "           4.9362e-03,  1.8204e-02],\n",
       "         [ 1.7834e-03,  2.2263e-02, -4.0779e-03,  ...,  4.2343e-03,\n",
       "          -1.5154e-03, -1.2482e-02],\n",
       "         [-1.3977e-02, -8.2397e-03, -3.6346e-02,  ..., -1.8982e-02,\n",
       "           8.0109e-03,  6.5231e-03],\n",
       "         ...,\n",
       "         [ 3.7456e-04,  8.9288e-05, -1.6754e-02,  ...,  3.2654e-02,\n",
       "           1.0735e-02,  8.0261e-03],\n",
       "         [-3.2654e-02,  3.3203e-02, -2.2751e-02,  ..., -7.5798e-03,\n",
       "          -5.7709e-02,  1.3313e-02],\n",
       "         [ 1.5442e-02, -2.6871e-02,  2.3849e-02,  ...,  1.4359e-02,\n",
       "           3.0136e-02, -2.5604e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_q.lora_up.weight': tensor([[-0.0021,  0.0026,  0.0085,  ...,  0.0057, -0.0074, -0.0129],\n",
       "         [ 0.0005,  0.0035,  0.0069,  ...,  0.0005,  0.0018,  0.0027],\n",
       "         [-0.0079, -0.0155, -0.0197,  ..., -0.0039,  0.0302, -0.0065],\n",
       "         ...,\n",
       "         [-0.0076,  0.0076,  0.0042,  ..., -0.0044, -0.0377,  0.0230],\n",
       "         [ 0.0155,  0.0135,  0.0091,  ...,  0.0126,  0.0226, -0.0167],\n",
       "         [ 0.0257,  0.0315,  0.0233,  ...,  0.0117, -0.0065, -0.0145]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_v.lora_down.weight': tensor([[-0.0211,  0.0273,  0.0273,  ..., -0.0027, -0.0329,  0.0115],\n",
       "         [-0.0141,  0.0331,  0.0059,  ...,  0.0123, -0.0184, -0.0177],\n",
       "         [-0.0307,  0.0116, -0.0180,  ..., -0.0184, -0.0445, -0.0148],\n",
       "         ...,\n",
       "         [ 0.0174,  0.0321, -0.0123,  ..., -0.0483, -0.0513, -0.0507],\n",
       "         [-0.0382,  0.0056, -0.0267,  ...,  0.0453,  0.0468,  0.0274],\n",
       "         [ 0.0095, -0.0042, -0.0061,  ..., -0.0462,  0.0144, -0.0157]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_v.lora_up.weight': tensor([[-0.0018,  0.0080,  0.0042,  ..., -0.0132, -0.0025, -0.0193],\n",
       "         [-0.0019, -0.0115,  0.0047,  ..., -0.0021,  0.0065,  0.0073],\n",
       "         [-0.0170,  0.0126, -0.0188,  ..., -0.0213,  0.0317, -0.0031],\n",
       "         ...,\n",
       "         [-0.0006,  0.0051, -0.0024,  ...,  0.0057, -0.0063,  0.0040],\n",
       "         [ 0.0071, -0.0032, -0.0067,  ...,  0.0139, -0.0152,  0.0065],\n",
       "         [-0.0004, -0.0240, -0.0004,  ...,  0.0119, -0.0168,  0.0046]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_k.lora_down.weight': tensor([[ 0.0061, -0.0134,  0.0033,  ...,  0.0113,  0.0014,  0.0222],\n",
       "         [ 0.0116,  0.0078, -0.0209,  ...,  0.0154, -0.0113, -0.0155],\n",
       "         [-0.0160,  0.0104,  0.0251,  ..., -0.0269, -0.0149, -0.0196],\n",
       "         ...,\n",
       "         [-0.0082,  0.0182,  0.0098,  ..., -0.0087, -0.0076,  0.0059],\n",
       "         [ 0.0304,  0.0073, -0.0160,  ...,  0.0058, -0.0244,  0.0049],\n",
       "         [ 0.0163, -0.0300, -0.0012,  ...,  0.0180, -0.0103,  0.0088]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_k.lora_up.weight': tensor([[-8.7357e-03,  2.3468e-02,  1.6129e-02,  ...,  1.9669e-02,\n",
       "          -9.2850e-03, -1.5060e-02],\n",
       "         [ 1.2444e-02, -2.6062e-02, -1.2985e-02,  ..., -1.7654e-02,\n",
       "           6.5536e-03,  1.4595e-02],\n",
       "         [ 8.7738e-03, -2.2400e-02, -1.2367e-02,  ..., -2.1164e-02,\n",
       "           1.8677e-02,  1.2939e-02],\n",
       "         ...,\n",
       "         [-3.9062e-03,  2.7924e-02,  1.3420e-02,  ...,  2.4261e-02,\n",
       "          -3.1357e-03, -5.7907e-03],\n",
       "         [-3.4752e-03,  1.8967e-02,  1.0971e-02,  ...,  1.5793e-02,\n",
       "           3.6299e-05, -4.1847e-03],\n",
       "         [-4.9438e-03, -2.0782e-02,  7.1907e-03,  ..., -1.8005e-02,\n",
       "          -4.8103e-03, -7.9346e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_out_0.lora_down.weight': tensor([[-0.0029,  0.0275, -0.0251,  ..., -0.0067,  0.0105,  0.0198],\n",
       "         [-0.0003, -0.0404,  0.0143,  ...,  0.0115, -0.0053,  0.0120],\n",
       "         [-0.0061, -0.0118, -0.0100,  ..., -0.0128,  0.0392, -0.0031],\n",
       "         ...,\n",
       "         [-0.0052,  0.0100, -0.0159,  ..., -0.0068, -0.0054, -0.0094],\n",
       "         [-0.0099, -0.0012, -0.0022,  ...,  0.0217, -0.0067, -0.0242],\n",
       "         [-0.0148,  0.0185, -0.0052,  ...,  0.0107,  0.0271, -0.0257]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_out_0.lora_up.weight': tensor([[-2.4681e-03,  3.5429e-04,  8.5473e-05,  ..., -2.2278e-03,\n",
       "           5.5504e-03, -6.1989e-03],\n",
       "         [ 6.3858e-03,  1.4626e-02, -5.8365e-03,  ...,  3.4180e-02,\n",
       "          -5.2719e-03,  7.6370e-03],\n",
       "         [-1.0815e-03,  9.5825e-03,  1.1283e-04,  ..., -3.2578e-03,\n",
       "           3.0060e-03,  2.1381e-03],\n",
       "         ...,\n",
       "         [ 1.9550e-03,  3.3627e-03,  4.4847e-04,  ...,  5.2872e-03,\n",
       "           4.9591e-04,  2.7828e-03],\n",
       "         [-1.8940e-03, -3.4392e-05,  2.8667e-03,  ..., -4.7569e-03,\n",
       "           3.8872e-03,  2.5902e-03],\n",
       "         [ 6.2599e-03, -5.1155e-03, -5.8250e-03,  ..., -1.0048e-02,\n",
       "          -7.9269e-03, -3.4618e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_q.lora_down.weight': tensor([[ 4.5180e-04,  6.1631e-05,  3.5706e-02,  ..., -1.2726e-02,\n",
       "          -2.5177e-02, -2.8320e-02],\n",
       "         [-2.0813e-02, -1.9928e-02, -1.3506e-04,  ...,  3.6682e-02,\n",
       "          -1.4305e-02, -1.2970e-02],\n",
       "         [-2.0309e-02, -1.5198e-02,  1.7548e-02,  ...,  1.3329e-02,\n",
       "           3.8483e-02,  1.8417e-02],\n",
       "         ...,\n",
       "         [-1.8997e-02, -1.4252e-02,  3.8208e-02,  ...,  1.6830e-02,\n",
       "          -1.8250e-02,  2.1103e-02],\n",
       "         [-3.5839e-03, -1.6968e-02,  9.1171e-03,  ...,  1.1993e-02,\n",
       "          -1.5274e-02,  2.1851e-02],\n",
       "         [-1.4069e-02,  1.5762e-02,  2.1114e-03,  ..., -5.0354e-02,\n",
       "          -1.5282e-02, -2.5269e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_q.lora_up.weight': tensor([[-0.0112, -0.0200,  0.0182,  ..., -0.0074, -0.0314,  0.0124],\n",
       "         [ 0.0006, -0.0124, -0.0025,  ...,  0.0029,  0.0093, -0.0072],\n",
       "         [-0.0023,  0.0085,  0.0057,  ..., -0.0031, -0.0142,  0.0063],\n",
       "         ...,\n",
       "         [ 0.0030,  0.0060,  0.0066,  ...,  0.0038, -0.0258, -0.0075],\n",
       "         [ 0.0078,  0.0284, -0.0047,  ...,  0.0143, -0.0136, -0.0159],\n",
       "         [ 0.0175,  0.0356, -0.0163,  ...,  0.0200,  0.0152, -0.0212]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_v.lora_down.weight': tensor([[-0.0025,  0.0056,  0.0257,  ...,  0.0007, -0.0184, -0.0135],\n",
       "         [ 0.0112, -0.0008,  0.0161,  ..., -0.0115, -0.0146,  0.0008],\n",
       "         [ 0.0157, -0.0138, -0.0148,  ..., -0.0125, -0.0010, -0.0034],\n",
       "         ...,\n",
       "         [ 0.0075,  0.0002,  0.0036,  ...,  0.0178,  0.0041,  0.0097],\n",
       "         [ 0.0020,  0.0019,  0.0202,  ...,  0.0086,  0.0058,  0.0036],\n",
       "         [ 0.0131,  0.0064, -0.0167,  ..., -0.0058,  0.0179,  0.0109]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_attn2_to_v.lora_up.weight': tensor([[ 0.0219, -0.0058, -0.0176,  ...,  0.0196,  0.0214, -0.0157],\n",
       "         [ 0.0074, -0.0036, -0.0059,  ...,  0.0104, -0.0149, -0.0060],\n",
       "         [ 0.0177, -0.0111, -0.0125,  ...,  0.0166, -0.0056, -0.0062],\n",
       "         ...,\n",
       "         [ 0.0053,  0.0079, -0.0097,  ...,  0.0062,  0.0251, -0.0074],\n",
       "         [ 0.0120, -0.0111, -0.0076,  ...,  0.0103,  0.0116, -0.0080],\n",
       "         [-0.0129,  0.0170,  0.0109,  ..., -0.0065, -0.0006,  0.0009]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_0_proj.lora_down.weight': tensor([[ 0.0098, -0.0042,  0.0020,  ...,  0.0294, -0.0092, -0.0183],\n",
       "         [-0.0072, -0.0375, -0.0044,  ..., -0.0035,  0.0194,  0.0042],\n",
       "         [ 0.0339,  0.0355,  0.0462,  ..., -0.0166, -0.0278, -0.0158],\n",
       "         ...,\n",
       "         [-0.0068, -0.0027, -0.0012,  ..., -0.0209,  0.0176,  0.0234],\n",
       "         [-0.0084, -0.0069,  0.0385,  ..., -0.0362, -0.0054,  0.0171],\n",
       "         [ 0.0363, -0.0022,  0.0267,  ..., -0.0172, -0.0198, -0.0276]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_0_proj.lora_up.weight': tensor([[-0.0187, -0.0109,  0.0095,  ..., -0.0019,  0.0051,  0.0009],\n",
       "         [ 0.0007,  0.0063, -0.0124,  ...,  0.0089, -0.0179, -0.0011],\n",
       "         [-0.0095, -0.0206,  0.0123,  ..., -0.0115,  0.0112,  0.0133],\n",
       "         ...,\n",
       "         [ 0.0019, -0.0068, -0.0047,  ..., -0.0004, -0.0081, -0.0031],\n",
       "         [ 0.0055,  0.0157, -0.0132,  ...,  0.0127, -0.0184, -0.0130],\n",
       "         [-0.0080, -0.0051, -0.0058,  ..., -0.0014,  0.0017, -0.0022]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_2.lora_down.weight': tensor([[ 0.0042,  0.0237, -0.0041,  ...,  0.0254, -0.0152,  0.0170],\n",
       "         [ 0.0249, -0.0055, -0.0159,  ...,  0.0032,  0.0240,  0.0116],\n",
       "         [ 0.0106, -0.0139, -0.0271,  ..., -0.0099,  0.0032,  0.0099],\n",
       "         ...,\n",
       "         [ 0.0100, -0.0003,  0.0103,  ..., -0.0261, -0.0157,  0.0011],\n",
       "         [-0.0069,  0.0099, -0.0255,  ...,  0.0260,  0.0204, -0.0064],\n",
       "         [ 0.0147, -0.0057, -0.0298,  ...,  0.0298,  0.0144, -0.0139]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_2.lora_up.weight': tensor([[ 8.9645e-04,  2.7908e-02,  7.5989e-03,  ..., -2.8629e-03,\n",
       "          -1.2624e-04, -4.8218e-03],\n",
       "         [ 2.3849e-02, -7.6828e-03, -1.3016e-02,  ..., -1.8112e-02,\n",
       "           1.5297e-02,  1.0727e-02],\n",
       "         [-8.5907e-03, -3.6507e-03,  1.9169e-03,  ...,  9.1629e-03,\n",
       "          -7.8201e-03, -1.5612e-03],\n",
       "         ...,\n",
       "         [-1.7776e-02,  1.4008e-02,  9.1705e-03,  ...,  1.1330e-02,\n",
       "          -7.1297e-03, -2.0538e-02],\n",
       "         [-8.2626e-03, -1.2535e-02, -7.9956e-03,  ...,  9.0003e-06,\n",
       "          -2.8172e-03,  4.1580e-03],\n",
       "         [ 8.1253e-03, -2.9388e-02, -1.2543e-02,  ..., -1.4854e-02,\n",
       "           5.9700e-03,  1.0462e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_0_emb_layers_1.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_0_emb_layers_1.lora_down.weight': tensor([[ 1.0368e-02, -3.1982e-02,  2.3071e-02,  ..., -8.7452e-04,\n",
       "           6.1569e-03,  1.0345e-02],\n",
       "         [ 1.0246e-02, -3.1052e-03, -1.2939e-02,  ..., -1.3939e-02,\n",
       "          -4.2877e-02, -2.9633e-02],\n",
       "         [ 1.9440e-02, -3.4022e-04,  1.2222e-02,  ..., -7.5378e-03,\n",
       "           4.0161e-02,  2.8625e-02],\n",
       "         ...,\n",
       "         [ 1.5366e-02, -1.1833e-02, -1.5869e-02,  ...,  8.7814e-03,\n",
       "           1.7807e-02,  2.6260e-02],\n",
       "         [-1.5175e-02, -5.4970e-03,  2.9027e-05,  ...,  2.8259e-02,\n",
       "           2.8839e-02, -2.2079e-02],\n",
       "         [-9.0179e-03,  1.8463e-02, -7.1106e-03,  ...,  4.3182e-02,\n",
       "           2.7695e-02,  7.9727e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_0_emb_layers_1.lora_up.weight': tensor([[ 0.0077,  0.0088, -0.0067,  ...,  0.0030,  0.0048, -0.0080],\n",
       "         [-0.0102,  0.0059,  0.0091,  ...,  0.0060,  0.0115,  0.0183],\n",
       "         [-0.0089,  0.0046,  0.0065,  ..., -0.0045,  0.0005,  0.0100],\n",
       "         ...,\n",
       "         [ 0.0136,  0.0053, -0.0111,  ..., -0.0048, -0.0107, -0.0139],\n",
       "         [-0.0037,  0.0052,  0.0035,  ..., -0.0025, -0.0010,  0.0041],\n",
       "         [ 0.0113, -0.0002, -0.0086,  ..., -0.0044, -0.0073, -0.0127]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_0_in_layers_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_0_in_layers_2.lora_down.weight': tensor([[[[ 1.6708e-02,  3.0334e-02,  1.1871e-02],\n",
       "           [ 1.1734e-02,  2.8076e-02,  3.8879e-02],\n",
       "           [ 3.4241e-02,  1.8921e-02,  3.7994e-02]],\n",
       " \n",
       "          [[ 2.4597e-02,  3.4607e-02,  3.1921e-02],\n",
       "           [ 1.8005e-02,  3.3813e-02,  2.5055e-02],\n",
       "           [ 2.5543e-02,  2.2552e-02,  2.8214e-02]],\n",
       " \n",
       "          [[ 1.3168e-02,  5.8556e-03, -1.5092e-04],\n",
       "           [ 2.4211e-04, -4.7989e-03, -7.3433e-03],\n",
       "           [ 8.5373e-03,  1.2047e-02,  5.0621e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6861e-02,  1.8158e-02,  1.3504e-02],\n",
       "           [ 6.4316e-03,  1.2848e-02,  2.0645e-02],\n",
       "           [ 1.8463e-02,  2.0905e-02,  2.6627e-02]],\n",
       " \n",
       "          [[ 4.2877e-03, -1.4046e-02, -4.6234e-03],\n",
       "           [-6.6757e-03, -2.5772e-02, -3.8548e-03],\n",
       "           [-8.8806e-03, -1.3741e-02, -7.2021e-03]],\n",
       " \n",
       "          [[ 2.3746e-03,  3.8738e-03, -1.4809e-02],\n",
       "           [-1.0996e-03,  8.7967e-03, -3.0785e-03],\n",
       "           [-9.3231e-03, -3.7718e-04,  5.5618e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.8412e-02,  2.8687e-02,  4.4769e-02],\n",
       "           [ 1.7960e-02,  1.8875e-02,  9.7580e-03],\n",
       "           [ 2.3483e-02,  2.3315e-02,  1.5808e-02]],\n",
       " \n",
       "          [[ 3.3836e-03,  8.0948e-03,  4.5776e-03],\n",
       "           [ 1.6724e-02,  7.8506e-03,  1.6388e-02],\n",
       "           [ 2.0065e-02,  1.2932e-02,  1.1574e-02]],\n",
       " \n",
       "          [[-1.3985e-02, -2.5848e-02, -1.8768e-02],\n",
       "           [-1.9424e-02, -2.1652e-02, -1.2772e-02],\n",
       "           [-1.5495e-02, -1.2085e-02, -1.6266e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-9.8877e-03, -1.2100e-02,  2.9259e-03],\n",
       "           [-1.7654e-02,  2.3861e-03, -4.1389e-03],\n",
       "           [-2.1378e-02, -2.0615e-02, -1.9196e-02]],\n",
       " \n",
       "          [[ 2.7817e-02,  3.3569e-02,  3.1433e-02],\n",
       "           [ 1.5732e-02,  2.6398e-02,  2.2552e-02],\n",
       "           [ 2.5192e-02,  2.4490e-02,  3.1921e-02]],\n",
       " \n",
       "          [[-2.2537e-02, -1.6708e-02, -1.1757e-02],\n",
       "           [-2.2614e-02, -4.8637e-03,  3.3569e-04],\n",
       "           [-2.1992e-03, -1.4772e-03,  5.0049e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 4.7798e-03, -5.4665e-03,  1.4549e-02],\n",
       "           [ 3.1509e-03,  6.3400e-03,  9.9106e-03],\n",
       "           [-9.2468e-03, -1.3908e-02, -6.4735e-03]],\n",
       " \n",
       "          [[-2.3224e-02, -2.8824e-02, -3.3112e-02],\n",
       "           [-9.1934e-03, -1.6937e-02, -1.9928e-02],\n",
       "           [-1.3618e-02, -1.9592e-02, -1.0620e-02]],\n",
       " \n",
       "          [[-1.0399e-02, -1.1421e-02, -2.3972e-02],\n",
       "           [-1.1986e-02, -7.1602e-03, -6.9962e-03],\n",
       "           [-2.6077e-02, -3.0212e-02, -3.1677e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.6398e-02, -2.8946e-02, -2.2354e-02],\n",
       "           [-1.3397e-02, -3.2593e-02, -1.3168e-02],\n",
       "           [-4.2152e-03, -9.5825e-03, -6.7406e-03]],\n",
       " \n",
       "          [[-8.8120e-03,  2.9922e-04,  1.0424e-03],\n",
       "           [-1.5137e-02, -8.1253e-04, -2.1439e-02],\n",
       "           [-1.5190e-02, -5.4359e-03, -1.1124e-02]],\n",
       " \n",
       "          [[ 5.5008e-03,  1.0163e-04,  4.3068e-03],\n",
       "           [-2.5349e-03, -1.4389e-02,  6.1607e-03],\n",
       "           [ 7.3204e-03, -5.1003e-03, -2.3556e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.8084e-04,  6.6605e-03,  2.4738e-03],\n",
       "           [ 6.7749e-03,  1.3885e-02,  3.2692e-03],\n",
       "           [ 1.9119e-02,  5.1041e-03,  7.3166e-03]],\n",
       " \n",
       "          [[ 2.8732e-02,  1.6251e-02,  3.5278e-02],\n",
       "           [ 1.7609e-02,  1.8127e-02,  2.3636e-02],\n",
       "           [ 2.9648e-02,  3.3600e-02,  1.4023e-02]],\n",
       " \n",
       "          [[ 1.3214e-02, -2.5578e-03,  5.6267e-03],\n",
       "           [-6.4163e-03, -8.2159e-04,  7.0381e-03],\n",
       "           [ 1.4801e-02,  1.4534e-02,  9.9258e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.9864e-03,  1.5060e-02,  2.5848e-02],\n",
       "           [ 1.3725e-02,  5.7335e-03,  1.0254e-02],\n",
       "           [ 1.7746e-02,  2.2278e-02,  9.3460e-03]],\n",
       " \n",
       "          [[ 1.3039e-02,  1.3199e-03,  1.0269e-02],\n",
       "           [ 1.5926e-03, -5.9853e-03,  4.8676e-03],\n",
       "           [-4.1533e-04,  4.4746e-03, -1.1578e-03]],\n",
       " \n",
       "          [[-6.7406e-03, -3.0174e-03, -1.2924e-02],\n",
       "           [-1.1429e-02,  4.3068e-03,  7.1812e-04],\n",
       "           [ 3.2783e-06,  5.7144e-03, -1.6346e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0445e-02,  1.9913e-02,  2.3956e-02],\n",
       "           [ 1.6251e-02,  1.5289e-02,  1.8250e-02],\n",
       "           [ 1.5564e-02,  2.0554e-02,  1.6098e-02]],\n",
       " \n",
       "          [[-1.0849e-02,  2.2106e-03,  2.9697e-03],\n",
       "           [ 4.7646e-03, -5.4359e-03,  9.7215e-05],\n",
       "           [ 4.2868e-04,  2.0432e-02,  7.5874e-03]],\n",
       " \n",
       "          [[-1.8219e-02, -7.0381e-03, -2.1591e-02],\n",
       "           [-2.0309e-02, -1.7746e-02, -1.1681e-02],\n",
       "           [-1.5823e-02, -3.0701e-02, -1.3153e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 9.7942e-04, -6.5613e-03,  2.4605e-04],\n",
       "           [-3.1986e-03,  6.4430e-03,  1.8280e-02],\n",
       "           [ 1.0063e-02,  1.1757e-02,  1.7944e-02]],\n",
       " \n",
       "          [[ 1.0460e-02, -1.1116e-02, -4.1466e-03],\n",
       "           [-1.2108e-02, -1.2016e-03, -1.1032e-02],\n",
       "           [-2.7733e-03, -1.1215e-02, -1.3077e-02]],\n",
       " \n",
       "          [[-1.0300e-02, -6.3133e-03, -1.3359e-02],\n",
       "           [-2.2011e-03, -1.0078e-02, -3.7346e-03],\n",
       "           [ 1.8759e-03,  6.5231e-03,  5.4321e-03]]],\n",
       " \n",
       " \n",
       "         [[[-5.0879e-04, -2.0542e-03, -4.7493e-03],\n",
       "           [-2.6035e-03, -1.6556e-02, -1.3054e-02],\n",
       "           [-1.1864e-02, -1.5762e-02, -6.1378e-03]],\n",
       " \n",
       "          [[-4.9011e-02, -3.9185e-02, -4.0222e-02],\n",
       "           [-4.4983e-02, -2.5940e-02, -2.8839e-02],\n",
       "           [-3.0350e-02, -3.8239e-02, -3.5645e-02]],\n",
       " \n",
       "          [[ 1.8291e-03,  1.2207e-02, -1.3618e-02],\n",
       "           [-5.5237e-03,  1.0750e-02,  1.5078e-03],\n",
       "           [-2.6455e-03,  5.5656e-03, -9.3508e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.1124e-02, -2.0752e-02, -1.3016e-02],\n",
       "           [-1.4847e-02, -1.0910e-02, -1.7410e-02],\n",
       "           [-1.2436e-02, -2.7176e-02, -2.7679e-02]],\n",
       " \n",
       "          [[-1.0010e-02,  4.2839e-03, -1.6571e-02],\n",
       "           [-9.7275e-03,  2.9545e-03, -9.4757e-03],\n",
       "           [ 2.4319e-03,  4.0207e-03,  1.0643e-03]],\n",
       " \n",
       "          [[ 7.7248e-03,  8.1482e-03, -5.7526e-03],\n",
       "           [ 2.0161e-03, -1.5472e-02, -3.9101e-03],\n",
       "           [-4.4937e-03, -7.5912e-03, -1.8921e-02]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_0_in_layers_2.lora_up.weight': tensor([[[[-0.0113]],\n",
       " \n",
       "          [[-0.0052]],\n",
       " \n",
       "          [[-0.0044]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0131]],\n",
       " \n",
       "          [[-0.0114]],\n",
       " \n",
       "          [[ 0.0067]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0078]],\n",
       " \n",
       "          [[-0.0023]],\n",
       " \n",
       "          [[-0.0066]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0141]],\n",
       " \n",
       "          [[ 0.0013]],\n",
       " \n",
       "          [[-0.0085]]],\n",
       " \n",
       " \n",
       "         [[[-0.0025]],\n",
       " \n",
       "          [[-0.0008]],\n",
       " \n",
       "          [[-0.0150]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0014]],\n",
       " \n",
       "          [[-0.0052]],\n",
       " \n",
       "          [[-0.0006]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0004]],\n",
       " \n",
       "          [[-0.0018]],\n",
       " \n",
       "          [[ 0.0191]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0022]],\n",
       " \n",
       "          [[ 0.0103]],\n",
       " \n",
       "          [[ 0.0165]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0068]],\n",
       " \n",
       "          [[ 0.0188]],\n",
       " \n",
       "          [[ 0.0054]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0083]],\n",
       " \n",
       "          [[ 0.0126]],\n",
       " \n",
       "          [[-0.0038]]],\n",
       " \n",
       " \n",
       "         [[[-0.0059]],\n",
       " \n",
       "          [[-0.0064]],\n",
       " \n",
       "          [[ 0.0186]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0133]],\n",
       " \n",
       "          [[ 0.0056]],\n",
       " \n",
       "          [[ 0.0111]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_0_out_layers_3.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_0_out_layers_3.lora_down.weight': tensor([[[[-4.8950e-02, -5.0110e-02, -4.4464e-02],\n",
       "           [-4.4830e-02, -4.0619e-02, -4.5410e-02],\n",
       "           [-3.8971e-02, -4.1779e-02, -2.4780e-02]],\n",
       " \n",
       "          [[-2.9449e-03, -7.7133e-03, -1.0216e-02],\n",
       "           [-6.4087e-04, -4.8790e-03, -3.4790e-03],\n",
       "           [-2.1057e-03,  9.2773e-03,  6.9847e-03]],\n",
       " \n",
       "          [[-1.3496e-02,  3.2787e-03, -9.3918e-03],\n",
       "           [-2.7199e-03, -1.3893e-02, -2.1240e-02],\n",
       "           [ 1.6968e-02,  4.7722e-03,  2.7218e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.7695e-03, -1.8415e-03, -8.3389e-03],\n",
       "           [ 1.3523e-03, -5.6343e-03, -1.2527e-02],\n",
       "           [-3.6407e-02, -4.2419e-03,  8.1635e-04]],\n",
       " \n",
       "          [[-8.9951e-03,  1.0208e-02, -8.0032e-03],\n",
       "           [-1.1959e-03, -4.8561e-03,  3.8929e-03],\n",
       "           [-1.0462e-03,  3.3569e-03, -1.4038e-02]],\n",
       " \n",
       "          [[-1.1909e-02,  2.3003e-03, -1.0994e-02],\n",
       "           [-7.4997e-03, -1.2955e-02, -1.1726e-02],\n",
       "           [-2.5879e-02, -2.4338e-02, -1.5732e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.2085e-02, -8.8806e-03, -1.7075e-02],\n",
       "           [-2.4490e-02, -3.3997e-02, -3.7262e-02],\n",
       "           [-3.2257e-02, -4.2786e-02, -3.8544e-02]],\n",
       " \n",
       "          [[-1.7334e-02, -4.4159e-02, -2.5589e-02],\n",
       "           [-2.1484e-02, -2.9968e-02, -4.0253e-02],\n",
       "           [-2.3239e-02, -1.8524e-02, -1.2825e-02]],\n",
       " \n",
       "          [[ 4.4060e-03,  8.3160e-03,  1.4397e-02],\n",
       "           [ 2.5925e-02,  6.0387e-03,  4.4656e-04],\n",
       "           [ 3.4851e-02,  2.3224e-02,  4.6326e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.8082e-02, -3.2082e-03, -1.6235e-02],\n",
       "           [ 6.6223e-03, -5.1918e-03, -9.5825e-03],\n",
       "           [-1.7944e-02, -4.7417e-03, -8.5735e-04]],\n",
       " \n",
       "          [[ 5.0812e-03,  1.3247e-03,  9.2087e-03],\n",
       "           [ 1.5106e-03,  4.3869e-04, -6.6071e-03],\n",
       "           [ 5.2757e-03,  1.0696e-02, -1.0468e-02]],\n",
       " \n",
       "          [[-8.9951e-03, -8.7433e-03, -1.1421e-02],\n",
       "           [-1.2749e-02, -5.4893e-03, -2.2476e-02],\n",
       "           [-6.8321e-03, -2.0294e-02, -1.3229e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.3756e-02, -1.3451e-02, -6.0921e-03],\n",
       "           [-3.6011e-02, -2.3010e-02, -2.6215e-02],\n",
       "           [-3.0823e-02, -2.7527e-02, -1.1353e-02]],\n",
       " \n",
       "          [[-2.7649e-02, -2.8534e-02, -3.7781e-02],\n",
       "           [-2.5803e-02, -4.3121e-02, -3.0777e-02],\n",
       "           [-1.7715e-02, -2.5330e-02, -1.5015e-02]],\n",
       " \n",
       "          [[ 1.3649e-02, -8.4534e-03,  1.9083e-03],\n",
       "           [ 2.3331e-02, -1.7120e-02, -5.7907e-03],\n",
       "           [ 1.0818e-02,  1.0811e-02,  1.9775e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.1734e-02, -6.0844e-03, -2.0996e-02],\n",
       "           [ 5.9586e-03, -6.2103e-03, -1.4214e-02],\n",
       "           [-6.9656e-03,  7.5455e-03, -1.0681e-03]],\n",
       " \n",
       "          [[ 7.6370e-03,  8.3771e-03,  1.1997e-03],\n",
       "           [ 6.3324e-03, -5.8975e-03,  6.3095e-03],\n",
       "           [ 2.0844e-02,  1.3245e-02,  4.1466e-03]],\n",
       " \n",
       "          [[-1.8600e-02, -1.7319e-02, -5.3635e-03],\n",
       "           [-1.2810e-02, -1.2222e-02, -1.9318e-02],\n",
       "           [-3.4271e-02, -3.5034e-02, -2.7924e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.7792e-02, -2.3453e-02, -2.9770e-02],\n",
       "           [-3.6224e-02, -2.9480e-02, -3.1403e-02],\n",
       "           [-3.3936e-02, -2.6917e-02, -4.3152e-02]],\n",
       " \n",
       "          [[-2.1164e-02, -2.6886e-02, -3.5858e-02],\n",
       "           [-1.8402e-02, -3.4180e-02, -4.2999e-02],\n",
       "           [-1.4572e-02, -1.4694e-02, -5.0621e-03]],\n",
       " \n",
       "          [[ 1.2917e-02,  1.0788e-02,  1.1826e-02],\n",
       "           [ 8.7128e-03,  3.3131e-03, -4.5776e-03],\n",
       "           [ 1.9257e-02,  7.7782e-03,  3.3600e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.6790e-03,  5.8212e-03, -6.1111e-03],\n",
       "           [ 7.9870e-04,  7.1347e-05,  1.5764e-03],\n",
       "           [-1.8951e-02,  1.3494e-03,  9.7122e-03]],\n",
       " \n",
       "          [[ 9.4833e-03, -2.5654e-03,  1.1978e-03],\n",
       "           [-4.7340e-03, -3.5973e-03,  7.6256e-03],\n",
       "           [ 1.1490e-02,  1.2924e-02, -5.5580e-03]],\n",
       " \n",
       "          [[-5.3558e-03, -7.8888e-03, -3.3989e-03],\n",
       "           [-3.7098e-04, -1.3565e-02, -1.8051e-02],\n",
       "           [-2.2869e-03, -2.3529e-02, -1.2886e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.3315e-02, -1.9775e-02, -1.2146e-02],\n",
       "           [-2.9465e-02, -2.7328e-02, -4.4983e-02],\n",
       "           [-3.3295e-02, -3.9459e-02, -2.6443e-02]],\n",
       " \n",
       "          [[-1.6739e-02, -3.2654e-02, -3.4454e-02],\n",
       "           [-1.6891e-02, -3.4546e-02, -3.1830e-02],\n",
       "           [-1.1307e-02, -2.4063e-02, -1.6312e-02]],\n",
       " \n",
       "          [[ 9.7122e-03,  1.6937e-02, -4.2343e-03],\n",
       "           [ 1.8204e-02, -8.8549e-04, -1.4793e-02],\n",
       "           [ 2.5894e-02,  1.8936e-02,  3.4149e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.0084e-03, -5.0011e-03, -8.2855e-03],\n",
       "           [ 6.6910e-03,  7.0648e-03,  1.0881e-03],\n",
       "           [-7.0076e-03, -4.6959e-03, -2.0599e-03]],\n",
       " \n",
       "          [[-6.7558e-03,  1.2474e-02,  1.1749e-02],\n",
       "           [ 3.7384e-04, -5.3291e-03,  1.0033e-02],\n",
       "           [ 6.8932e-03,  7.0572e-03,  6.6233e-04]],\n",
       " \n",
       "          [[-1.2894e-03, -9.7427e-03, -9.9335e-03],\n",
       "           [-1.9669e-02, -9.8038e-03, -8.5602e-03],\n",
       "           [-8.4305e-03, -1.5007e-02, -2.9736e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.9714e-02, -6.1760e-03, -2.0798e-02],\n",
       "           [-2.3285e-02, -1.6678e-02, -3.0457e-02],\n",
       "           [-2.7451e-02, -3.4149e-02, -3.4485e-02]],\n",
       " \n",
       "          [[-2.7252e-02, -3.1174e-02, -2.1423e-02],\n",
       "           [-1.8112e-02, -3.5431e-02, -3.8605e-02],\n",
       "           [-2.0020e-02, -1.9272e-02, -1.3290e-02]],\n",
       " \n",
       "          [[ 6.9885e-03,  3.0727e-03,  6.2599e-03],\n",
       "           [ 3.0151e-02,  4.1275e-03, -1.8250e-02],\n",
       "           [ 3.4943e-02,  3.0823e-02,  3.7689e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.4671e-02, -3.7060e-03, -1.5884e-02],\n",
       "           [ 6.6261e-03,  9.2468e-03, -1.2825e-02],\n",
       "           [-1.5610e-02, -9.5520e-03,  2.9812e-03]],\n",
       " \n",
       "          [[-5.6877e-03, -1.7099e-03, -4.6015e-04],\n",
       "           [-2.1708e-04, -1.5793e-03, -2.3289e-03],\n",
       "           [ 3.5305e-03, -3.3455e-03, -1.4366e-02]],\n",
       " \n",
       "          [[-8.2016e-03, -1.2598e-03, -3.3989e-03],\n",
       "           [ 2.7618e-03, -1.5366e-02, -4.0321e-03],\n",
       "           [ 3.7403e-03, -8.3313e-03, -1.4771e-02]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_0_out_layers_3.lora_up.weight': tensor([[[[ 0.0104]],\n",
       " \n",
       "          [[ 0.0053]],\n",
       " \n",
       "          [[ 0.0159]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0050]],\n",
       " \n",
       "          [[ 0.0078]],\n",
       " \n",
       "          [[ 0.0055]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0064]],\n",
       " \n",
       "          [[-0.0057]],\n",
       " \n",
       "          [[ 0.0059]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0012]],\n",
       " \n",
       "          [[ 0.0022]],\n",
       " \n",
       "          [[ 0.0024]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0094]],\n",
       " \n",
       "          [[-0.0077]],\n",
       " \n",
       "          [[ 0.0116]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0083]],\n",
       " \n",
       "          [[-0.0095]],\n",
       " \n",
       "          [[-0.0035]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0213]],\n",
       " \n",
       "          [[-0.0211]],\n",
       " \n",
       "          [[-0.0013]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0148]],\n",
       " \n",
       "          [[-0.0181]],\n",
       " \n",
       "          [[-0.0216]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0211]],\n",
       " \n",
       "          [[ 0.0096]],\n",
       " \n",
       "          [[ 0.0055]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0107]],\n",
       " \n",
       "          [[ 0.0063]],\n",
       " \n",
       "          [[ 0.0027]]],\n",
       " \n",
       " \n",
       "         [[[-0.0043]],\n",
       " \n",
       "          [[-0.0161]],\n",
       " \n",
       "          [[-0.0058]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0008]],\n",
       " \n",
       "          [[ 0.0039]],\n",
       " \n",
       "          [[-0.0075]]]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_proj_in.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_proj_in.lora_down.weight': tensor([[-0.0113, -0.0088,  0.0172,  ..., -0.0194, -0.0052, -0.0509],\n",
       "         [-0.0155,  0.0358,  0.0235,  ...,  0.0229, -0.0003,  0.0038],\n",
       "         [ 0.0011, -0.0574,  0.0147,  ..., -0.0193,  0.0050, -0.0340],\n",
       "         ...,\n",
       "         [ 0.0195,  0.0021,  0.0214,  ...,  0.0292, -0.0135,  0.0025],\n",
       "         [ 0.0211,  0.0080, -0.0019,  ..., -0.0029,  0.0114,  0.0310],\n",
       "         [-0.0024, -0.0091,  0.0243,  ...,  0.0159, -0.0310,  0.0172]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_proj_in.lora_up.weight': tensor([[-0.0073, -0.0062,  0.0060,  ..., -0.0083,  0.0115, -0.0127],\n",
       "         [-0.0036,  0.0158, -0.0082,  ...,  0.0008,  0.0038,  0.0053],\n",
       "         [ 0.0119, -0.0209,  0.0028,  ..., -0.0140,  0.0048, -0.0154],\n",
       "         ...,\n",
       "         [-0.0159,  0.0208, -0.0063,  ...,  0.0077,  0.0055,  0.0049],\n",
       "         [ 0.0136, -0.0084,  0.0111,  ..., -0.0135, -0.0026, -0.0140],\n",
       "         [ 0.0069,  0.0044,  0.0056,  ...,  0.0052, -0.0096,  0.0038]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_proj_out.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_proj_out.lora_down.weight': tensor([[ 0.0164,  0.0061, -0.0194,  ...,  0.0410, -0.0069,  0.0063],\n",
       "         [ 0.0276, -0.0115, -0.0222,  ..., -0.0172, -0.0252,  0.0008],\n",
       "         [ 0.0183,  0.0160, -0.0010,  ...,  0.0151, -0.0399, -0.0334],\n",
       "         ...,\n",
       "         [-0.0122,  0.0264, -0.0012,  ...,  0.0039, -0.0096,  0.0108],\n",
       "         [ 0.0280, -0.0557,  0.0100,  ..., -0.0052,  0.0258,  0.0301],\n",
       "         [-0.0055,  0.0018, -0.0230,  ..., -0.0010, -0.0095, -0.0252]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_proj_out.lora_up.weight': tensor([[-0.0244,  0.0189,  0.0244,  ..., -0.0235,  0.0047,  0.0187],\n",
       "         [-0.0190,  0.0220, -0.0002,  ..., -0.0163,  0.0173,  0.0104],\n",
       "         [ 0.0137, -0.0046,  0.0073,  ...,  0.0246, -0.0201,  0.0097],\n",
       "         ...,\n",
       "         [-0.0163,  0.0039,  0.0101,  ..., -0.0029,  0.0247,  0.0200],\n",
       "         [-0.0046,  0.0094,  0.0124,  ..., -0.0002, -0.0010,  0.0159],\n",
       "         [ 0.0045, -0.0070, -0.0070,  ...,  0.0108,  0.0234, -0.0146]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_k.lora_down.weight': tensor([[ 0.0003,  0.0340, -0.0227,  ..., -0.0239,  0.0333,  0.0276],\n",
       "         [ 0.0232, -0.0065,  0.0071,  ...,  0.0384, -0.0294, -0.0243],\n",
       "         [-0.0393, -0.0213, -0.0063,  ..., -0.0127,  0.0055,  0.0094],\n",
       "         ...,\n",
       "         [ 0.0155,  0.0228,  0.0049,  ..., -0.0388, -0.0064, -0.0117],\n",
       "         [ 0.0149, -0.0084, -0.0120,  ...,  0.0270, -0.0152, -0.0024],\n",
       "         [ 0.0022, -0.0350, -0.0058,  ..., -0.0057,  0.0147, -0.0168]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_k.lora_up.weight': tensor([[ 2.1896e-02, -2.8992e-02, -1.7471e-02,  ..., -2.1729e-02,\n",
       "           1.4282e-02, -8.5068e-03],\n",
       "         [-7.4244e-04,  2.8670e-05, -1.5808e-02,  ..., -9.9564e-04,\n",
       "          -1.7136e-02,  2.1072e-02],\n",
       "         [ 1.4420e-02,  1.5282e-02,  1.4862e-02,  ..., -1.1072e-03,\n",
       "          -4.9477e-03,  5.8784e-03],\n",
       "         ...,\n",
       "         [-1.7258e-02,  1.3912e-04,  1.1757e-02,  ...,  2.5787e-02,\n",
       "          -4.4365e-03,  1.8177e-03],\n",
       "         [ 1.6689e-03,  3.8948e-03,  2.1301e-02,  ..., -3.1834e-03,\n",
       "           1.2695e-02,  4.5109e-04],\n",
       "         [-3.9101e-03,  5.3482e-03,  2.1286e-02,  ...,  3.1586e-03,\n",
       "           6.4812e-03,  1.5001e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight': tensor([[-0.0147,  0.0202, -0.0114,  ..., -0.0422, -0.0056, -0.0368],\n",
       "         [-0.0416,  0.0005, -0.0132,  ..., -0.0099,  0.0231,  0.0054],\n",
       "         [ 0.0079, -0.0149, -0.0063,  ..., -0.0005, -0.0022, -0.0119],\n",
       "         ...,\n",
       "         [-0.0191,  0.0197, -0.0213,  ...,  0.0264,  0.0251,  0.0191],\n",
       "         [ 0.0299, -0.0178,  0.0235,  ...,  0.0223,  0.0018,  0.0230],\n",
       "         [ 0.0102,  0.0280, -0.0282,  ..., -0.0032, -0.0181, -0.0323]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight': tensor([[-0.0175,  0.0033, -0.0057,  ...,  0.0107,  0.0183, -0.0132],\n",
       "         [ 0.0325, -0.0003,  0.0189,  ..., -0.0200, -0.0168,  0.0124],\n",
       "         [ 0.0268, -0.0020, -0.0009,  ..., -0.0073, -0.0134,  0.0144],\n",
       "         ...,\n",
       "         [-0.0029,  0.0030,  0.0052,  ..., -0.0006, -0.0028,  0.0019],\n",
       "         [-0.0022,  0.0087,  0.0021,  ...,  0.0006, -0.0061,  0.0091],\n",
       "         [ 0.0172,  0.0049,  0.0255,  ..., -0.0143, -0.0097, -0.0043]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_q.lora_down.weight': tensor([[ 0.0126, -0.0024,  0.0189,  ...,  0.0196, -0.0031,  0.0087],\n",
       "         [ 0.0121, -0.0162, -0.0167,  ..., -0.0202, -0.0082,  0.0195],\n",
       "         [-0.0294, -0.0367,  0.0107,  ...,  0.0150, -0.0239,  0.0111],\n",
       "         ...,\n",
       "         [ 0.0056, -0.0131,  0.0119,  ...,  0.0101,  0.0183, -0.0008],\n",
       "         [-0.0183,  0.0076, -0.0112,  ..., -0.0003,  0.0066, -0.0069],\n",
       "         [ 0.0033, -0.0022, -0.0063,  ..., -0.0362,  0.0309,  0.0013]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_q.lora_up.weight': tensor([[ 0.0278, -0.0285,  0.0049,  ..., -0.0290,  0.0071, -0.0109],\n",
       "         [-0.0035, -0.0217, -0.0011,  ..., -0.0121,  0.0034, -0.0028],\n",
       "         [-0.0123, -0.0015, -0.0013,  ..., -0.0095, -0.0046,  0.0074],\n",
       "         ...,\n",
       "         [ 0.0045,  0.0165, -0.0112,  ...,  0.0132, -0.0298,  0.0350],\n",
       "         [-0.0070, -0.0114,  0.0008,  ...,  0.0020, -0.0058, -0.0026],\n",
       "         [ 0.0239, -0.0054,  0.0097,  ..., -0.0005, -0.0025,  0.0017]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_v.lora_down.weight': tensor([[ 0.0259,  0.0166,  0.0035,  ...,  0.0334,  0.0158, -0.0288],\n",
       "         [ 0.0029,  0.0041,  0.0045,  ...,  0.0284,  0.0134,  0.0287],\n",
       "         [-0.0001, -0.0234,  0.0315,  ..., -0.0342, -0.0021,  0.0424],\n",
       "         ...,\n",
       "         [-0.0271, -0.0143,  0.0029,  ..., -0.0106, -0.0063,  0.0116],\n",
       "         [ 0.0128, -0.0125, -0.0033,  ..., -0.0177,  0.0025,  0.0294],\n",
       "         [ 0.0154, -0.0129, -0.0120,  ...,  0.0257,  0.0161, -0.0042]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_v.lora_up.weight': tensor([[-2.9205e-02,  3.2196e-02,  9.3384e-03,  ..., -1.9363e-02,\n",
       "           2.8748e-02,  1.0490e-03],\n",
       "         [-5.1041e-03, -1.7796e-03, -1.3657e-02,  ...,  1.1711e-03,\n",
       "           1.4015e-02,  8.3313e-03],\n",
       "         [ 6.5765e-03,  1.7300e-03, -9.0790e-03,  ...,  4.9744e-03,\n",
       "           5.1117e-03, -1.0433e-03],\n",
       "         ...,\n",
       "         [-1.4275e-02,  1.3634e-02,  1.7023e-04,  ..., -2.4872e-02,\n",
       "           4.5252e-04,  1.6113e-02],\n",
       "         [ 1.3313e-03,  6.0921e-03,  2.2640e-03,  ..., -1.8921e-02,\n",
       "           1.3229e-02,  8.7662e-03],\n",
       "         [ 8.6904e-05, -1.4668e-03,  7.8583e-03,  ...,  1.0361e-02,\n",
       "           5.7411e-03,  9.5291e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_k.lora_down.weight': tensor([[-6.3286e-03, -2.8015e-02,  1.3702e-02,  ...,  1.9104e-02,\n",
       "           2.3636e-02,  3.0411e-02],\n",
       "         [ 2.9556e-02,  1.1549e-03, -3.2959e-02,  ...,  2.4204e-03,\n",
       "           1.6602e-02,  2.7496e-02],\n",
       "         [-9.4604e-03,  6.9618e-03,  2.5558e-02,  ...,  9.3079e-03,\n",
       "          -9.2316e-03,  2.6093e-02],\n",
       "         ...,\n",
       "         [-2.8789e-05, -1.3611e-02, -1.8799e-02,  ..., -1.6602e-02,\n",
       "           1.3702e-02,  3.0899e-02],\n",
       "         [-1.2749e-02,  9.1629e-03,  1.3145e-02,  ...,  8.9417e-03,\n",
       "          -1.1047e-02, -2.4399e-02],\n",
       "         [-9.0027e-03, -2.2888e-02,  2.3102e-02,  ...,  8.5373e-03,\n",
       "           8.8501e-03,  1.3725e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_k.lora_up.weight': tensor([[ 0.0045, -0.0106,  0.0098,  ...,  0.0032, -0.0127,  0.0049],\n",
       "         [-0.0062, -0.0073, -0.0116,  ..., -0.0109, -0.0051, -0.0011],\n",
       "         [ 0.0054,  0.0294, -0.0031,  ...,  0.0095,  0.0095, -0.0047],\n",
       "         ...,\n",
       "         [-0.0203, -0.0010, -0.0296,  ..., -0.0129,  0.0068, -0.0175],\n",
       "         [-0.0146,  0.0058, -0.0257,  ..., -0.0090, -0.0019, -0.0111],\n",
       "         [ 0.0120,  0.0320, -0.0139,  ...,  0.0165, -0.0074, -0.0069]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight': tensor([[-0.0369,  0.0251,  0.0349,  ..., -0.0123,  0.0077,  0.0460],\n",
       "         [-0.0315,  0.0108, -0.0037,  ...,  0.0241,  0.0202,  0.0167],\n",
       "         [-0.0039, -0.0190,  0.0215,  ..., -0.0234,  0.0045,  0.0195],\n",
       "         ...,\n",
       "         [ 0.0089, -0.0026,  0.0215,  ..., -0.0339,  0.0164,  0.0060],\n",
       "         [-0.0043,  0.0066,  0.0119,  ..., -0.0258, -0.0095,  0.0568],\n",
       "         [-0.0076, -0.0142, -0.0145,  ..., -0.0066,  0.0206,  0.0194]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight': tensor([[-0.0117,  0.0151, -0.0207,  ..., -0.0315, -0.0138, -0.0174],\n",
       "         [-0.0144, -0.0055,  0.0035,  ...,  0.0017, -0.0153, -0.0002],\n",
       "         [ 0.0154, -0.0340,  0.0170,  ...,  0.0295,  0.0240,  0.0074],\n",
       "         ...,\n",
       "         [-0.0040,  0.0031, -0.0048,  ..., -0.0075, -0.0042, -0.0021],\n",
       "         [-0.0071, -0.0061, -0.0147,  ..., -0.0151, -0.0043, -0.0118],\n",
       "         [ 0.0116,  0.0249,  0.0106,  ...,  0.0109,  0.0040,  0.0127]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_q.lora_down.weight': tensor([[-0.0278, -0.0314,  0.0158,  ..., -0.0163, -0.0219,  0.0052],\n",
       "         [-0.0232,  0.0067, -0.0108,  ..., -0.0059,  0.0066,  0.0171],\n",
       "         [-0.0282, -0.0039,  0.0421,  ..., -0.0051, -0.0098,  0.0006],\n",
       "         ...,\n",
       "         [-0.0045, -0.0268,  0.0055,  ..., -0.0609, -0.0210,  0.0111],\n",
       "         [-0.0245, -0.0178, -0.0072,  ..., -0.0660, -0.0270, -0.0310],\n",
       "         [ 0.0059, -0.0125,  0.0253,  ...,  0.0373,  0.0047,  0.0312]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_q.lora_up.weight': tensor([[-0.0018, -0.0185, -0.0028,  ...,  0.0067,  0.0072,  0.0005],\n",
       "         [-0.0016,  0.0116,  0.0007,  ..., -0.0003, -0.0034, -0.0005],\n",
       "         [ 0.0054,  0.0223, -0.0023,  ..., -0.0022,  0.0052, -0.0106],\n",
       "         ...,\n",
       "         [-0.0105,  0.0113,  0.0103,  ..., -0.0017, -0.0023,  0.0198],\n",
       "         [ 0.0055, -0.0149, -0.0110,  ..., -0.0047, -0.0080, -0.0182],\n",
       "         [ 0.0078, -0.0139, -0.0116,  ..., -0.0020, -0.0041, -0.0199]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_v.lora_down.weight': tensor([[-0.0186,  0.0133,  0.0111,  ..., -0.0312, -0.0037,  0.0121],\n",
       "         [ 0.0102, -0.0259,  0.0080,  ...,  0.0134, -0.0063, -0.0123],\n",
       "         [ 0.0029,  0.0051, -0.0169,  ..., -0.0068, -0.0021, -0.0272],\n",
       "         ...,\n",
       "         [ 0.0168,  0.0187,  0.0088,  ...,  0.0027,  0.0121,  0.0114],\n",
       "         [-0.0132, -0.0092, -0.0015,  ..., -0.0308,  0.0109, -0.0040],\n",
       "         [ 0.0179,  0.0074,  0.0069,  ...,  0.0073, -0.0028, -0.0029]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_attn2_to_v.lora_up.weight': tensor([[ 0.0028, -0.0026,  0.0178,  ...,  0.0077,  0.0009,  0.0032],\n",
       "         [ 0.0080, -0.0095,  0.0126,  ...,  0.0191,  0.0128,  0.0104],\n",
       "         [ 0.0049, -0.0057, -0.0082,  ...,  0.0254,  0.0057,  0.0048],\n",
       "         ...,\n",
       "         [-0.0038,  0.0063, -0.0032,  ..., -0.0082, -0.0098, -0.0067],\n",
       "         [-0.0056,  0.0090,  0.0015,  ..., -0.0097, -0.0119, -0.0093],\n",
       "         [ 0.0124, -0.0107,  0.0057,  ..., -0.0320,  0.0140,  0.0107]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight': tensor([[ 0.0245,  0.0321, -0.0107,  ...,  0.0021, -0.0159, -0.0212],\n",
       "         [ 0.0164, -0.0011, -0.0167,  ...,  0.0098,  0.0142, -0.0108],\n",
       "         [-0.0151, -0.0140, -0.0224,  ..., -0.0164, -0.0260,  0.0183],\n",
       "         ...,\n",
       "         [-0.0084, -0.0139, -0.0317,  ...,  0.0297,  0.0002,  0.0007],\n",
       "         [-0.0362,  0.0276,  0.0226,  ..., -0.0211,  0.0003, -0.0372],\n",
       "         [ 0.0009, -0.0047, -0.0275,  ..., -0.0572,  0.0106, -0.0185]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight': tensor([[-0.0048,  0.0134, -0.0215,  ..., -0.0048,  0.0188, -0.0321],\n",
       "         [-0.0392, -0.0020, -0.0126,  ..., -0.0013,  0.0153, -0.0019],\n",
       "         [-0.0161, -0.0033,  0.0434,  ...,  0.0057,  0.0177,  0.0034],\n",
       "         ...,\n",
       "         [-0.0372, -0.0164, -0.0152,  ...,  0.0057,  0.0443, -0.0133],\n",
       "         [ 0.0020,  0.0053,  0.0234,  ..., -0.0115,  0.0161, -0.0031],\n",
       "         [-0.0267, -0.0097,  0.0083,  ...,  0.0204,  0.0137, -0.0152]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_2.lora_down.weight': tensor([[-0.0222, -0.0215, -0.0062,  ...,  0.0087,  0.0089, -0.0107],\n",
       "         [ 0.0055, -0.0194, -0.0106,  ..., -0.0210, -0.0119,  0.0045],\n",
       "         [-0.0196, -0.0027,  0.0237,  ...,  0.0005,  0.0180,  0.0166],\n",
       "         ...,\n",
       "         [ 0.0198, -0.0049,  0.0038,  ...,  0.0014, -0.0270, -0.0153],\n",
       "         [-0.0316,  0.0097,  0.0138,  ..., -0.0173,  0.0068,  0.0301],\n",
       "         [ 0.0329,  0.0057, -0.0065,  ...,  0.0028, -0.0023, -0.0087]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_2.lora_up.weight': tensor([[-0.0020,  0.0086, -0.0031,  ..., -0.0191,  0.0153, -0.0142],\n",
       "         [ 0.0021,  0.0167, -0.0049,  ..., -0.0113,  0.0041,  0.0003],\n",
       "         [ 0.0200,  0.0194, -0.0103,  ..., -0.0044, -0.0239,  0.0227],\n",
       "         ...,\n",
       "         [ 0.0090, -0.0100,  0.0208,  ...,  0.0131,  0.0004, -0.0005],\n",
       "         [-0.0066, -0.0086,  0.0052,  ..., -0.0015, -0.0031, -0.0047],\n",
       "         [-0.0127, -0.0012,  0.0054,  ...,  0.0053,  0.0013, -0.0038]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_k.lora_down.weight': tensor([[ 0.0111,  0.0154, -0.0322,  ...,  0.0548,  0.0059, -0.0410],\n",
       "         [ 0.0228, -0.0036,  0.0061,  ...,  0.0184,  0.0032, -0.0397],\n",
       "         [-0.0420,  0.0120, -0.0045,  ...,  0.0081,  0.0301, -0.0281],\n",
       "         ...,\n",
       "         [-0.0045,  0.0009,  0.0127,  ...,  0.0073,  0.0017,  0.0144],\n",
       "         [-0.0288,  0.0289, -0.0293,  ...,  0.0018,  0.0015,  0.0130],\n",
       "         [ 0.0220, -0.0246,  0.0347,  ...,  0.0134,  0.0090,  0.0041]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_k.lora_up.weight': tensor([[-0.0165, -0.0006, -0.0178,  ...,  0.0188, -0.0112,  0.0060],\n",
       "         [ 0.0102,  0.0166,  0.0260,  ..., -0.0197,  0.0119, -0.0096],\n",
       "         [ 0.0104,  0.0197,  0.0172,  ..., -0.0209,  0.0036, -0.0032],\n",
       "         ...,\n",
       "         [-0.0120, -0.0245, -0.0103,  ...,  0.0206,  0.0095,  0.0139],\n",
       "         [ 0.0399,  0.0151,  0.0229,  ..., -0.0183,  0.0223,  0.0077],\n",
       "         [ 0.0303, -0.0103,  0.0105,  ..., -0.0084,  0.0175,  0.0037]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_out_0.lora_down.weight': tensor([[ 0.0274, -0.0115,  0.0108,  ...,  0.0591,  0.0075, -0.0302],\n",
       "         [ 0.0062,  0.0133,  0.0021,  ..., -0.0016,  0.0162, -0.0101],\n",
       "         [-0.0055, -0.0019,  0.0147,  ..., -0.0271,  0.0104, -0.0143],\n",
       "         ...,\n",
       "         [-0.0062, -0.0038, -0.0190,  ..., -0.0183,  0.0049,  0.0124],\n",
       "         [-0.0260,  0.0008, -0.0035,  ..., -0.0091, -0.0160,  0.0143],\n",
       "         [-0.0332,  0.0192, -0.0204,  ..., -0.0267,  0.0053, -0.0150]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_out_0.lora_up.weight': tensor([[-1.3237e-02,  1.4458e-02,  8.1718e-05,  ...,  2.2733e-04,\n",
       "           1.1673e-02,  5.7411e-03],\n",
       "         [ 1.2245e-02,  8.4915e-03,  2.1820e-02,  ...,  6.5506e-05,\n",
       "          -5.9242e-03, -1.7288e-02],\n",
       "         [-2.7420e-02,  1.2733e-02,  2.8656e-02,  ...,  2.5730e-03,\n",
       "           1.2169e-02,  4.8375e-04],\n",
       "         ...,\n",
       "         [ 1.2428e-02, -1.1513e-02, -2.1637e-02,  ..., -3.1738e-03,\n",
       "          -2.0035e-02, -1.8234e-02],\n",
       "         [-6.2256e-03, -1.7700e-03, -8.5449e-03,  ..., -3.0956e-03,\n",
       "          -3.0499e-03,  7.7820e-03],\n",
       "         [-8.5144e-03,  1.6165e-03,  2.8210e-03,  ...,  1.0628e-02,\n",
       "          -3.6087e-03,  3.5534e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_q.lora_down.weight': tensor([[-0.0005,  0.0282,  0.0312,  ..., -0.0033,  0.0136, -0.0220],\n",
       "         [ 0.0141,  0.0008,  0.0034,  ..., -0.0082,  0.0014,  0.0147],\n",
       "         [-0.0220, -0.0003, -0.0139,  ..., -0.0143, -0.0390,  0.0359],\n",
       "         ...,\n",
       "         [ 0.0382, -0.0432, -0.0037,  ..., -0.0111, -0.0004,  0.0059],\n",
       "         [ 0.0021, -0.0066, -0.0025,  ...,  0.0003,  0.0256, -0.0126],\n",
       "         [ 0.0192,  0.0342, -0.0136,  ..., -0.0134,  0.0016,  0.0180]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_q.lora_up.weight': tensor([[ 0.0242, -0.0223, -0.0169,  ...,  0.0276,  0.0169,  0.0269],\n",
       "         [-0.0148, -0.0101, -0.0211,  ...,  0.0057,  0.0203, -0.0082],\n",
       "         [ 0.0167, -0.0136, -0.0102,  ...,  0.0235,  0.0195,  0.0276],\n",
       "         ...,\n",
       "         [ 0.0231,  0.0084, -0.0131,  ...,  0.0018,  0.0137, -0.0114],\n",
       "         [-0.0012,  0.0024, -0.0121,  ...,  0.0235,  0.0082,  0.0065],\n",
       "         [-0.0039,  0.0089, -0.0053,  ..., -0.0049,  0.0138,  0.0019]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_v.lora_down.weight': tensor([[-0.0145, -0.0278, -0.0116,  ..., -0.0182, -0.0428, -0.0266],\n",
       "         [-0.0414,  0.0001,  0.0238,  ..., -0.0675, -0.0153, -0.0303],\n",
       "         [-0.0131,  0.0091,  0.0185,  ...,  0.0053, -0.0081,  0.0431],\n",
       "         ...,\n",
       "         [-0.0182,  0.0242,  0.0219,  ..., -0.0092, -0.0144,  0.0007],\n",
       "         [-0.0227, -0.0182, -0.0160,  ..., -0.0044, -0.0268, -0.0423],\n",
       "         [-0.0313, -0.0054,  0.0013,  ..., -0.0035,  0.0014, -0.0208]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_v.lora_up.weight': tensor([[-0.0086, -0.0173, -0.0028,  ..., -0.0300,  0.0230,  0.0043],\n",
       "         [ 0.0081, -0.0016,  0.0044,  ...,  0.0003,  0.0285, -0.0139],\n",
       "         [ 0.0038,  0.0086, -0.0124,  ...,  0.0013,  0.0166,  0.0111],\n",
       "         ...,\n",
       "         [-0.0100,  0.0075,  0.0123,  ...,  0.0012,  0.0077, -0.0077],\n",
       "         [ 0.0082,  0.0072, -0.0156,  ...,  0.0198, -0.0041, -0.0105],\n",
       "         [ 0.0040,  0.0150, -0.0094,  ..., -0.0158,  0.0268,  0.0246]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_k.lora_down.weight': tensor([[ 0.0308,  0.0187, -0.0263,  ...,  0.0236, -0.0143, -0.0221],\n",
       "         [ 0.0070, -0.0023, -0.0224,  ...,  0.0042, -0.0126, -0.0234],\n",
       "         [ 0.0149, -0.0002, -0.0116,  ...,  0.0069, -0.0320,  0.0194],\n",
       "         ...,\n",
       "         [ 0.0191, -0.0195, -0.0102,  ...,  0.0059, -0.0265,  0.0167],\n",
       "         [ 0.0068, -0.0021, -0.0271,  ...,  0.0094,  0.0296,  0.0099],\n",
       "         [ 0.0105, -0.0053, -0.0160,  ...,  0.0049, -0.0212,  0.0010]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_k.lora_up.weight': tensor([[ 0.0037,  0.0154,  0.0060,  ..., -0.0173,  0.0150,  0.0049],\n",
       "         [-0.0304, -0.0122, -0.0356,  ..., -0.0191,  0.0083, -0.0331],\n",
       "         [-0.0098,  0.0041, -0.0216,  ..., -0.0246,  0.0173, -0.0086],\n",
       "         ...,\n",
       "         [ 0.0019,  0.0037, -0.0173,  ..., -0.0211,  0.0071,  0.0020],\n",
       "         [ 0.0070, -0.0245,  0.0204,  ...,  0.0111, -0.0189,  0.0012],\n",
       "         [ 0.0064,  0.0165,  0.0043,  ..., -0.0143,  0.0170,  0.0054]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_out_0.lora_down.weight': tensor([[ 0.0307, -0.0072,  0.0036,  ...,  0.0238, -0.0130,  0.0023],\n",
       "         [-0.0123,  0.0031, -0.0049,  ..., -0.0026,  0.0193, -0.0133],\n",
       "         [-0.0213,  0.0155, -0.0137,  ...,  0.0002, -0.0257, -0.0305],\n",
       "         ...,\n",
       "         [-0.0135,  0.0136,  0.0246,  ..., -0.0047, -0.0142,  0.0105],\n",
       "         [-0.0110, -0.0064,  0.0143,  ...,  0.0073, -0.0008,  0.0220],\n",
       "         [-0.0297,  0.0270, -0.0175,  ..., -0.0157,  0.0126,  0.0130]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_out_0.lora_up.weight': tensor([[ 5.4932e-03, -5.7602e-03,  7.7400e-03,  ..., -1.2627e-02,\n",
       "           2.3258e-04, -6.7177e-03],\n",
       "         [-9.0179e-03,  3.4981e-03, -2.4757e-03,  ...,  1.5564e-02,\n",
       "          -4.0169e-03,  1.9217e-03],\n",
       "         [-2.9510e-02,  1.4977e-02, -1.8143e-02,  ...,  1.1856e-02,\n",
       "           1.6373e-02, -4.9448e-04],\n",
       "         ...,\n",
       "         [ 2.6779e-02, -2.2392e-03, -3.1853e-03,  ...,  9.1782e-03,\n",
       "          -3.2623e-02,  1.6661e-03],\n",
       "         [ 1.8835e-03, -6.5842e-03,  5.5084e-03,  ...,  4.8027e-03,\n",
       "          -4.7874e-03, -5.5771e-03],\n",
       "         [ 1.2550e-02,  4.2763e-03, -5.7280e-05,  ..., -9.2468e-03,\n",
       "           4.1199e-04, -9.1219e-04]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_q.lora_down.weight': tensor([[-2.6703e-02, -3.8567e-03, -2.2064e-02,  ..., -4.6417e-02,\n",
       "          -9.8324e-04, -3.9185e-02],\n",
       "         [-6.4087e-03,  1.5045e-02,  2.3453e-02,  ..., -2.4231e-02,\n",
       "           3.4790e-02, -6.7139e-03],\n",
       "         [-7.8659e-03,  3.9697e-05, -4.4220e-02,  ...,  4.4312e-02,\n",
       "           3.9291e-03,  2.5589e-02],\n",
       "         ...,\n",
       "         [ 2.7756e-02, -3.0609e-02, -1.4771e-02,  ..., -4.1077e-02,\n",
       "           1.4374e-02, -1.9760e-02],\n",
       "         [ 2.4551e-02,  4.7607e-02,  1.2341e-03,  ...,  3.3691e-02,\n",
       "          -1.2749e-02,  4.1473e-02],\n",
       "         [-1.1940e-03, -1.0658e-02,  9.4757e-03,  ..., -1.7120e-02,\n",
       "          -6.1188e-03, -1.5564e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_q.lora_up.weight': tensor([[ 1.0895e-02,  1.9913e-02, -2.0645e-02,  ..., -6.0425e-03,\n",
       "          -1.2558e-02,  2.0370e-02],\n",
       "         [-1.1398e-02,  5.7449e-03,  1.0986e-02,  ..., -1.3588e-02,\n",
       "          -7.8082e-05,  3.9825e-03],\n",
       "         [-1.5793e-02, -1.5671e-02,  4.2915e-03,  ..., -1.1459e-02,\n",
       "           1.2070e-02, -1.1459e-02],\n",
       "         ...,\n",
       "         [-2.6260e-02, -7.7934e-03,  1.4473e-02,  ..., -2.4261e-02,\n",
       "           2.0462e-02, -7.8278e-03],\n",
       "         [-2.3926e-02, -1.0071e-02,  1.6861e-02,  ..., -1.8448e-02,\n",
       "           2.9663e-02, -4.2877e-03],\n",
       "         [-1.8173e-02, -2.2202e-03,  1.3573e-02,  ..., -1.8326e-02,\n",
       "           1.8906e-02,  8.9741e-04]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_v.lora_down.weight': tensor([[-0.0098,  0.0018,  0.0175,  ...,  0.0056,  0.0023, -0.0094],\n",
       "         [-0.0107,  0.0218,  0.0096,  ..., -0.0016, -0.0017,  0.0054],\n",
       "         [ 0.0150,  0.0090, -0.0101,  ..., -0.0072, -0.0033,  0.0006],\n",
       "         ...,\n",
       "         [ 0.0034,  0.0164,  0.0143,  ...,  0.0082, -0.0075,  0.0107],\n",
       "         [-0.0031, -0.0207,  0.0010,  ...,  0.0008,  0.0133, -0.0021],\n",
       "         [-0.0188,  0.0054, -0.0173,  ...,  0.0241,  0.0092, -0.0073]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_attn2_to_v.lora_up.weight': tensor([[ 0.0242,  0.0051, -0.0131,  ..., -0.0285, -0.0075, -0.0121],\n",
       "         [ 0.0065, -0.0164, -0.0081,  ..., -0.0068, -0.0180, -0.0188],\n",
       "         [-0.0286,  0.0008,  0.0207,  ...,  0.0220,  0.0242,  0.0273],\n",
       "         ...,\n",
       "         [ 0.0056,  0.0024,  0.0062,  ..., -0.0314,  0.0139,  0.0085],\n",
       "         [-0.0100, -0.0161,  0.0029,  ..., -0.0107,  0.0005,  0.0031],\n",
       "         [ 0.0060,  0.0107, -0.0016,  ..., -0.0374,  0.0086, -0.0001]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_0_proj.lora_down.weight': tensor([[ 0.0147,  0.0016,  0.0406,  ..., -0.0455,  0.0335,  0.0053],\n",
       "         [-0.0408, -0.0186, -0.0061,  ..., -0.0087, -0.0211, -0.0131],\n",
       "         [ 0.0119, -0.0150,  0.0222,  ..., -0.0369, -0.0086, -0.0282],\n",
       "         ...,\n",
       "         [ 0.0184,  0.0285, -0.0318,  ..., -0.0345, -0.0109,  0.0221],\n",
       "         [ 0.0199,  0.0099, -0.0341,  ..., -0.0327,  0.0204, -0.0089],\n",
       "         [ 0.0232,  0.0428,  0.0199,  ..., -0.0204,  0.0369, -0.0255]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_0_proj.lora_up.weight': tensor([[-1.1108e-02, -1.7441e-02, -1.1940e-02,  ...,  1.0672e-03,\n",
       "          -9.6023e-05, -1.6006e-02],\n",
       "         [ 1.4771e-02,  3.5767e-02,  3.6346e-02,  ..., -4.8518e-05,\n",
       "           2.0996e-02, -1.0849e-02],\n",
       "         [-3.7384e-03, -5.9891e-03,  2.0569e-02,  ...,  1.2459e-02,\n",
       "           8.2111e-04,  1.5060e-02],\n",
       "         ...,\n",
       "         [-3.0499e-03, -1.4420e-02,  4.4250e-03,  ...,  8.1558e-03,\n",
       "          -6.9885e-03,  1.1314e-02],\n",
       "         [ 1.4938e-02, -2.2217e-02,  8.0261e-03,  ...,  1.7303e-02,\n",
       "          -3.2013e-02,  1.6968e-02],\n",
       "         [ 5.9586e-03,  1.6870e-03,  1.7227e-02,  ...,  3.0457e-02,\n",
       "           4.5815e-03,  1.3977e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_2.lora_down.weight': tensor([[ 0.0086,  0.0116, -0.0089,  ..., -0.0114, -0.0085, -0.0159],\n",
       "         [ 0.0100, -0.0006,  0.0297,  ...,  0.0176, -0.0025, -0.0087],\n",
       "         [-0.0111, -0.0170, -0.0234,  ..., -0.0265,  0.0066,  0.0260],\n",
       "         ...,\n",
       "         [ 0.0057,  0.0062,  0.0229,  ...,  0.0057, -0.0183, -0.0105],\n",
       "         [ 0.0161,  0.0126,  0.0112,  ...,  0.0139,  0.0119, -0.0321],\n",
       "         [-0.0204,  0.0069,  0.0084,  ..., -0.0179, -0.0103,  0.0309]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_2.lora_up.weight': tensor([[-0.0122, -0.0070,  0.0006,  ..., -0.0066, -0.0282,  0.0152],\n",
       "         [-0.0056,  0.0056,  0.0187,  ..., -0.0018, -0.0030,  0.0103],\n",
       "         [-0.0052,  0.0092,  0.0011,  ..., -0.0012,  0.0094, -0.0070],\n",
       "         ...,\n",
       "         [-0.0030, -0.0138,  0.0145,  ..., -0.0165,  0.0102, -0.0003],\n",
       "         [-0.0108, -0.0147,  0.0050,  ..., -0.0116, -0.0133,  0.0137],\n",
       "         [-0.0068, -0.0136,  0.0208,  ..., -0.0159, -0.0061,  0.0142]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_k.lora_down.weight': tensor([[ 0.0257, -0.0194,  0.0138,  ..., -0.0258, -0.0042,  0.0030],\n",
       "         [-0.0054, -0.0300, -0.0115,  ...,  0.0516, -0.0179, -0.0171],\n",
       "         [ 0.0137,  0.0042, -0.0094,  ...,  0.0285,  0.0147, -0.0130],\n",
       "         ...,\n",
       "         [-0.0177, -0.0370,  0.0179,  ...,  0.0191, -0.0009,  0.0193],\n",
       "         [-0.0257,  0.0123,  0.0456,  ..., -0.0172,  0.0071,  0.0086],\n",
       "         [-0.0174, -0.0039, -0.0269,  ...,  0.0165, -0.0234,  0.0396]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_k.lora_up.weight': tensor([[ 0.0006, -0.0070,  0.0177,  ..., -0.0020, -0.0039, -0.0076],\n",
       "         [ 0.0007,  0.0313, -0.0079,  ...,  0.0044, -0.0127,  0.0453],\n",
       "         [-0.0030,  0.0269, -0.0083,  ..., -0.0061, -0.0140,  0.0331],\n",
       "         ...,\n",
       "         [ 0.0065,  0.0010, -0.0154,  ...,  0.0022, -0.0032,  0.0103],\n",
       "         [ 0.0044,  0.0158, -0.0111,  ...,  0.0141, -0.0029,  0.0014],\n",
       "         [ 0.0066, -0.0126,  0.0019,  ..., -0.0210,  0.0074, -0.0277]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_out_0.lora_down.weight': tensor([[-0.0093,  0.0111, -0.0032,  ...,  0.0232,  0.0268, -0.0035],\n",
       "         [ 0.0444, -0.0502, -0.0094,  ...,  0.0108, -0.0325,  0.0284],\n",
       "         [-0.0282,  0.0357, -0.0063,  ..., -0.0168,  0.0029, -0.0467],\n",
       "         ...,\n",
       "         [ 0.0251, -0.0072,  0.0153,  ..., -0.0110,  0.0300,  0.0347],\n",
       "         [ 0.0089, -0.0263,  0.0088,  ..., -0.0147, -0.0022,  0.0127],\n",
       "         [ 0.0274, -0.0116,  0.0166,  ...,  0.0176,  0.0109, -0.0155]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_out_0.lora_up.weight': tensor([[-0.0208,  0.0150, -0.0199,  ...,  0.0122,  0.0005,  0.0004],\n",
       "         [ 0.0014,  0.0029, -0.0177,  ..., -0.0109,  0.0140,  0.0303],\n",
       "         [ 0.0048,  0.0186,  0.0030,  ..., -0.0216,  0.0141,  0.0414],\n",
       "         ...,\n",
       "         [ 0.0170, -0.0087,  0.0130,  ...,  0.0025, -0.0076, -0.0173],\n",
       "         [-0.0173, -0.0054,  0.0015,  ...,  0.0302, -0.0203, -0.0215],\n",
       "         [-0.0062,  0.0169,  0.0055,  ...,  0.0011,  0.0183, -0.0173]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_q.lora_down.weight': tensor([[ 2.1652e-02,  4.3304e-02,  2.8553e-03,  ..., -4.2328e-02,\n",
       "          -4.4952e-02, -2.6413e-02],\n",
       "         [-2.5620e-02, -1.0178e-02, -8.2932e-03,  ..., -7.2212e-03,\n",
       "           2.5406e-02, -3.2104e-02],\n",
       "         [-4.8599e-03, -3.4637e-02, -5.5313e-03,  ..., -1.9272e-02,\n",
       "           8.6823e-03, -1.2878e-02],\n",
       "         ...,\n",
       "         [ 1.0292e-02, -9.6893e-03,  2.3132e-02,  ..., -2.0920e-02,\n",
       "           1.3184e-02, -1.0386e-03],\n",
       "         [ 1.7883e-02,  3.5217e-02, -1.8524e-02,  ...,  5.3291e-03,\n",
       "           1.9333e-02, -6.6280e-05],\n",
       "         [-2.2522e-02, -6.5117e-03,  5.0842e-02,  ..., -1.4259e-02,\n",
       "           6.4583e-03, -3.5645e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_q.lora_up.weight': tensor([[-0.0035, -0.0127, -0.0124,  ...,  0.0052, -0.0021, -0.0007],\n",
       "         [ 0.0134, -0.0046, -0.0168,  ..., -0.0054,  0.0167, -0.0212],\n",
       "         [ 0.0314, -0.0233, -0.0002,  ...,  0.0242, -0.0047,  0.0019],\n",
       "         ...,\n",
       "         [-0.0113,  0.0124, -0.0097,  ..., -0.0133, -0.0030, -0.0086],\n",
       "         [-0.0071,  0.0170,  0.0005,  ..., -0.0113, -0.0083, -0.0145],\n",
       "         [-0.0040, -0.0010, -0.0101,  ...,  0.0071,  0.0068, -0.0016]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_v.lora_down.weight': tensor([[ 0.0495,  0.0426, -0.0208,  ..., -0.0014,  0.0493, -0.0081],\n",
       "         [-0.0055, -0.0040, -0.0042,  ..., -0.0179, -0.0039,  0.0372],\n",
       "         [ 0.0005, -0.0293, -0.0372,  ...,  0.0056, -0.0110, -0.0085],\n",
       "         ...,\n",
       "         [ 0.0261, -0.0158, -0.0242,  ..., -0.0001, -0.0324,  0.0004],\n",
       "         [ 0.0031, -0.0261, -0.0418,  ..., -0.0231, -0.0565,  0.0561],\n",
       "         [ 0.0055,  0.0313, -0.0042,  ..., -0.0229, -0.0231,  0.0276]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_v.lora_up.weight': tensor([[ 8.6441e-03,  9.1171e-03, -1.0506e-02,  ...,  4.5586e-03,\n",
       "          -3.0231e-03,  1.7929e-02],\n",
       "         [ 1.5503e-02,  6.8092e-03, -5.1308e-03,  ...,  3.0655e-02,\n",
       "           8.4152e-03,  1.4511e-02],\n",
       "         [-4.2343e-03, -1.3704e-03, -1.1459e-02,  ..., -8.2493e-04,\n",
       "          -1.9684e-02, -4.3755e-03],\n",
       "         ...,\n",
       "         [-1.2215e-02,  5.6953e-03, -1.2810e-02,  ...,  1.0468e-02,\n",
       "           8.6823e-03, -1.8559e-03],\n",
       "         [-8.6288e-03, -6.9962e-03, -6.5517e-04,  ..., -1.4067e-03,\n",
       "           2.2202e-02, -6.3181e-05],\n",
       "         [ 1.2665e-02,  9.4223e-03, -1.1452e-02,  ...,  8.9111e-03,\n",
       "          -1.9531e-02,  1.2138e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_k.lora_down.weight': tensor([[ 0.0185, -0.0275, -0.0162,  ...,  0.0215,  0.0242,  0.0102],\n",
       "         [ 0.0328, -0.0092, -0.0130,  ..., -0.0066, -0.0212,  0.0032],\n",
       "         [-0.0013, -0.0087, -0.0196,  ...,  0.0102, -0.0057, -0.0119],\n",
       "         ...,\n",
       "         [ 0.0111,  0.0267,  0.0186,  ..., -0.0242,  0.0165,  0.0199],\n",
       "         [ 0.0054,  0.0006,  0.0107,  ..., -0.0023, -0.0032,  0.0089],\n",
       "         [ 0.0336, -0.0188, -0.0237,  ...,  0.0208, -0.0082,  0.0374]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_k.lora_up.weight': tensor([[-0.0006, -0.0006,  0.0011,  ...,  0.0009, -0.0108,  0.0028],\n",
       "         [ 0.0099, -0.0088,  0.0124,  ..., -0.0129,  0.0037,  0.0143],\n",
       "         [-0.0014,  0.0027, -0.0111,  ..., -0.0018, -0.0034, -0.0132],\n",
       "         ...,\n",
       "         [ 0.0028, -0.0180,  0.0169,  ..., -0.0046,  0.0184,  0.0069],\n",
       "         [ 0.0069,  0.0010, -0.0035,  ..., -0.0084, -0.0095,  0.0215],\n",
       "         [-0.0122, -0.0061,  0.0068,  ...,  0.0086,  0.0063, -0.0300]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_out_0.lora_down.weight': tensor([[-0.0113, -0.0126,  0.0199,  ..., -0.0186, -0.0138,  0.0027],\n",
       "         [-0.0088,  0.0205, -0.0305,  ...,  0.0060, -0.0057, -0.0094],\n",
       "         [-0.0093, -0.0131, -0.0146,  ...,  0.0083,  0.0137, -0.0214],\n",
       "         ...,\n",
       "         [ 0.0108,  0.0317,  0.0121,  ..., -0.0121,  0.0045,  0.0148],\n",
       "         [-0.0364, -0.0014,  0.0273,  ..., -0.0034, -0.0181, -0.0095],\n",
       "         [ 0.0031, -0.0195, -0.0045,  ..., -0.0084, -0.0251,  0.0051]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_out_0.lora_up.weight': tensor([[-0.0009, -0.0038,  0.0069,  ...,  0.0040,  0.0021, -0.0061],\n",
       "         [-0.0062,  0.0115, -0.0061,  ...,  0.0161, -0.0102, -0.0336],\n",
       "         [-0.0121,  0.0157, -0.0210,  ...,  0.0378, -0.0018, -0.0343],\n",
       "         ...,\n",
       "         [ 0.0053, -0.0097, -0.0075,  ..., -0.0175, -0.0065,  0.0063],\n",
       "         [ 0.0079, -0.0014,  0.0092,  ..., -0.0068,  0.0064,  0.0098],\n",
       "         [ 0.0191, -0.0056,  0.0103,  ..., -0.0154, -0.0148,  0.0117]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_q.lora_down.weight': tensor([[-0.0453, -0.0301,  0.0052,  ...,  0.0559,  0.0005, -0.0244],\n",
       "         [-0.0062, -0.0027,  0.0323,  ..., -0.0306, -0.0352,  0.0252],\n",
       "         [ 0.0078,  0.0280,  0.0076,  ..., -0.0173, -0.0098,  0.0237],\n",
       "         ...,\n",
       "         [ 0.0538, -0.0194, -0.0135,  ...,  0.0139,  0.0070, -0.0117],\n",
       "         [ 0.0141,  0.0514, -0.0184,  ..., -0.0123,  0.0215,  0.0256],\n",
       "         [ 0.0068, -0.0125, -0.0065,  ..., -0.0400, -0.0245, -0.0013]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_q.lora_up.weight': tensor([[-0.0201,  0.0081,  0.0205,  ...,  0.0256,  0.0144,  0.0070],\n",
       "         [ 0.0212, -0.0080, -0.0187,  ..., -0.0257, -0.0155, -0.0042],\n",
       "         [ 0.0224, -0.0224, -0.0321,  ..., -0.0128, -0.0175, -0.0300],\n",
       "         ...,\n",
       "         [-0.0057,  0.0103,  0.0035,  ...,  0.0133,  0.0258,  0.0169],\n",
       "         [-0.0105,  0.0106,  0.0062,  ...,  0.0091,  0.0253,  0.0142],\n",
       "         [ 0.0148, -0.0145, -0.0102,  ..., -0.0191, -0.0224, -0.0165]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_v.lora_down.weight': tensor([[-0.0188,  0.0172,  0.0256,  ...,  0.0025, -0.0016, -0.0022],\n",
       "         [-0.0039, -0.0036,  0.0085,  ..., -0.0043,  0.0046, -0.0047],\n",
       "         [-0.0046, -0.0057, -0.0337,  ...,  0.0062, -0.0259, -0.0069],\n",
       "         ...,\n",
       "         [ 0.0074, -0.0040, -0.0070,  ...,  0.0151, -0.0070, -0.0186],\n",
       "         [ 0.0052, -0.0180, -0.0004,  ..., -0.0021,  0.0173,  0.0157],\n",
       "         [-0.0081, -0.0070, -0.0138,  ...,  0.0106, -0.0242, -0.0044]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_attn2_to_v.lora_up.weight': tensor([[ 0.0225,  0.0161, -0.0059,  ..., -0.0201,  0.0177, -0.0110],\n",
       "         [ 0.0174,  0.0127,  0.0061,  ...,  0.0018,  0.0143,  0.0021],\n",
       "         [-0.0099, -0.0137,  0.0054,  ..., -0.0163, -0.0230, -0.0015],\n",
       "         ...,\n",
       "         [ 0.0126,  0.0079, -0.0192,  ..., -0.0016, -0.0040, -0.0051],\n",
       "         [-0.0233, -0.0024,  0.0125,  ..., -0.0044,  0.0034,  0.0139],\n",
       "         [ 0.0002,  0.0034, -0.0150,  ...,  0.0050,  0.0064, -0.0058]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_0_proj.lora_down.weight': tensor([[-0.0143, -0.0173, -0.0051,  ..., -0.0467,  0.0010,  0.0096],\n",
       "         [ 0.0215, -0.0142,  0.0388,  ...,  0.0142, -0.0020, -0.0122],\n",
       "         [-0.0096, -0.0201,  0.0083,  ..., -0.0018,  0.0141, -0.0182],\n",
       "         ...,\n",
       "         [ 0.0176,  0.0258,  0.0165,  ...,  0.0221,  0.0183,  0.0070],\n",
       "         [ 0.0069,  0.0177,  0.0273,  ...,  0.0160, -0.0104,  0.0329],\n",
       "         [ 0.0214, -0.0161, -0.0211,  ...,  0.0180,  0.0324,  0.0229]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_0_proj.lora_up.weight': tensor([[ 2.2766e-02, -1.2543e-02,  1.2455e-03,  ..., -3.5610e-03,\n",
       "          -4.7035e-03,  3.8013e-03],\n",
       "         [ 9.8038e-03, -1.3283e-02, -1.0513e-02,  ..., -1.0681e-03,\n",
       "          -1.2665e-02, -1.4717e-02],\n",
       "         [ 4.5319e-03, -1.4481e-02, -1.3000e-02,  ..., -9.9411e-03,\n",
       "           5.0354e-03, -3.1021e-02],\n",
       "         ...,\n",
       "         [-1.3741e-02, -1.6495e-02, -6.9046e-03,  ...,  3.0899e-03,\n",
       "           1.1772e-02,  2.3186e-04],\n",
       "         [-2.9831e-02, -7.0648e-03, -2.9984e-03,  ...,  4.2839e-03,\n",
       "          -1.1154e-02,  7.5698e-05],\n",
       "         [-3.1223e-03,  6.2256e-03, -2.0721e-02,  ..., -1.7380e-02,\n",
       "          -2.6184e-02, -2.0172e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_2.lora_down.weight': tensor([[-0.0101, -0.0193,  0.0163,  ...,  0.0062,  0.0131,  0.0026],\n",
       "         [-0.0157,  0.0050,  0.0193,  ...,  0.0364,  0.0465,  0.0043],\n",
       "         [ 0.0121, -0.0078, -0.0019,  ..., -0.0058,  0.0132,  0.0013],\n",
       "         ...,\n",
       "         [-0.0028, -0.0031, -0.0029,  ...,  0.0170,  0.0290, -0.0002],\n",
       "         [ 0.0293,  0.0303, -0.0179,  ..., -0.0024, -0.0211, -0.0031],\n",
       "         [-0.0293,  0.0035, -0.0039,  ...,  0.0247,  0.0130, -0.0057]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_2.lora_up.weight': tensor([[ 2.4281e-03, -5.0974e-04,  5.8270e-04,  ..., -1.3046e-03,\n",
       "          -1.0590e-02,  8.6725e-05],\n",
       "         [ 4.0855e-03, -4.7088e-06, -4.6883e-03,  ...,  3.6469e-03,\n",
       "          -2.8133e-03,  8.1940e-03],\n",
       "         [ 2.2259e-03, -3.0090e-02,  8.8501e-03,  ...,  5.5504e-03,\n",
       "          -3.7651e-03,  8.0261e-03],\n",
       "         ...,\n",
       "         [-2.3819e-02,  1.4534e-03, -1.2817e-02,  ..., -2.8198e-02,\n",
       "           2.0020e-02, -1.5022e-02],\n",
       "         [-1.5411e-02, -8.6975e-03,  1.3290e-02,  ..., -1.4244e-02,\n",
       "           3.5019e-03, -8.6365e-03],\n",
       "         [-7.8735e-03,  1.2787e-02,  7.8125e-03,  ..., -9.6817e-03,\n",
       "           1.4809e-02, -5.9509e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_k.lora_down.weight': tensor([[ 0.0206, -0.0191, -0.0132,  ...,  0.0327,  0.0247,  0.0037],\n",
       "         [-0.0224, -0.0064,  0.0229,  ..., -0.0058,  0.0151, -0.0322],\n",
       "         [ 0.0153, -0.0077,  0.0128,  ..., -0.0045,  0.0071,  0.0169],\n",
       "         ...,\n",
       "         [-0.0259, -0.0015,  0.0433,  ..., -0.0088, -0.0138, -0.0252],\n",
       "         [-0.0215,  0.0108, -0.0312,  ...,  0.0164,  0.0007,  0.0112],\n",
       "         [ 0.0082, -0.0601, -0.0093,  ..., -0.0373,  0.0304, -0.0106]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_k.lora_up.weight': tensor([[ 0.0371, -0.0503, -0.0048,  ..., -0.0420,  0.0392, -0.0248],\n",
       "         [ 0.0036, -0.0427,  0.0026,  ..., -0.0250,  0.0189, -0.0410],\n",
       "         [ 0.0092, -0.0104, -0.0049,  ..., -0.0021,  0.0020,  0.0121],\n",
       "         ...,\n",
       "         [-0.0206,  0.0032,  0.0072,  ...,  0.0159, -0.0009,  0.0054],\n",
       "         [-0.0245,  0.0056,  0.0208,  ...,  0.0149, -0.0016,  0.0071],\n",
       "         [ 0.0185,  0.0015, -0.0147,  ..., -0.0158, -0.0024, -0.0057]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_out_0.lora_down.weight': tensor([[ 0.0302,  0.0262,  0.0280,  ...,  0.0063,  0.0037,  0.0087],\n",
       "         [-0.0103, -0.0078, -0.0174,  ..., -0.0027,  0.0029, -0.0072],\n",
       "         [-0.0035,  0.0020,  0.0216,  ...,  0.0002,  0.0159, -0.0064],\n",
       "         ...,\n",
       "         [-0.0291,  0.0145,  0.0174,  ..., -0.0139,  0.0268, -0.0056],\n",
       "         [-0.0179,  0.0277, -0.0341,  ...,  0.0356, -0.0538, -0.0091],\n",
       "         [ 0.0189, -0.0023,  0.0078,  ..., -0.0005, -0.0191,  0.0105]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_out_0.lora_up.weight': tensor([[ 0.0094,  0.0007, -0.0035,  ..., -0.0066, -0.0033, -0.0049],\n",
       "         [-0.0061,  0.0353, -0.0206,  ...,  0.0052,  0.0240, -0.0035],\n",
       "         [-0.0346,  0.0185, -0.0050,  ..., -0.0036, -0.0005,  0.0080],\n",
       "         ...,\n",
       "         [-0.0071,  0.0042,  0.0010,  ..., -0.0207, -0.0019,  0.0067],\n",
       "         [ 0.0158, -0.0149,  0.0224,  ..., -0.0101, -0.0161,  0.0166],\n",
       "         [ 0.0151, -0.0198,  0.0090,  ...,  0.0100, -0.0363, -0.0139]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_q.lora_down.weight': tensor([[ 0.0210, -0.0169, -0.0479,  ..., -0.0100, -0.0124, -0.0297],\n",
       "         [-0.0079,  0.0239,  0.0082,  ...,  0.0054,  0.0084, -0.0200],\n",
       "         [-0.0090,  0.0087,  0.0341,  ...,  0.0398,  0.0093,  0.0086],\n",
       "         ...,\n",
       "         [-0.0286, -0.0124,  0.0099,  ...,  0.0322,  0.0212, -0.0141],\n",
       "         [ 0.0032,  0.0305, -0.0261,  ...,  0.0089, -0.0089, -0.0030],\n",
       "         [ 0.0321, -0.0058,  0.0011,  ..., -0.0051, -0.0308, -0.0247]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_q.lora_up.weight': tensor([[-1.7567e-03,  1.0269e-02, -5.1689e-03,  ...,  2.7752e-03,\n",
       "           3.7994e-03, -4.7505e-05],\n",
       "         [ 7.5769e-04,  1.7288e-02,  1.0757e-02,  ...,  8.9493e-03,\n",
       "           1.3590e-03,  4.7073e-03],\n",
       "         [-6.8130e-03,  1.0567e-02,  2.1286e-02,  ...,  7.4348e-03,\n",
       "          -3.3550e-03, -5.0306e-04],\n",
       "         ...,\n",
       "         [ 1.2779e-02, -2.5311e-03,  2.2964e-03,  ..., -8.2169e-03,\n",
       "          -4.2152e-04, -4.6635e-04],\n",
       "         [ 1.5213e-02,  8.8196e-03, -3.0609e-02,  ..., -3.3783e-02,\n",
       "           1.8463e-02,  2.8488e-02],\n",
       "         [ 2.4776e-03,  5.1460e-03,  1.1002e-02,  ...,  7.4158e-03,\n",
       "           1.1497e-02,  5.1155e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_v.lora_down.weight': tensor([[ 0.0186,  0.0043, -0.0199,  ..., -0.0366, -0.0035, -0.0515],\n",
       "         [ 0.0188,  0.0245,  0.0115,  ..., -0.0106, -0.0201, -0.0205],\n",
       "         [ 0.0074, -0.0056,  0.0360,  ...,  0.0207, -0.0206,  0.0125],\n",
       "         ...,\n",
       "         [-0.0051,  0.0165, -0.0009,  ...,  0.0051,  0.0242,  0.0589],\n",
       "         [ 0.0157, -0.0129,  0.0203,  ...,  0.0220,  0.0128,  0.0240],\n",
       "         [-0.0087, -0.0125,  0.0319,  ...,  0.0120, -0.0191,  0.0086]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_v.lora_up.weight': tensor([[-6.0043e-03, -2.4586e-03, -1.2711e-02,  ...,  1.4145e-02,\n",
       "          -3.8948e-03, -7.9095e-05],\n",
       "         [-1.2169e-02, -1.5671e-02,  6.6261e-03,  ...,  4.8637e-03,\n",
       "          -3.3069e-04,  2.2202e-02],\n",
       "         [-2.5177e-02,  7.2060e-03,  1.7929e-02,  ...,  7.8125e-03,\n",
       "          -9.9640e-03,  5.9814e-03],\n",
       "         ...,\n",
       "         [-5.3596e-04,  1.7715e-02,  1.4893e-02,  ...,  2.0233e-02,\n",
       "           8.1635e-03,  1.0712e-02],\n",
       "         [-3.1452e-03, -1.7365e-02, -1.7776e-02,  ...,  2.4734e-02,\n",
       "          -2.6657e-02, -1.1040e-02],\n",
       "         [-1.9470e-02,  2.9144e-03, -1.3180e-03,  ..., -4.4250e-03,\n",
       "          -2.0020e-02, -2.9312e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_k.lora_down.weight': tensor([[-4.0245e-03,  2.1912e-02, -3.2257e-02,  ..., -4.1733e-03,\n",
       "          -7.0839e-03, -5.5313e-03],\n",
       "         [-1.7380e-02,  3.7048e-02, -5.5194e-05,  ..., -1.9817e-03,\n",
       "          -1.1673e-02, -3.5339e-02],\n",
       "         [ 5.3368e-03, -2.1912e-02,  1.6327e-02,  ..., -4.3702e-04,\n",
       "          -1.0139e-02,  1.5717e-02],\n",
       "         ...,\n",
       "         [-2.8793e-02,  3.3752e-02, -2.7359e-02,  ...,  2.1500e-02,\n",
       "          -3.8910e-03, -2.3941e-02],\n",
       "         [-2.2491e-02,  3.0380e-02, -1.4854e-02,  ...,  1.1147e-02,\n",
       "           2.9175e-02, -4.4189e-02],\n",
       "         [-5.5275e-03,  2.4734e-02,  8.7280e-03,  ...,  5.4131e-03,\n",
       "           1.6052e-02, -4.1107e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_k.lora_up.weight': tensor([[ 0.0122, -0.0039, -0.0035,  ..., -0.0072, -0.0005, -0.0042],\n",
       "         [-0.0009,  0.0069, -0.0063,  ...,  0.0115,  0.0072,  0.0083],\n",
       "         [-0.0460, -0.0270,  0.0310,  ..., -0.0298, -0.0321, -0.0289],\n",
       "         ...,\n",
       "         [ 0.0092,  0.0106, -0.0192,  ...,  0.0357,  0.0238,  0.0175],\n",
       "         [-0.0151, -0.0133,  0.0051,  ..., -0.0133, -0.0084, -0.0084],\n",
       "         [-0.0011,  0.0080, -0.0079,  ...,  0.0139,  0.0116,  0.0110]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_out_0.lora_down.weight': tensor([[ 0.0219,  0.0119, -0.0148,  ...,  0.0293,  0.0150, -0.0096],\n",
       "         [ 0.0318, -0.0271,  0.0167,  ...,  0.0130,  0.0182, -0.0117],\n",
       "         [-0.0005, -0.0227, -0.0301,  ..., -0.0264,  0.0249,  0.0223],\n",
       "         ...,\n",
       "         [-0.0406,  0.0030, -0.0190,  ..., -0.0438,  0.0109,  0.0268],\n",
       "         [-0.0060, -0.0328,  0.0022,  ..., -0.0377,  0.0202,  0.0134],\n",
       "         [ 0.0321, -0.0185, -0.0045,  ...,  0.0089, -0.0060,  0.0184]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_out_0.lora_up.weight': tensor([[ 0.0054,  0.0087, -0.0041,  ..., -0.0005, -0.0049,  0.0204],\n",
       "         [-0.0010, -0.0029,  0.0071,  ...,  0.0126,  0.0017,  0.0035],\n",
       "         [-0.0086, -0.0053,  0.0121,  ...,  0.0170,  0.0081, -0.0099],\n",
       "         ...,\n",
       "         [ 0.0157, -0.0064, -0.0003,  ...,  0.0006, -0.0108, -0.0069],\n",
       "         [ 0.0069,  0.0050, -0.0071,  ..., -0.0024, -0.0079,  0.0002],\n",
       "         [ 0.0065, -0.0075, -0.0021,  ..., -0.0026, -0.0009,  0.0042]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_q.lora_down.weight': tensor([[-0.0320,  0.0133, -0.0181,  ...,  0.0088,  0.0180, -0.0225],\n",
       "         [-0.0104,  0.0218,  0.0275,  ...,  0.0310, -0.0018, -0.0060],\n",
       "         [-0.0399,  0.0035, -0.0027,  ...,  0.0170,  0.0055, -0.0198],\n",
       "         ...,\n",
       "         [ 0.0254, -0.0266,  0.0028,  ...,  0.0019, -0.0325, -0.0177],\n",
       "         [ 0.0201, -0.0185,  0.0194,  ..., -0.0208, -0.0119,  0.0298],\n",
       "         [-0.0116, -0.0229, -0.0172,  ..., -0.0180,  0.0080, -0.0197]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_q.lora_up.weight': tensor([[-5.7983e-04,  6.3820e-03, -3.7727e-03,  ..., -4.2462e-04,\n",
       "          -1.1024e-02, -4.5624e-03],\n",
       "         [ 3.6030e-03, -5.6458e-04, -1.5211e-03,  ..., -7.4081e-03,\n",
       "           1.1539e-03, -3.9177e-03],\n",
       "         [ 3.8743e-06, -6.2103e-03,  5.9242e-03,  ..., -1.4086e-03,\n",
       "           1.3252e-02,  2.8725e-03],\n",
       "         ...,\n",
       "         [ 1.8494e-02, -3.1464e-02, -7.8354e-03,  ..., -1.9608e-02,\n",
       "          -2.0828e-03,  2.9800e-02],\n",
       "         [-1.3870e-02,  2.9358e-02,  8.5144e-03,  ...,  2.1774e-02,\n",
       "           1.0414e-02, -2.8854e-02],\n",
       "         [ 6.3171e-03, -2.7008e-02, -1.5976e-02,  ..., -1.1719e-02,\n",
       "          -5.6801e-03,  2.3087e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_v.lora_down.weight': tensor([[ 8.3618e-03,  1.4122e-02, -8.0338e-03,  ..., -7.0429e-04,\n",
       "           1.2650e-02,  1.3390e-02],\n",
       "         [-1.0767e-03,  6.8550e-03,  1.3876e-03,  ..., -5.1880e-03,\n",
       "           1.6373e-02,  3.4424e-02],\n",
       "         [ 6.2027e-03, -1.7639e-02, -3.6180e-05,  ...,  1.5656e-02,\n",
       "           1.4901e-05,  4.6661e-02],\n",
       "         ...,\n",
       "         [-2.2629e-02, -2.6001e-02,  1.0361e-02,  ...,  9.4757e-03,\n",
       "           4.0016e-03, -1.3893e-02],\n",
       "         [-7.1287e-04, -1.8906e-02,  1.9623e-02,  ...,  2.5604e-02,\n",
       "           1.5289e-02,  5.5275e-03],\n",
       "         [-1.1436e-02,  1.2672e-02,  6.1188e-03,  ...,  1.2741e-02,\n",
       "          -9.6893e-04, -1.1024e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_attn2_to_v.lora_up.weight': tensor([[ 0.0064,  0.0080, -0.0049,  ...,  0.0056,  0.0072, -0.0010],\n",
       "         [-0.0253,  0.0082,  0.0246,  ..., -0.0162, -0.0267, -0.0035],\n",
       "         [ 0.0061, -0.0007, -0.0021,  ..., -0.0001,  0.0002,  0.0172],\n",
       "         ...,\n",
       "         [ 0.0082, -0.0215, -0.0216,  ...,  0.0176,  0.0095,  0.0104],\n",
       "         [ 0.0054,  0.0140,  0.0108,  ..., -0.0179,  0.0046, -0.0145],\n",
       "         [ 0.0129, -0.0138, -0.0164,  ...,  0.0057, -0.0046,  0.0181]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_0_proj.lora_down.weight': tensor([[ 6.5155e-03,  1.5228e-02,  3.1067e-02,  ...,  1.1726e-02,\n",
       "           2.2163e-03,  9.6130e-03],\n",
       "         [ 1.7776e-02, -2.3865e-02, -5.0812e-02,  ..., -8.8806e-03,\n",
       "          -8.0414e-03,  1.8463e-02],\n",
       "         [ 1.1396e-03,  1.7223e-03, -1.2466e-02,  ...,  2.4853e-03,\n",
       "          -2.5208e-02,  2.9404e-02],\n",
       "         ...,\n",
       "         [ 3.1052e-02,  3.8028e-05, -1.2596e-02,  ..., -3.7476e-02,\n",
       "          -8.2245e-03, -1.7532e-02],\n",
       "         [ 4.3869e-03, -1.3809e-02, -7.3013e-03,  ..., -4.2992e-03,\n",
       "           2.0737e-02, -2.4689e-02],\n",
       "         [-6.5956e-03,  1.0948e-03,  1.0590e-02,  ..., -1.3145e-02,\n",
       "           2.0462e-02,  2.1332e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_0_proj.lora_up.weight': tensor([[-0.0186, -0.0012, -0.0206,  ..., -0.0241,  0.0034,  0.0115],\n",
       "         [-0.0164, -0.0194,  0.0190,  ..., -0.0167, -0.0175,  0.0080],\n",
       "         [ 0.0105,  0.0006, -0.0343,  ...,  0.0090, -0.0495, -0.0136],\n",
       "         ...,\n",
       "         [-0.0137,  0.0431,  0.0171,  ..., -0.0047, -0.0251,  0.0064],\n",
       "         [ 0.0063,  0.0135,  0.0153,  ...,  0.0138,  0.0015, -0.0043],\n",
       "         [-0.0014, -0.0035,  0.0074,  ...,  0.0063,  0.0026,  0.0062]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_2.lora_down.weight': tensor([[ 3.3607e-03, -1.0384e-02, -3.3836e-03,  ..., -1.0529e-02,\n",
       "           9.0942e-03, -9.5749e-04],\n",
       "         [ 1.5610e-02, -1.3185e-04,  1.3916e-02,  ..., -1.7029e-02,\n",
       "           2.6413e-02,  1.4648e-02],\n",
       "         [ 1.1482e-02, -1.4801e-02, -1.6937e-03,  ...,  1.7456e-02,\n",
       "          -1.0880e-02,  3.6087e-03],\n",
       "         ...,\n",
       "         [-2.1576e-02,  5.7936e-05, -1.7715e-02,  ..., -5.1308e-03,\n",
       "          -1.8951e-02, -7.8659e-03],\n",
       "         [ 6.8283e-04,  3.1357e-03, -1.5656e-02,  ..., -1.1597e-02,\n",
       "          -2.7863e-02,  1.1223e-02],\n",
       "         [ 1.2222e-02,  5.6801e-03,  1.1955e-02,  ...,  5.9748e-04,\n",
       "          -2.2793e-03, -1.1513e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_2.lora_up.weight': tensor([[-0.0030, -0.0202, -0.0036,  ...,  0.0132,  0.0059, -0.0119],\n",
       "         [-0.0057,  0.0057,  0.0081,  ...,  0.0204,  0.0015,  0.0059],\n",
       "         [ 0.0199, -0.0134, -0.0233,  ...,  0.0291,  0.0248, -0.0291],\n",
       "         ...,\n",
       "         [-0.0109,  0.0241,  0.0035,  ..., -0.0088, -0.0148,  0.0262],\n",
       "         [-0.0052, -0.0034, -0.0019,  ..., -0.0104, -0.0075,  0.0016],\n",
       "         [-0.0128,  0.0014,  0.0216,  ...,  0.0003, -0.0180,  0.0101]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_k.lora_down.weight': tensor([[-0.0138,  0.0088,  0.0184,  ...,  0.0309, -0.0277,  0.0030],\n",
       "         [ 0.0425, -0.0054,  0.0090,  ..., -0.0162,  0.0251,  0.0121],\n",
       "         [-0.0088,  0.0193,  0.0086,  ...,  0.0080,  0.0402, -0.0031],\n",
       "         ...,\n",
       "         [ 0.0043, -0.0276, -0.0164,  ..., -0.0061, -0.0374, -0.0203],\n",
       "         [ 0.0048, -0.0331, -0.0100,  ...,  0.0211, -0.0167,  0.0064],\n",
       "         [ 0.0229, -0.0010, -0.0016,  ..., -0.0113,  0.0121,  0.0076]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_k.lora_up.weight': tensor([[ 0.0074, -0.0207, -0.0128,  ...,  0.0098,  0.0037,  0.0182],\n",
       "         [-0.0001, -0.0122, -0.0101,  ...,  0.0114, -0.0132, -0.0140],\n",
       "         [-0.0206, -0.0056,  0.0156,  ...,  0.0143, -0.0060, -0.0127],\n",
       "         ...,\n",
       "         [ 0.0025,  0.0056, -0.0037,  ..., -0.0089,  0.0163,  0.0162],\n",
       "         [ 0.0082, -0.0057, -0.0086,  ..., -0.0196, -0.0131, -0.0035],\n",
       "         [-0.0164,  0.0303,  0.0253,  ..., -0.0277,  0.0105, -0.0124]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_out_0.lora_down.weight': tensor([[ 0.0011,  0.0007, -0.0220,  ...,  0.0034, -0.0002, -0.0348],\n",
       "         [ 0.0197,  0.0421, -0.0084,  ..., -0.0038,  0.0233,  0.0084],\n",
       "         [-0.0083, -0.0315,  0.0197,  ...,  0.0014,  0.0087, -0.0009],\n",
       "         ...,\n",
       "         [-0.0166, -0.0287,  0.0021,  ...,  0.0297, -0.0416,  0.0333],\n",
       "         [ 0.0079, -0.0160,  0.0018,  ..., -0.0122,  0.0388, -0.0148],\n",
       "         [ 0.0099, -0.0078,  0.0006,  ...,  0.0268, -0.0326,  0.0058]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_out_0.lora_up.weight': tensor([[-0.0066,  0.0033,  0.0100,  ...,  0.0089, -0.0111,  0.0012],\n",
       "         [ 0.0065, -0.0105, -0.0021,  ..., -0.0118,  0.0015,  0.0034],\n",
       "         [ 0.0089,  0.0014, -0.0106,  ..., -0.0034,  0.0231, -0.0119],\n",
       "         ...,\n",
       "         [-0.0012,  0.0211,  0.0148,  ...,  0.0028, -0.0017,  0.0101],\n",
       "         [-0.0232,  0.0210,  0.0229,  ...,  0.0152, -0.0157,  0.0288],\n",
       "         [-0.0133, -0.0228,  0.0072,  ...,  0.0139, -0.0023,  0.0102]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_q.lora_down.weight': tensor([[ 0.0249, -0.0250,  0.0094,  ..., -0.0235, -0.0065,  0.0083],\n",
       "         [-0.0146,  0.0554,  0.0074,  ...,  0.0253,  0.0054, -0.0103],\n",
       "         [ 0.0020, -0.0135,  0.0014,  ...,  0.0060, -0.0146, -0.0282],\n",
       "         ...,\n",
       "         [ 0.0075,  0.0034, -0.0337,  ...,  0.0031, -0.0061,  0.0121],\n",
       "         [ 0.0064,  0.0030,  0.0172,  ..., -0.0195,  0.0176,  0.0315],\n",
       "         [ 0.0050, -0.0372,  0.0178,  ..., -0.0174,  0.0260, -0.0038]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_q.lora_up.weight': tensor([[ 0.0085, -0.0149,  0.0056,  ...,  0.0102, -0.0037,  0.0081],\n",
       "         [-0.0032,  0.0112, -0.0081,  ..., -0.0123,  0.0107, -0.0031],\n",
       "         [-0.0145, -0.0031,  0.0096,  ...,  0.0104, -0.0002,  0.0037],\n",
       "         ...,\n",
       "         [ 0.0080, -0.0150,  0.0128,  ...,  0.0082, -0.0168,  0.0220],\n",
       "         [ 0.0035, -0.0147, -0.0006,  ...,  0.0083, -0.0123,  0.0103],\n",
       "         [ 0.0007, -0.0026,  0.0007,  ...,  0.0025,  0.0018,  0.0077]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_v.lora_down.weight': tensor([[-1.3588e-02,  3.1738e-02, -9.2087e-03,  ..., -6.1111e-03,\n",
       "          -1.2436e-02, -5.1832e-04],\n",
       "         [-1.6647e-02,  1.1208e-02, -3.5553e-02,  ...,  1.2787e-02,\n",
       "           1.0468e-02,  3.0632e-03],\n",
       "         [ 3.2471e-02,  7.2861e-03,  2.1835e-02,  ...,  1.8250e-02,\n",
       "          -1.0366e-03,  1.1818e-02],\n",
       "         ...,\n",
       "         [ 2.7313e-02, -1.0841e-02,  1.7960e-02,  ..., -1.4553e-03,\n",
       "           2.7969e-02,  8.8334e-05],\n",
       "         [ 6.3553e-03, -2.6489e-02, -1.8356e-02,  ..., -9.6970e-03,\n",
       "           2.1362e-02, -2.2079e-02],\n",
       "         [-3.8116e-02, -5.0201e-03, -5.9738e-03,  ...,  1.7214e-04,\n",
       "          -3.1891e-02, -1.7181e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_v.lora_up.weight': tensor([[ 0.0151, -0.0135, -0.0128,  ..., -0.0132, -0.0206,  0.0024],\n",
       "         [-0.0164,  0.0094, -0.0094,  ...,  0.0122,  0.0185,  0.0025],\n",
       "         [-0.0070,  0.0049, -0.0041,  ...,  0.0044,  0.0328,  0.0209],\n",
       "         ...,\n",
       "         [-0.0045,  0.0082, -0.0085,  ...,  0.0060, -0.0013, -0.0259],\n",
       "         [-0.0029, -0.0034, -0.0088,  ...,  0.0034,  0.0048,  0.0165],\n",
       "         [-0.0095, -0.0039,  0.0151,  ...,  0.0021, -0.0176,  0.0139]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_k.lora_down.weight': tensor([[ 1.5945e-02,  5.1320e-05, -1.3603e-02,  ...,  4.7226e-03,\n",
       "          -2.6226e-03, -9.4528e-03],\n",
       "         [ 1.9241e-02,  5.8060e-03, -2.1988e-02,  ..., -5.2223e-03,\n",
       "          -9.2621e-03,  2.0850e-04],\n",
       "         [-5.1842e-03,  8.9493e-03,  2.7176e-02,  ..., -1.7807e-02,\n",
       "           2.6627e-02,  2.3282e-04],\n",
       "         ...,\n",
       "         [-2.2964e-03,  1.2230e-02, -4.3273e-04,  ..., -3.9795e-02,\n",
       "           7.7438e-03,  1.2360e-02],\n",
       "         [-1.5602e-02,  3.1281e-03, -1.2741e-02,  ..., -3.6865e-02,\n",
       "           1.1177e-02, -1.0132e-02],\n",
       "         [ 2.1801e-03,  4.6563e-04,  1.8494e-02,  ..., -5.4092e-03,\n",
       "           3.2825e-03,  9.9487e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_k.lora_up.weight': tensor([[-0.0102, -0.0162,  0.0107,  ...,  0.0127,  0.0115,  0.0076],\n",
       "         [-0.0136,  0.0041, -0.0025,  ...,  0.0121,  0.0173, -0.0104],\n",
       "         [-0.0133,  0.0094, -0.0147,  ..., -0.0087,  0.0006, -0.0098],\n",
       "         ...,\n",
       "         [-0.0047, -0.0011, -0.0006,  ..., -0.0013,  0.0025, -0.0036],\n",
       "         [-0.0061,  0.0120, -0.0338,  ..., -0.0166, -0.0025, -0.0077],\n",
       "         [ 0.0096, -0.0226,  0.0359,  ...,  0.0286,  0.0100,  0.0167]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_out_0.lora_down.weight': tensor([[-0.0392, -0.0163, -0.0255,  ..., -0.0100,  0.0230,  0.0095],\n",
       "         [-0.0220,  0.0171,  0.0130,  ...,  0.0063,  0.0209, -0.0098],\n",
       "         [-0.0300, -0.0120, -0.0100,  ...,  0.0259,  0.0142,  0.0069],\n",
       "         ...,\n",
       "         [ 0.0271,  0.0107,  0.0008,  ...,  0.0058, -0.0017,  0.0017],\n",
       "         [ 0.0124, -0.0177,  0.0246,  ...,  0.0112, -0.0340,  0.0093],\n",
       "         [ 0.0208,  0.0349, -0.0157,  ...,  0.0389, -0.0287,  0.0307]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_out_0.lora_up.weight': tensor([[-0.0103, -0.0060, -0.0096,  ...,  0.0153, -0.0013,  0.0118],\n",
       "         [-0.0070,  0.0064, -0.0062,  ..., -0.0004,  0.0018, -0.0036],\n",
       "         [-0.0022,  0.0132,  0.0047,  ...,  0.0231,  0.0048,  0.0054],\n",
       "         ...,\n",
       "         [ 0.0233,  0.0137,  0.0014,  ..., -0.0061,  0.0180,  0.0101],\n",
       "         [-0.0093,  0.0082, -0.0097,  ...,  0.0008, -0.0072,  0.0023],\n",
       "         [-0.0093,  0.0289,  0.0026,  ..., -0.0072, -0.0186, -0.0185]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_q.lora_down.weight': tensor([[-0.0058, -0.0228,  0.0010,  ..., -0.0391,  0.0089, -0.0115],\n",
       "         [ 0.0031,  0.0302, -0.0387,  ...,  0.0106,  0.0156,  0.0050],\n",
       "         [-0.0254, -0.0215,  0.0175,  ..., -0.0183, -0.0089, -0.0180],\n",
       "         ...,\n",
       "         [ 0.0016,  0.0055,  0.0163,  ...,  0.0109, -0.0333,  0.0429],\n",
       "         [-0.0176, -0.0103,  0.0150,  ..., -0.0248,  0.0201, -0.0363],\n",
       "         [ 0.0010,  0.0288,  0.0028,  ..., -0.0007,  0.0056,  0.0086]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_q.lora_up.weight': tensor([[-1.2718e-02, -4.8248e-02, -1.9894e-03,  ..., -1.2024e-02,\n",
       "          -1.6317e-03, -1.0315e-02],\n",
       "         [-3.1147e-03, -3.3169e-03, -2.2995e-02,  ...,  2.3651e-03,\n",
       "          -1.6479e-02, -6.3057e-03],\n",
       "         [ 4.4479e-03,  5.8479e-03,  2.1805e-02,  ..., -3.3684e-03,\n",
       "           1.6891e-02,  4.9667e-03],\n",
       "         ...,\n",
       "         [-1.1501e-03, -1.4961e-02, -2.6643e-05,  ...,  7.0152e-03,\n",
       "          -7.5836e-03,  2.5787e-03],\n",
       "         [-8.9569e-03,  8.4076e-03,  3.0231e-03,  ..., -1.8051e-02,\n",
       "           2.3758e-02,  7.5874e-03],\n",
       "         [ 1.8066e-02,  2.1484e-02, -8.8120e-03,  ...,  1.8005e-02,\n",
       "          -2.7328e-02, -2.0859e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_v.lora_down.weight': tensor([[ 0.0037,  0.0060, -0.0259,  ...,  0.0055, -0.0163, -0.0259],\n",
       "         [-0.0104, -0.0091, -0.0114,  ...,  0.0280,  0.0112, -0.0142],\n",
       "         [-0.0097,  0.0055, -0.0209,  ...,  0.0061, -0.0134,  0.0178],\n",
       "         ...,\n",
       "         [-0.0228,  0.0010,  0.0101,  ...,  0.0110,  0.0195,  0.0189],\n",
       "         [-0.0025, -0.0022,  0.0270,  ..., -0.0149,  0.0238,  0.0153],\n",
       "         [ 0.0133, -0.0018,  0.0151,  ..., -0.0018,  0.0143,  0.0446]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_attn2_to_v.lora_up.weight': tensor([[-0.0096,  0.0089,  0.0064,  ...,  0.0103,  0.0097,  0.0093],\n",
       "         [-0.0173, -0.0059,  0.0093,  ...,  0.0172,  0.0174,  0.0160],\n",
       "         [ 0.0058, -0.0096,  0.0004,  ..., -0.0068, -0.0056, -0.0052],\n",
       "         ...,\n",
       "         [ 0.0177, -0.0221,  0.0049,  ..., -0.0175, -0.0183, -0.0177],\n",
       "         [ 0.0109, -0.0227,  0.0089,  ..., -0.0156, -0.0113, -0.0110],\n",
       "         [-0.0042,  0.0223, -0.0034,  ...,  0.0048,  0.0041,  0.0042]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_0_proj.lora_down.weight': tensor([[-0.0053,  0.0132, -0.0045,  ...,  0.0029,  0.0102,  0.0255],\n",
       "         [-0.0058, -0.0010, -0.0369,  ..., -0.0024, -0.0318,  0.0291],\n",
       "         [-0.0035, -0.0296,  0.0182,  ...,  0.0230, -0.0021,  0.0093],\n",
       "         ...,\n",
       "         [-0.0065, -0.0307,  0.0330,  ..., -0.0249, -0.0007,  0.0006],\n",
       "         [ 0.0225, -0.0189,  0.0193,  ...,  0.0026, -0.0224, -0.0114],\n",
       "         [-0.0012, -0.0209,  0.0040,  ...,  0.0317,  0.0251, -0.0108]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_0_proj.lora_up.weight': tensor([[-0.0038,  0.0011, -0.0192,  ..., -0.0029,  0.0028,  0.0084],\n",
       "         [-0.0284,  0.0095, -0.0023,  ..., -0.0032,  0.0009,  0.0252],\n",
       "         [ 0.0087, -0.0094,  0.0325,  ...,  0.0089, -0.0018,  0.0035],\n",
       "         ...,\n",
       "         [ 0.0145,  0.0161, -0.0266,  ..., -0.0126, -0.0281, -0.0146],\n",
       "         [-0.0142,  0.0171, -0.0126,  ..., -0.0143, -0.0160, -0.0007],\n",
       "         [ 0.0102,  0.0038, -0.0156,  ..., -0.0165, -0.0017, -0.0164]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_2.lora_down.weight': tensor([[-4.6730e-03, -2.9388e-02, -2.5253e-02,  ..., -5.5075e-05,\n",
       "          -3.1052e-03, -2.5452e-02],\n",
       "         [-1.5427e-02, -3.7231e-02, -7.1068e-03,  ..., -3.5834e-04,\n",
       "          -8.6060e-03, -2.5192e-02],\n",
       "         [-1.6388e-02, -1.7700e-02, -1.4267e-02,  ...,  1.0544e-02,\n",
       "           4.6806e-03, -1.1826e-02],\n",
       "         ...,\n",
       "         [-1.9470e-02, -4.3884e-02,  2.3300e-02,  ..., -6.3286e-03,\n",
       "           9.5215e-03,  3.3417e-02],\n",
       "         [ 1.4587e-02,  2.3102e-02,  2.4750e-02,  ...,  1.6022e-02,\n",
       "          -8.0566e-03,  1.7258e-02],\n",
       "         [ 7.2289e-03, -3.6407e-02,  1.2138e-02,  ..., -1.2474e-02,\n",
       "          -6.2323e-04, -3.4546e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_2.lora_up.weight': tensor([[ 0.0024, -0.0026,  0.0056,  ..., -0.0055, -0.0077, -0.0173],\n",
       "         [ 0.0078,  0.0050,  0.0096,  ..., -0.0080, -0.0028, -0.0040],\n",
       "         [-0.0254, -0.0365, -0.0238,  ...,  0.0128,  0.0303, -0.0258],\n",
       "         ...,\n",
       "         [ 0.0174,  0.0126,  0.0215,  ...,  0.0045, -0.0206, -0.0008],\n",
       "         [ 0.0131,  0.0107,  0.0124,  ..., -0.0010, -0.0085,  0.0005],\n",
       "         [ 0.0067,  0.0150,  0.0030,  ...,  0.0002, -0.0051,  0.0127]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_k.lora_down.weight': tensor([[ 0.0172,  0.0064, -0.0150,  ..., -0.0113,  0.0185, -0.0122],\n",
       "         [ 0.0036, -0.0141, -0.0121,  ..., -0.0163, -0.0183,  0.0032],\n",
       "         [ 0.0254,  0.0230, -0.0162,  ..., -0.0514,  0.0033,  0.0554],\n",
       "         ...,\n",
       "         [-0.0133, -0.0331,  0.0199,  ..., -0.0151,  0.0092, -0.0215],\n",
       "         [-0.0086,  0.0081,  0.0163,  ...,  0.0295,  0.0017, -0.0139],\n",
       "         [ 0.0232,  0.0034, -0.0178,  ..., -0.0030,  0.0097,  0.0052]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_k.lora_up.weight': tensor([[-1.5839e-02, -6.6948e-03, -1.9730e-02,  ...,  2.5578e-03,\n",
       "           9.6359e-03,  8.3847e-03],\n",
       "         [ 1.9150e-02,  1.8997e-02,  1.8951e-02,  ...,  1.5497e-03,\n",
       "          -2.8091e-02, -1.9348e-02],\n",
       "         [-2.4548e-03, -1.2680e-02, -3.4760e-02,  ...,  1.5373e-02,\n",
       "           1.5900e-02,  4.3121e-02],\n",
       "         ...,\n",
       "         [-8.2016e-03, -2.0615e-02, -1.1116e-02,  ...,  7.1983e-03,\n",
       "           2.6798e-03,  9.3002e-03],\n",
       "         [-8.0338e-03,  1.3741e-02, -1.1017e-02,  ..., -1.7502e-02,\n",
       "           4.9477e-03, -2.3956e-02],\n",
       "         [ 2.6642e-02, -3.3112e-02,  7.9498e-03,  ..., -1.6613e-03,\n",
       "          -6.9737e-05,  1.5656e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_out_0.lora_down.weight': tensor([[ 0.0112, -0.0104,  0.0161,  ...,  0.0168, -0.0157,  0.0346],\n",
       "         [ 0.0002, -0.0030, -0.0007,  ...,  0.0169, -0.0131,  0.0081],\n",
       "         [ 0.0063, -0.0264,  0.0128,  ..., -0.0535,  0.0053,  0.0172],\n",
       "         ...,\n",
       "         [ 0.0482,  0.0088,  0.0008,  ...,  0.0247, -0.0102, -0.0183],\n",
       "         [ 0.0146, -0.0451, -0.0070,  ...,  0.0272,  0.0041, -0.0263],\n",
       "         [ 0.0107,  0.0040, -0.0217,  ...,  0.0240,  0.0262,  0.0028]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_out_0.lora_up.weight': tensor([[-0.0249, -0.0130, -0.0051,  ...,  0.0131,  0.0161, -0.0107],\n",
       "         [ 0.0018,  0.0026,  0.0342,  ..., -0.0117,  0.0021,  0.0119],\n",
       "         [ 0.0255,  0.0351,  0.0135,  ..., -0.0280, -0.0210,  0.0255],\n",
       "         ...,\n",
       "         [ 0.0025, -0.0107, -0.0204,  ...,  0.0219,  0.0072, -0.0023],\n",
       "         [-0.0034, -0.0046, -0.0119,  ...,  0.0110,  0.0088, -0.0031],\n",
       "         [-0.0147, -0.0127, -0.0049,  ..., -0.0064,  0.0240, -0.0103]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_q.lora_down.weight': tensor([[-0.0077,  0.0127, -0.0434,  ...,  0.0333, -0.0149, -0.0308],\n",
       "         [ 0.0206,  0.0075, -0.0050,  ..., -0.0034, -0.0142, -0.0261],\n",
       "         [ 0.0337,  0.0286, -0.0140,  ..., -0.0017,  0.0189,  0.0041],\n",
       "         ...,\n",
       "         [ 0.0047, -0.0477,  0.0203,  ..., -0.0152, -0.0216,  0.0023],\n",
       "         [ 0.0507,  0.0308,  0.0211,  ...,  0.0275,  0.0360, -0.0353],\n",
       "         [ 0.0164,  0.0609, -0.0002,  ...,  0.0663, -0.0200, -0.0220]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_q.lora_up.weight': tensor([[-5.6028e-04,  1.4696e-03,  6.5079e-03,  ..., -5.9891e-03,\n",
       "          -7.5150e-03, -1.5020e-05],\n",
       "         [ 1.9119e-02, -1.5039e-03, -1.1528e-02,  ...,  1.6769e-02,\n",
       "          -2.7924e-02,  7.4081e-03],\n",
       "         [ 7.5684e-03,  2.1606e-02, -5.6992e-03,  ...,  8.6899e-03,\n",
       "           8.9722e-03, -1.6830e-02],\n",
       "         ...,\n",
       "         [-4.3411e-03, -6.4735e-03,  1.8463e-02,  ..., -7.6828e-03,\n",
       "          -3.4962e-03,  1.1200e-02],\n",
       "         [-7.5836e-03, -3.4847e-03,  1.0124e-02,  ..., -5.7449e-03,\n",
       "           1.0696e-02,  1.1452e-02],\n",
       "         [ 2.6047e-02,  1.3664e-02,  9.8801e-03,  ..., -6.3057e-03,\n",
       "           1.3588e-02,  2.1271e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_v.lora_down.weight': tensor([[-4.5929e-03, -2.0660e-02, -2.8286e-03,  ...,  7.4883e-03,\n",
       "          -1.3908e-02,  2.2400e-02],\n",
       "         [ 1.3512e-02, -1.6037e-02,  2.2812e-03,  ...,  3.2013e-02,\n",
       "          -1.1002e-02,  9.3231e-03],\n",
       "         [ 3.0106e-02,  1.0124e-02,  3.8788e-02,  ...,  2.0676e-02,\n",
       "          -2.5406e-03,  2.8946e-02],\n",
       "         ...,\n",
       "         [-7.2098e-03,  2.6584e-05, -1.4221e-02,  ..., -3.1525e-02,\n",
       "           9.9373e-04,  1.5495e-02],\n",
       "         [-6.2485e-03, -5.9547e-03, -2.4078e-02,  ..., -2.3285e-02,\n",
       "          -6.7596e-03,  1.0395e-03],\n",
       "         [ 1.3748e-02, -2.0050e-02,  1.4160e-02,  ..., -7.0839e-03,\n",
       "           5.8289e-03,  2.5360e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_v.lora_up.weight': tensor([[ 0.0156,  0.0279,  0.0210,  ..., -0.0113,  0.0050,  0.0169],\n",
       "         [-0.0457, -0.0322, -0.0289,  ...,  0.0414,  0.0219, -0.0284],\n",
       "         [-0.0178, -0.0259, -0.0016,  ...,  0.0067, -0.0076, -0.0081],\n",
       "         ...,\n",
       "         [-0.0006,  0.0241, -0.0083,  ...,  0.0095,  0.0146, -0.0017],\n",
       "         [ 0.0069, -0.0040, -0.0044,  ..., -0.0079, -0.0043,  0.0009],\n",
       "         [-0.0240, -0.0202, -0.0154,  ...,  0.0377,  0.0350, -0.0311]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_k.lora_down.weight': tensor([[-0.0037,  0.0195, -0.0007,  ...,  0.0071, -0.0006,  0.0137],\n",
       "         [-0.0402, -0.0042, -0.0084,  ..., -0.0298,  0.0019, -0.0333],\n",
       "         [ 0.0268,  0.0134, -0.0286,  ...,  0.0199, -0.0185,  0.0122],\n",
       "         ...,\n",
       "         [ 0.0192, -0.0009,  0.0092,  ...,  0.0216, -0.0054,  0.0176],\n",
       "         [ 0.0147,  0.0209,  0.0147,  ...,  0.0141, -0.0151, -0.0152],\n",
       "         [-0.0026,  0.0041,  0.0146,  ...,  0.0061,  0.0222,  0.0058]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_k.lora_up.weight': tensor([[-0.0038,  0.0037,  0.0083,  ..., -0.0012, -0.0123,  0.0113],\n",
       "         [-0.0153,  0.0110,  0.0113,  ..., -0.0062, -0.0207,  0.0142],\n",
       "         [ 0.0041, -0.0116,  0.0145,  ...,  0.0098, -0.0103,  0.0121],\n",
       "         ...,\n",
       "         [ 0.0014, -0.0057,  0.0107,  ...,  0.0022, -0.0080,  0.0068],\n",
       "         [ 0.0124,  0.0013, -0.0042,  ..., -0.0016,  0.0131, -0.0163],\n",
       "         [ 0.0038, -0.0092,  0.0032,  ...,  0.0003, -0.0014, -0.0033]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_out_0.lora_down.weight': tensor([[-0.0081, -0.0069, -0.0047,  ..., -0.0281, -0.0170,  0.0006],\n",
       "         [-0.0387, -0.0192, -0.0014,  ..., -0.0016,  0.0151, -0.0006],\n",
       "         [-0.0183, -0.0020, -0.0033,  ..., -0.0263, -0.0175, -0.0288],\n",
       "         ...,\n",
       "         [ 0.0128,  0.0174, -0.0004,  ..., -0.0028, -0.0079,  0.0169],\n",
       "         [-0.0195, -0.0083, -0.0171,  ..., -0.0061,  0.0158,  0.0011],\n",
       "         [-0.0080,  0.0039,  0.0011,  ...,  0.0200,  0.0118, -0.0202]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_out_0.lora_up.weight': tensor([[ 0.0211, -0.0190, -0.0117,  ...,  0.0127, -0.0138,  0.0206],\n",
       "         [-0.0022,  0.0063,  0.0021,  ..., -0.0006,  0.0077, -0.0092],\n",
       "         [-0.0079,  0.0169,  0.0064,  ...,  0.0177,  0.0162, -0.0225],\n",
       "         ...,\n",
       "         [-0.0014, -0.0093,  0.0128,  ..., -0.0058, -0.0140,  0.0066],\n",
       "         [ 0.0073,  0.0071,  0.0026,  ..., -0.0045, -0.0013, -0.0049],\n",
       "         [ 0.0018, -0.0068, -0.0057,  ..., -0.0016,  0.0113, -0.0047]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_q.lora_down.weight': tensor([[-3.4546e-02, -5.0735e-03, -4.4312e-02,  ...,  1.2344e-02,\n",
       "           6.3801e-04,  9.1934e-03],\n",
       "         [ 3.8788e-02,  4.0649e-02,  1.3985e-02,  ..., -8.2493e-05,\n",
       "           4.8889e-02, -5.0903e-02],\n",
       "         [ 4.0375e-02, -5.2872e-03,  2.3537e-03,  ..., -5.8517e-03,\n",
       "          -1.1818e-02, -5.6274e-02],\n",
       "         ...,\n",
       "         [ 2.2163e-03, -3.7140e-02,  3.6926e-03,  ...,  1.6434e-02,\n",
       "           3.8204e-03,  1.3977e-02],\n",
       "         [ 3.1250e-02,  2.1439e-02,  2.0508e-02,  ...,  7.0877e-03,\n",
       "          -1.2169e-02, -4.9896e-02],\n",
       "         [ 2.6459e-02, -7.5951e-03, -2.5539e-03,  ...,  3.9856e-02,\n",
       "          -1.5656e-02,  2.1027e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_q.lora_up.weight': tensor([[ 0.0107, -0.0110, -0.0155,  ...,  0.0136, -0.0100, -0.0107],\n",
       "         [ 0.0079, -0.0097, -0.0120,  ...,  0.0124, -0.0068, -0.0121],\n",
       "         [-0.0132,  0.0147,  0.0259,  ..., -0.0234,  0.0221,  0.0128],\n",
       "         ...,\n",
       "         [ 0.0261,  0.0013, -0.0135,  ...,  0.0282, -0.0181, -0.0007],\n",
       "         [ 0.0194,  0.0078,  0.0015,  ...,  0.0150, -0.0016,  0.0103],\n",
       "         [-0.0103,  0.0183,  0.0238,  ..., -0.0251,  0.0298,  0.0188]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_v.lora_down.weight': tensor([[-0.0134, -0.0209, -0.0110,  ...,  0.0024,  0.0154, -0.0279],\n",
       "         [ 0.0089,  0.0026, -0.0027,  ...,  0.0041, -0.0189, -0.0240],\n",
       "         [-0.0037, -0.0067,  0.0183,  ...,  0.0154, -0.0071,  0.0129],\n",
       "         ...,\n",
       "         [ 0.0167, -0.0141,  0.0072,  ..., -0.0059,  0.0166,  0.0159],\n",
       "         [-0.0086, -0.0050, -0.0106,  ...,  0.0258, -0.0034, -0.0029],\n",
       "         [-0.0089,  0.0098, -0.0004,  ..., -0.0249, -0.0115, -0.0076]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_attn2_to_v.lora_up.weight': tensor([[-0.0123,  0.0026, -0.0022,  ...,  0.0151,  0.0129, -0.0059],\n",
       "         [ 0.0155,  0.0037,  0.0015,  ..., -0.0116,  0.0011,  0.0026],\n",
       "         [-0.0120, -0.0160,  0.0131,  ..., -0.0383,  0.0170,  0.0044],\n",
       "         ...,\n",
       "         [ 0.0159,  0.0113,  0.0161,  ...,  0.0017, -0.0207,  0.0282],\n",
       "         [-0.0093,  0.0068,  0.0070,  ...,  0.0152, -0.0046,  0.0056],\n",
       "         [-0.0283, -0.0227, -0.0317,  ..., -0.0054,  0.0220, -0.0440]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_0_proj.lora_down.weight': tensor([[-0.0168,  0.0103,  0.0206,  ...,  0.0161,  0.0302,  0.0368],\n",
       "         [ 0.0378,  0.0126, -0.0284,  ..., -0.0119,  0.0453, -0.0024],\n",
       "         [-0.0145, -0.0120,  0.0071,  ...,  0.0447, -0.0152,  0.0233],\n",
       "         ...,\n",
       "         [-0.0104,  0.0181, -0.0549,  ...,  0.0269, -0.0279, -0.0170],\n",
       "         [-0.0029, -0.0368,  0.0224,  ..., -0.0130, -0.0193,  0.0250],\n",
       "         [-0.0027, -0.0228, -0.0125,  ..., -0.0131, -0.0267,  0.0113]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_0_proj.lora_up.weight': tensor([[-0.0053,  0.0195,  0.0009,  ...,  0.0143, -0.0050,  0.0059],\n",
       "         [ 0.0282, -0.0057,  0.0289,  ..., -0.0367,  0.0077, -0.0293],\n",
       "         [-0.0022, -0.0359, -0.0527,  ..., -0.0178,  0.0198,  0.0024],\n",
       "         ...,\n",
       "         [ 0.0167, -0.0056,  0.0005,  ...,  0.0220, -0.0173, -0.0110],\n",
       "         [-0.0172, -0.0103, -0.0177,  ...,  0.0202, -0.0005,  0.0089],\n",
       "         [ 0.0125,  0.0245, -0.0179,  ...,  0.0132, -0.0386, -0.0046]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_2.lora_down.weight': tensor([[-0.0191,  0.0028,  0.0054,  ..., -0.0237, -0.0100, -0.0164],\n",
       "         [-0.0052, -0.0008, -0.0359,  ..., -0.0047, -0.0014,  0.0134],\n",
       "         [-0.0152, -0.0178, -0.0022,  ...,  0.0193, -0.0065,  0.0072],\n",
       "         ...,\n",
       "         [-0.0322,  0.0111,  0.0229,  ..., -0.0344,  0.0161, -0.0004],\n",
       "         [ 0.0296,  0.0021,  0.0309,  ..., -0.0045,  0.0005, -0.0099],\n",
       "         [ 0.0250,  0.0113,  0.0087,  ...,  0.0278,  0.0055, -0.0174]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_2.lora_up.weight': tensor([[-0.0114,  0.0037, -0.0028,  ...,  0.0095,  0.0043, -0.0040],\n",
       "         [-0.0083,  0.0059,  0.0031,  ...,  0.0060,  0.0141,  0.0074],\n",
       "         [ 0.0143,  0.0307, -0.0340,  ...,  0.0102, -0.0099, -0.0164],\n",
       "         ...,\n",
       "         [ 0.0100,  0.0011,  0.0166,  ..., -0.0103,  0.0066,  0.0039],\n",
       "         [-0.0182, -0.0169,  0.0095,  ..., -0.0045,  0.0102,  0.0134],\n",
       "         [-0.0139, -0.0168,  0.0304,  ...,  0.0004,  0.0176,  0.0245]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_k.lora_down.weight': tensor([[-0.0072, -0.0453,  0.0150,  ..., -0.0511,  0.0068, -0.0229],\n",
       "         [-0.0349,  0.0147,  0.0220,  ..., -0.0209,  0.0192,  0.0363],\n",
       "         [ 0.0342, -0.0293, -0.0061,  ...,  0.0349, -0.0217, -0.0431],\n",
       "         ...,\n",
       "         [ 0.0080, -0.0256,  0.0155,  ..., -0.0141,  0.0017,  0.0339],\n",
       "         [-0.0050,  0.0095,  0.0123,  ...,  0.0182,  0.0058, -0.0374],\n",
       "         [-0.0150, -0.0228, -0.0283,  ..., -0.0164, -0.0123, -0.0252]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_k.lora_up.weight': tensor([[-0.0296,  0.0125, -0.0213,  ...,  0.0074, -0.0087, -0.0156],\n",
       "         [-0.0012, -0.0007, -0.0140,  ..., -0.0166, -0.0125, -0.0142],\n",
       "         [-0.0206,  0.0054, -0.0418,  ..., -0.0040, -0.0161, -0.0235],\n",
       "         ...,\n",
       "         [-0.0358, -0.0096, -0.0053,  ..., -0.0273,  0.0010,  0.0156],\n",
       "         [ 0.0149, -0.0234,  0.0198,  ..., -0.0220,  0.0105, -0.0026],\n",
       "         [-0.0160,  0.0147,  0.0167,  ...,  0.0130, -0.0072,  0.0048]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_out_0.lora_down.weight': tensor([[-0.0077, -0.0022,  0.0038,  ...,  0.0215, -0.0061,  0.0008],\n",
       "         [-0.0136, -0.0265, -0.0187,  ..., -0.0095, -0.0072, -0.0060],\n",
       "         [-0.0378,  0.0067,  0.0219,  ..., -0.0306,  0.0006, -0.0457],\n",
       "         ...,\n",
       "         [ 0.0348,  0.0066, -0.0185,  ...,  0.0166, -0.0072,  0.0458],\n",
       "         [ 0.0249, -0.0182, -0.0306,  ...,  0.0318,  0.0124,  0.0309],\n",
       "         [ 0.0205,  0.0120,  0.0017,  ...,  0.0106, -0.0118,  0.0047]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_out_0.lora_up.weight': tensor([[-0.0051, -0.0202,  0.0118,  ...,  0.0035, -0.0073, -0.0069],\n",
       "         [ 0.0049, -0.0108,  0.0116,  ..., -0.0004, -0.0038,  0.0004],\n",
       "         [ 0.0240,  0.0033,  0.0214,  ...,  0.0171,  0.0103,  0.0140],\n",
       "         ...,\n",
       "         [ 0.0005, -0.0286,  0.0249,  ...,  0.0106, -0.0251,  0.0046],\n",
       "         [-0.0129, -0.0070,  0.0208,  ..., -0.0105,  0.0030, -0.0136],\n",
       "         [-0.0143,  0.0355, -0.0224,  ..., -0.0250, -0.0084, -0.0109]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_q.lora_down.weight': tensor([[ 0.0086, -0.0325,  0.0296,  ...,  0.0064, -0.0151,  0.0166],\n",
       "         [ 0.0450,  0.0038, -0.0170,  ..., -0.0074, -0.0389,  0.0015],\n",
       "         [-0.0419,  0.0170, -0.0013,  ..., -0.0187, -0.0019, -0.0091],\n",
       "         ...,\n",
       "         [-0.0022, -0.0121,  0.0170,  ..., -0.0025,  0.0405,  0.0320],\n",
       "         [ 0.0293,  0.0046, -0.0129,  ...,  0.0082, -0.0464, -0.0231],\n",
       "         [-0.0032, -0.0339, -0.0150,  ..., -0.0043,  0.0014, -0.0262]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_q.lora_up.weight': tensor([[ 2.7344e-02,  1.6937e-02,  1.5762e-02,  ..., -9.8705e-04,\n",
       "           1.7746e-02, -9.2163e-03],\n",
       "         [-1.0727e-02, -1.0887e-02, -1.5038e-02,  ...,  1.1200e-02,\n",
       "          -5.3749e-03,  1.1803e-02],\n",
       "         [ 1.0635e-02,  6.4316e-03, -8.9264e-03,  ...,  1.5320e-02,\n",
       "           6.6566e-03, -4.6043e-03],\n",
       "         ...,\n",
       "         [-1.9623e-02, -1.3184e-02, -5.7297e-03,  ..., -2.0844e-02,\n",
       "           7.7896e-03,  3.2043e-02],\n",
       "         [-3.4119e-02, -1.4244e-02, -7.1144e-03,  ..., -1.3237e-02,\n",
       "          -7.2479e-05,  1.8448e-02],\n",
       "         [-1.0750e-02,  3.0174e-03,  8.2321e-03,  ..., -3.2166e-02,\n",
       "           5.2681e-03,  1.0803e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_v.lora_down.weight': tensor([[ 0.0185,  0.0059, -0.0392,  ...,  0.0143, -0.0168, -0.0421],\n",
       "         [ 0.0097,  0.0121,  0.0289,  ...,  0.0208,  0.0238, -0.0190],\n",
       "         [ 0.0024,  0.0028,  0.0062,  ...,  0.0042, -0.0311,  0.0090],\n",
       "         ...,\n",
       "         [-0.0033, -0.0111,  0.0084,  ..., -0.0139, -0.0389, -0.0224],\n",
       "         [ 0.0311, -0.0059, -0.0341,  ...,  0.0066, -0.0078,  0.0031],\n",
       "         [ 0.0154, -0.0069, -0.0078,  ..., -0.0459, -0.0179,  0.0277]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_v.lora_up.weight': tensor([[ 0.0085, -0.0079, -0.0129,  ...,  0.0040, -0.0080, -0.0103],\n",
       "         [-0.0222, -0.0126,  0.0312,  ...,  0.0397, -0.0428,  0.0072],\n",
       "         [ 0.0170,  0.0129, -0.0056,  ..., -0.0303,  0.0161, -0.0059],\n",
       "         ...,\n",
       "         [ 0.0044,  0.0008, -0.0115,  ..., -0.0073, -0.0146,  0.0056],\n",
       "         [-0.0338,  0.0033,  0.0160,  ...,  0.0044, -0.0093, -0.0009],\n",
       "         [ 0.0014, -0.0032,  0.0112,  ..., -0.0038,  0.0113, -0.0146]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_k.lora_down.weight': tensor([[-0.0421,  0.0054,  0.0302,  ..., -0.0282, -0.0025, -0.0040],\n",
       "         [-0.0073, -0.0132,  0.0332,  ...,  0.0005,  0.0020,  0.0252],\n",
       "         [-0.0167, -0.0035,  0.0066,  ..., -0.0318,  0.0058, -0.0091],\n",
       "         ...,\n",
       "         [ 0.0065, -0.0038,  0.0255,  ..., -0.0034, -0.0210,  0.0016],\n",
       "         [-0.0123, -0.0048,  0.0297,  ..., -0.0034,  0.0092,  0.0133],\n",
       "         [ 0.0025,  0.0032,  0.0333,  ..., -0.0121, -0.0227,  0.0233]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_k.lora_up.weight': tensor([[ 8.1863e-03, -2.3937e-04,  5.0659e-03,  ...,  6.6795e-03,\n",
       "           3.1185e-03,  2.4529e-03],\n",
       "         [ 7.4506e-05, -1.5533e-04,  7.6828e-03,  ...,  1.1383e-02,\n",
       "           6.9275e-03,  1.0277e-02],\n",
       "         [-7.0953e-03, -1.9806e-02, -1.2306e-02,  ..., -1.5900e-02,\n",
       "          -1.8463e-02, -1.3985e-02],\n",
       "         ...,\n",
       "         [-1.6479e-02, -2.2095e-02, -2.3331e-02,  ..., -1.2856e-02,\n",
       "          -1.4641e-02, -2.0569e-02],\n",
       "         [ 1.5961e-02,  1.3618e-02,  1.8906e-02,  ...,  1.0895e-02,\n",
       "           1.2268e-02,  1.7410e-02],\n",
       "         [ 5.9509e-03,  3.1528e-03,  4.7607e-03,  ...,  8.2245e-03,\n",
       "           7.5226e-03,  5.3101e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_out_0.lora_down.weight': tensor([[-0.0222, -0.0132, -0.0031,  ...,  0.0044,  0.0124, -0.0011],\n",
       "         [-0.0035, -0.0009,  0.0284,  ...,  0.0198, -0.0018,  0.0240],\n",
       "         [-0.0253,  0.0050,  0.0321,  ..., -0.0136, -0.0047, -0.0141],\n",
       "         ...,\n",
       "         [-0.0180, -0.0220,  0.0123,  ..., -0.0006,  0.0121, -0.0012],\n",
       "         [-0.0129, -0.0091, -0.0210,  ...,  0.0148, -0.0049,  0.0094],\n",
       "         [-0.0434, -0.0363,  0.0258,  ..., -0.0346,  0.0207,  0.0030]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_out_0.lora_up.weight': tensor([[ 1.4153e-02,  1.6647e-02, -2.7084e-02,  ..., -1.2222e-02,\n",
       "           8.5907e-03, -2.5848e-02],\n",
       "         [ 2.1553e-03, -7.7896e-03, -1.1604e-02,  ..., -6.4392e-03,\n",
       "           7.3700e-03, -9.9640e-03],\n",
       "         [-1.2917e-02,  1.6052e-02,  1.3611e-02,  ...,  1.7532e-02,\n",
       "          -5.1308e-03,  1.4198e-02],\n",
       "         ...,\n",
       "         [ 8.2932e-03, -5.7716e-03, -6.2981e-03,  ...,  5.0507e-03,\n",
       "           1.2039e-02, -8.4305e-03],\n",
       "         [ 3.3169e-03,  3.0079e-03, -1.4565e-02,  ..., -6.1035e-03,\n",
       "          -8.8730e-03, -9.7656e-03],\n",
       "         [ 7.0496e-03, -8.3771e-03, -5.4054e-03,  ...,  8.0719e-03,\n",
       "           5.3253e-03,  4.8280e-06]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_q.lora_down.weight': tensor([[ 0.0140,  0.0076,  0.0038,  ..., -0.0034, -0.0174, -0.0105],\n",
       "         [-0.0116,  0.0123, -0.0314,  ..., -0.0186, -0.0083, -0.0318],\n",
       "         [ 0.0129,  0.0017,  0.0176,  ..., -0.0303,  0.0321,  0.0117],\n",
       "         ...,\n",
       "         [ 0.0025,  0.0236, -0.0155,  ..., -0.0200, -0.0026,  0.0163],\n",
       "         [ 0.0073, -0.0111,  0.0190,  ...,  0.0017,  0.0228, -0.0014],\n",
       "         [-0.0298,  0.0399, -0.0217,  ..., -0.0353, -0.0240, -0.0014]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_q.lora_up.weight': tensor([[-0.0007,  0.0005, -0.0080,  ..., -0.0040, -0.0071, -0.0018],\n",
       "         [-0.0024,  0.0082,  0.0122,  ..., -0.0044,  0.0140,  0.0053],\n",
       "         [-0.0014,  0.0094,  0.0041,  ..., -0.0122,  0.0099,  0.0041],\n",
       "         ...,\n",
       "         [ 0.0105, -0.0214, -0.0047,  ..., -0.0130, -0.0053, -0.0223],\n",
       "         [-0.0058,  0.0071, -0.0036,  ..., -0.0029,  0.0112, -0.0010],\n",
       "         [ 0.0135, -0.0284, -0.0098,  ..., -0.0252,  0.0009, -0.0356]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_v.lora_down.weight': tensor([[-1.7105e-02,  6.0654e-03,  2.8968e-05,  ..., -3.1708e-02,\n",
       "           1.9073e-02,  2.9282e-02],\n",
       "         [-4.8485e-03, -1.7853e-02, -1.7710e-03,  ...,  2.0180e-03,\n",
       "          -5.7983e-03, -9.4147e-03],\n",
       "         [-3.6297e-03, -1.7334e-02, -1.0681e-02,  ..., -5.6419e-03,\n",
       "           1.7881e-03,  4.4403e-02],\n",
       "         ...,\n",
       "         [ 1.1604e-02,  2.1713e-02,  5.3139e-03,  ..., -1.1162e-02,\n",
       "          -1.3573e-02,  1.4473e-02],\n",
       "         [ 1.1490e-02,  1.5640e-02, -2.2873e-02,  ..., -2.4681e-03,\n",
       "           1.0330e-02, -1.2924e-02],\n",
       "         [ 3.2425e-04, -1.0887e-02,  1.7944e-02,  ...,  2.9984e-03,\n",
       "           7.3509e-03,  4.5776e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_attn2_to_v.lora_up.weight': tensor([[ 2.5864e-02, -1.7700e-02,  2.2995e-02,  ...,  2.0905e-02,\n",
       "          -2.0325e-02,  1.9043e-02],\n",
       "         [ 8.0338e-03, -9.5444e-03,  1.4832e-02,  ...,  5.6028e-04,\n",
       "          -1.0033e-02,  1.2810e-02],\n",
       "         [-3.1143e-02,  2.9892e-02, -3.7079e-02,  ..., -2.5955e-02,\n",
       "           3.1342e-02, -4.0466e-02],\n",
       "         ...,\n",
       "         [-1.5259e-05, -3.7251e-03, -3.2024e-03,  ..., -2.4223e-03,\n",
       "          -1.9350e-03, -5.4264e-04],\n",
       "         [ 1.2123e-02, -1.6617e-02,  2.0340e-02,  ...,  1.8509e-02,\n",
       "          -1.4565e-02,  1.3527e-02],\n",
       "         [ 1.9852e-02, -2.6108e-02,  2.1164e-02,  ...,  1.5587e-02,\n",
       "          -2.5482e-02,  1.8066e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_0_proj.lora_down.weight': tensor([[ 0.0014,  0.0105, -0.0139,  ..., -0.0467, -0.0161,  0.0066],\n",
       "         [ 0.0391, -0.0289,  0.0097,  ..., -0.0378, -0.0273, -0.0270],\n",
       "         [ 0.0206, -0.0208, -0.0004,  ..., -0.0382,  0.0095, -0.0007],\n",
       "         ...,\n",
       "         [-0.0441,  0.0050, -0.0209,  ...,  0.0098,  0.0126, -0.0173],\n",
       "         [ 0.0139,  0.0030, -0.0266,  ..., -0.0152,  0.0050, -0.0156],\n",
       "         [ 0.0161, -0.0044,  0.0193,  ..., -0.0295, -0.0031, -0.0286]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_0_proj.lora_up.weight': tensor([[-0.0036, -0.0101, -0.0071,  ..., -0.0028, -0.0155,  0.0050],\n",
       "         [-0.0111, -0.0204, -0.0132,  ...,  0.0155, -0.0237, -0.0166],\n",
       "         [ 0.0170,  0.0009,  0.0312,  ..., -0.0148, -0.0284,  0.0326],\n",
       "         ...,\n",
       "         [ 0.0203,  0.0320,  0.0229,  ..., -0.0237,  0.0104,  0.0113],\n",
       "         [ 0.0103,  0.0082,  0.0127,  ..., -0.0212, -0.0025,  0.0116],\n",
       "         [-0.0155,  0.0204, -0.0103,  ...,  0.0171, -0.0220,  0.0037]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_2.lora_down.weight': tensor([[-1.4702e-02,  5.2643e-04,  3.0350e-02,  ...,  1.2016e-02,\n",
       "          -2.9445e-05,  2.7939e-02],\n",
       "         [-4.0855e-03, -4.6387e-03,  8.7051e-03,  ...,  5.8479e-03,\n",
       "          -1.1816e-03,  2.6459e-02],\n",
       "         [-4.9477e-03,  2.2869e-03,  2.7405e-02,  ...,  1.9974e-02,\n",
       "          -4.9973e-03,  3.6194e-02],\n",
       "         ...,\n",
       "         [ 3.9253e-03, -1.1711e-02,  2.3880e-02,  ...,  1.6357e-02,\n",
       "          -9.5749e-03,  9.9106e-03],\n",
       "         [ 1.5686e-02, -5.4169e-03,  2.5909e-02,  ..., -5.7190e-02,\n",
       "          -1.0933e-02,  1.3252e-02],\n",
       "         [-1.5976e-02,  1.6968e-02, -1.7975e-02,  ..., -2.2247e-02,\n",
       "           8.6670e-03, -3.4729e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_2.lora_up.weight': tensor([[ 5.6915e-03, -2.0447e-03, -1.3399e-03,  ...,  1.8845e-03,\n",
       "          -7.7400e-03,  1.5545e-04],\n",
       "         [ 6.2799e-04, -1.2589e-03, -5.4884e-04,  ..., -4.2260e-05,\n",
       "           2.6825e-02,  4.4212e-03],\n",
       "         [-1.8341e-02, -1.9196e-02, -2.4399e-02,  ..., -1.9226e-02,\n",
       "           4.1504e-02,  1.8906e-02],\n",
       "         ...,\n",
       "         [ 5.8670e-03,  4.5547e-03,  2.9373e-03,  ...,  3.6869e-03,\n",
       "           7.8011e-03,  3.2806e-04],\n",
       "         [ 4.8599e-03,  8.1863e-03,  6.7940e-03,  ...,  9.7961e-03,\n",
       "          -3.2288e-02, -9.7580e-03],\n",
       "         [ 6.6910e-03,  7.8812e-03,  9.2087e-03,  ...,  2.5997e-03,\n",
       "           2.4887e-02, -4.9286e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_k.lora_down.weight': tensor([[ 4.4632e-03, -2.3590e-02,  8.8043e-03,  ..., -5.1880e-03,\n",
       "          -8.0948e-03,  1.5274e-02],\n",
       "         [ 2.3376e-02,  7.8812e-03,  2.4963e-02,  ..., -4.0680e-02,\n",
       "           3.2365e-05,  4.3869e-04],\n",
       "         [-1.3222e-02,  9.3689e-03, -2.6962e-02,  ..., -9.0790e-03,\n",
       "          -3.0014e-02, -3.1052e-02],\n",
       "         ...,\n",
       "         [ 2.5742e-02, -1.0262e-02, -4.5280e-03,  ..., -1.7334e-02,\n",
       "           1.5991e-02,  1.6586e-02],\n",
       "         [ 3.3997e-02,  6.3553e-03,  4.6356e-02,  ..., -1.9550e-03,\n",
       "           1.5884e-02,  1.2573e-02],\n",
       "         [ 6.5804e-04,  3.9520e-02,  2.9205e-02,  ..., -4.1534e-02,\n",
       "           9.2163e-03,  1.6937e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_k.lora_up.weight': tensor([[ 0.0005,  0.0127, -0.0139,  ...,  0.0055,  0.0048,  0.0244],\n",
       "         [ 0.0123, -0.0295,  0.0052,  ..., -0.0173, -0.0115, -0.0261],\n",
       "         [ 0.0172,  0.0080,  0.0093,  ..., -0.0181,  0.0174, -0.0026],\n",
       "         ...,\n",
       "         [-0.0004, -0.0246,  0.0077,  ...,  0.0343, -0.0295,  0.0127],\n",
       "         [ 0.0106, -0.0196,  0.0248,  ..., -0.0085,  0.0080, -0.0075],\n",
       "         [ 0.0470, -0.0102,  0.0037,  ..., -0.0014,  0.0214, -0.0145]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_out_0.lora_down.weight': tensor([[-2.3788e-02,  4.6349e-03, -1.4740e-02,  ..., -2.4429e-02,\n",
       "           7.1106e-03, -3.9635e-03],\n",
       "         [-5.0163e-04, -1.1398e-02,  1.0468e-02,  ...,  3.5736e-02,\n",
       "           3.0151e-02, -2.0504e-05],\n",
       "         [ 1.5793e-03, -3.9673e-02, -3.4363e-02,  ..., -2.5269e-02,\n",
       "          -1.0078e-02,  6.7902e-03],\n",
       "         ...,\n",
       "         [ 1.2520e-02,  2.4384e-02,  1.9714e-02,  ..., -8.4152e-03,\n",
       "           7.2021e-03,  2.9327e-02],\n",
       "         [ 3.3691e-02, -1.7395e-03, -3.5034e-02,  ...,  1.4238e-03,\n",
       "           1.1139e-02,  6.3744e-03],\n",
       "         [ 3.0685e-02, -2.9327e-02, -2.5879e-02,  ...,  3.4058e-02,\n",
       "           1.0429e-02,  8.7500e-05]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_out_0.lora_up.weight': tensor([[ 0.0107,  0.0123,  0.0023,  ...,  0.0012, -0.0158, -0.0023],\n",
       "         [ 0.0123, -0.0153, -0.0117,  ...,  0.0204,  0.0130,  0.0112],\n",
       "         [-0.0125, -0.0110, -0.0016,  ...,  0.0038,  0.0113,  0.0134],\n",
       "         ...,\n",
       "         [ 0.0126,  0.0030,  0.0076,  ..., -0.0023, -0.0106,  0.0018],\n",
       "         [ 0.0122,  0.0111, -0.0023,  ...,  0.0099, -0.0156, -0.0135],\n",
       "         [-0.0028, -0.0125, -0.0075,  ...,  0.0028,  0.0292,  0.0097]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_q.lora_down.weight': tensor([[ 0.0219, -0.0032,  0.0019,  ...,  0.0043,  0.0190,  0.0001],\n",
       "         [ 0.0013, -0.0285,  0.0377,  ..., -0.0076,  0.0094, -0.0011],\n",
       "         [ 0.0305,  0.0199,  0.0186,  ...,  0.0118,  0.0132,  0.0119],\n",
       "         ...,\n",
       "         [-0.0152,  0.0088,  0.0229,  ...,  0.0058,  0.0171,  0.0016],\n",
       "         [-0.0479,  0.0186,  0.0168,  ...,  0.0136,  0.0085,  0.0042],\n",
       "         [-0.0078,  0.0019, -0.0044,  ...,  0.0021,  0.0396,  0.0179]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_q.lora_up.weight': tensor([[-2.6596e-02, -1.3420e-02,  1.6953e-02,  ..., -2.5665e-02,\n",
       "          -9.5444e-03, -3.2928e-02],\n",
       "         [-1.9369e-03, -6.0654e-03, -7.9250e-04,  ..., -1.3672e-02,\n",
       "          -1.0750e-02, -1.4465e-02],\n",
       "         [-1.2238e-02, -1.2245e-02, -2.7597e-05,  ...,  9.1324e-03,\n",
       "          -5.9166e-03, -8.7738e-03],\n",
       "         ...,\n",
       "         [-1.7044e-02, -1.3466e-02, -2.4700e-03,  ..., -1.2238e-02,\n",
       "          -6.0806e-03, -1.4389e-02],\n",
       "         [-6.1913e-03,  3.6812e-03,  1.4084e-02,  ...,  5.7983e-03,\n",
       "          -9.2621e-03, -2.9697e-03],\n",
       "         [-1.3428e-02, -2.4368e-02,  1.2566e-02,  ..., -1.7990e-02,\n",
       "          -1.9821e-02, -1.3161e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_v.lora_down.weight': tensor([[ 0.0387,  0.0189,  0.0173,  ...,  0.0081,  0.0057,  0.0019],\n",
       "         [-0.0030, -0.0226,  0.0127,  ..., -0.0324, -0.0169, -0.0695],\n",
       "         [ 0.0135,  0.0178,  0.0064,  ..., -0.0182, -0.0279,  0.0145],\n",
       "         ...,\n",
       "         [ 0.0016, -0.0323, -0.0307,  ..., -0.0020, -0.0089, -0.0158],\n",
       "         [-0.0072,  0.0082,  0.0216,  ..., -0.0044,  0.0175, -0.0105],\n",
       "         [-0.0036, -0.0360, -0.0032,  ..., -0.0241,  0.0091,  0.0310]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_v.lora_up.weight': tensor([[-0.0098, -0.0046,  0.0049,  ..., -0.0071,  0.0164, -0.0019],\n",
       "         [-0.0063, -0.0067, -0.0088,  ..., -0.0044, -0.0100,  0.0123],\n",
       "         [ 0.0018, -0.0147,  0.0144,  ..., -0.0090,  0.0052, -0.0064],\n",
       "         ...,\n",
       "         [-0.0117,  0.0103, -0.0128,  ..., -0.0113,  0.0199, -0.0074],\n",
       "         [-0.0121, -0.0087,  0.0101,  ..., -0.0087, -0.0015, -0.0066],\n",
       "         [-0.0090,  0.0021, -0.0031,  ..., -0.0057,  0.0239, -0.0138]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_k.lora_down.weight': tensor([[-0.0122, -0.0318,  0.0114,  ...,  0.0201, -0.0097, -0.0077],\n",
       "         [-0.0302,  0.0041,  0.0121,  ..., -0.0166, -0.0377, -0.0074],\n",
       "         [-0.0195,  0.0179,  0.0015,  ..., -0.0038, -0.0330, -0.0285],\n",
       "         ...,\n",
       "         [-0.0191,  0.0105,  0.0192,  ..., -0.0211, -0.0235,  0.0014],\n",
       "         [ 0.0182, -0.0045, -0.0064,  ...,  0.0103,  0.0167,  0.0299],\n",
       "         [-0.0056,  0.0001, -0.0248,  ...,  0.0197,  0.0062,  0.0154]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_k.lora_up.weight': tensor([[ 0.0199,  0.0163,  0.0200,  ...,  0.0149, -0.0162, -0.0249],\n",
       "         [-0.0079,  0.0415,  0.0360,  ...,  0.0405, -0.0423, -0.0052],\n",
       "         [ 0.0103, -0.0353, -0.0255,  ..., -0.0346,  0.0352, -0.0109],\n",
       "         ...,\n",
       "         [-0.0246, -0.0143, -0.0202,  ..., -0.0146,  0.0142,  0.0169],\n",
       "         [ 0.0008,  0.0262,  0.0201,  ...,  0.0267, -0.0264, -0.0110],\n",
       "         [-0.0068, -0.0202, -0.0154,  ..., -0.0212,  0.0205,  0.0119]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_out_0.lora_down.weight': tensor([[-1.4029e-03, -3.5667e-03,  1.2894e-02,  ..., -1.1108e-02,\n",
       "          -1.5888e-03, -4.0314e-02],\n",
       "         [ 1.5736e-05, -1.0338e-02,  2.4643e-02,  ...,  3.6896e-02,\n",
       "          -1.4801e-02, -1.0635e-02],\n",
       "         [-2.8046e-02,  1.4893e-02, -5.6076e-03,  ...,  4.8553e-02,\n",
       "          -3.1021e-02, -4.6844e-03],\n",
       "         ...,\n",
       "         [-1.6298e-03, -2.1790e-02,  6.8741e-03,  ...,  1.3451e-02,\n",
       "          -1.9150e-02, -4.8599e-03],\n",
       "         [-1.2093e-02,  5.9242e-03,  5.0392e-03,  ...,  3.2501e-02,\n",
       "           1.5854e-02,  1.0910e-02],\n",
       "         [-9.9945e-03,  1.1322e-02, -3.8776e-03,  ..., -2.2522e-02,\n",
       "           3.8696e-02,  2.5742e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_out_0.lora_up.weight': tensor([[ 0.0090,  0.0116,  0.0338,  ...,  0.0291,  0.0038, -0.0282],\n",
       "         [-0.0076,  0.0079, -0.0030,  ..., -0.0047,  0.0112,  0.0119],\n",
       "         [ 0.0038, -0.0032, -0.0155,  ..., -0.0121,  0.0067,  0.0117],\n",
       "         ...,\n",
       "         [-0.0085, -0.0042,  0.0041,  ..., -0.0010, -0.0134, -0.0079],\n",
       "         [ 0.0118,  0.0039, -0.0181,  ..., -0.0092, -0.0145,  0.0042],\n",
       "         [-0.0167, -0.0079, -0.0068,  ..., -0.0042, -0.0103,  0.0122]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_q.lora_down.weight': tensor([[-0.0205, -0.0089,  0.0238,  ...,  0.0399,  0.0026,  0.0279],\n",
       "         [ 0.0328,  0.0107,  0.0132,  ...,  0.0072, -0.0073,  0.0257],\n",
       "         [ 0.0411,  0.0275,  0.0222,  ..., -0.0115,  0.0217, -0.0279],\n",
       "         ...,\n",
       "         [-0.0316, -0.0173,  0.0274,  ..., -0.0324, -0.0298,  0.0230],\n",
       "         [ 0.0434,  0.0465, -0.0205,  ..., -0.0136,  0.0367,  0.0071],\n",
       "         [-0.0252, -0.0513,  0.0203,  ..., -0.0103,  0.0079,  0.0179]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_q.lora_up.weight': tensor([[-0.0023,  0.0068, -0.0093,  ...,  0.0042, -0.0083,  0.0170],\n",
       "         [-0.0051, -0.0080, -0.0028,  ..., -0.0023,  0.0040, -0.0008],\n",
       "         [-0.0261, -0.0112,  0.0201,  ..., -0.0087,  0.0299, -0.0390],\n",
       "         ...,\n",
       "         [ 0.0080,  0.0335, -0.0096,  ..., -0.0030, -0.0179,  0.0199],\n",
       "         [ 0.0103,  0.0022, -0.0152,  ...,  0.0037, -0.0094,  0.0247],\n",
       "         [-0.0066, -0.0381,  0.0070,  ...,  0.0034,  0.0166, -0.0175]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_v.lora_down.weight': tensor([[-0.0116,  0.0073,  0.0037,  ..., -0.0075,  0.0208,  0.0056],\n",
       "         [ 0.0109, -0.0143, -0.0014,  ...,  0.0190,  0.0090, -0.0180],\n",
       "         [ 0.0135, -0.0145, -0.0089,  ...,  0.0257,  0.0208, -0.0017],\n",
       "         ...,\n",
       "         [ 0.0150,  0.0038, -0.0149,  ..., -0.0166,  0.0102, -0.0053],\n",
       "         [-0.0055, -0.0215,  0.0079,  ...,  0.0028,  0.0134, -0.0091],\n",
       "         [-0.0121,  0.0073, -0.0133,  ..., -0.0006, -0.0202,  0.0153]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_attn2_to_v.lora_up.weight': tensor([[ 0.0078, -0.0115, -0.0053,  ...,  0.0126,  0.0137,  0.0135],\n",
       "         [ 0.0047, -0.0043,  0.0048,  ...,  0.0169, -0.0080,  0.0013],\n",
       "         [ 0.0040, -0.0049, -0.0039,  ...,  0.0203,  0.0089,  0.0192],\n",
       "         ...,\n",
       "         [ 0.0118, -0.0011, -0.0029,  ...,  0.0014, -0.0168, -0.0036],\n",
       "         [-0.0483,  0.0565,  0.0001,  ..., -0.0193, -0.0029, -0.0119],\n",
       "         [-0.0090,  0.0252, -0.0237,  ..., -0.0252, -0.0245, -0.0224]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_0_proj.lora_down.weight': tensor([[ 0.0163,  0.0076,  0.0320,  ..., -0.0220, -0.0193,  0.0127],\n",
       "         [-0.0418,  0.0185, -0.0205,  ...,  0.0183,  0.0189, -0.0204],\n",
       "         [-0.0471,  0.0202,  0.0232,  ...,  0.0229, -0.0028,  0.0151],\n",
       "         ...,\n",
       "         [-0.0004,  0.0204, -0.0172,  ..., -0.0274, -0.0204, -0.0042],\n",
       "         [ 0.0284, -0.0102,  0.0253,  ..., -0.0274,  0.0053, -0.0302],\n",
       "         [ 0.0299, -0.0259, -0.0211,  ..., -0.0158, -0.0234,  0.0156]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_0_proj.lora_up.weight': tensor([[-0.0078,  0.0052, -0.0036,  ..., -0.0077,  0.0062, -0.0033],\n",
       "         [-0.0057,  0.0064,  0.0096,  ..., -0.0073, -0.0060, -0.0020],\n",
       "         [-0.0055,  0.0013, -0.0125,  ...,  0.0059,  0.0186,  0.0031],\n",
       "         ...,\n",
       "         [-0.0001,  0.0136,  0.0111,  ..., -0.0098, -0.0077, -0.0144],\n",
       "         [-0.0024,  0.0010,  0.0066,  ..., -0.0059,  0.0054, -0.0050],\n",
       "         [ 0.0151, -0.0152, -0.0096,  ...,  0.0105,  0.0127,  0.0108]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_2.lora_down.weight': tensor([[ 3.2471e-02,  7.4883e-03, -1.1978e-02,  ...,  1.3153e-02,\n",
       "           1.5076e-02, -1.9318e-02],\n",
       "         [ 2.7817e-02, -5.9009e-05, -2.2690e-02,  ...,  7.9498e-03,\n",
       "           2.2373e-03, -1.9501e-02],\n",
       "         [-2.4750e-02,  7.0229e-03,  1.3390e-02,  ..., -1.1154e-02,\n",
       "           1.4238e-03,  1.5305e-02],\n",
       "         ...,\n",
       "         [-2.8656e-02,  1.6647e-02,  8.2855e-03,  ..., -3.8391e-02,\n",
       "           3.5725e-03,  9.3155e-03],\n",
       "         [ 1.3077e-02,  1.1047e-02, -8.6899e-03,  ...,  9.5673e-03,\n",
       "          -1.4412e-02, -5.5389e-03],\n",
       "         [-2.5673e-03, -1.4763e-03, -1.4019e-03,  ..., -1.2138e-02,\n",
       "           4.3449e-03,  1.6464e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_2.lora_up.weight': tensor([[-0.0025,  0.0019, -0.0026,  ...,  0.0048,  0.0015, -0.0012],\n",
       "         [ 0.0059, -0.0111,  0.0011,  ...,  0.0128, -0.0025, -0.0014],\n",
       "         [ 0.0189,  0.0009, -0.0088,  ..., -0.0130,  0.0202, -0.0110],\n",
       "         ...,\n",
       "         [-0.0091, -0.0060,  0.0100,  ...,  0.0043, -0.0028,  0.0038],\n",
       "         [-0.0157, -0.0047,  0.0082,  ...,  0.0067, -0.0040,  0.0083],\n",
       "         [ 0.0015, -0.0017,  0.0051,  ...,  0.0038, -0.0033,  0.0045]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_k.lora_down.weight': tensor([[ 1.4542e-02,  1.3702e-02,  2.9755e-02,  ...,  9.7632e-05,\n",
       "          -3.5882e-05,  2.9144e-03],\n",
       "         [ 1.3901e-02, -3.8574e-02,  6.6528e-03,  ...,  2.4246e-02,\n",
       "           1.4175e-02, -1.2787e-02],\n",
       "         [-2.2186e-02,  2.4567e-03,  2.1820e-02,  ...,  2.5955e-02,\n",
       "           1.2985e-02, -2.6337e-02],\n",
       "         ...,\n",
       "         [ 1.4984e-02, -3.7670e-03,  2.9099e-02,  ...,  3.1555e-02,\n",
       "           1.7548e-02, -2.7634e-02],\n",
       "         [-2.3117e-02,  2.4582e-02,  1.1330e-02,  ..., -3.3356e-02,\n",
       "          -2.8000e-03,  1.8112e-02],\n",
       "         [ 3.8086e-02, -2.5425e-03, -3.4393e-02,  ...,  2.0538e-02,\n",
       "          -3.4485e-02,  1.6312e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_k.lora_up.weight': tensor([[-9.7847e-04, -1.7157e-03, -6.5231e-04,  ..., -1.4977e-02,\n",
       "           3.9139e-03,  5.3596e-03],\n",
       "         [ 1.9958e-02,  7.3547e-03,  2.1271e-02,  ...,  2.6077e-02,\n",
       "           2.6535e-02, -1.5962e-04],\n",
       "         [ 4.3392e-04,  7.6904e-03,  2.5345e-02,  ...,  4.3121e-02,\n",
       "           2.8877e-03, -6.0959e-03],\n",
       "         ...,\n",
       "         [ 2.0447e-02, -1.0662e-03, -1.2836e-03,  ..., -3.8967e-03,\n",
       "           2.0996e-02, -3.2768e-03],\n",
       "         [-8.0109e-03,  1.2756e-02,  1.0185e-02,  ..., -1.0312e-05,\n",
       "           9.5367e-03,  2.6512e-03],\n",
       "         [-7.2021e-03, -6.5384e-03,  2.0294e-02,  ..., -6.5269e-03,\n",
       "           4.2305e-03,  5.6267e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_out_0.lora_down.weight': tensor([[ 0.0199,  0.0045, -0.0380,  ...,  0.0057, -0.0154, -0.0048],\n",
       "         [-0.0149,  0.0213, -0.0103,  ..., -0.0018, -0.0030, -0.0287],\n",
       "         [-0.0086,  0.0151, -0.0219,  ...,  0.0022,  0.0125,  0.0119],\n",
       "         ...,\n",
       "         [ 0.0030,  0.0327, -0.0138,  ...,  0.0248,  0.0118,  0.0153],\n",
       "         [ 0.0072,  0.0011, -0.0457,  ...,  0.0174, -0.0042, -0.0332],\n",
       "         [-0.0103, -0.0174, -0.0163,  ..., -0.0166, -0.0188, -0.0284]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_out_0.lora_up.weight': tensor([[-0.0016,  0.0061, -0.0074,  ...,  0.0109, -0.0118,  0.0034],\n",
       "         [-0.0005,  0.0081, -0.0018,  ...,  0.0073, -0.0112,  0.0005],\n",
       "         [-0.0047,  0.0037,  0.0159,  ..., -0.0085,  0.0117,  0.0037],\n",
       "         ...,\n",
       "         [ 0.0069,  0.0110,  0.0029,  ...,  0.0052, -0.0084, -0.0060],\n",
       "         [ 0.0211, -0.0043, -0.0081,  ...,  0.0037,  0.0087, -0.0098],\n",
       "         [ 0.0042, -0.0113, -0.0041,  ...,  0.0048, -0.0201, -0.0063]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_q.lora_down.weight': tensor([[-0.0115,  0.0288,  0.0093,  ...,  0.0010,  0.0228, -0.0310],\n",
       "         [ 0.0034, -0.0449,  0.0294,  ..., -0.0033, -0.0021,  0.0159],\n",
       "         [-0.0326, -0.0078, -0.0020,  ..., -0.0102,  0.0140,  0.0093],\n",
       "         ...,\n",
       "         [ 0.0096, -0.0220,  0.0263,  ...,  0.0032, -0.0101, -0.0075],\n",
       "         [-0.0032, -0.0285, -0.0058,  ..., -0.0369, -0.0147,  0.0085],\n",
       "         [-0.0066, -0.0235,  0.0090,  ...,  0.0337,  0.0165,  0.0426]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_q.lora_up.weight': tensor([[-0.0310,  0.0205, -0.0335,  ...,  0.0205,  0.0357,  0.0230],\n",
       "         [ 0.0032, -0.0087, -0.0031,  ..., -0.0013,  0.0061, -0.0038],\n",
       "         [ 0.0161, -0.0037,  0.0112,  ...,  0.0016, -0.0028,  0.0323],\n",
       "         ...,\n",
       "         [ 0.0082, -0.0210,  0.0275,  ...,  0.0266, -0.0033,  0.0080],\n",
       "         [-0.0021, -0.0170,  0.0195,  ..., -0.0026, -0.0082, -0.0047],\n",
       "         [-0.0017,  0.0174, -0.0095,  ..., -0.0015,  0.0116, -0.0196]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_v.lora_down.weight': tensor([[-0.0158,  0.0153, -0.0361,  ..., -0.0092, -0.0058,  0.0390],\n",
       "         [-0.0040, -0.0115,  0.0227,  ...,  0.0234, -0.0039,  0.0191],\n",
       "         [-0.0364, -0.0140, -0.0150,  ..., -0.0101,  0.0325,  0.0317],\n",
       "         ...,\n",
       "         [-0.0396,  0.0229, -0.0216,  ...,  0.0110,  0.0071,  0.0394],\n",
       "         [ 0.0197,  0.0412,  0.0156,  ..., -0.0028,  0.0293,  0.0020],\n",
       "         [-0.0307, -0.0065,  0.0069,  ..., -0.0223,  0.0308,  0.0413]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_v.lora_up.weight': tensor([[-0.0184, -0.0146, -0.0204,  ..., -0.0227,  0.0187, -0.0204],\n",
       "         [ 0.0371, -0.0094,  0.0171,  ...,  0.0355,  0.0054,  0.0519],\n",
       "         [ 0.0220,  0.0030,  0.0029,  ...,  0.0066, -0.0077,  0.0056],\n",
       "         ...,\n",
       "         [ 0.0016, -0.0058,  0.0102,  ...,  0.0110,  0.0159,  0.0204],\n",
       "         [-0.0157,  0.0099, -0.0122,  ..., -0.0089, -0.0206, -0.0068],\n",
       "         [-0.0027,  0.0024,  0.0053,  ...,  0.0091,  0.0144,  0.0129]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_k.lora_down.weight': tensor([[ 0.0036, -0.0201, -0.0036,  ..., -0.0006, -0.0109,  0.0145],\n",
       "         [-0.0246, -0.0107, -0.0194,  ..., -0.0136, -0.0106, -0.0233],\n",
       "         [-0.0160, -0.0120,  0.0035,  ..., -0.0013, -0.0077,  0.0009],\n",
       "         ...,\n",
       "         [ 0.0080, -0.0035,  0.0136,  ...,  0.0170, -0.0306,  0.0034],\n",
       "         [-0.0183,  0.0008, -0.0312,  ...,  0.0328, -0.0007, -0.0178],\n",
       "         [ 0.0068,  0.0278, -0.0067,  ...,  0.0337,  0.0125,  0.0071]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_k.lora_up.weight': tensor([[ 0.0221,  0.0003,  0.0212,  ...,  0.0063, -0.0223, -0.0219],\n",
       "         [ 0.0106,  0.0053,  0.0113,  ...,  0.0075, -0.0096, -0.0108],\n",
       "         [-0.0236,  0.0179, -0.0197,  ...,  0.0175,  0.0238,  0.0230],\n",
       "         ...,\n",
       "         [ 0.0197, -0.0277,  0.0142,  ..., -0.0298, -0.0207, -0.0195],\n",
       "         [-0.0185, -0.0124, -0.0250,  ..., -0.0068,  0.0187,  0.0188],\n",
       "         [-0.0236,  0.0382, -0.0151,  ...,  0.0305,  0.0243,  0.0234]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_out_0.lora_down.weight': tensor([[ 0.0239, -0.0239, -0.0021,  ...,  0.0087, -0.0133, -0.0278],\n",
       "         [ 0.0200, -0.0359,  0.0031,  ...,  0.0208, -0.0048,  0.0118],\n",
       "         [ 0.0202, -0.0216, -0.0015,  ...,  0.0057,  0.0213, -0.0265],\n",
       "         ...,\n",
       "         [-0.0049, -0.0014, -0.0159,  ..., -0.0062,  0.0167,  0.0170],\n",
       "         [-0.0096,  0.0338, -0.0091,  ..., -0.0155,  0.0140, -0.0219],\n",
       "         [-0.0153,  0.0479, -0.0105,  ...,  0.0239, -0.0142, -0.0174]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_out_0.lora_up.weight': tensor([[-0.0105,  0.0027, -0.0110,  ..., -0.0114,  0.0138,  0.0226],\n",
       "         [-0.0118, -0.0112, -0.0092,  ..., -0.0112,  0.0120, -0.0075],\n",
       "         [ 0.0086,  0.0050,  0.0109,  ...,  0.0127, -0.0139, -0.0183],\n",
       "         ...,\n",
       "         [ 0.0113, -0.0157,  0.0076,  ...,  0.0082, -0.0084,  0.0153],\n",
       "         [ 0.0075,  0.0169,  0.0078,  ...,  0.0025, -0.0014,  0.0099],\n",
       "         [ 0.0064,  0.0100,  0.0045,  ...,  0.0053, -0.0066,  0.0078]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_q.lora_down.weight': tensor([[-0.0016,  0.0307, -0.0561,  ...,  0.0590, -0.0170,  0.0225],\n",
       "         [-0.0054,  0.0437,  0.0290,  ..., -0.0013,  0.0313, -0.0315],\n",
       "         [ 0.0011,  0.0060, -0.0118,  ...,  0.0024,  0.0071, -0.0291],\n",
       "         ...,\n",
       "         [-0.0173,  0.0083, -0.0083,  ...,  0.0049,  0.0097, -0.0254],\n",
       "         [-0.0210, -0.0154,  0.0339,  ..., -0.0369, -0.0075, -0.0016],\n",
       "         [-0.0311, -0.0148,  0.0034,  ...,  0.0008, -0.0248,  0.0480]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_q.lora_up.weight': tensor([[ 0.0171, -0.0088, -0.0052,  ...,  0.0177, -0.0071,  0.0117],\n",
       "         [ 0.0216, -0.0121, -0.0081,  ...,  0.0108, -0.0057,  0.0179],\n",
       "         [ 0.0169, -0.0114, -0.0104,  ..., -0.0005, -0.0013,  0.0153],\n",
       "         ...,\n",
       "         [-0.0075, -0.0009, -0.0026,  ..., -0.0046, -0.0154, -0.0115],\n",
       "         [-0.0158,  0.0078,  0.0056,  ..., -0.0090,  0.0195,  0.0006],\n",
       "         [ 0.0055,  0.0047,  0.0129,  ...,  0.0145, -0.0009,  0.0014]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_v.lora_down.weight': tensor([[-0.0287, -0.0287,  0.0276,  ..., -0.0096,  0.0211, -0.0301],\n",
       "         [-0.0018, -0.0154, -0.0094,  ..., -0.0197, -0.0227, -0.0018],\n",
       "         [ 0.0181,  0.0090, -0.0202,  ...,  0.0232, -0.0240, -0.0064],\n",
       "         ...,\n",
       "         [ 0.0179,  0.0093,  0.0129,  ...,  0.0081,  0.0108, -0.0040],\n",
       "         [ 0.0003, -0.0178,  0.0197,  ..., -0.0243,  0.0204,  0.0071],\n",
       "         [-0.0088, -0.0195,  0.0225,  ...,  0.0032, -0.0022, -0.0099]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_attn2_to_v.lora_up.weight': tensor([[ 0.0241, -0.0045, -0.0206,  ..., -0.0122,  0.0240,  0.0273],\n",
       "         [ 0.0174, -0.0076, -0.0229,  ..., -0.0130, -0.0007,  0.0163],\n",
       "         [ 0.0274, -0.0121, -0.0179,  ..., -0.0226,  0.0338,  0.0322],\n",
       "         ...,\n",
       "         [ 0.0228, -0.0136, -0.0287,  ..., -0.0167,  0.0169,  0.0215],\n",
       "         [-0.0230,  0.0147,  0.0184,  ...,  0.0123,  0.0077, -0.0221],\n",
       "         [-0.0100,  0.0065,  0.0075,  ...,  0.0065, -0.0054, -0.0101]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_0_proj.lora_down.weight': tensor([[ 0.0593, -0.0211, -0.0260,  ..., -0.0401, -0.0374, -0.0186],\n",
       "         [-0.0321, -0.0085,  0.0068,  ..., -0.0122,  0.0102, -0.0352],\n",
       "         [ 0.0137, -0.0184, -0.0359,  ...,  0.0042, -0.0022,  0.0187],\n",
       "         ...,\n",
       "         [ 0.0008, -0.0109,  0.0221,  ..., -0.0060, -0.0098, -0.0223],\n",
       "         [-0.0224,  0.0405,  0.0267,  ...,  0.0354, -0.0040,  0.0007],\n",
       "         [ 0.0134, -0.0261,  0.0253,  ...,  0.0166,  0.0106,  0.0131]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_0_proj.lora_up.weight': tensor([[ 0.0117, -0.0133, -0.0050,  ...,  0.0124, -0.0113,  0.0172],\n",
       "         [-0.0010,  0.0018, -0.0086,  ..., -0.0052,  0.0016, -0.0092],\n",
       "         [ 0.0211,  0.0061,  0.0128,  ..., -0.0130, -0.0043, -0.0030],\n",
       "         ...,\n",
       "         [ 0.0033, -0.0152,  0.0217,  ...,  0.0163, -0.0139,  0.0045],\n",
       "         [-0.0163,  0.0082, -0.0141,  ...,  0.0029,  0.0117, -0.0102],\n",
       "         [-0.0079,  0.0165, -0.0186,  ...,  0.0121, -0.0010,  0.0095]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_2.lora_down.weight': tensor([[-0.0022, -0.0275, -0.0199,  ...,  0.0108, -0.0211,  0.0125],\n",
       "         [ 0.0300,  0.0115,  0.0289,  ..., -0.0182, -0.0009, -0.0254],\n",
       "         [-0.0043, -0.0030, -0.0270,  ...,  0.0012, -0.0042, -0.0126],\n",
       "         ...,\n",
       "         [ 0.0105,  0.0228,  0.0269,  ..., -0.0057,  0.0044,  0.0049],\n",
       "         [ 0.0279,  0.0138,  0.0547,  ..., -0.0145,  0.0055, -0.0401],\n",
       "         [ 0.0080, -0.0098, -0.0159,  ...,  0.0181, -0.0050,  0.0046]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_2.lora_up.weight': tensor([[ 0.0012,  0.0022, -0.0034,  ..., -0.0104, -0.0087,  0.0068],\n",
       "         [ 0.0004, -0.0190, -0.0045,  ..., -0.0093,  0.0070,  0.0096],\n",
       "         [-0.0102, -0.0006, -0.0076,  ...,  0.0060, -0.0014, -0.0128],\n",
       "         ...,\n",
       "         [ 0.0079, -0.0224,  0.0100,  ..., -0.0246, -0.0094,  0.0196],\n",
       "         [ 0.0148, -0.0024,  0.0099,  ..., -0.0063, -0.0144,  0.0132],\n",
       "         [-0.0224,  0.0094, -0.0044,  ...,  0.0084,  0.0211, -0.0107]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_k.lora_down.weight': tensor([[ 0.0087, -0.0514, -0.0261,  ..., -0.0270,  0.0600,  0.0135],\n",
       "         [ 0.0326,  0.0093,  0.0294,  ..., -0.0240, -0.0245, -0.0311],\n",
       "         [ 0.0335,  0.0375,  0.0127,  ...,  0.0008, -0.0263,  0.0179],\n",
       "         ...,\n",
       "         [-0.0125, -0.0244, -0.0264,  ...,  0.0105,  0.0302,  0.0464],\n",
       "         [-0.0093,  0.0041, -0.0357,  ...,  0.0211, -0.0120, -0.0050],\n",
       "         [ 0.0122,  0.0114,  0.0059,  ...,  0.0120,  0.0033,  0.0374]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_k.lora_up.weight': tensor([[ 0.0207, -0.0152,  0.0279,  ...,  0.0066, -0.0261,  0.0155],\n",
       "         [-0.0003,  0.0052,  0.0074,  ..., -0.0178, -0.0155, -0.0231],\n",
       "         [ 0.0393, -0.0023, -0.0417,  ..., -0.0094, -0.0089, -0.0098],\n",
       "         ...,\n",
       "         [ 0.0067, -0.0109,  0.0117,  ...,  0.0159, -0.0177,  0.0218],\n",
       "         [-0.0112, -0.0063, -0.0369,  ..., -0.0282,  0.0229, -0.0306],\n",
       "         [ 0.0040,  0.0179,  0.0165,  ..., -0.0079,  0.0040, -0.0037]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_out_0.lora_down.weight': tensor([[-0.0053, -0.0187, -0.0073,  ...,  0.0074,  0.0028,  0.0242],\n",
       "         [ 0.0351,  0.0110,  0.0282,  ..., -0.0187,  0.0125, -0.0064],\n",
       "         [ 0.0089,  0.0283, -0.0170,  ...,  0.0210, -0.0349,  0.0049],\n",
       "         ...,\n",
       "         [-0.0391, -0.0098, -0.0070,  ...,  0.0221,  0.0232,  0.0208],\n",
       "         [-0.0175,  0.0091,  0.0069,  ..., -0.0056,  0.0295, -0.0180],\n",
       "         [-0.0471, -0.0256, -0.0306,  ..., -0.0138,  0.0329,  0.0210]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_out_0.lora_up.weight': tensor([[ 0.0026, -0.0026,  0.0134,  ..., -0.0036, -0.0021, -0.0051],\n",
       "         [-0.0098, -0.0058,  0.0051,  ..., -0.0181, -0.0073,  0.0096],\n",
       "         [ 0.0023,  0.0037, -0.0144,  ...,  0.0175,  0.0142,  0.0196],\n",
       "         ...,\n",
       "         [ 0.0035, -0.0013, -0.0166,  ..., -0.0049,  0.0064,  0.0139],\n",
       "         [-0.0257,  0.0060,  0.0108,  ..., -0.0226, -0.0202, -0.0066],\n",
       "         [ 0.0154, -0.0105, -0.0241,  ...,  0.0041,  0.0074,  0.0349]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_q.lora_down.weight': tensor([[-0.0391, -0.0420,  0.0320,  ..., -0.0248, -0.0041, -0.0025],\n",
       "         [ 0.0352,  0.0157, -0.0064,  ...,  0.0158,  0.0056, -0.0090],\n",
       "         [ 0.0210,  0.0098,  0.0358,  ..., -0.0514,  0.0210,  0.0154],\n",
       "         ...,\n",
       "         [ 0.0037,  0.0289, -0.0257,  ..., -0.0290,  0.0097,  0.0224],\n",
       "         [ 0.0033,  0.0021, -0.0372,  ...,  0.0078,  0.0229, -0.0048],\n",
       "         [ 0.0186, -0.0303,  0.0170,  ..., -0.0321, -0.0220,  0.0347]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_q.lora_up.weight': tensor([[-0.0050,  0.0099, -0.0069,  ...,  0.0031, -0.0196, -0.0226],\n",
       "         [-0.0065, -0.0332,  0.0349,  ...,  0.0103, -0.0017,  0.0123],\n",
       "         [-0.0074, -0.0092,  0.0013,  ...,  0.0112,  0.0054,  0.0009],\n",
       "         ...,\n",
       "         [-0.0004,  0.0023, -0.0105,  ...,  0.0217,  0.0025, -0.0043],\n",
       "         [ 0.0001,  0.0018, -0.0026,  ...,  0.0177,  0.0109,  0.0202],\n",
       "         [ 0.0193,  0.0055,  0.0051,  ..., -0.0212, -0.0191, -0.0148]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_v.lora_down.weight': tensor([[-0.0362,  0.0129,  0.0215,  ..., -0.0159, -0.0146, -0.0119],\n",
       "         [ 0.0025,  0.0624, -0.0468,  ..., -0.0197,  0.0077, -0.0161],\n",
       "         [ 0.0058,  0.0023,  0.0303,  ...,  0.0050,  0.0129, -0.0067],\n",
       "         ...,\n",
       "         [ 0.0010,  0.0016, -0.0140,  ...,  0.0279,  0.0440,  0.0081],\n",
       "         [-0.0152, -0.0137, -0.0027,  ..., -0.0225,  0.0038,  0.0280],\n",
       "         [-0.0204,  0.0141,  0.0227,  ...,  0.0333,  0.0250, -0.0036]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_v.lora_up.weight': tensor([[ 0.0099,  0.0181,  0.0034,  ...,  0.0150,  0.0060,  0.0280],\n",
       "         [ 0.0267, -0.0067,  0.0157,  ...,  0.0068,  0.0049,  0.0091],\n",
       "         [ 0.0303, -0.0422, -0.0047,  ...,  0.0184,  0.0136,  0.0085],\n",
       "         ...,\n",
       "         [ 0.0095,  0.0029, -0.0215,  ..., -0.0215,  0.0507, -0.0251],\n",
       "         [ 0.0145,  0.0211,  0.0031,  ...,  0.0144, -0.0107,  0.0060],\n",
       "         [-0.0217, -0.0159, -0.0037,  ..., -0.0290,  0.0299, -0.0088]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_k.lora_down.weight': tensor([[ 0.0023, -0.0144, -0.0200,  ...,  0.0174, -0.0248,  0.0091],\n",
       "         [-0.0208,  0.0132,  0.0286,  ..., -0.0302,  0.0244,  0.0106],\n",
       "         [-0.0012,  0.0183, -0.0179,  ...,  0.0037, -0.0346, -0.0217],\n",
       "         ...,\n",
       "         [-0.0174, -0.0078, -0.0060,  ..., -0.0225, -0.0243, -0.0202],\n",
       "         [ 0.0187,  0.0062, -0.0205,  ...,  0.0238, -0.0366,  0.0038],\n",
       "         [ 0.0036,  0.0285,  0.0412,  ..., -0.0352,  0.0076,  0.0311]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_k.lora_up.weight': tensor([[ 2.9221e-02, -2.5391e-02,  1.8799e-02,  ..., -8.0585e-05,\n",
       "           1.8982e-02, -2.3376e-02],\n",
       "         [ 2.0386e-02, -1.6800e-02,  1.1444e-02,  ...,  1.4353e-03,\n",
       "           1.1360e-02, -1.4931e-02],\n",
       "         [ 1.9180e-02, -1.5869e-02,  8.3160e-03,  ..., -5.5847e-03,\n",
       "           7.2937e-03, -1.4793e-02],\n",
       "         ...,\n",
       "         [ 2.3670e-03, -4.1161e-03,  1.2749e-02,  ...,  1.3992e-02,\n",
       "          -5.3291e-03,  2.5730e-03],\n",
       "         [-4.8309e-02,  4.8401e-02, -5.1178e-02,  ..., -3.0884e-02,\n",
       "          -3.2623e-02,  3.8788e-02],\n",
       "         [-2.6474e-02,  2.9190e-02, -3.3173e-02,  ..., -2.9343e-02,\n",
       "          -1.1101e-02,  2.0401e-02]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_out_0.lora_down.weight': tensor([[ 0.0280,  0.0356, -0.0279,  ...,  0.0096, -0.0140, -0.0147],\n",
       "         [-0.0406, -0.0264, -0.0147,  ...,  0.0135,  0.0275, -0.0061],\n",
       "         [ 0.0020, -0.0067,  0.0160,  ..., -0.0197, -0.0207, -0.0014],\n",
       "         ...,\n",
       "         [ 0.0041,  0.0188, -0.0031,  ..., -0.0150,  0.0178,  0.0153],\n",
       "         [-0.0319, -0.0370,  0.0151,  ..., -0.0129, -0.0261,  0.0008],\n",
       "         [ 0.0349, -0.0134,  0.0234,  ...,  0.0273,  0.0131,  0.0240]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_out_0.lora_up.weight': tensor([[-0.0145,  0.0154,  0.0113,  ..., -0.0103,  0.0151, -0.0178],\n",
       "         [-0.0268,  0.0313,  0.0083,  ..., -0.0300,  0.0272, -0.0149],\n",
       "         [ 0.0028,  0.0009,  0.0055,  ...,  0.0110, -0.0043, -0.0084],\n",
       "         ...,\n",
       "         [ 0.0176, -0.0137, -0.0103,  ...,  0.0197, -0.0136,  0.0073],\n",
       "         [-0.0095,  0.0139,  0.0123,  ..., -0.0080,  0.0100, -0.0035],\n",
       "         [ 0.0049, -0.0055, -0.0015,  ...,  0.0066, -0.0070, -0.0032]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_q.lora_down.weight': tensor([[-0.0170,  0.0107,  0.0067,  ...,  0.0096, -0.0111,  0.0089],\n",
       "         [-0.0159, -0.0024, -0.0140,  ...,  0.0059, -0.0226, -0.0417],\n",
       "         [ 0.0244,  0.0152, -0.0344,  ...,  0.0082,  0.0298,  0.0285],\n",
       "         ...,\n",
       "         [-0.0315,  0.0248,  0.0116,  ..., -0.0125,  0.0061,  0.0115],\n",
       "         [ 0.0560, -0.0338, -0.0331,  ..., -0.0248,  0.0063,  0.0139],\n",
       "         [ 0.0029, -0.0158,  0.0155,  ..., -0.0273, -0.0193,  0.0044]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_q.lora_up.weight': tensor([[-0.0175, -0.0047,  0.0156,  ..., -0.0264,  0.0162,  0.0128],\n",
       "         [-0.0129, -0.0024,  0.0096,  ..., -0.0232,  0.0155,  0.0080],\n",
       "         [-0.0180, -0.0046,  0.0162,  ..., -0.0289,  0.0175,  0.0128],\n",
       "         ...,\n",
       "         [ 0.0102,  0.0014, -0.0028,  ..., -0.0091, -0.0040,  0.0010],\n",
       "         [-0.0027, -0.0182, -0.0049,  ...,  0.0319, -0.0196, -0.0009],\n",
       "         [-0.0082, -0.0135, -0.0042,  ...,  0.0279, -0.0201, -0.0038]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_v.lora_down.weight': tensor([[-0.0117, -0.0026,  0.0004,  ...,  0.0030, -0.0362,  0.0143],\n",
       "         [-0.0057, -0.0265, -0.0125,  ..., -0.0306,  0.0267,  0.0211],\n",
       "         [-0.0195, -0.0127,  0.0126,  ..., -0.0057,  0.0071, -0.0049],\n",
       "         ...,\n",
       "         [ 0.0089,  0.0226,  0.0034,  ...,  0.0039, -0.0063,  0.0006],\n",
       "         [-0.0034,  0.0077, -0.0283,  ...,  0.0431, -0.0114,  0.0178],\n",
       "         [-0.0066,  0.0034, -0.0078,  ...,  0.0024, -0.0299,  0.0145]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_attn2_to_v.lora_up.weight': tensor([[-0.0236,  0.0330,  0.0246,  ...,  0.0117, -0.0256, -0.0238],\n",
       "         [-0.0100,  0.0073,  0.0104,  ..., -0.0009, -0.0146, -0.0112],\n",
       "         [ 0.0168, -0.0287, -0.0246,  ..., -0.0057,  0.0307,  0.0220],\n",
       "         ...,\n",
       "         [ 0.0092,  0.0033,  0.0070,  ...,  0.0155,  0.0036, -0.0072],\n",
       "         [-0.0110,  0.0208,  0.0172,  ...,  0.0016, -0.0337, -0.0215],\n",
       "         [-0.0591,  0.0537,  0.0608,  ...,  0.0156, -0.0676, -0.0630]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_0_proj.lora_down.weight': tensor([[-0.0156, -0.0232,  0.0109,  ...,  0.0220, -0.0260,  0.0126],\n",
       "         [-0.0440, -0.0284,  0.0141,  ...,  0.0176,  0.0151, -0.0235],\n",
       "         [ 0.0423,  0.0273, -0.0134,  ...,  0.0265,  0.0171, -0.0367],\n",
       "         ...,\n",
       "         [-0.0269, -0.0039,  0.0286,  ...,  0.0260,  0.0012, -0.0145],\n",
       "         [-0.0181,  0.0347, -0.0141,  ...,  0.0075,  0.0033, -0.0175],\n",
       "         [ 0.0210, -0.0065,  0.0202,  ...,  0.0177, -0.0111, -0.0193]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_0_proj.lora_up.weight': tensor([[-3.6221e-03,  1.5884e-02, -2.1515e-03,  ...,  4.2236e-02,\n",
       "           1.6479e-02,  5.4588e-03],\n",
       "         [-1.1139e-03, -3.9444e-03,  1.4839e-02,  ..., -8.2855e-03,\n",
       "          -6.7558e-03,  7.0035e-05],\n",
       "         [ 1.8921e-03, -1.3304e-03, -8.3847e-03,  ..., -1.8661e-02,\n",
       "          -5.2452e-03, -9.4147e-03],\n",
       "         ...,\n",
       "         [-5.6839e-03,  1.3176e-02, -8.8043e-03,  ...,  6.8054e-03,\n",
       "           8.1635e-03,  1.2226e-03],\n",
       "         [ 9.5215e-03,  8.5754e-03,  3.1700e-03,  ...,  2.5673e-03,\n",
       "           1.8829e-02, -1.0597e-02],\n",
       "         [ 3.5954e-03,  6.6910e-03,  4.0932e-03,  ...,  4.3178e-04,\n",
       "          -1.6041e-03,  1.8616e-03]], dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_2.lora_down.weight': tensor([[-0.0792, -0.0147, -0.0169,  ..., -0.0159, -0.0161,  0.0457],\n",
       "         [ 0.0602,  0.0027,  0.0111,  ...,  0.0114,  0.0034, -0.0098],\n",
       "         [ 0.0473,  0.0047,  0.0089,  ..., -0.0190, -0.0124, -0.0304],\n",
       "         ...,\n",
       "         [-0.0316, -0.0364,  0.0065,  ...,  0.0123, -0.0074,  0.0235],\n",
       "         [ 0.0676, -0.0092, -0.0032,  ...,  0.0073,  0.0294, -0.0502],\n",
       "         [-0.0018, -0.0165, -0.0191,  ...,  0.0184, -0.0436,  0.0233]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_2.lora_up.weight': tensor([[-0.0126, -0.0216, -0.0149,  ...,  0.0053, -0.0054, -0.0219],\n",
       "         [ 0.0199, -0.0111, -0.0085,  ...,  0.0125, -0.0090,  0.0189],\n",
       "         [-0.0108,  0.0036,  0.0042,  ...,  0.0001,  0.0090,  0.0061],\n",
       "         ...,\n",
       "         [ 0.0343, -0.0242, -0.0183,  ...,  0.0260, -0.0298, -0.0098],\n",
       "         [-0.0011, -0.0237, -0.0272,  ...,  0.0185,  0.0004, -0.0466],\n",
       "         [ 0.0051, -0.0053,  0.0051,  ..., -0.0060, -0.0025,  0.0179]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_0_emb_layers_1.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_0_emb_layers_1.lora_down.weight': tensor([[ 0.0258, -0.0171,  0.0237,  ..., -0.0132, -0.0331,  0.0361],\n",
       "         [-0.0174, -0.0186, -0.0026,  ..., -0.0190, -0.0098,  0.0081],\n",
       "         [ 0.0197, -0.0451, -0.0035,  ...,  0.0015,  0.0091,  0.0080],\n",
       "         ...,\n",
       "         [-0.0148, -0.0448,  0.0197,  ...,  0.0084, -0.0184,  0.0079],\n",
       "         [-0.0200,  0.0013,  0.0261,  ..., -0.0080,  0.0130, -0.0426],\n",
       "         [-0.0072, -0.0208,  0.0241,  ...,  0.0184, -0.0035, -0.0119]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_0_emb_layers_1.lora_up.weight': tensor([[-0.0181, -0.0175, -0.0183,  ..., -0.0213,  0.0144, -0.0013],\n",
       "         [ 0.0029,  0.0295,  0.0258,  ...,  0.0235, -0.0260,  0.0059],\n",
       "         [-0.0179, -0.0141, -0.0130,  ..., -0.0152,  0.0155, -0.0256],\n",
       "         ...,\n",
       "         [ 0.0231,  0.0253,  0.0242,  ...,  0.0273, -0.0349,  0.0289],\n",
       "         [ 0.0339, -0.0029,  0.0036,  ..., -0.0042,  0.0154, -0.0096],\n",
       "         [ 0.0077,  0.0120,  0.0103,  ...,  0.0060, -0.0068, -0.0041]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_0_in_layers_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_0_in_layers_2.lora_down.weight': tensor([[[[-1.9913e-02, -5.7373e-03, -1.2917e-02],\n",
       "           [-8.8730e-03, -8.0261e-03, -3.9635e-03],\n",
       "           [-1.8661e-02, -7.1373e-03, -4.0321e-03]],\n",
       " \n",
       "          [[-2.5444e-03, -6.7329e-03,  2.4738e-03],\n",
       "           [-2.5223e-02, -1.7670e-02, -9.7046e-03],\n",
       "           [ 5.4283e-03,  1.3664e-02, -4.8523e-03]],\n",
       " \n",
       "          [[-3.4790e-02, -3.3722e-02, -2.4216e-02],\n",
       "           [-3.3081e-02, -1.5564e-02, -1.5732e-02],\n",
       "           [-3.5034e-02, -2.7267e-02, -1.2856e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.8279e-02,  5.6122e-02,  4.6783e-02],\n",
       "           [ 5.1483e-02,  5.4291e-02,  4.2908e-02],\n",
       "           [ 4.5013e-02,  4.6204e-02,  3.7659e-02]],\n",
       " \n",
       "          [[-1.2276e-02,  1.2451e-02,  1.4505e-03],\n",
       "           [ 5.4216e-04,  1.7426e-02, -1.7462e-03],\n",
       "           [-6.0616e-03,  1.4791e-03, -1.2177e-02]],\n",
       " \n",
       "          [[-1.6739e-02, -2.9999e-02, -1.9196e-02],\n",
       "           [-1.7681e-03, -1.5327e-02, -3.9291e-03],\n",
       "           [-1.1578e-03, -1.0429e-02,  5.9280e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 8.4763e-03,  1.7105e-02,  1.1108e-02],\n",
       "           [ 1.1742e-02,  3.0457e-02,  3.3752e-02],\n",
       "           [ 6.7863e-03,  2.0477e-02,  4.2511e-02]],\n",
       " \n",
       "          [[ 1.9958e-02,  3.8261e-03,  2.4166e-03],\n",
       "           [-1.8024e-03, -9.9182e-03,  1.1654e-03],\n",
       "           [-1.7426e-02,  8.9407e-04, -1.2810e-02]],\n",
       " \n",
       "          [[ 1.3227e-03,  2.7637e-03,  1.9646e-03],\n",
       "           [ 3.5362e-03,  6.9008e-03, -7.3891e-03],\n",
       "           [-4.2129e-04,  3.1929e-03,  1.6815e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.2390e-02,  2.3544e-02,  1.1820e-04],\n",
       "           [ 2.9022e-02,  1.4053e-02, -6.4201e-03],\n",
       "           [-2.5311e-03,  6.7635e-03,  1.7654e-02]],\n",
       " \n",
       "          [[-4.1382e-02, -1.3992e-02, -9.9564e-03],\n",
       "           [-8.6594e-03, -1.2413e-02, -4.3106e-03],\n",
       "           [-1.7654e-02, -1.9043e-02, -4.9400e-03]],\n",
       " \n",
       "          [[-5.8441e-03, -8.3542e-03,  1.1032e-02],\n",
       "           [ 1.6451e-03,  4.7073e-03,  1.6708e-02],\n",
       "           [-6.9313e-03,  4.7073e-03,  1.7517e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.9379e-02,  4.3373e-03,  1.0605e-02],\n",
       "           [ 3.1090e-04,  4.7684e-03,  4.3449e-03],\n",
       "           [ 1.5808e-02,  7.7782e-03,  9.5444e-03]],\n",
       " \n",
       "          [[ 1.0353e-02,  8.3847e-03,  9.4757e-03],\n",
       "           [ 1.2627e-02,  3.4790e-03,  2.6665e-03],\n",
       "           [-8.3008e-03, -7.5188e-03,  1.9443e-04]],\n",
       " \n",
       "          [[ 3.0655e-02,  4.2267e-02,  3.0807e-02],\n",
       "           [ 3.3325e-02,  2.1912e-02,  2.2202e-02],\n",
       "           [ 1.6724e-02,  1.7960e-02,  1.4496e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.2074e-02, -3.1464e-02, -3.7567e-02],\n",
       "           [-3.5400e-02, -4.9652e-02, -4.2572e-02],\n",
       "           [-3.5126e-02, -4.5959e-02, -3.0991e-02]],\n",
       " \n",
       "          [[-3.4547e-04, -1.2245e-02, -2.8915e-02],\n",
       "           [-6.2675e-03, -2.2888e-02, -1.3435e-02],\n",
       "           [-2.4166e-03,  1.4534e-03, -3.0541e-04]],\n",
       " \n",
       "          [[ 2.5436e-02,  2.2720e-02,  1.5579e-02],\n",
       "           [ 1.9913e-02,  1.2482e-02,  1.3866e-03],\n",
       "           [ 4.1542e-03,  1.3008e-02, -6.4049e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.0864e-02, -5.5361e-04,  6.0844e-04],\n",
       "           [ 7.3853e-03,  3.1910e-03,  9.8419e-03],\n",
       "           [ 1.4427e-02,  3.6736e-03,  2.4353e-02]],\n",
       " \n",
       "          [[ 1.4496e-03,  1.6037e-02, -8.5678e-03],\n",
       "           [-7.6818e-04,  7.6790e-03,  1.6155e-03],\n",
       "           [-9.8572e-03, -1.5297e-02, -2.3651e-02]],\n",
       " \n",
       "          [[ 2.7832e-02,  3.6987e-02,  3.5370e-02],\n",
       "           [ 4.6570e-02,  3.9764e-02,  3.2227e-02],\n",
       "           [ 4.1870e-02,  3.1555e-02,  1.5244e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.2643e-02, -6.1462e-02, -5.6488e-02],\n",
       "           [-5.1483e-02, -5.9265e-02, -5.4657e-02],\n",
       "           [-6.1523e-02, -4.3671e-02, -5.2032e-02]],\n",
       " \n",
       "          [[ 7.6714e-03, -1.1238e-02, -1.9043e-02],\n",
       "           [-1.1314e-02, -2.7451e-02, -9.5444e-03],\n",
       "           [-1.3893e-02, -1.1665e-02, -9.4147e-03]],\n",
       " \n",
       "          [[ 1.6083e-02,  8.7128e-03,  6.4468e-03],\n",
       "           [-2.1470e-04,  1.1024e-02,  9.4910e-03],\n",
       "           [ 2.7027e-03,  1.3458e-02, -4.4632e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2659e-02,  1.0628e-02,  1.3779e-02],\n",
       "           [ 1.9119e-02,  2.2621e-03,  2.0737e-02],\n",
       "           [ 7.8812e-03,  1.2863e-02,  1.0483e-02]],\n",
       " \n",
       "          [[ 1.5007e-02, -5.0163e-04, -1.1971e-02],\n",
       "           [ 9.8114e-03, -6.4278e-03, -1.0178e-02],\n",
       "           [ 3.0918e-03, -2.0676e-03,  1.3824e-02]],\n",
       " \n",
       "          [[ 2.4933e-02,  3.9032e-02,  3.0487e-02],\n",
       "           [ 2.5818e-02,  1.3512e-02,  1.5511e-02],\n",
       "           [ 1.6022e-02,  2.8366e-02,  3.9406e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.5095e-02, -5.5786e-02, -5.9662e-02],\n",
       "           [-4.4312e-02, -6.5125e-02, -4.9255e-02],\n",
       "           [-2.5650e-02, -4.7302e-02, -3.8361e-02]],\n",
       " \n",
       "          [[-1.5640e-02, -2.3270e-02, -1.8936e-02],\n",
       "           [-2.2263e-02, -2.8900e-02, -1.2215e-02],\n",
       "           [-2.7267e-02, -3.1281e-02, -2.2003e-02]],\n",
       " \n",
       "          [[ 4.2542e-02,  4.5837e-02,  2.5696e-02],\n",
       "           [ 2.9190e-02,  4.3671e-02,  1.0841e-02],\n",
       "           [ 1.1726e-02,  1.8646e-02,  6.8398e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.0370e-02,  4.8089e-04,  2.6093e-03],\n",
       "           [-1.2789e-03,  3.1338e-03, -8.5983e-03],\n",
       "           [ 1.0307e-02, -8.1253e-04,  1.2482e-02]],\n",
       " \n",
       "          [[ 2.6302e-03,  1.6266e-02,  6.0959e-03],\n",
       "           [ 1.4618e-02,  1.0803e-02,  1.4076e-02],\n",
       "           [ 1.7719e-03, -1.8448e-02, -1.4591e-03]],\n",
       " \n",
       "          [[ 1.8265e-02,  1.8478e-02,  8.6212e-03],\n",
       "           [ 2.3834e-02,  1.3557e-02,  9.6970e-03],\n",
       "           [ 2.1744e-02, -2.6722e-03, -2.7542e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.6976e-02, -4.7485e-02, -5.2582e-02],\n",
       "           [-5.7404e-02, -5.4962e-02, -4.0436e-02],\n",
       "           [-3.9368e-02, -4.4952e-02, -3.5645e-02]],\n",
       " \n",
       "          [[ 1.3374e-02,  1.7977e-03, -1.2016e-02],\n",
       "           [-1.3649e-02, -1.8692e-02,  5.1193e-03],\n",
       "           [-2.2842e-02, -1.4778e-02, -5.0964e-03]],\n",
       " \n",
       "          [[ 1.7136e-02,  2.5314e-02,  3.7136e-03],\n",
       "           [-2.9163e-03,  1.0521e-02, -9.4235e-05],\n",
       "           [-6.9008e-03,  1.5381e-02, -1.4420e-02]]]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_0_in_layers_2.lora_up.weight': tensor([[[[ 0.0062]],\n",
       " \n",
       "          [[ 0.0158]],\n",
       " \n",
       "          [[-0.0073]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0021]],\n",
       " \n",
       "          [[-0.0083]],\n",
       " \n",
       "          [[-0.0084]]],\n",
       " \n",
       " \n",
       "         [[[-0.0037]],\n",
       " \n",
       "          [[-0.0171]],\n",
       " \n",
       "          [[ 0.0058]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0012]],\n",
       " \n",
       "          [[-0.0026]],\n",
       " \n",
       "          [[ 0.0155]]],\n",
       " \n",
       " \n",
       "         [[[-0.0078]],\n",
       " \n",
       "          [[-0.0173]],\n",
       " \n",
       "          [[ 0.0130]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0008]],\n",
       " \n",
       "          [[ 0.0162]],\n",
       " \n",
       "          [[ 0.0124]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0071]],\n",
       " \n",
       "          [[ 0.0060]],\n",
       " \n",
       "          [[ 0.0086]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0008]],\n",
       " \n",
       "          [[ 0.0065]],\n",
       " \n",
       "          [[ 0.0117]]],\n",
       " \n",
       " \n",
       "         [[[-0.0323]],\n",
       " \n",
       "          [[ 0.0046]],\n",
       " \n",
       "          [[ 0.0264]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0213]],\n",
       " \n",
       "          [[ 0.0256]],\n",
       " \n",
       "          [[ 0.0304]]],\n",
       " \n",
       " \n",
       "         [[[-0.0080]],\n",
       " \n",
       "          [[ 0.0117]],\n",
       " \n",
       "          [[ 0.0092]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0177]],\n",
       " \n",
       "          [[-0.0086]],\n",
       " \n",
       "          [[ 0.0118]]]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_0_out_layers_3.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_0_out_layers_3.lora_down.weight': tensor([[[[ 1.4404e-02,  1.4862e-02,  6.5842e-03],\n",
       "           [ 5.0011e-03,  1.1795e-02,  3.9935e-05],\n",
       "           [-3.5934e-03,  6.2418e-04, -1.4481e-02]],\n",
       " \n",
       "          [[-3.0380e-02, -2.6138e-02, -2.0615e-02],\n",
       "           [-1.4915e-02, -1.7960e-02, -3.5267e-03],\n",
       "           [-1.0857e-02, -3.0563e-02, -6.6109e-03]],\n",
       " \n",
       "          [[ 1.0109e-02,  2.6367e-02,  2.5909e-02],\n",
       "           [ 1.1311e-03, -3.0971e-04,  2.1454e-02],\n",
       "           [-7.8278e-03,  1.3489e-02,  1.3512e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.4708e-03,  9.2077e-04, -1.8101e-03],\n",
       "           [ 7.9918e-04, -8.8654e-03,  9.5701e-04],\n",
       "           [-1.6174e-02,  8.8196e-03, -1.6342e-02]],\n",
       " \n",
       "          [[-4.0412e-05, -1.0399e-02, -2.3529e-02],\n",
       "           [-6.2828e-03, -2.6886e-02, -2.2217e-02],\n",
       "           [-1.6434e-02, -1.8036e-02, -2.2125e-02]],\n",
       " \n",
       "          [[ 2.2278e-02,  3.9673e-02,  2.5513e-02],\n",
       "           [ 3.8696e-02,  3.0777e-02,  1.7212e-02],\n",
       "           [ 3.0594e-02,  2.3911e-02,  2.0233e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.5726e-02,  1.1349e-03, -1.5795e-04],\n",
       "           [ 2.4323e-02,  1.1635e-03,  7.8506e-03],\n",
       "           [ 1.1124e-02,  1.5488e-02, -6.8741e-03]],\n",
       " \n",
       "          [[-2.7649e-02, -2.5116e-02, -1.8143e-02],\n",
       "           [-1.4526e-02, -9.2554e-04, -1.6136e-03],\n",
       "           [-7.0038e-03, -1.2627e-02, -3.2959e-03]],\n",
       " \n",
       "          [[-1.7757e-03,  1.1513e-02,  1.8539e-02],\n",
       "           [-6.7444e-03, -3.4084e-03,  1.6220e-02],\n",
       "           [ 7.5150e-03,  7.8888e-03,  1.6907e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.5272e-03,  1.1314e-02, -2.0733e-03],\n",
       "           [ 1.4595e-02,  6.5269e-03,  1.7136e-02],\n",
       "           [-2.8381e-03,  1.1185e-02,  4.0703e-03]],\n",
       " \n",
       "          [[-6.8436e-03, -1.8921e-02, -1.4252e-02],\n",
       "           [-5.8136e-03, -4.9438e-03, -1.6373e-02],\n",
       "           [-2.5635e-02, -1.3412e-02, -9.0637e-03]],\n",
       " \n",
       "          [[ 1.5854e-02,  2.1378e-02,  5.4245e-03],\n",
       "           [ 3.3813e-02,  1.5900e-02,  8.9417e-03],\n",
       "           [ 1.0307e-02,  1.9150e-02,  9.7504e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.3367e-02, -7.7896e-03, -1.5465e-02],\n",
       "           [-2.8717e-02, -3.3722e-03, -6.0539e-03],\n",
       "           [ 9.4681e-03, -6.1340e-03, -6.0797e-06]],\n",
       " \n",
       "          [[ 2.6367e-02,  1.7044e-02,  2.5421e-02],\n",
       "           [-7.8964e-04,  8.6355e-04,  1.6525e-02],\n",
       "           [ 1.8478e-02,  9.6741e-03, -3.6597e-05]],\n",
       " \n",
       "          [[ 4.4632e-03, -1.7731e-02, -1.3878e-02],\n",
       "           [ 9.4461e-04,  1.3328e-04, -2.1027e-02],\n",
       "           [ 1.0643e-02, -2.6855e-03, -3.1311e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.5959e-03, -5.9166e-03,  3.7441e-03],\n",
       "           [-1.1093e-02, -3.1033e-03, -1.0353e-02],\n",
       "           [ 3.3665e-03, -1.1215e-02,  1.0429e-02]],\n",
       " \n",
       "          [[ 2.7161e-03,  1.1650e-02,  1.0887e-02],\n",
       "           [ 7.9193e-03,  4.6616e-03, -2.5725e-04],\n",
       "           [ 2.4887e-02,  4.6768e-03,  1.1467e-02]],\n",
       " \n",
       "          [[-1.4320e-02, -1.5450e-02, -1.7822e-02],\n",
       "           [-2.4933e-02, -1.2535e-02, -1.3519e-02],\n",
       "           [-1.3725e-02, -1.5465e-02, -3.5477e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.8936e-02, -1.3268e-02, -1.4244e-02],\n",
       "           [-6.6605e-03,  4.1866e-04,  4.0627e-03],\n",
       "           [ 6.7596e-03, -4.0817e-03,  6.6414e-03]],\n",
       " \n",
       "          [[ 2.5864e-02,  1.6617e-02,  1.7670e-02],\n",
       "           [-1.4505e-03,  1.9989e-03, -4.5433e-03],\n",
       "           [ 1.1740e-03,  1.4938e-02,  1.0223e-02]],\n",
       " \n",
       "          [[-6.0463e-03, -8.0948e-03, -2.5742e-02],\n",
       "           [-9.6970e-03, -1.3256e-03, -1.4832e-02],\n",
       "           [ 2.1529e-04, -5.8823e-03, -8.3160e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.4015e-02,  4.7922e-04,  1.0551e-02],\n",
       "           [ 8.1100e-03,  7.9880e-03, -8.7967e-03],\n",
       "           [-3.9787e-03, -9.2773e-03,  9.8572e-03]],\n",
       " \n",
       "          [[ 4.2000e-03,  7.3128e-03,  6.5918e-03],\n",
       "           [ 5.7945e-03,  5.4016e-03,  1.4908e-02],\n",
       "           [ 1.2688e-02,  8.9874e-03,  1.5106e-02]],\n",
       " \n",
       "          [[-1.7715e-02, -3.3966e-02, -1.4069e-02],\n",
       "           [-2.7039e-02, -3.0853e-02, -4.8447e-03],\n",
       "           [-3.9062e-02, -2.7985e-02, -2.0645e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.8397e-02,  7.2174e-03,  3.2635e-03],\n",
       "           [ 1.6541e-02,  5.3101e-03,  6.5269e-03],\n",
       "           [-4.7340e-03,  9.9106e-03, -4.4250e-03]],\n",
       " \n",
       "          [[-2.6016e-02, -1.7227e-02, -6.7749e-03],\n",
       "           [-7.0930e-06, -4.4670e-03, -4.2844e-04],\n",
       "           [-1.9196e-02, -1.8112e-02, -1.8250e-02]],\n",
       " \n",
       "          [[ 1.4320e-02,  1.5068e-02,  2.3315e-02],\n",
       "           [ 1.2016e-02,  1.9741e-03,  1.3268e-02],\n",
       "           [ 8.4763e-03,  7.7095e-03,  2.4734e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6068e-02,  1.4519e-02, -5.2681e-03],\n",
       "           [ 9.4452e-03,  1.8280e-02,  8.8501e-03],\n",
       "           [ 8.3237e-03,  8.2245e-03,  1.3016e-02]],\n",
       " \n",
       "          [[ 4.1466e-03, -2.0218e-02, -4.5891e-03],\n",
       "           [-6.5422e-03, -1.2787e-02, -7.3395e-03],\n",
       "           [-2.0630e-02, -1.8524e-02, -1.4526e-02]],\n",
       " \n",
       "          [[-7.8201e-04,  3.2867e-02,  8.5526e-03],\n",
       "           [ 2.8656e-02,  2.2522e-02,  8.3466e-03],\n",
       "           [ 2.0584e-02,  2.4902e-02,  2.0432e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.4015e-02,  4.8256e-03, -3.7289e-03],\n",
       "           [-6.4545e-03, -8.9188e-03, -1.0391e-02],\n",
       "           [-1.0586e-03, -5.9738e-03,  6.7177e-03]],\n",
       " \n",
       "          [[ 1.8265e-02,  1.8433e-02,  9.8267e-03],\n",
       "           [ 3.0327e-03,  9.7504e-03,  1.0826e-02],\n",
       "           [ 1.1902e-02,  1.6174e-02,  1.6083e-02]],\n",
       " \n",
       "          [[ 4.7226e-03, -5.2185e-03, -2.2339e-02],\n",
       "           [-1.5173e-03, -8.7891e-03, -1.0719e-02],\n",
       "           [-3.7479e-03, -1.1383e-02, -1.9363e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0231e-02, -4.4556e-03, -3.3092e-03],\n",
       "           [-1.2062e-02, -1.8435e-03, -1.1353e-02],\n",
       "           [-1.3676e-03, -1.4305e-02, -1.1055e-02]],\n",
       " \n",
       "          [[ 1.9569e-03,  2.2491e-02,  1.3397e-02],\n",
       "           [ 2.1744e-02,  2.0554e-02,  1.1826e-02],\n",
       "           [ 2.0599e-02,  1.4099e-02,  2.4368e-02]],\n",
       " \n",
       "          [[-5.1918e-03, -2.8595e-02, -5.2528e-03],\n",
       "           [-2.9282e-02, -1.6586e-02, -1.9331e-03],\n",
       "           [-2.2797e-02, -1.2970e-02,  1.2102e-03]]]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_0_out_layers_3.lora_up.weight': tensor([[[[ 0.0081]],\n",
       " \n",
       "          [[ 0.0216]],\n",
       " \n",
       "          [[-0.0195]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0138]],\n",
       " \n",
       "          [[ 0.0154]],\n",
       " \n",
       "          [[-0.0158]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0085]],\n",
       " \n",
       "          [[ 0.0126]],\n",
       " \n",
       "          [[-0.0091]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0108]],\n",
       " \n",
       "          [[ 0.0053]],\n",
       " \n",
       "          [[-0.0098]]],\n",
       " \n",
       " \n",
       "         [[[-0.0202]],\n",
       " \n",
       "          [[-0.0115]],\n",
       " \n",
       "          [[ 0.0179]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0169]],\n",
       " \n",
       "          [[-0.0142]],\n",
       " \n",
       "          [[ 0.0140]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0123]],\n",
       " \n",
       "          [[ 0.0177]],\n",
       " \n",
       "          [[-0.0181]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0175]],\n",
       " \n",
       "          [[ 0.0210]],\n",
       " \n",
       "          [[-0.0171]]],\n",
       " \n",
       " \n",
       "         [[[-0.0102]],\n",
       " \n",
       "          [[-0.0214]],\n",
       " \n",
       "          [[ 0.0226]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0163]],\n",
       " \n",
       "          [[-0.0149]],\n",
       " \n",
       "          [[ 0.0201]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0057]],\n",
       " \n",
       "          [[-0.0046]],\n",
       " \n",
       "          [[ 0.0030]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0026]],\n",
       " \n",
       "          [[-0.0073]],\n",
       " \n",
       "          [[ 0.0061]]]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_proj_in.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_proj_in.lora_down.weight': tensor([[ 0.0417,  0.0097,  0.0070,  ..., -0.0148, -0.0244, -0.0071],\n",
       "         [ 0.0411,  0.0031, -0.0283,  ..., -0.0138, -0.0152, -0.0365],\n",
       "         [-0.0045,  0.0133,  0.0170,  ..., -0.0180,  0.0053,  0.0186],\n",
       "         ...,\n",
       "         [-0.0002,  0.0348,  0.0425,  ...,  0.0066, -0.0297, -0.0157],\n",
       "         [-0.0098,  0.0222,  0.0071,  ..., -0.0310, -0.0241, -0.0247],\n",
       "         [-0.0406,  0.0135, -0.0113,  ..., -0.0428, -0.0210,  0.0192]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_proj_in.lora_up.weight': tensor([[-1.2817e-03, -2.1477e-03, -7.5569e-03,  ..., -2.2461e-02,\n",
       "          -8.8348e-03,  6.2523e-03],\n",
       "         [-9.6588e-03, -8.2397e-03,  1.1383e-02,  ..., -1.3523e-03,\n",
       "          -3.1548e-03,  5.4092e-03],\n",
       "         [ 2.1439e-02, -2.2125e-03, -1.7242e-03,  ...,  1.6876e-02,\n",
       "           1.7883e-02,  1.8906e-02],\n",
       "         ...,\n",
       "         [-1.1940e-02, -3.6736e-03, -1.0368e-02,  ...,  6.2294e-03,\n",
       "          -1.0101e-02, -6.8188e-05],\n",
       "         [ 7.2174e-03,  8.4763e-03, -7.2784e-03,  ...,  9.9030e-03,\n",
       "           7.3013e-03, -1.3000e-02],\n",
       "         [-1.5396e-02,  1.3115e-02, -1.5137e-02,  ..., -1.0475e-02,\n",
       "          -9.6893e-03, -1.3351e-02]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_proj_out.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_proj_out.lora_down.weight': tensor([[ 0.0168, -0.0080, -0.0091,  ..., -0.0323,  0.0308, -0.0225],\n",
       "         [-0.0179,  0.0018,  0.0202,  ..., -0.0023, -0.0103, -0.0032],\n",
       "         [ 0.0004,  0.0036, -0.0053,  ..., -0.0036,  0.0451,  0.0100],\n",
       "         ...,\n",
       "         [-0.0126, -0.0074, -0.0189,  ..., -0.0366,  0.0052,  0.0263],\n",
       "         [ 0.0184, -0.0331, -0.0242,  ..., -0.0168,  0.0041, -0.0242],\n",
       "         [-0.0427, -0.0160, -0.0040,  ..., -0.0080,  0.0019, -0.0004]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_proj_out.lora_up.weight': tensor([[-0.0069, -0.0101,  0.0113,  ...,  0.0073,  0.0011,  0.0025],\n",
       "         [ 0.0181, -0.0159,  0.0100,  ...,  0.0035,  0.0285, -0.0340],\n",
       "         [ 0.0023,  0.0047,  0.0106,  ...,  0.0011,  0.0023, -0.0204],\n",
       "         ...,\n",
       "         [ 0.0027, -0.0032,  0.0157,  ...,  0.0078, -0.0115,  0.0153],\n",
       "         [ 0.0155,  0.0194, -0.0020,  ..., -0.0166, -0.0086,  0.0040],\n",
       "         [-0.0097, -0.0113, -0.0057,  ...,  0.0060,  0.0059, -0.0101]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_k.lora_down.weight': tensor([[ 0.0379,  0.0238,  0.0003,  ...,  0.0152,  0.0002, -0.0645],\n",
       "         [ 0.0242,  0.0052, -0.0098,  ...,  0.0140,  0.0052,  0.0204],\n",
       "         [ 0.0004,  0.0309, -0.0235,  ...,  0.0184,  0.0087, -0.0004],\n",
       "         ...,\n",
       "         [ 0.0190,  0.0010, -0.0137,  ...,  0.0136, -0.0080, -0.0490],\n",
       "         [ 0.0008,  0.0014, -0.0235,  ..., -0.0127,  0.0362,  0.0064],\n",
       "         [ 0.0172, -0.0036,  0.0267,  ...,  0.0227, -0.0007,  0.0084]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_k.lora_up.weight': tensor([[-0.0161,  0.0124, -0.0199,  ..., -0.0182,  0.0239,  0.0049],\n",
       "         [-0.0389,  0.0164, -0.0223,  ..., -0.0156,  0.0143, -0.0037],\n",
       "         [-0.0034,  0.0252, -0.0155,  ..., -0.0231,  0.0129,  0.0207],\n",
       "         ...,\n",
       "         [-0.0170,  0.0132, -0.0279,  ..., -0.0065, -0.0067, -0.0087],\n",
       "         [ 0.0211, -0.0273,  0.0243,  ...,  0.0282, -0.0327, -0.0146],\n",
       "         [-0.0153,  0.0035,  0.0037,  ...,  0.0271, -0.0158, -0.0039]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight': tensor([[ 0.0248, -0.0223,  0.0280,  ...,  0.0138, -0.0044, -0.0049],\n",
       "         [ 0.0595,  0.0130, -0.0172,  ..., -0.0017, -0.0290,  0.0079],\n",
       "         [ 0.0291, -0.0002,  0.0025,  ..., -0.0008,  0.0421, -0.0356],\n",
       "         ...,\n",
       "         [-0.0226,  0.0096, -0.0122,  ...,  0.0077, -0.0017, -0.0048],\n",
       "         [-0.0359, -0.0210, -0.0095,  ...,  0.0166,  0.0493, -0.0239],\n",
       "         [-0.0031, -0.0030,  0.0280,  ..., -0.0079,  0.0425,  0.0126]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight': tensor([[-0.0138, -0.0097,  0.0207,  ..., -0.0121,  0.0103, -0.0080],\n",
       "         [-0.0038, -0.0116,  0.0080,  ..., -0.0012,  0.0151,  0.0197],\n",
       "         [-0.0110, -0.0257,  0.0343,  ..., -0.0047,  0.0256,  0.0082],\n",
       "         ...,\n",
       "         [-0.0191, -0.0195,  0.0247,  ...,  0.0230,  0.0385, -0.0021],\n",
       "         [ 0.0154,  0.0002,  0.0021,  ...,  0.0026,  0.0107,  0.0348],\n",
       "         [-0.0140,  0.0241, -0.0132,  ..., -0.0050, -0.0106, -0.0106]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_q.lora_down.weight': tensor([[ 0.0142,  0.0059, -0.0299,  ..., -0.0272, -0.0236,  0.0027],\n",
       "         [ 0.0171,  0.0175, -0.0122,  ...,  0.0416,  0.0233, -0.0039],\n",
       "         [ 0.0039,  0.0014, -0.0060,  ..., -0.0224, -0.0064,  0.0048],\n",
       "         ...,\n",
       "         [ 0.0319,  0.0039,  0.0086,  ..., -0.0208, -0.0009,  0.0184],\n",
       "         [ 0.0359,  0.0421, -0.0368,  ..., -0.0093,  0.0352,  0.0372],\n",
       "         [ 0.0343,  0.0493,  0.0056,  ..., -0.0096, -0.0183,  0.0130]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_q.lora_up.weight': tensor([[-0.0170, -0.0214, -0.0032,  ..., -0.0100, -0.0136, -0.0067],\n",
       "         [ 0.0030, -0.0006, -0.0016,  ...,  0.0168, -0.0068,  0.0028],\n",
       "         [ 0.0153,  0.0101, -0.0161,  ...,  0.0137,  0.0038,  0.0201],\n",
       "         ...,\n",
       "         [ 0.0191,  0.0241, -0.0233,  ..., -0.0074,  0.0337,  0.0224],\n",
       "         [-0.0273, -0.0171,  0.0089,  ..., -0.0045, -0.0264,  0.0038],\n",
       "         [-0.0072,  0.0079, -0.0036,  ..., -0.0240,  0.0154,  0.0069]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_v.lora_down.weight': tensor([[ 0.0023, -0.0155,  0.0118,  ..., -0.0100,  0.0268,  0.0116],\n",
       "         [-0.0194,  0.0456,  0.0393,  ..., -0.0182,  0.0177, -0.0132],\n",
       "         [-0.0210, -0.0134,  0.0111,  ..., -0.0096, -0.0023, -0.0200],\n",
       "         ...,\n",
       "         [ 0.0336, -0.0237,  0.0315,  ..., -0.0190, -0.0167, -0.0002],\n",
       "         [ 0.0281,  0.0172,  0.0314,  ..., -0.0469,  0.0403,  0.0119],\n",
       "         [ 0.0169,  0.0353, -0.0109,  ..., -0.0244,  0.0005, -0.0078]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn1_to_v.lora_up.weight': tensor([[ 0.0166, -0.0060, -0.0427,  ...,  0.0406,  0.0060, -0.0185],\n",
       "         [-0.0094,  0.0028, -0.0110,  ...,  0.0170,  0.0175,  0.0128],\n",
       "         [-0.0295,  0.0193, -0.0015,  ...,  0.0021, -0.0033,  0.0231],\n",
       "         ...,\n",
       "         [-0.0133,  0.0121,  0.0182,  ..., -0.0080,  0.0264,  0.0108],\n",
       "         [ 0.0024, -0.0081, -0.0112,  ...,  0.0247,  0.0058, -0.0020],\n",
       "         [-0.0039,  0.0205,  0.0183,  ..., -0.0025,  0.0201, -0.0019]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_k.lora_down.weight': tensor([[ 0.0149, -0.0134,  0.0080,  ..., -0.0136,  0.0156,  0.0092],\n",
       "         [ 0.0405, -0.0061,  0.0097,  ..., -0.0157, -0.0083,  0.0331],\n",
       "         [ 0.0040,  0.0028, -0.0080,  ..., -0.0123,  0.0015,  0.0189],\n",
       "         ...,\n",
       "         [-0.0260, -0.0067,  0.0151,  ..., -0.0256,  0.0213, -0.0168],\n",
       "         [ 0.0324,  0.0187,  0.0146,  ...,  0.0130,  0.0111,  0.0080],\n",
       "         [ 0.0094,  0.0108, -0.0112,  ..., -0.0238,  0.0228,  0.0050]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_k.lora_up.weight': tensor([[ 0.0494,  0.0326,  0.0474,  ...,  0.0495,  0.0203, -0.0210],\n",
       "         [ 0.0084,  0.0070,  0.0050,  ...,  0.0028,  0.0194,  0.0031],\n",
       "         [ 0.0157, -0.0035,  0.0224,  ...,  0.0215, -0.0112, -0.0087],\n",
       "         ...,\n",
       "         [-0.0145,  0.0025, -0.0181,  ..., -0.0103, -0.0102,  0.0062],\n",
       "         [-0.0077, -0.0028, -0.0049,  ..., -0.0061, -0.0001, -0.0019],\n",
       "         [-0.0135, -0.0170, -0.0147,  ..., -0.0102, -0.0301,  0.0449]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight': tensor([[ 0.0470, -0.0268, -0.0205,  ...,  0.0148, -0.0193,  0.0137],\n",
       "         [ 0.0084, -0.0301,  0.0035,  ...,  0.0163, -0.0145, -0.0007],\n",
       "         [ 0.0424,  0.0125,  0.0086,  ...,  0.0037,  0.0280, -0.0257],\n",
       "         ...,\n",
       "         [ 0.0497, -0.0257, -0.0220,  ..., -0.0001,  0.0083, -0.0283],\n",
       "         [-0.0399,  0.0017, -0.0056,  ...,  0.0022,  0.0249,  0.0013],\n",
       "         [ 0.0366, -0.0102, -0.0125,  ..., -0.0227, -0.0235,  0.0211]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight': tensor([[ 5.7106e-03,  5.6686e-03,  8.9569e-03,  ..., -1.8616e-02,\n",
       "           2.7069e-02, -1.0121e-04],\n",
       "         [-1.3618e-02, -2.5818e-02,  1.0086e-02,  ..., -1.4305e-02,\n",
       "           1.5579e-02, -1.0117e-02],\n",
       "         [ 1.3237e-02,  1.5198e-02,  2.1271e-02,  ...,  2.2736e-02,\n",
       "          -1.3252e-02,  1.2238e-02],\n",
       "         ...,\n",
       "         [-1.0490e-02, -8.8043e-03, -8.2779e-03,  ...,  4.7874e-03,\n",
       "          -1.5915e-02,  1.8295e-02],\n",
       "         [-7.3776e-03, -3.1921e-02,  1.0803e-02,  ..., -3.6682e-02,\n",
       "           1.6785e-02, -2.6138e-02],\n",
       "         [ 5.2528e-03, -6.0043e-03,  1.0529e-02,  ..., -8.2374e-05,\n",
       "           1.1299e-02, -9.7942e-04]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_q.lora_down.weight': tensor([[ 0.0384,  0.0085, -0.0048,  ...,  0.0159, -0.0085,  0.0631],\n",
       "         [ 0.0101, -0.0093, -0.0058,  ..., -0.0121, -0.0098,  0.0197],\n",
       "         [-0.0223,  0.0005, -0.0303,  ..., -0.0465,  0.0336,  0.0413],\n",
       "         ...,\n",
       "         [ 0.0249, -0.0003, -0.0061,  ..., -0.0217, -0.0296, -0.0157],\n",
       "         [ 0.0017,  0.0084, -0.0032,  ..., -0.0053, -0.0008,  0.0023],\n",
       "         [-0.0209,  0.0091, -0.0345,  ...,  0.0093,  0.0098,  0.0055]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_q.lora_up.weight': tensor([[ 0.0083,  0.0137,  0.0042,  ..., -0.0013, -0.0022,  0.0212],\n",
       "         [-0.0049,  0.0056, -0.0330,  ...,  0.0004,  0.0145, -0.0246],\n",
       "         [-0.0098,  0.0159, -0.0023,  ...,  0.0060, -0.0148,  0.0019],\n",
       "         ...,\n",
       "         [-0.0003, -0.0152,  0.0026,  ...,  0.0094,  0.0230,  0.0028],\n",
       "         [ 0.0082, -0.0099, -0.0108,  ...,  0.0091,  0.0153, -0.0109],\n",
       "         [ 0.0127,  0.0328,  0.0173,  ..., -0.0164, -0.0479,  0.0183]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_v.lora_down.weight': tensor([[ 0.0160, -0.0098,  0.0050,  ..., -0.0418, -0.0004, -0.0215],\n",
       "         [ 0.0199, -0.0096,  0.0124,  ..., -0.0033,  0.0020,  0.0125],\n",
       "         [ 0.0199,  0.0212, -0.0041,  ..., -0.0152, -0.0038,  0.0168],\n",
       "         ...,\n",
       "         [-0.0190, -0.0104,  0.0253,  ...,  0.0303, -0.0111, -0.0054],\n",
       "         [-0.0099, -0.0241, -0.0089,  ...,  0.0023,  0.0056,  0.0113],\n",
       "         [-0.0140, -0.0097, -0.0159,  ...,  0.0173,  0.0108,  0.0184]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_attn2_to_v.lora_up.weight': tensor([[-0.0020,  0.0268,  0.0194,  ..., -0.0053, -0.0120, -0.0257],\n",
       "         [ 0.0188,  0.0129,  0.0087,  ..., -0.0230, -0.0210,  0.0013],\n",
       "         [-0.0110, -0.0036,  0.0010,  ...,  0.0117,  0.0115, -0.0061],\n",
       "         ...,\n",
       "         [-0.0050, -0.0179, -0.0184,  ...,  0.0068,  0.0097,  0.0275],\n",
       "         [ 0.0062,  0.0037,  0.0083,  ..., -0.0054, -0.0050, -0.0151],\n",
       "         [ 0.0191, -0.0056,  0.0019,  ..., -0.0103, -0.0051, -0.0015]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight': tensor([[ 0.0216, -0.0042,  0.0051,  ...,  0.0117, -0.0018,  0.0054],\n",
       "         [ 0.0297,  0.0320,  0.0020,  ..., -0.0229, -0.0454,  0.0010],\n",
       "         [-0.0085,  0.0356, -0.0309,  ...,  0.0215,  0.0081, -0.0303],\n",
       "         ...,\n",
       "         [-0.0305,  0.0064, -0.0136,  ...,  0.0180, -0.0184, -0.0031],\n",
       "         [ 0.0002, -0.0126,  0.0220,  ...,  0.0089, -0.0375, -0.0022],\n",
       "         [ 0.0077,  0.0632,  0.0055,  ..., -0.0302,  0.0092, -0.0244]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight': tensor([[ 0.0039,  0.0239, -0.0206,  ..., -0.0192, -0.0136,  0.0074],\n",
       "         [-0.0163,  0.0003,  0.0106,  ...,  0.0057,  0.0190,  0.0160],\n",
       "         [-0.0112,  0.0091,  0.0134,  ..., -0.0060, -0.0369,  0.0077],\n",
       "         ...,\n",
       "         [ 0.0095, -0.0092, -0.0102,  ...,  0.0226,  0.0037, -0.0051],\n",
       "         [-0.0165,  0.0324,  0.0348,  ...,  0.0194, -0.0150,  0.0357],\n",
       "         [ 0.0241,  0.0051, -0.0088,  ..., -0.0034,  0.0174,  0.0052]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_ff_net_2.lora_down.weight': tensor([[ 0.0166,  0.0298, -0.0023,  ...,  0.0251,  0.0081,  0.0075],\n",
       "         [-0.0108, -0.0329,  0.0323,  ..., -0.0082,  0.0097, -0.0062],\n",
       "         [-0.0047, -0.0093, -0.0040,  ...,  0.0147, -0.0155,  0.0129],\n",
       "         ...,\n",
       "         [ 0.0054,  0.0082, -0.0090,  ...,  0.0327, -0.0271,  0.0245],\n",
       "         [-0.0159, -0.0409,  0.0115,  ..., -0.0317, -0.0114, -0.0399],\n",
       "         [ 0.0224,  0.0300, -0.0246,  ...,  0.0100, -0.0192,  0.0101]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_0_ff_net_2.lora_up.weight': tensor([[-2.9736e-03,  1.3557e-02,  1.3626e-02,  ..., -1.6041e-03,\n",
       "          -5.3825e-03, -1.2646e-03],\n",
       "         [-4.3449e-03, -1.9958e-02, -1.0300e-02,  ...,  1.7576e-03,\n",
       "          -2.8114e-03, -1.1566e-02],\n",
       "         [ 1.9257e-02, -3.7140e-02, -1.4549e-02,  ..., -4.8752e-03,\n",
       "          -6.4373e-05,  5.3644e-04],\n",
       "         ...,\n",
       "         [ 2.7447e-03,  1.8097e-02,  7.1526e-05,  ...,  8.1873e-04,\n",
       "           1.5182e-02, -1.0742e-02],\n",
       "         [ 2.1423e-02, -1.1959e-03, -5.8784e-03,  ..., -7.3814e-03,\n",
       "          -1.4610e-02,  8.0261e-03],\n",
       "         [ 9.3307e-03,  6.2828e-03,  1.1871e-02,  ..., -8.8425e-03,\n",
       "          -5.4073e-04, -1.5602e-02]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_k.lora_down.weight': tensor([[ 0.0136, -0.0527,  0.0103,  ...,  0.0241, -0.0152, -0.0543],\n",
       "         [ 0.0453, -0.0052,  0.0305,  ...,  0.0172,  0.0538,  0.0283],\n",
       "         [ 0.0089,  0.0481,  0.0533,  ..., -0.0316, -0.0336,  0.0242],\n",
       "         ...,\n",
       "         [ 0.0058, -0.0164,  0.0042,  ...,  0.0448,  0.0034,  0.0064],\n",
       "         [-0.0127,  0.0574,  0.0176,  ..., -0.0320, -0.0295,  0.0063],\n",
       "         [ 0.0026,  0.0346,  0.0197,  ...,  0.0346, -0.0365,  0.0338]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_k.lora_up.weight': tensor([[ 2.8133e-03,  1.6281e-02, -2.5681e-02,  ...,  5.5122e-03,\n",
       "           1.5305e-02, -1.5656e-02],\n",
       "         [ 5.0163e-03,  4.3373e-03, -1.3176e-02,  ..., -3.5820e-03,\n",
       "           1.1116e-02, -1.5266e-02],\n",
       "         [-2.2430e-02,  1.7883e-02,  1.7405e-03,  ...,  2.6817e-03,\n",
       "           1.0078e-02, -4.0588e-03],\n",
       "         ...,\n",
       "         [ 1.8326e-02, -1.5793e-02, -1.7593e-02,  ..., -1.9455e-02,\n",
       "           1.9531e-02, -1.2718e-02],\n",
       "         [-1.0536e-02, -9.3043e-05,  7.9880e-03,  ..., -2.3918e-03,\n",
       "          -1.8921e-02, -2.5139e-03],\n",
       "         [ 4.3535e-04, -3.3844e-02,  3.1338e-03,  ..., -2.9114e-02,\n",
       "           2.4231e-02,  4.2610e-03]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_out_0.lora_down.weight': tensor([[ 0.0168, -0.0034,  0.0321,  ..., -0.0195,  0.0203,  0.0127],\n",
       "         [ 0.0068, -0.0246,  0.0020,  ...,  0.0144,  0.0062, -0.0070],\n",
       "         [ 0.0076,  0.0178,  0.0182,  ..., -0.0028,  0.0061,  0.0072],\n",
       "         ...,\n",
       "         [ 0.0151, -0.0033, -0.0255,  ...,  0.0241,  0.0272, -0.0537],\n",
       "         [ 0.0458, -0.0331,  0.0298,  ..., -0.0232, -0.0327,  0.0084],\n",
       "         [ 0.0127,  0.0308,  0.0198,  ..., -0.0283,  0.0077,  0.0406]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_out_0.lora_up.weight': tensor([[-0.0001, -0.0229,  0.0111,  ...,  0.0094,  0.0083, -0.0100],\n",
       "         [ 0.0120,  0.0016, -0.0005,  ...,  0.0030,  0.0080,  0.0123],\n",
       "         [ 0.0189, -0.0220, -0.0074,  ..., -0.0092,  0.0221,  0.0048],\n",
       "         ...,\n",
       "         [-0.0116,  0.0174, -0.0187,  ..., -0.0013, -0.0127, -0.0074],\n",
       "         [-0.0104,  0.0172,  0.0088,  ...,  0.0009, -0.0122, -0.0152],\n",
       "         [-0.0148,  0.0046, -0.0124,  ..., -0.0121,  0.0081,  0.0303]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_q.lora_down.weight': tensor([[-0.0276, -0.0305, -0.0065,  ..., -0.0195, -0.0108, -0.0046],\n",
       "         [-0.0194,  0.0076, -0.0240,  ..., -0.0218, -0.0041, -0.0247],\n",
       "         [-0.0022,  0.0128, -0.0298,  ..., -0.0101, -0.0363,  0.0099],\n",
       "         ...,\n",
       "         [ 0.0134, -0.0330,  0.0152,  ..., -0.0180,  0.0172,  0.0122],\n",
       "         [-0.0081,  0.0289,  0.0305,  ...,  0.0165, -0.0047, -0.0078],\n",
       "         [ 0.0104,  0.0181, -0.0019,  ...,  0.0316, -0.0121, -0.0180]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_q.lora_up.weight': tensor([[ 0.0157, -0.0005, -0.0258,  ...,  0.0124, -0.0155,  0.0187],\n",
       "         [-0.0194,  0.0132,  0.0090,  ..., -0.0249, -0.0042,  0.0057],\n",
       "         [-0.0020,  0.0166, -0.0163,  ...,  0.0158,  0.0155, -0.0278],\n",
       "         ...,\n",
       "         [-0.0128, -0.0168, -0.0147,  ..., -0.0140, -0.0092,  0.0161],\n",
       "         [-0.0155, -0.0089,  0.0243,  ...,  0.0108,  0.0042,  0.0131],\n",
       "         [-0.0053, -0.0105, -0.0002,  ...,  0.0090, -0.0133,  0.0025]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_v.lora_down.weight': tensor([[-0.0236,  0.0004,  0.0061,  ..., -0.0309, -0.0019, -0.0178],\n",
       "         [ 0.0321,  0.0300,  0.0442,  ...,  0.0280, -0.0315, -0.0090],\n",
       "         [-0.0004, -0.0079,  0.0030,  ...,  0.0057,  0.0024,  0.0114],\n",
       "         ...,\n",
       "         [-0.0253, -0.0334, -0.0162,  ...,  0.0202,  0.0155, -0.0172],\n",
       "         [-0.0051,  0.0412, -0.0267,  ..., -0.0045, -0.0010, -0.0109],\n",
       "         [ 0.0327,  0.0356,  0.0088,  ..., -0.0014,  0.0108, -0.0204]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn1_to_v.lora_up.weight': tensor([[-0.0094,  0.0245,  0.0255,  ...,  0.0121,  0.0070,  0.0402],\n",
       "         [-0.0032,  0.0009,  0.0200,  ..., -0.0247, -0.0396, -0.0116],\n",
       "         [ 0.0158, -0.0203, -0.0108,  ...,  0.0031, -0.0206, -0.0196],\n",
       "         ...,\n",
       "         [ 0.0163, -0.0119, -0.0089,  ...,  0.0170,  0.0163,  0.0049],\n",
       "         [ 0.0141, -0.0012,  0.0248,  ...,  0.0244,  0.0229,  0.0386],\n",
       "         [ 0.0150, -0.0415, -0.0234,  ..., -0.0143, -0.0050, -0.0375]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_k.lora_down.weight': tensor([[-0.0395, -0.0085, -0.0175,  ...,  0.0150,  0.0052, -0.0011],\n",
       "         [ 0.0381, -0.0030,  0.0370,  ..., -0.0271,  0.0311,  0.0353],\n",
       "         [-0.0038,  0.0187,  0.0105,  ..., -0.0435, -0.0042,  0.0398],\n",
       "         ...,\n",
       "         [-0.0375, -0.0187, -0.0267,  ...,  0.0011, -0.0217, -0.0142],\n",
       "         [-0.0457, -0.0084,  0.0022,  ...,  0.0126,  0.0202, -0.0269],\n",
       "         [ 0.0136,  0.0099,  0.0214,  ..., -0.0167, -0.0240,  0.0225]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_k.lora_up.weight': tensor([[-0.0074,  0.0033, -0.0018,  ...,  0.0053, -0.0054,  0.0029],\n",
       "         [-0.0170,  0.0233,  0.0289,  ..., -0.0246, -0.0175,  0.0170],\n",
       "         [ 0.0082, -0.0111, -0.0120,  ...,  0.0151,  0.0121, -0.0107],\n",
       "         ...,\n",
       "         [ 0.0062, -0.0052, -0.0066,  ...,  0.0100,  0.0121, -0.0112],\n",
       "         [ 0.0149, -0.0190, -0.0222,  ...,  0.0203,  0.0269, -0.0209],\n",
       "         [ 0.0026, -0.0081, -0.0118,  ...,  0.0124,  0.0066, -0.0056]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_out_0.lora_down.weight': tensor([[ 3.3302e-03,  9.5673e-03, -6.4969e-06,  ...,  2.3361e-02,\n",
       "          -6.0921e-03,  1.5976e-02],\n",
       "         [ 3.0270e-03, -8.4066e-04, -2.8687e-02,  ..., -3.6377e-02,\n",
       "           6.7635e-03,  1.3786e-02],\n",
       "         [ 6.5918e-03,  1.0445e-02,  7.6628e-04,  ..., -2.1408e-02,\n",
       "          -2.1267e-03,  2.8648e-03],\n",
       "         ...,\n",
       "         [-1.4061e-02,  1.5915e-02, -7.9956e-03,  ..., -2.2781e-02,\n",
       "           1.9012e-02, -1.7136e-02],\n",
       "         [-2.5436e-02,  1.5459e-03, -1.6113e-02,  ...,  2.0187e-02,\n",
       "          -2.7557e-02, -1.0376e-02],\n",
       "         [-1.8539e-02, -1.7929e-02,  2.2736e-02,  ...,  1.2169e-02,\n",
       "          -1.3947e-02,  8.4000e-03]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_out_0.lora_up.weight': tensor([[ 0.0110,  0.0119,  0.0010,  ...,  0.0148, -0.0005,  0.0211],\n",
       "         [-0.0051, -0.0014, -0.0063,  ..., -0.0216, -0.0027, -0.0160],\n",
       "         [ 0.0023,  0.0030, -0.0038,  ..., -0.0012, -0.0039, -0.0077],\n",
       "         ...,\n",
       "         [-0.0265, -0.0246,  0.0266,  ...,  0.0005,  0.0289, -0.0075],\n",
       "         [ 0.0103,  0.0221, -0.0139,  ..., -0.0091, -0.0170, -0.0066],\n",
       "         [ 0.0112,  0.0014, -0.0022,  ...,  0.0001, -0.0099,  0.0099]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_q.lora_down.weight': tensor([[-0.0166, -0.0170,  0.0054,  ..., -0.0169, -0.0247, -0.0017],\n",
       "         [-0.0277, -0.0046,  0.0076,  ..., -0.0108,  0.0141,  0.0006],\n",
       "         [-0.0151,  0.0304, -0.0069,  ..., -0.0106,  0.0333, -0.0508],\n",
       "         ...,\n",
       "         [-0.0177, -0.0151, -0.0020,  ...,  0.0247, -0.0126,  0.0061],\n",
       "         [ 0.0132, -0.0291,  0.0117,  ..., -0.0181, -0.0082,  0.0122],\n",
       "         [ 0.0160,  0.0188,  0.0366,  ..., -0.0216,  0.0356,  0.0111]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_q.lora_up.weight': tensor([[-0.0275,  0.0164,  0.0305,  ...,  0.0013,  0.0105,  0.0197],\n",
       "         [-0.0324,  0.0133,  0.0378,  ..., -0.0005,  0.0137,  0.0262],\n",
       "         [ 0.0256, -0.0128, -0.0296,  ...,  0.0093,  0.0011, -0.0153],\n",
       "         ...,\n",
       "         [ 0.0231, -0.0109, -0.0403,  ...,  0.0024,  0.0073, -0.0280],\n",
       "         [-0.0192,  0.0021,  0.0351,  ...,  0.0082,  0.0114,  0.0235],\n",
       "         [-0.0156, -0.0003,  0.0305,  ...,  0.0170,  0.0238,  0.0239]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_v.lora_down.weight': tensor([[-3.7518e-03,  1.3130e-02, -1.0277e-02,  ...,  3.0258e-02,\n",
       "           1.9178e-03, -1.6632e-02],\n",
       "         [ 1.0712e-02,  6.8512e-03,  7.9575e-03,  ..., -2.3529e-02,\n",
       "           9.8114e-03, -1.4580e-02],\n",
       "         [ 1.4015e-02,  2.4521e-02,  1.4694e-02,  ..., -2.2960e-04,\n",
       "           5.6190e-03,  2.4509e-03],\n",
       "         ...,\n",
       "         [ 1.8890e-02,  5.6839e-04,  1.5114e-02,  ..., -4.8561e-03,\n",
       "          -1.3489e-02, -1.3657e-02],\n",
       "         [ 3.4988e-05, -1.2093e-02,  9.3155e-03,  ...,  9.8724e-03,\n",
       "           1.3222e-02, -1.2711e-02],\n",
       "         [-1.1108e-02,  3.6287e-04, -5.8479e-03,  ...,  2.3224e-02,\n",
       "           5.9700e-03, -7.8735e-03]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_attn2_to_v.lora_up.weight': tensor([[ 0.0113, -0.0135, -0.0083,  ..., -0.0131, -0.0213,  0.0138],\n",
       "         [-0.0245,  0.0374,  0.0200,  ...,  0.0287, -0.0039, -0.0203],\n",
       "         [-0.0164,  0.0219,  0.0158,  ...,  0.0204,  0.0018, -0.0163],\n",
       "         ...,\n",
       "         [-0.0022,  0.0047,  0.0091,  ...,  0.0025, -0.0014,  0.0034],\n",
       "         [ 0.0172, -0.0086, -0.0127,  ..., -0.0106, -0.0407,  0.0256],\n",
       "         [-0.0053, -0.0048,  0.0003,  ..., -0.0091,  0.0066, -0.0089]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_ff_net_0_proj.lora_down.weight': tensor([[-2.8503e-02, -5.5618e-03,  1.2436e-02,  ...,  2.6112e-03,\n",
       "          -3.7384e-03, -2.5391e-02],\n",
       "         [ 6.8130e-03, -9.6130e-03,  1.2947e-02,  ...,  3.0861e-03,\n",
       "          -4.2915e-03,  5.9853e-03],\n",
       "         [-4.7646e-03,  8.4381e-03,  1.6266e-02,  ...,  3.9124e-02,\n",
       "          -5.4047e-02,  2.6779e-02],\n",
       "         ...,\n",
       "         [-2.4395e-03,  3.7842e-02, -7.4923e-05,  ...,  1.6113e-02,\n",
       "          -3.0823e-02, -4.3869e-03],\n",
       "         [-2.4338e-02,  5.1025e-02, -2.7206e-02,  ...,  3.7885e-04,\n",
       "          -2.0355e-02, -1.8173e-02],\n",
       "         [-2.9449e-02,  1.5427e-02,  3.1464e-02,  ..., -1.7685e-02,\n",
       "          -2.5120e-03, -8.0795e-03]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_ff_net_0_proj.lora_up.weight': tensor([[ 0.0109,  0.0123,  0.0169,  ...,  0.0053,  0.0286,  0.0194],\n",
       "         [ 0.0186,  0.0115, -0.0416,  ..., -0.0056, -0.0006,  0.0118],\n",
       "         [-0.0154, -0.0078,  0.0026,  ...,  0.0079,  0.0289, -0.0112],\n",
       "         ...,\n",
       "         [ 0.0015,  0.0084,  0.0191,  ...,  0.0003, -0.0170,  0.0008],\n",
       "         [ 0.0035,  0.0112, -0.0245,  ...,  0.0076,  0.0273,  0.0323],\n",
       "         [ 0.0120,  0.0185, -0.0141,  ..., -0.0155, -0.0061,  0.0115]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_ff_net_2.lora_down.weight': tensor([[-0.0089, -0.0384, -0.0161,  ..., -0.0152,  0.0370, -0.0109],\n",
       "         [-0.0349,  0.0359,  0.0201,  ..., -0.0177, -0.0569, -0.0132],\n",
       "         [-0.0078,  0.0278,  0.0046,  ..., -0.0078, -0.0141, -0.0042],\n",
       "         ...,\n",
       "         [-0.0154,  0.0121,  0.0087,  ..., -0.0100, -0.0240,  0.0017],\n",
       "         [ 0.0106, -0.0214, -0.0058,  ..., -0.0037,  0.0265,  0.0129],\n",
       "         [ 0.0185, -0.0162, -0.0174,  ...,  0.0099,  0.0296, -0.0018]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_1_ff_net_2.lora_up.weight': tensor([[-0.0176,  0.0087,  0.0056,  ...,  0.0099, -0.0087, -0.0107],\n",
       "         [ 0.0137, -0.0146, -0.0072,  ..., -0.0076,  0.0062,  0.0050],\n",
       "         [ 0.0132, -0.0237,  0.0028,  ..., -0.0048,  0.0037, -0.0104],\n",
       "         ...,\n",
       "         [-0.0104, -0.0099,  0.0197,  ...,  0.0087, -0.0111, -0.0117],\n",
       "         [ 0.0191, -0.0102, -0.0168,  ..., -0.0168,  0.0098,  0.0109],\n",
       "         [-0.0048, -0.0061,  0.0186,  ..., -0.0080, -0.0171, -0.0063]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_k.lora_down.weight': tensor([[-0.0301,  0.0302, -0.0050,  ...,  0.0134,  0.0037,  0.0212],\n",
       "         [ 0.0204,  0.0106, -0.0123,  ...,  0.0224,  0.0083,  0.0253],\n",
       "         [-0.0056,  0.0125, -0.0294,  ..., -0.0163, -0.0094, -0.0256],\n",
       "         ...,\n",
       "         [ 0.0108, -0.0140, -0.0223,  ..., -0.0059,  0.0226,  0.0186],\n",
       "         [-0.0073, -0.0112, -0.0097,  ..., -0.0012, -0.0171, -0.0007],\n",
       "         [-0.0129, -0.0419,  0.0158,  ..., -0.0085, -0.0273,  0.0389]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_k.lora_up.weight': tensor([[ 0.0023, -0.0224, -0.0034,  ..., -0.0016, -0.0046,  0.0066],\n",
       "         [ 0.0072,  0.0280, -0.0160,  ...,  0.0306, -0.0324, -0.0023],\n",
       "         [ 0.0280,  0.0026,  0.0235,  ...,  0.0211, -0.0276,  0.0170],\n",
       "         ...,\n",
       "         [-0.0218, -0.0107, -0.0034,  ..., -0.0243,  0.0029,  0.0066],\n",
       "         [-0.0046,  0.0102, -0.0265,  ...,  0.0439,  0.0023,  0.0104],\n",
       "         [ 0.0026,  0.0228, -0.0184,  ...,  0.0204, -0.0019, -0.0032]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_out_0.lora_down.weight': tensor([[ 0.0121, -0.0236, -0.0162,  ..., -0.0061, -0.0088, -0.0191],\n",
       "         [ 0.0153, -0.0054, -0.0060,  ...,  0.0053, -0.0116, -0.0179],\n",
       "         [-0.0186, -0.0023,  0.0046,  ...,  0.0072,  0.0040,  0.0029],\n",
       "         ...,\n",
       "         [-0.0252, -0.0217,  0.0125,  ...,  0.0474,  0.0435,  0.0366],\n",
       "         [-0.0274,  0.0126,  0.0209,  ...,  0.0229,  0.0368,  0.0024],\n",
       "         [-0.0099,  0.0109,  0.0218,  ...,  0.0253,  0.0011, -0.0082]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_out_0.lora_up.weight': tensor([[-0.0006, -0.0002,  0.0183,  ..., -0.0133, -0.0108,  0.0175],\n",
       "         [-0.0062,  0.0082,  0.0237,  ...,  0.0020,  0.0226, -0.0009],\n",
       "         [ 0.0009,  0.0096,  0.0109,  ..., -0.0149,  0.0094,  0.0074],\n",
       "         ...,\n",
       "         [-0.0088, -0.0076, -0.0235,  ...,  0.0289,  0.0111, -0.0062],\n",
       "         [ 0.0129,  0.0163,  0.0048,  ...,  0.0136,  0.0246,  0.0221],\n",
       "         [-0.0178, -0.0061,  0.0166,  ...,  0.0014,  0.0102, -0.0247]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_q.lora_down.weight': tensor([[-0.0075,  0.0335, -0.0334,  ..., -0.0327, -0.0045, -0.0174],\n",
       "         [-0.0151,  0.0134, -0.0425,  ..., -0.0079, -0.0290,  0.0108],\n",
       "         [ 0.0417,  0.0269,  0.0008,  ..., -0.0354, -0.0133,  0.0144],\n",
       "         ...,\n",
       "         [-0.0149,  0.0355, -0.0081,  ..., -0.0332, -0.0114,  0.0275],\n",
       "         [ 0.0023, -0.0386,  0.0201,  ...,  0.0014,  0.0344,  0.0081],\n",
       "         [ 0.0012, -0.0252, -0.0065,  ...,  0.0264,  0.0318,  0.0295]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_q.lora_up.weight': tensor([[-3.1052e-03, -9.9564e-03, -4.0550e-03,  ..., -1.0269e-02,\n",
       "           8.9569e-03,  1.0712e-02],\n",
       "         [ 7.2517e-03,  7.2746e-03,  7.5302e-03,  ...,  2.7084e-02,\n",
       "          -4.4861e-03, -1.9638e-02],\n",
       "         [ 4.9171e-03,  7.8812e-03,  1.9436e-03,  ...,  1.2245e-02,\n",
       "          -1.2772e-02, -5.7793e-03],\n",
       "         ...,\n",
       "         [-8.7891e-03,  1.5175e-04,  4.3321e-04,  ..., -2.3098e-03,\n",
       "          -5.1308e-04,  1.2718e-02],\n",
       "         [ 8.1558e-03, -2.7657e-03,  8.9951e-03,  ...,  1.1597e-02,\n",
       "          -2.0187e-02, -1.6815e-02],\n",
       "         [-5.4240e-05, -1.2733e-02,  2.1103e-02,  ...,  9.8877e-03,\n",
       "          -4.5357e-03, -1.6800e-02]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_v.lora_down.weight': tensor([[ 0.0089, -0.0365,  0.0118,  ..., -0.0156,  0.0203,  0.0325],\n",
       "         [-0.0226, -0.0292,  0.0131,  ..., -0.0029,  0.0046, -0.0288],\n",
       "         [-0.0105, -0.0042, -0.0180,  ..., -0.0239,  0.0021,  0.0084],\n",
       "         ...,\n",
       "         [ 0.0230, -0.0065, -0.0113,  ..., -0.0267, -0.0198, -0.0110],\n",
       "         [ 0.0207,  0.0320,  0.0005,  ..., -0.0119, -0.0190,  0.0191],\n",
       "         [-0.0247, -0.0178, -0.0064,  ...,  0.0242, -0.0077,  0.0336]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn1_to_v.lora_up.weight': tensor([[-0.0368, -0.0268,  0.0107,  ...,  0.0065,  0.0290, -0.0159],\n",
       "         [ 0.0100,  0.0146,  0.0006,  ..., -0.0089, -0.0086,  0.0016],\n",
       "         [-0.0206, -0.0131,  0.0406,  ...,  0.0051,  0.0282,  0.0235],\n",
       "         ...,\n",
       "         [ 0.0181,  0.0241, -0.0017,  ..., -0.0154, -0.0083,  0.0235],\n",
       "         [ 0.0115,  0.0107, -0.0210,  ..., -0.0200, -0.0051,  0.0048],\n",
       "         [ 0.0025,  0.0035, -0.0137,  ..., -0.0026,  0.0181,  0.0147]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_k.lora_down.weight': tensor([[ 4.4405e-05, -1.3866e-03,  4.5013e-02,  ..., -2.7664e-02,\n",
       "           4.1595e-02,  1.5717e-03],\n",
       "         [ 1.9703e-03,  1.4923e-02,  2.7527e-02,  ..., -2.5726e-02,\n",
       "           2.3514e-02,  3.9101e-05],\n",
       "         [ 9.5901e-03, -8.9111e-03, -5.7373e-03,  ...,  5.9128e-03,\n",
       "          -1.8326e-02, -2.5654e-03],\n",
       "         ...,\n",
       "         [ 2.2629e-02,  9.1248e-03, -2.7267e-02,  ...,  4.5471e-02,\n",
       "          -2.5005e-03,  1.4122e-02],\n",
       "         [-2.0065e-02, -1.7120e-02,  2.7573e-02,  ..., -1.7532e-02,\n",
       "          -8.5373e-03,  3.5000e-03],\n",
       "         [-4.1565e-02, -1.4320e-02, -4.7531e-03,  ..., -2.7756e-02,\n",
       "           2.1324e-03, -2.1768e-04]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_k.lora_up.weight': tensor([[ 0.0016,  0.0078, -0.0040,  ..., -0.0057, -0.0029,  0.0039],\n",
       "         [ 0.0056,  0.0078,  0.0063,  ..., -0.0083, -0.0035, -0.0043],\n",
       "         [-0.0007, -0.0107,  0.0031,  ...,  0.0064, -0.0126, -0.0047],\n",
       "         ...,\n",
       "         [-0.0239, -0.0044,  0.0014,  ...,  0.0110, -0.0003, -0.0009],\n",
       "         [ 0.0250,  0.0155, -0.0125,  ..., -0.0197,  0.0007,  0.0123],\n",
       "         [ 0.0232,  0.0015, -0.0049,  ..., -0.0047, -0.0019,  0.0016]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_out_0.lora_down.weight': tensor([[ 0.0209, -0.0028,  0.0282,  ...,  0.0005, -0.0186, -0.0005],\n",
       "         [-0.0169, -0.0128, -0.0027,  ..., -0.0341,  0.0140,  0.0083],\n",
       "         [ 0.0017,  0.0112,  0.0037,  ...,  0.0152, -0.0321,  0.0322],\n",
       "         ...,\n",
       "         [ 0.0230,  0.0216,  0.0107,  ...,  0.0001,  0.0273,  0.0289],\n",
       "         [ 0.0198, -0.0118, -0.0162,  ...,  0.0165, -0.0053, -0.0209],\n",
       "         [-0.0051, -0.0072,  0.0011,  ...,  0.0173, -0.0215,  0.0275]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_out_0.lora_up.weight': tensor([[ 0.0092,  0.0230,  0.0064,  ...,  0.0036, -0.0164,  0.0226],\n",
       "         [-0.0095, -0.0025, -0.0205,  ...,  0.0009,  0.0091, -0.0088],\n",
       "         [-0.0164, -0.0120, -0.0173,  ..., -0.0162,  0.0124, -0.0161],\n",
       "         ...,\n",
       "         [ 0.0036, -0.0034, -0.0033,  ...,  0.0052,  0.0003, -0.0021],\n",
       "         [ 0.0059, -0.0062,  0.0018,  ...,  0.0107,  0.0031, -0.0062],\n",
       "         [ 0.0053,  0.0021, -0.0040,  ...,  0.0033, -0.0014,  0.0073]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_q.lora_down.weight': tensor([[-0.0105,  0.0004, -0.0233,  ..., -0.0158,  0.0187, -0.0153],\n",
       "         [ 0.0075, -0.0175, -0.0072,  ..., -0.0062,  0.0191, -0.0137],\n",
       "         [ 0.0015, -0.0083, -0.0086,  ..., -0.0125,  0.0234,  0.0206],\n",
       "         ...,\n",
       "         [-0.0277, -0.0016,  0.0112,  ...,  0.0100, -0.0214, -0.0056],\n",
       "         [ 0.0262,  0.0651, -0.0171,  ...,  0.0132, -0.0085,  0.0256],\n",
       "         [-0.0050,  0.0230, -0.0292,  ..., -0.0322, -0.0133, -0.0203]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_q.lora_up.weight': tensor([[-5.0583e-03, -2.4357e-03, -8.3008e-03,  ..., -7.3166e-03,\n",
       "           1.1429e-02, -5.2452e-05],\n",
       "         [ 3.4294e-03, -1.2350e-03, -3.6564e-03,  ..., -8.4915e-03,\n",
       "           1.6312e-02, -4.4250e-03],\n",
       "         [ 1.2421e-02, -2.1229e-03,  9.3231e-03,  ..., -8.7814e-03,\n",
       "           2.1957e-02, -1.4107e-02],\n",
       "         ...,\n",
       "         [ 2.4536e-02, -1.8859e-04,  1.4442e-02,  ...,  1.0347e-03,\n",
       "           1.4282e-02, -3.1967e-03],\n",
       "         [-2.6169e-02, -1.9424e-02, -1.2398e-02,  ...,  2.6611e-02,\n",
       "          -1.4549e-02, -1.7776e-02],\n",
       "         [-1.1391e-02, -1.3260e-02, -4.4785e-03,  ...,  2.0660e-02,\n",
       "           1.7900e-03, -1.2924e-02]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_v.lora_down.weight': tensor([[ 0.0290, -0.0047, -0.0198,  ...,  0.0102, -0.0112, -0.0143],\n",
       "         [ 0.0120,  0.0142,  0.0056,  ..., -0.0169, -0.0134,  0.0186],\n",
       "         [-0.0020,  0.0111, -0.0241,  ..., -0.0233,  0.0015, -0.0102],\n",
       "         ...,\n",
       "         [ 0.0077,  0.0015, -0.0022,  ...,  0.0089, -0.0029,  0.0028],\n",
       "         [ 0.0062, -0.0134,  0.0253,  ...,  0.0051,  0.0143,  0.0103],\n",
       "         [ 0.0090, -0.0323,  0.0079,  ..., -0.0113, -0.0046, -0.0012]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_attn2_to_v.lora_up.weight': tensor([[ 0.0157,  0.0161,  0.0172,  ..., -0.0172, -0.0177, -0.0225],\n",
       "         [-0.0085,  0.0046, -0.0056,  ..., -0.0005,  0.0091,  0.0092],\n",
       "         [-0.0400, -0.0246, -0.0040,  ...,  0.0070,  0.0078,  0.0378],\n",
       "         ...,\n",
       "         [-0.0162, -0.0258, -0.0086,  ...,  0.0082,  0.0087,  0.0401],\n",
       "         [-0.0286, -0.0263, -0.0150,  ...,  0.0155,  0.0086,  0.0258],\n",
       "         [ 0.0106, -0.0018, -0.0081,  ...,  0.0183, -0.0024, -0.0105]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_ff_net_0_proj.lora_down.weight': tensor([[ 0.0140,  0.0095, -0.0166,  ..., -0.0309, -0.0403,  0.0141],\n",
       "         [-0.0161, -0.0234, -0.0106,  ...,  0.0333,  0.0027, -0.0040],\n",
       "         [-0.0422, -0.0220, -0.0182,  ..., -0.0102, -0.0048,  0.0307],\n",
       "         ...,\n",
       "         [ 0.0086,  0.0143, -0.0048,  ..., -0.0423, -0.0281,  0.0503],\n",
       "         [ 0.0075, -0.0063, -0.0073,  ...,  0.0166, -0.0155, -0.0004],\n",
       "         [ 0.0125, -0.0212,  0.0137,  ...,  0.0066, -0.0298, -0.0017]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_ff_net_0_proj.lora_up.weight': tensor([[-0.0151, -0.0318, -0.0111,  ...,  0.0047,  0.0140, -0.0075],\n",
       "         [ 0.0102,  0.0076, -0.0048,  ..., -0.0074,  0.0011,  0.0036],\n",
       "         [ 0.0014, -0.0420, -0.0052,  ...,  0.0132, -0.0036,  0.0022],\n",
       "         ...,\n",
       "         [ 0.0056, -0.0487, -0.0017,  ...,  0.0025,  0.0200,  0.0053],\n",
       "         [-0.0106, -0.0508,  0.0176,  ..., -0.0475,  0.0354, -0.0162],\n",
       "         [ 0.0130,  0.0058, -0.0048,  ..., -0.0050, -0.0070,  0.0049]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_ff_net_2.lora_down.weight': tensor([[-0.0047, -0.0036,  0.0109,  ...,  0.0065, -0.0155, -0.0094],\n",
       "         [ 0.0406, -0.0155, -0.0246,  ...,  0.0017, -0.0083, -0.0176],\n",
       "         [ 0.0027,  0.0218,  0.0073,  ..., -0.0254,  0.0034, -0.0075],\n",
       "         ...,\n",
       "         [-0.0199, -0.0128,  0.0141,  ..., -0.0112, -0.0156,  0.0060],\n",
       "         [-0.0270, -0.0070, -0.0006,  ...,  0.0155,  0.0147, -0.0134],\n",
       "         [ 0.0107, -0.0063, -0.0146,  ...,  0.0149, -0.0022,  0.0215]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_2_ff_net_2.lora_up.weight': tensor([[-0.0082, -0.0044,  0.0155,  ...,  0.0093, -0.0121, -0.0135],\n",
       "         [ 0.0029,  0.0007,  0.0022,  ..., -0.0152, -0.0007, -0.0045],\n",
       "         [ 0.0051,  0.0040,  0.0056,  ..., -0.0122, -0.0045, -0.0092],\n",
       "         ...,\n",
       "         [ 0.0156, -0.0090,  0.0223,  ...,  0.0183, -0.0033, -0.0164],\n",
       "         [ 0.0051, -0.0065,  0.0029,  ...,  0.0136,  0.0013,  0.0030],\n",
       "         [ 0.0050,  0.0046, -0.0063,  ..., -0.0042,  0.0136,  0.0029]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_k.lora_down.weight': tensor([[-0.0535,  0.0093, -0.0381,  ..., -0.0306, -0.0062, -0.0048],\n",
       "         [-0.0530,  0.0010, -0.0363,  ...,  0.0170,  0.0182,  0.0330],\n",
       "         [ 0.0448, -0.0114,  0.0063,  ..., -0.0474, -0.0406,  0.0249],\n",
       "         ...,\n",
       "         [ 0.0095, -0.0072,  0.0043,  ..., -0.0033,  0.0116,  0.0062],\n",
       "         [-0.0249,  0.0209, -0.0292,  ..., -0.0035,  0.0336, -0.0243],\n",
       "         [ 0.0177,  0.0033, -0.0003,  ..., -0.0136,  0.0217, -0.0133]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_k.lora_up.weight': tensor([[-0.0066, -0.0178,  0.0145,  ..., -0.0277,  0.0054,  0.0366],\n",
       "         [ 0.0131,  0.0038,  0.0074,  ..., -0.0014, -0.0179, -0.0078],\n",
       "         [-0.0021, -0.0417,  0.0164,  ..., -0.0001,  0.0112,  0.0664],\n",
       "         ...,\n",
       "         [-0.0221,  0.0107,  0.0153,  ...,  0.0011, -0.0168, -0.0195],\n",
       "         [ 0.0047, -0.0130,  0.0029,  ...,  0.0073, -0.0249, -0.0152],\n",
       "         [-0.0176, -0.0058,  0.0141,  ..., -0.0058,  0.0159,  0.0247]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_out_0.lora_down.weight': tensor([[ 2.7328e-02, -1.8101e-03,  4.5624e-03,  ..., -4.7821e-02,\n",
       "           3.0197e-02,  1.0895e-02],\n",
       "         [ 1.8036e-02, -1.3550e-02, -2.7332e-03,  ..., -1.2764e-02,\n",
       "           5.3711e-02, -2.5177e-02],\n",
       "         [-4.2358e-02,  1.3710e-02,  2.0386e-02,  ...,  1.4130e-02,\n",
       "          -5.0873e-02,  1.7681e-03],\n",
       "         ...,\n",
       "         [-2.3453e-02, -2.1027e-02, -2.5467e-02,  ..., -2.5497e-02,\n",
       "           4.3213e-02, -1.2794e-02],\n",
       "         [-3.8940e-02,  2.3895e-02, -4.8981e-03,  ...,  3.5339e-02,\n",
       "          -1.8280e-02,  1.6022e-02],\n",
       "         [-4.0131e-02,  2.4963e-02, -1.5518e-02,  ..., -2.1338e-05,\n",
       "          -3.0624e-02, -1.8606e-03]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_out_0.lora_up.weight': tensor([[-0.0231,  0.0130, -0.0004,  ..., -0.0107, -0.0018, -0.0005],\n",
       "         [ 0.0053, -0.0085, -0.0016,  ...,  0.0165, -0.0023, -0.0043],\n",
       "         [-0.0224,  0.0005,  0.0086,  ..., -0.0140,  0.0124,  0.0100],\n",
       "         ...,\n",
       "         [ 0.0194, -0.0038, -0.0089,  ..., -0.0054,  0.0102,  0.0026],\n",
       "         [ 0.0164,  0.0144, -0.0187,  ...,  0.0001, -0.0150, -0.0127],\n",
       "         [-0.0350, -0.0272,  0.0346,  ..., -0.0167,  0.0165,  0.0175]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_q.lora_down.weight': tensor([[ 0.0208, -0.0070,  0.0096,  ...,  0.0398, -0.0327, -0.0067],\n",
       "         [ 0.0130, -0.0323,  0.0096,  ..., -0.0199,  0.0055, -0.0144],\n",
       "         [ 0.0135, -0.0269,  0.0085,  ...,  0.0108, -0.0166, -0.0227],\n",
       "         ...,\n",
       "         [-0.0067,  0.0172,  0.0186,  ..., -0.0091,  0.0469, -0.0316],\n",
       "         [ 0.0303,  0.0543, -0.0014,  ..., -0.0025, -0.0069,  0.0078],\n",
       "         [ 0.0508,  0.0105,  0.0324,  ...,  0.0201, -0.0193,  0.0072]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_q.lora_up.weight': tensor([[ 0.0052,  0.0158, -0.0002,  ..., -0.0064, -0.0179, -0.0316],\n",
       "         [ 0.0147,  0.0032,  0.0175,  ..., -0.0012, -0.0005,  0.0030],\n",
       "         [ 0.0013, -0.0070,  0.0008,  ...,  0.0110,  0.0109,  0.0233],\n",
       "         ...,\n",
       "         [-0.0223, -0.0207,  0.0096,  ..., -0.0087,  0.0125, -0.0040],\n",
       "         [-0.0258, -0.0166,  0.0117,  ..., -0.0209,  0.0161, -0.0055],\n",
       "         [-0.0175, -0.0140, -0.0100,  ...,  0.0048,  0.0176,  0.0090]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_v.lora_down.weight': tensor([[-0.0299, -0.0281,  0.0112,  ...,  0.0339,  0.0515, -0.0076],\n",
       "         [ 0.0323,  0.0230,  0.0166,  ..., -0.0072, -0.0500,  0.0033],\n",
       "         [ 0.0091,  0.0268,  0.0092,  ..., -0.0008, -0.0410,  0.0372],\n",
       "         ...,\n",
       "         [ 0.0131,  0.0362, -0.0203,  ..., -0.0254, -0.0337,  0.0418],\n",
       "         [ 0.0048, -0.0045,  0.0068,  ...,  0.0590,  0.0273, -0.0296],\n",
       "         [ 0.0114, -0.0126, -0.0136,  ..., -0.0209,  0.0456, -0.0332]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn1_to_v.lora_up.weight': tensor([[-0.0011, -0.0081,  0.0048,  ...,  0.0042, -0.0081, -0.0083],\n",
       "         [ 0.0393, -0.0453, -0.0427,  ..., -0.0316,  0.0430,  0.0297],\n",
       "         [ 0.0051,  0.0007, -0.0008,  ...,  0.0015,  0.0084,  0.0029],\n",
       "         ...,\n",
       "         [ 0.0082,  0.0074, -0.0048,  ..., -0.0087,  0.0020,  0.0059],\n",
       "         [ 0.0037, -0.0245, -0.0042,  ..., -0.0135,  0.0160,  0.0159],\n",
       "         [-0.0165,  0.0226,  0.0098,  ...,  0.0263, -0.0176, -0.0210]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_k.lora_down.weight': tensor([[-0.0206, -0.0015,  0.0108,  ...,  0.0153,  0.0158,  0.0054],\n",
       "         [ 0.0113, -0.0053,  0.0214,  ..., -0.0004, -0.0104,  0.0177],\n",
       "         [ 0.0253,  0.0049,  0.0208,  ..., -0.0181, -0.0141,  0.0276],\n",
       "         ...,\n",
       "         [-0.0115, -0.0222,  0.0228,  ...,  0.0143, -0.0212, -0.0078],\n",
       "         [ 0.0051, -0.0132,  0.0089,  ...,  0.0072, -0.0009,  0.0201],\n",
       "         [-0.0061, -0.0267, -0.0014,  ..., -0.0219, -0.0121,  0.0208]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_k.lora_up.weight': tensor([[ 0.0129, -0.0120, -0.0090,  ..., -0.0122, -0.0122, -0.0113],\n",
       "         [-0.0045,  0.0035,  0.0012,  ...,  0.0036,  0.0038,  0.0030],\n",
       "         [-0.0043,  0.0022,  0.0024,  ...,  0.0008,  0.0005,  0.0039],\n",
       "         ...,\n",
       "         [-0.0080,  0.0066,  0.0035,  ...,  0.0037,  0.0061,  0.0067],\n",
       "         [ 0.0072, -0.0054, -0.0056,  ..., -0.0070, -0.0046, -0.0057],\n",
       "         [-0.0199,  0.0244,  0.0254,  ...,  0.0228,  0.0227,  0.0235]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_out_0.lora_down.weight': tensor([[-0.0103,  0.0336, -0.0126,  ..., -0.0247,  0.0039, -0.0121],\n",
       "         [-0.0255,  0.0035,  0.0200,  ..., -0.0156,  0.0426, -0.0103],\n",
       "         [ 0.0282, -0.0102,  0.0053,  ...,  0.0039,  0.0025, -0.0053],\n",
       "         ...,\n",
       "         [ 0.0231, -0.0118,  0.0111,  ...,  0.0028, -0.0017, -0.0165],\n",
       "         [ 0.0065, -0.0042, -0.0260,  ...,  0.0241, -0.0152,  0.0262],\n",
       "         [-0.0349, -0.0389,  0.0176,  ..., -0.0223,  0.0164, -0.0234]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_out_0.lora_up.weight': tensor([[ 0.0109, -0.0048,  0.0196,  ..., -0.0205,  0.0094,  0.0228],\n",
       "         [ 0.0043, -0.0112,  0.0079,  ..., -0.0132,  0.0127, -0.0022],\n",
       "         [-0.0007,  0.0040, -0.0075,  ...,  0.0145,  0.0036, -0.0574],\n",
       "         ...,\n",
       "         [ 0.0131, -0.0075,  0.0205,  ..., -0.0216, -0.0054,  0.0187],\n",
       "         [-0.0104, -0.0069, -0.0098,  ...,  0.0083,  0.0010,  0.0268],\n",
       "         [-0.0052,  0.0091, -0.0053,  ...,  0.0019, -0.0089,  0.0052]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_q.lora_down.weight': tensor([[ 0.0056, -0.0269,  0.0176,  ...,  0.0096, -0.0407,  0.0067],\n",
       "         [-0.0014,  0.0048, -0.0108,  ..., -0.0291,  0.0085,  0.0155],\n",
       "         [-0.0066,  0.0133, -0.0152,  ...,  0.0065,  0.0038,  0.0260],\n",
       "         ...,\n",
       "         [ 0.0107,  0.0253,  0.0154,  ...,  0.0087, -0.0408, -0.0017],\n",
       "         [ 0.0389,  0.0003,  0.0144,  ..., -0.0136,  0.0008,  0.0445],\n",
       "         [-0.0186,  0.0406, -0.0085,  ..., -0.0187, -0.0098, -0.0399]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_q.lora_up.weight': tensor([[ 7.6332e-03, -4.2953e-03,  3.1281e-02,  ..., -1.2802e-02,\n",
       "           8.2855e-03, -1.4717e-02],\n",
       "         [-4.4861e-03,  6.0463e-03, -3.2135e-02,  ...,  1.5366e-02,\n",
       "          -2.5902e-03,  8.8425e-03],\n",
       "         [ 9.0179e-03, -3.5763e-03,  3.2318e-02,  ..., -1.3832e-02,\n",
       "           1.0094e-02, -1.7136e-02],\n",
       "         ...,\n",
       "         [ 3.0861e-03,  1.7462e-03, -4.5128e-03,  ..., -1.1391e-02,\n",
       "           1.2665e-02, -1.2474e-02],\n",
       "         [ 4.1656e-03, -1.7047e-05, -4.5395e-03,  ..., -1.0284e-02,\n",
       "           1.1948e-02, -1.4442e-02],\n",
       "         [-2.1064e-04,  3.0422e-03, -3.2406e-03,  ..., -9.8877e-03,\n",
       "           1.4450e-02, -8.9111e-03]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_v.lora_down.weight': tensor([[ 1.2604e-02,  1.9547e-02,  1.8951e-02,  ..., -3.0875e-05,\n",
       "           1.9379e-02,  1.6815e-02],\n",
       "         [-1.4477e-03, -1.6647e-02, -1.1940e-02,  ...,  4.7798e-03,\n",
       "           1.5345e-03,  1.3817e-02],\n",
       "         [ 1.3466e-02,  2.2827e-02, -2.0111e-02,  ...,  2.0782e-02,\n",
       "          -1.1124e-02, -1.0521e-02],\n",
       "         ...,\n",
       "         [ 5.3177e-03,  2.6596e-02,  4.3893e-04,  ..., -7.6027e-03,\n",
       "          -1.6983e-02,  3.4275e-03],\n",
       "         [ 1.7176e-03,  1.8005e-02, -2.4551e-02,  ..., -1.4503e-02,\n",
       "           2.7294e-03,  1.7105e-02],\n",
       "         [-1.8799e-02,  1.6846e-02, -1.6159e-02,  ...,  8.6517e-03,\n",
       "           3.1924e-04,  7.6151e-04]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_attn2_to_v.lora_up.weight': tensor([[ 0.0040, -0.0038, -0.0122,  ...,  0.0219,  0.0028, -0.0111],\n",
       "         [-0.0041, -0.0062,  0.0076,  ..., -0.0247, -0.0117, -0.0029],\n",
       "         [-0.0016,  0.0040,  0.0048,  ..., -0.0061, -0.0074,  0.0032],\n",
       "         ...,\n",
       "         [-0.0084,  0.0118, -0.0051,  ...,  0.0047,  0.0066,  0.0109],\n",
       "         [ 0.0028, -0.0032,  0.0050,  ..., -0.0210, -0.0007,  0.0029],\n",
       "         [ 0.0092, -0.0027, -0.0097,  ...,  0.0037,  0.0056, -0.0050]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_ff_net_0_proj.lora_down.weight': tensor([[ 0.0280,  0.0064,  0.0274,  ...,  0.0055,  0.0259, -0.0345],\n",
       "         [-0.0138,  0.0181,  0.0116,  ...,  0.0164,  0.0191, -0.0196],\n",
       "         [ 0.0423,  0.0158,  0.0198,  ..., -0.0262, -0.0059,  0.0145],\n",
       "         ...,\n",
       "         [-0.0012, -0.0016, -0.0176,  ...,  0.0027, -0.0110,  0.0423],\n",
       "         [ 0.0126, -0.0199,  0.0161,  ...,  0.0249, -0.0258,  0.0057],\n",
       "         [ 0.0427, -0.0243, -0.0208,  ..., -0.0059,  0.0206, -0.0212]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_ff_net_0_proj.lora_up.weight': tensor([[ 3.2883e-03, -2.7351e-03, -9.1171e-04,  ...,  6.5536e-03,\n",
       "           5.1079e-03,  3.5187e-02],\n",
       "         [ 2.7990e-04, -7.0877e-03, -9.2545e-03,  ...,  1.0872e-02,\n",
       "           1.7679e-04,  4.4983e-02],\n",
       "         [-9.8114e-03,  5.0583e-03,  2.0695e-03,  ...,  3.9482e-03,\n",
       "          -3.6716e-03,  1.8341e-02],\n",
       "         ...,\n",
       "         [-1.0658e-02,  1.1406e-03, -6.9847e-03,  ..., -1.3359e-02,\n",
       "          -3.6240e-04,  2.2411e-03],\n",
       "         [-2.1877e-03,  1.0674e-02, -9.7198e-03,  ..., -3.5324e-03,\n",
       "           1.4175e-02, -3.2558e-03],\n",
       "         [ 8.2397e-03, -1.3733e-02,  2.2903e-02,  ...,  1.7654e-02,\n",
       "          -1.7105e-02,  5.1677e-05]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_ff_net_2.lora_down.weight': tensor([[-0.0136, -0.0243,  0.0070,  ...,  0.0159,  0.0080, -0.0037],\n",
       "         [ 0.0082, -0.0169,  0.0171,  ..., -0.0071,  0.0033,  0.0186],\n",
       "         [-0.0163,  0.0016, -0.0025,  ...,  0.0110, -0.0125, -0.0101],\n",
       "         ...,\n",
       "         [-0.0064,  0.0108, -0.0024,  ...,  0.0099,  0.0026, -0.0220],\n",
       "         [ 0.0045,  0.0097,  0.0071,  ...,  0.0054,  0.0204, -0.0202],\n",
       "         [-0.0143, -0.0300, -0.0110,  ...,  0.0136, -0.0149,  0.0003]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_3_ff_net_2.lora_up.weight': tensor([[-0.0103, -0.0061,  0.0096,  ...,  0.0141,  0.0027,  0.0121],\n",
       "         [ 0.0121,  0.0079,  0.0015,  ..., -0.0120,  0.0147, -0.0083],\n",
       "         [ 0.0027, -0.0058,  0.0037,  ..., -0.0023, -0.0004,  0.0107],\n",
       "         ...,\n",
       "         [-0.0152, -0.0117,  0.0196,  ...,  0.0138, -0.0203,  0.0276],\n",
       "         [-0.0127, -0.0087, -0.0045,  ...,  0.0015,  0.0097, -0.0093],\n",
       "         [ 0.0174,  0.0016, -0.0024,  ..., -0.0079, -0.0246,  0.0211]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_k.lora_down.weight': tensor([[ 0.0224,  0.0011, -0.0073,  ..., -0.0062, -0.0234, -0.0285],\n",
       "         [ 0.0288, -0.0443,  0.0451,  ..., -0.0177, -0.0342,  0.0275],\n",
       "         [-0.0035, -0.0010, -0.0267,  ...,  0.0340,  0.0045, -0.0071],\n",
       "         ...,\n",
       "         [ 0.0185,  0.0067, -0.0362,  ...,  0.0113,  0.0136,  0.0014],\n",
       "         [ 0.0134,  0.0208, -0.0296,  ...,  0.0111, -0.0238, -0.0235],\n",
       "         [ 0.0125,  0.0090, -0.0032,  ...,  0.0333, -0.0273, -0.0136]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_k.lora_up.weight': tensor([[-0.0012, -0.0096,  0.0120,  ..., -0.0211, -0.0182,  0.0002],\n",
       "         [ 0.0202, -0.0217,  0.0096,  ...,  0.0100,  0.0285,  0.0098],\n",
       "         [-0.0143, -0.0049,  0.0050,  ...,  0.0064,  0.0151,  0.0225],\n",
       "         ...,\n",
       "         [-0.0083,  0.0241, -0.0037,  ...,  0.0201, -0.0144,  0.0006],\n",
       "         [-0.0046,  0.0235, -0.0135,  ..., -0.0131, -0.0132, -0.0092],\n",
       "         [ 0.0014,  0.0179, -0.0061,  ...,  0.0195, -0.0028,  0.0035]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_out_0.lora_down.weight': tensor([[-0.0101, -0.0024, -0.0155,  ..., -0.0138,  0.0078, -0.0342],\n",
       "         [-0.0300,  0.0032,  0.0050,  ...,  0.0069,  0.0498,  0.0082],\n",
       "         [ 0.0027,  0.0133,  0.0073,  ...,  0.0131,  0.0079,  0.0095],\n",
       "         ...,\n",
       "         [ 0.0151,  0.0224,  0.0068,  ...,  0.0041,  0.0235,  0.0208],\n",
       "         [ 0.0129,  0.0223,  0.0043,  ...,  0.0091,  0.0014,  0.0244],\n",
       "         [ 0.0061,  0.0116,  0.0284,  ...,  0.0036, -0.0013, -0.0122]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_out_0.lora_up.weight': tensor([[ 6.5765e-03, -1.3542e-03,  3.3545e-04,  ..., -1.0284e-02,\n",
       "          -1.5022e-02,  4.9820e-03],\n",
       "         [ 4.7874e-03,  2.1484e-02, -2.4071e-03,  ...,  1.4786e-02,\n",
       "           8.4686e-03, -4.4937e-03],\n",
       "         [ 1.1871e-02,  7.7934e-03,  1.6232e-03,  ...,  3.7518e-03,\n",
       "          -8.7891e-03,  1.9131e-03],\n",
       "         ...,\n",
       "         [ 6.3095e-03, -3.0380e-02, -5.2032e-03,  ...,  3.6449e-03,\n",
       "           4.4513e-04,  1.3666e-03],\n",
       "         [-1.4305e-02, -9.1324e-03, -9.8267e-03,  ..., -4.2992e-03,\n",
       "          -4.4136e-03, -1.0133e-06],\n",
       "         [-1.4771e-02, -6.9847e-03, -1.9760e-02,  ...,  1.9211e-02,\n",
       "           2.6779e-02, -1.0902e-02]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_q.lora_down.weight': tensor([[-0.0190,  0.0040, -0.0211,  ...,  0.0010,  0.0235,  0.0041],\n",
       "         [-0.0107,  0.0197,  0.0190,  ..., -0.0266, -0.0077, -0.0042],\n",
       "         [ 0.0137,  0.0111, -0.0201,  ...,  0.0097, -0.0048, -0.0373],\n",
       "         ...,\n",
       "         [ 0.0121, -0.0197,  0.0149,  ...,  0.0399,  0.0304,  0.0424],\n",
       "         [ 0.0161, -0.0123,  0.0133,  ...,  0.0055,  0.0137,  0.0440],\n",
       "         [-0.0096, -0.0109, -0.0240,  ...,  0.0133, -0.0156, -0.0129]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_q.lora_up.weight': tensor([[-0.0067,  0.0159, -0.0002,  ...,  0.0287,  0.0183, -0.0055],\n",
       "         [-0.0192, -0.0095, -0.0090,  ..., -0.0073, -0.0241, -0.0033],\n",
       "         [ 0.0038, -0.0001,  0.0432,  ...,  0.0024,  0.0057,  0.0077],\n",
       "         ...,\n",
       "         [-0.0273, -0.0149,  0.0107,  ..., -0.0051,  0.0003,  0.0050],\n",
       "         [ 0.0004, -0.0023, -0.0058,  ..., -0.0063,  0.0036,  0.0073],\n",
       "         [ 0.0110,  0.0033, -0.0262,  ..., -0.0134, -0.0013,  0.0032]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_v.lora_down.weight': tensor([[ 0.0046,  0.0074,  0.0069,  ...,  0.0019, -0.0556,  0.0230],\n",
       "         [ 0.0108,  0.0239, -0.0273,  ..., -0.0108, -0.0005,  0.0304],\n",
       "         [-0.0368, -0.0124, -0.0058,  ..., -0.0098,  0.0512, -0.0308],\n",
       "         ...,\n",
       "         [ 0.0259, -0.0051, -0.0202,  ...,  0.0177,  0.0106, -0.0096],\n",
       "         [ 0.0380, -0.0105,  0.0241,  ...,  0.0032, -0.0306, -0.0210],\n",
       "         [-0.0235, -0.0298,  0.0045,  ...,  0.0226,  0.0532, -0.0210]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn1_to_v.lora_up.weight': tensor([[ 0.0270,  0.0074, -0.0224,  ...,  0.0206,  0.0270, -0.0306],\n",
       "         [ 0.0006,  0.0168,  0.0079,  ...,  0.0137,  0.0126,  0.0006],\n",
       "         [-0.0038, -0.0045,  0.0007,  ..., -0.0109,  0.0070,  0.0022],\n",
       "         ...,\n",
       "         [ 0.0090, -0.0067, -0.0128,  ..., -0.0160, -0.0155, -0.0146],\n",
       "         [ 0.0123, -0.0079, -0.0150,  ..., -0.0080, -0.0127, -0.0141],\n",
       "         [-0.0039, -0.0096,  0.0021,  ..., -0.0015, -0.0005,  0.0034]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_k.lora_down.weight': tensor([[ 0.0032,  0.0017, -0.0070,  ..., -0.0255,  0.0009,  0.0060],\n",
       "         [ 0.0064, -0.0056, -0.0090,  ...,  0.0381,  0.0084, -0.0066],\n",
       "         [ 0.0124,  0.0038,  0.0425,  ..., -0.0091,  0.0130,  0.0146],\n",
       "         ...,\n",
       "         [-0.0090,  0.0098,  0.0112,  ..., -0.0271,  0.0074,  0.0247],\n",
       "         [-0.0010,  0.0170,  0.0161,  ..., -0.0021, -0.0228, -0.0049],\n",
       "         [-0.0055, -0.0079, -0.0053,  ..., -0.0032,  0.0036, -0.0054]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_k.lora_up.weight': tensor([[ 0.0224, -0.0230,  0.0203,  ...,  0.0217,  0.0213,  0.0154],\n",
       "         [-0.0192,  0.0212, -0.0224,  ..., -0.0230, -0.0221, -0.0164],\n",
       "         [ 0.0298, -0.0305,  0.0277,  ...,  0.0277,  0.0288,  0.0220],\n",
       "         ...,\n",
       "         [ 0.0149, -0.0113,  0.0114,  ...,  0.0094,  0.0086,  0.0112],\n",
       "         [-0.0213,  0.0109, -0.0142,  ..., -0.0128, -0.0138, -0.0229],\n",
       "         [-0.0054,  0.0067, -0.0044,  ..., -0.0014, -0.0040, -0.0022]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_out_0.lora_down.weight': tensor([[ 0.0223,  0.0185, -0.0046,  ..., -0.0236, -0.0059, -0.0241],\n",
       "         [ 0.0099, -0.0301,  0.0117,  ...,  0.0015, -0.0306,  0.0390],\n",
       "         [-0.0229, -0.0088,  0.0193,  ..., -0.0199,  0.0205,  0.0103],\n",
       "         ...,\n",
       "         [-0.0296,  0.0442, -0.0134,  ...,  0.0287, -0.0188,  0.0118],\n",
       "         [ 0.0180, -0.0571,  0.0215,  ..., -0.0053,  0.0103,  0.0142],\n",
       "         [ 0.0152,  0.0471,  0.0261,  ...,  0.0120,  0.0257,  0.0062]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_out_0.lora_up.weight': tensor([[-0.0036,  0.0126,  0.0117,  ...,  0.0086,  0.0071, -0.0164],\n",
       "         [-0.0028, -0.0019, -0.0024,  ...,  0.0107, -0.0097,  0.0070],\n",
       "         [ 0.0052, -0.0097, -0.0056,  ...,  0.0044, -0.0074,  0.0247],\n",
       "         ...,\n",
       "         [ 0.0101, -0.0126, -0.0091,  ...,  0.0193, -0.0153,  0.0106],\n",
       "         [ 0.0052, -0.0130, -0.0092,  ..., -0.0071, -0.0037, -0.0089],\n",
       "         [-0.0139,  0.0166,  0.0136,  ..., -0.0106,  0.0134, -0.0188]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_q.lora_down.weight': tensor([[-6.2332e-03,  1.4671e-02,  1.3176e-02,  ..., -5.5847e-02,\n",
       "          -4.7424e-02,  3.7628e-02],\n",
       "         [ 7.6981e-03, -2.3246e-06,  2.3117e-02,  ..., -3.7140e-02,\n",
       "          -3.8940e-02,  3.0807e-02],\n",
       "         [ 4.4891e-02, -3.1509e-03,  1.3901e-02,  ..., -1.6785e-02,\n",
       "          -1.1997e-03, -3.6865e-02],\n",
       "         ...,\n",
       "         [ 1.9875e-03,  3.3234e-02, -2.2873e-02,  ..., -4.6356e-02,\n",
       "          -2.1439e-02, -3.9978e-02],\n",
       "         [-2.3098e-03,  9.8267e-03, -4.2839e-03,  ...,  1.5625e-02,\n",
       "           8.0948e-03, -4.4632e-03],\n",
       "         [ 7.3166e-03, -2.2259e-03,  1.0017e-02,  ..., -4.5135e-02,\n",
       "           4.0474e-03, -4.0131e-03]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_q.lora_up.weight': tensor([[ 0.0041,  0.0080, -0.0128,  ..., -0.0106, -0.0151, -0.0042],\n",
       "         [-0.0083, -0.0085,  0.0111,  ...,  0.0068,  0.0127, -0.0018],\n",
       "         [ 0.0073,  0.0083, -0.0118,  ..., -0.0082, -0.0130, -0.0011],\n",
       "         ...,\n",
       "         [ 0.0110,  0.0035, -0.0068,  ...,  0.0071, -0.0009,  0.0089],\n",
       "         [-0.0074, -0.0067,  0.0017,  ...,  0.0030,  0.0043, -0.0070],\n",
       "         [ 0.0017, -0.0024, -0.0073,  ...,  0.0136,  0.0082,  0.0092]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_v.lora_down.weight': tensor([[-0.0091,  0.0058, -0.0106,  ..., -0.0088, -0.0115,  0.0072],\n",
       "         [ 0.0221,  0.0101, -0.0113,  ..., -0.0239,  0.0062, -0.0238],\n",
       "         [-0.0102, -0.0079,  0.0126,  ..., -0.0098,  0.0224, -0.0047],\n",
       "         ...,\n",
       "         [ 0.0198, -0.0099,  0.0169,  ..., -0.0193,  0.0207, -0.0201],\n",
       "         [ 0.0040, -0.0211, -0.0140,  ...,  0.0050, -0.0015,  0.0230],\n",
       "         [-0.0172,  0.0194, -0.0186,  ...,  0.0127,  0.0096,  0.0173]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_attn2_to_v.lora_up.weight': tensor([[-6.4354e-03, -4.0512e-03, -4.8447e-03,  ..., -1.7490e-03,\n",
       "           2.9640e-03, -3.0479e-03],\n",
       "         [ 7.0524e-04, -2.9564e-03, -5.9605e-06,  ..., -1.2503e-03,\n",
       "           3.5954e-03,  1.6069e-03],\n",
       "         [ 1.6495e-02,  2.2110e-02, -2.3560e-02,  ...,  2.1713e-02,\n",
       "          -2.3041e-02,  1.8997e-02],\n",
       "         ...,\n",
       "         [-1.1574e-02, -3.0701e-02,  1.4259e-02,  ..., -2.1240e-02,\n",
       "           3.0350e-02, -1.1269e-02],\n",
       "         [-7.3471e-03,  9.1782e-03, -1.3428e-02,  ...,  7.6714e-03,\n",
       "          -9.4681e-03,  3.2711e-03],\n",
       "         [ 2.4128e-03,  2.5406e-03,  1.6602e-02,  ..., -2.6894e-03,\n",
       "           1.4343e-03, -2.8267e-03]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_ff_net_0_proj.lora_down.weight': tensor([[ 2.3819e-02, -1.0290e-03, -1.7761e-02,  ...,  9.9182e-03,\n",
       "          -5.0812e-03, -1.7395e-02],\n",
       "         [-1.8143e-02,  1.2680e-02,  3.0258e-02,  ...,  7.4043e-03,\n",
       "          -2.0691e-02, -7.6141e-03],\n",
       "         [-1.7075e-02,  1.5144e-03,  2.7908e-02,  ...,  3.2501e-02,\n",
       "          -2.8458e-02,  1.3790e-03],\n",
       "         ...,\n",
       "         [ 4.3373e-03,  2.9862e-05, -9.0942e-03,  ...,  3.9856e-02,\n",
       "           3.7292e-02,  4.7913e-03],\n",
       "         [ 2.4063e-02,  1.8295e-02, -2.3234e-04,  ...,  1.5388e-02,\n",
       "          -1.5854e-02, -6.2037e-04],\n",
       "         [-3.0041e-03, -4.0161e-02,  1.2238e-02,  ...,  3.1528e-03,\n",
       "          -3.7079e-03, -2.6627e-02]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_ff_net_0_proj.lora_up.weight': tensor([[-1.8234e-02, -9.0332e-03,  8.8577e-03,  ..., -1.4252e-02,\n",
       "          -4.6997e-03, -1.4259e-02],\n",
       "         [ 9.6512e-03,  1.7090e-02,  8.1406e-03,  ..., -1.3742e-03,\n",
       "           1.1726e-02, -2.2125e-03],\n",
       "         [ 4.4212e-03, -1.4086e-03,  6.8045e-04,  ...,  1.1238e-02,\n",
       "          -5.1575e-03,  9.9411e-03],\n",
       "         ...,\n",
       "         [ 4.5280e-03,  6.4316e-03,  5.0545e-04,  ..., -6.5625e-05,\n",
       "           7.5951e-03, -1.1650e-02],\n",
       "         [-3.4313e-03, -2.8809e-02, -2.3865e-02,  ...,  7.8583e-03,\n",
       "          -2.9205e-02,  3.8788e-02],\n",
       "         [ 4.2206e-02,  4.0070e-02,  1.2032e-02,  ..., -2.9755e-03,\n",
       "           3.3691e-02, -8.8043e-03]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_ff_net_2.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_ff_net_2.lora_down.weight': tensor([[-0.0251, -0.0220, -0.0183,  ...,  0.0191, -0.0075, -0.0087],\n",
       "         [ 0.0169,  0.0534,  0.0059,  ..., -0.0165,  0.0276,  0.0063],\n",
       "         [-0.0134, -0.0358,  0.0050,  ..., -0.0064, -0.0384, -0.0045],\n",
       "         ...,\n",
       "         [-0.0102, -0.0142, -0.0054,  ...,  0.0172, -0.0103, -0.0214],\n",
       "         [ 0.0137,  0.0529,  0.0161,  ...,  0.0038,  0.0094,  0.0057],\n",
       "         [-0.0128, -0.0136, -0.0109,  ...,  0.0055, -0.0299, -0.0222]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_4_ff_net_2.lora_up.weight': tensor([[-0.0111,  0.0012, -0.0052,  ..., -0.0060,  0.0079, -0.0079],\n",
       "         [ 0.0083, -0.0293,  0.0105,  ...,  0.0068, -0.0160,  0.0105],\n",
       "         [-0.0054, -0.0117,  0.0069,  ..., -0.0025,  0.0081, -0.0024],\n",
       "         ...,\n",
       "         [-0.0183, -0.0044, -0.0057,  ..., -0.0124, -0.0024, -0.0047],\n",
       "         [ 0.0061,  0.0103, -0.0083,  ..., -0.0037,  0.0034, -0.0103],\n",
       "         [-0.0020, -0.0007, -0.0037,  ..., -0.0032,  0.0030,  0.0044]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_k.lora_down.weight': tensor([[-4.5204e-03,  5.6744e-04, -2.1774e-02,  ...,  5.9967e-03,\n",
       "           6.5918e-03, -2.8763e-02],\n",
       "         [ 3.3539e-02,  5.1689e-04,  1.6098e-02,  ...,  4.6478e-02,\n",
       "          -3.1292e-05, -1.7258e-02],\n",
       "         [ 3.1982e-02,  3.7140e-02,  3.7018e-02,  ..., -2.0943e-03,\n",
       "           1.5678e-03, -2.2018e-02],\n",
       "         ...,\n",
       "         [-7.1068e-03,  3.1414e-03, -3.2898e-02,  ...,  4.5349e-02,\n",
       "          -2.2949e-02,  1.7929e-02],\n",
       "         [-2.8000e-02,  1.4153e-02, -7.3280e-03,  ..., -2.7023e-02,\n",
       "           1.7242e-02, -8.5754e-03],\n",
       "         [ 6.8817e-03,  1.9272e-02,  1.8356e-02,  ..., -5.8105e-02,\n",
       "           4.4037e-02, -4.7684e-03]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_k.lora_up.weight': tensor([[ 0.0236, -0.0331,  0.0041,  ...,  0.0173,  0.0037,  0.0050],\n",
       "         [ 0.0019, -0.0168, -0.0065,  ..., -0.0034,  0.0082, -0.0054],\n",
       "         [ 0.0323, -0.0285, -0.0311,  ..., -0.0268, -0.0048,  0.0130],\n",
       "         ...,\n",
       "         [ 0.0043,  0.0165,  0.0089,  ...,  0.0020,  0.0031,  0.0030],\n",
       "         [-0.0351,  0.0011, -0.0091,  ...,  0.0057,  0.0098, -0.0101],\n",
       "         [-0.0301,  0.0135, -0.0139,  ...,  0.0032,  0.0041, -0.0059]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_out_0.lora_down.weight': tensor([[-0.0260, -0.0024, -0.0297,  ..., -0.0225,  0.0159,  0.0228],\n",
       "         [ 0.0336,  0.0162,  0.0022,  ...,  0.0397, -0.0220,  0.0018],\n",
       "         [-0.0237, -0.0151,  0.0235,  ..., -0.0155,  0.0162,  0.0231],\n",
       "         ...,\n",
       "         [-0.0299,  0.0193,  0.0100,  ..., -0.0078,  0.0107, -0.0006],\n",
       "         [ 0.0002,  0.0046, -0.0197,  ..., -0.0011,  0.0266,  0.0157],\n",
       "         [-0.0029,  0.0064, -0.0340,  ...,  0.0210,  0.0190,  0.0341]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_out_0.lora_up.weight': tensor([[-0.0039,  0.0106, -0.0091,  ...,  0.0007, -0.0013, -0.0029],\n",
       "         [-0.0106, -0.0010,  0.0178,  ..., -0.0018, -0.0005, -0.0001],\n",
       "         [-0.0008,  0.0067, -0.0062,  ..., -0.0131,  0.0218,  0.0137],\n",
       "         ...,\n",
       "         [-0.0031,  0.0045, -0.0129,  ..., -0.0019,  0.0076,  0.0338],\n",
       "         [-0.0083,  0.0101,  0.0027,  ..., -0.0035,  0.0079,  0.0040],\n",
       "         [-0.0044,  0.0039, -0.0131,  ..., -0.0182, -0.0020, -0.0092]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_q.lora_down.weight': tensor([[-0.0342, -0.0347, -0.0577,  ...,  0.0338,  0.0252,  0.0030],\n",
       "         [ 0.0183,  0.0294, -0.0365,  ..., -0.0061, -0.0020, -0.0522],\n",
       "         [-0.0514, -0.0307,  0.0027,  ..., -0.0359,  0.0001,  0.0086],\n",
       "         ...,\n",
       "         [-0.0119,  0.0207,  0.0305,  ..., -0.0151, -0.0202,  0.0172],\n",
       "         [ 0.0120, -0.0299, -0.0199,  ..., -0.0239,  0.0384, -0.0194],\n",
       "         [-0.0129, -0.0077, -0.0207,  ...,  0.0189, -0.0030,  0.0041]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_q.lora_up.weight': tensor([[ 0.0143, -0.0086,  0.0009,  ..., -0.0075,  0.0066,  0.0035],\n",
       "         [-0.0141,  0.0179,  0.0108,  ..., -0.0126,  0.0273, -0.0145],\n",
       "         [ 0.0087, -0.0119,  0.0191,  ..., -0.0253,  0.0230,  0.0177],\n",
       "         ...,\n",
       "         [ 0.0003, -0.0097,  0.0259,  ..., -0.0086,  0.0070, -0.0016],\n",
       "         [ 0.0124,  0.0020,  0.0209,  ..., -0.0104,  0.0021,  0.0010],\n",
       "         [ 0.0017,  0.0092,  0.0163,  ..., -0.0340,  0.0177,  0.0070]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_v.lora_down.weight': tensor([[ 0.0026,  0.0363, -0.0021,  ..., -0.0002,  0.0010, -0.0167],\n",
       "         [-0.0214,  0.0060, -0.0016,  ..., -0.0120, -0.0115, -0.0129],\n",
       "         [ 0.0022, -0.0253, -0.0390,  ..., -0.0204, -0.0054,  0.0243],\n",
       "         ...,\n",
       "         [-0.0097, -0.0484,  0.0303,  ...,  0.0199,  0.0175, -0.0220],\n",
       "         [-0.0029,  0.0024,  0.0038,  ...,  0.0250,  0.0284, -0.0460],\n",
       "         [-0.0171, -0.0323,  0.0170,  ..., -0.0147,  0.0059, -0.0220]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn1_to_v.lora_up.weight': tensor([[-0.0097, -0.0146, -0.0102,  ..., -0.0050,  0.0180,  0.0217],\n",
       "         [ 0.0078,  0.0221, -0.0012,  ..., -0.0218, -0.0088, -0.0258],\n",
       "         [ 0.0110, -0.0071, -0.0113,  ..., -0.0145,  0.0193,  0.0014],\n",
       "         ...,\n",
       "         [ 0.0017, -0.0127,  0.0143,  ...,  0.0025, -0.0058, -0.0065],\n",
       "         [-0.0285,  0.0233,  0.0228,  ...,  0.0037, -0.0039,  0.0066],\n",
       "         [-0.0273, -0.0158,  0.0049,  ...,  0.0222,  0.0095,  0.0292]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_k.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_k.lora_down.weight': tensor([[-0.0266,  0.0320,  0.0113,  ...,  0.0189,  0.0010, -0.0139],\n",
       "         [-0.0232,  0.0349, -0.0136,  ..., -0.0071,  0.0132, -0.0088],\n",
       "         [-0.0386,  0.0188, -0.0262,  ..., -0.0203,  0.0260, -0.0047],\n",
       "         ...,\n",
       "         [ 0.0298, -0.0345, -0.0041,  ...,  0.0191, -0.0114,  0.0252],\n",
       "         [ 0.0071, -0.0152,  0.0117,  ...,  0.0036, -0.0372, -0.0033],\n",
       "         [-0.0069,  0.0114,  0.0065,  ..., -0.0190,  0.0063, -0.0220]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_k.lora_up.weight': tensor([[ 1.0748e-03,  1.1188e-04,  4.2772e-04,  ...,  5.9187e-05,\n",
       "           9.9659e-04,  2.5177e-03],\n",
       "         [-1.2426e-03, -1.2722e-03, -2.5010e-04,  ...,  9.4652e-04,\n",
       "           5.2977e-04, -2.4662e-03],\n",
       "         [-1.6922e-02, -1.1887e-02, -1.3809e-02,  ...,  1.6022e-02,\n",
       "           1.2535e-02, -1.4206e-02],\n",
       "         ...,\n",
       "         [-7.3242e-03, -6.7863e-03, -5.7526e-03,  ...,  5.9967e-03,\n",
       "           6.3438e-03, -8.9417e-03],\n",
       "         [ 7.5722e-03,  9.1400e-03,  6.6414e-03,  ..., -3.5973e-03,\n",
       "          -6.4468e-03,  1.0880e-02],\n",
       "         [-6.2904e-03, -6.8245e-03, -4.2229e-03,  ...,  1.9798e-03,\n",
       "           3.5076e-03, -1.0269e-02]], dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_out_0.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_out_0.lora_down.weight': tensor([[ 0.0233,  0.0164, -0.0032,  ..., -0.0080, -0.0299, -0.0569],\n",
       "         [-0.0139, -0.0191,  0.0366,  ...,  0.0239,  0.0230,  0.0368],\n",
       "         [-0.0041, -0.0225,  0.0192,  ...,  0.0274, -0.0067,  0.0164],\n",
       "         ...,\n",
       "         [-0.0227,  0.0056,  0.0059,  ..., -0.0417,  0.0010, -0.0098],\n",
       "         [ 0.0068,  0.0290, -0.0037,  ..., -0.0005,  0.0122, -0.0197],\n",
       "         [-0.0123,  0.0016,  0.0019,  ..., -0.0349, -0.0016, -0.0066]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_out_0.lora_up.weight': tensor([[-0.0184,  0.0068,  0.0293,  ...,  0.0002, -0.0117, -0.0220],\n",
       "         [ 0.0048, -0.0046, -0.0045,  ..., -0.0078,  0.0052,  0.0110],\n",
       "         [-0.0105,  0.0122,  0.0043,  ..., -0.0135, -0.0129,  0.0041],\n",
       "         ...,\n",
       "         [-0.0034,  0.0021,  0.0065,  ...,  0.0060, -0.0017, -0.0055],\n",
       "         [-0.0028,  0.0100,  0.0052,  ..., -0.0070, -0.0080, -0.0117],\n",
       "         [ 0.0081, -0.0035,  0.0034,  ...,  0.0095,  0.0043, -0.0043]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_q.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_q.lora_down.weight': tensor([[ 0.0363,  0.0389, -0.0406,  ...,  0.0023,  0.0085, -0.0211],\n",
       "         [-0.0087, -0.0108,  0.0395,  ...,  0.0107, -0.0189,  0.0133],\n",
       "         [-0.0065,  0.0136,  0.0208,  ..., -0.0027, -0.0186,  0.0068],\n",
       "         ...,\n",
       "         [ 0.0002, -0.0075,  0.0017,  ..., -0.0203, -0.0030, -0.0415],\n",
       "         [ 0.0121, -0.0194,  0.0030,  ...,  0.0352, -0.0254, -0.0073],\n",
       "         [-0.0453,  0.0009,  0.0129,  ..., -0.0082, -0.0100,  0.0117]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_q.lora_up.weight': tensor([[-0.0149, -0.0102,  0.0120,  ...,  0.0083, -0.0044, -0.0225],\n",
       "         [-0.0033, -0.0075,  0.0093,  ...,  0.0080,  0.0017, -0.0206],\n",
       "         [ 0.0192,  0.0019, -0.0124,  ...,  0.0110,  0.0128, -0.0031],\n",
       "         ...,\n",
       "         [ 0.0055,  0.0131, -0.0045,  ..., -0.0044, -0.0093,  0.0038],\n",
       "         [-0.0017, -0.0175, -0.0016,  ...,  0.0103,  0.0182, -0.0049],\n",
       "         [ 0.0028,  0.0164, -0.0005,  ..., -0.0087, -0.0159,  0.0052]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_v.alpha': tensor(1., dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_v.lora_down.weight': tensor([[-0.0031,  0.0142, -0.0333,  ...,  0.0201, -0.0170,  0.0011],\n",
       "         [-0.0055,  0.0013, -0.0210,  ...,  0.0208, -0.0087, -0.0157],\n",
       "         [ 0.0033,  0.0145, -0.0023,  ...,  0.0231,  0.0142,  0.0131],\n",
       "         ...,\n",
       "         [-0.0213,  0.0129,  0.0044,  ..., -0.0262, -0.0083,  0.0101],\n",
       "         [-0.0100, -0.0180,  0.0348,  ..., -0.0183,  0.0142, -0.0064],\n",
       "         [-0.0022, -0.0271, -0.0074,  ..., -0.0299,  0.0157,  0.0174]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_attn2_to_v.lora_up.weight': tensor([[-0.0192, -0.0320, -0.0105,  ...,  0.0187,  0.0258,  0.0201],\n",
       "         [-0.0014, -0.0150, -0.0109,  ..., -0.0019,  0.0052,  0.0017],\n",
       "         [-0.0171, -0.0175, -0.0146,  ...,  0.0162,  0.0136,  0.0148],\n",
       "         ...,\n",
       "         [ 0.0114,  0.0274,  0.0065,  ..., -0.0085, -0.0190, -0.0106],\n",
       "         [-0.0017, -0.0050, -0.0086,  ...,  0.0004,  0.0019,  0.0009],\n",
       "         [ 0.0085, -0.0108,  0.0041,  ..., -0.0133,  0.0006, -0.0099]],\n",
       "        dtype=torch.float16),\n",
       " 'lora_unet_middle_block_1_transformer_blocks_5_ff_net_0_proj.alpha': tensor(1., dtype=torch.float16),\n",
       " ...}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
